{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1BExyOuIBZWciCmKDXhAD5DNVtDA9Rm2d",
      "authorship_tag": "ABX9TyMUl2xknBPE9pd2OAdl2ngk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e357431f12d4f34a8761354cc92adfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb5b89a39b154ad8bd7643038970e12e",
              "IPY_MODEL_37cc864cac3b48eb96d211ff3cd72130",
              "IPY_MODEL_a812f713b3e14af9a1136b66383938ca"
            ],
            "layout": "IPY_MODEL_129d2e082e4144ecae0d64f2d2c1d43a"
          }
        },
        "eb5b89a39b154ad8bd7643038970e12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ecdf3eca0934d309a43dda85cc9defb",
            "placeholder": "​",
            "style": "IPY_MODEL_b24d4e3772fa4edaabf1346c7e977c51",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "37cc864cac3b48eb96d211ff3cd72130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74baa462ec9b458aa01c6e5bb4993ac4",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d3438773894c5c9eaac114284055e4",
            "value": 28
          }
        },
        "a812f713b3e14af9a1136b66383938ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7be02a7eb0f4a8e83172de445f246dd",
            "placeholder": "​",
            "style": "IPY_MODEL_028c4445007547dcae3ded9b54f9194d",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.70kB/s]"
          }
        },
        "129d2e082e4144ecae0d64f2d2c1d43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecdf3eca0934d309a43dda85cc9defb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24d4e3772fa4edaabf1346c7e977c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74baa462ec9b458aa01c6e5bb4993ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d3438773894c5c9eaac114284055e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7be02a7eb0f4a8e83172de445f246dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028c4445007547dcae3ded9b54f9194d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e190e2cdb8e4d9dba250c7f5e7b78a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27a9427f07844c3380ca9a4ea77bb523",
              "IPY_MODEL_2354dacb441a47c6ad67888a41779a4c",
              "IPY_MODEL_299b54d4eb5e464782fed027390f1e40"
            ],
            "layout": "IPY_MODEL_995d9b7f422b41dbb52a594d4a35a99e"
          }
        },
        "27a9427f07844c3380ca9a4ea77bb523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51a09a96f7444b2a6fee0bdca30ea07",
            "placeholder": "​",
            "style": "IPY_MODEL_c46402d5d6684277b0b3b035a38d5cbb",
            "value": "vocab.txt: 100%"
          }
        },
        "2354dacb441a47c6ad67888a41779a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc815194ea0c46c3a0492aae5906f209",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23bb530d490846d18642b077a022085e",
            "value": 231508
          }
        },
        "299b54d4eb5e464782fed027390f1e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00481d115bc94b0c93ecba83a49539ff",
            "placeholder": "​",
            "style": "IPY_MODEL_f34f3b5c5d3b4cb08040cc52cf5130cb",
            "value": " 232k/232k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "995d9b7f422b41dbb52a594d4a35a99e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51a09a96f7444b2a6fee0bdca30ea07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46402d5d6684277b0b3b035a38d5cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc815194ea0c46c3a0492aae5906f209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bb530d490846d18642b077a022085e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00481d115bc94b0c93ecba83a49539ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34f3b5c5d3b4cb08040cc52cf5130cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbe1060c50a461e8f528d330135a0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fdfe5fb83534cb9b64e606c10c838cf",
              "IPY_MODEL_993c19393ef745b5bbe1031cadbecfd9",
              "IPY_MODEL_fb5c3c4f506b486a9f81448a1c83c1f9"
            ],
            "layout": "IPY_MODEL_cf1a326f40ae41afa2407d6ec361d73b"
          }
        },
        "8fdfe5fb83534cb9b64e606c10c838cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ee45a17bb44f4db2daceb11369825b",
            "placeholder": "​",
            "style": "IPY_MODEL_15715530d50f4686a9790f6a59fbbd8d",
            "value": "tokenizer.json: 100%"
          }
        },
        "993c19393ef745b5bbe1031cadbecfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f597d1699ba042c49d2e666e9935d248",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_558f07e431204c2899b700831608b0b0",
            "value": 466062
          }
        },
        "fb5c3c4f506b486a9f81448a1c83c1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69214210f9d843988f03c8525fb46d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_0866785b129f4ee593624b074a2bceb4",
            "value": " 466k/466k [00:00&lt;00:00, 1.91MB/s]"
          }
        },
        "cf1a326f40ae41afa2407d6ec361d73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ee45a17bb44f4db2daceb11369825b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15715530d50f4686a9790f6a59fbbd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f597d1699ba042c49d2e666e9935d248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558f07e431204c2899b700831608b0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69214210f9d843988f03c8525fb46d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0866785b129f4ee593624b074a2bceb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96fb91a12b4e4b43be8062eb58e8d6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4024de9d50b549218dce7f468ce57e43",
              "IPY_MODEL_8d1bb49e3d054d8da8845ae836c01942",
              "IPY_MODEL_ef52e6bdbd154cb1b53bf9881a49bf0b"
            ],
            "layout": "IPY_MODEL_428e60dcbce943f2ab80f84b77d20646"
          }
        },
        "4024de9d50b549218dce7f468ce57e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e1f4c904b7c4a98a71277e403532886",
            "placeholder": "​",
            "style": "IPY_MODEL_33998b7a81514a6598c1e4e3c818dea8",
            "value": "config.json: 100%"
          }
        },
        "8d1bb49e3d054d8da8845ae836c01942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59ea811c8d44625bc87af5e6b5a5ddd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca9fd90ba5044eff9e95d4e22a248930",
            "value": 570
          }
        },
        "ef52e6bdbd154cb1b53bf9881a49bf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06501d7dd83349bd84c0e9315c340bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_26f16034ac624d60bdab58140876d186",
            "value": " 570/570 [00:00&lt;00:00, 30.2kB/s]"
          }
        },
        "428e60dcbce943f2ab80f84b77d20646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1f4c904b7c4a98a71277e403532886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33998b7a81514a6598c1e4e3c818dea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e59ea811c8d44625bc87af5e6b5a5ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9fd90ba5044eff9e95d4e22a248930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06501d7dd83349bd84c0e9315c340bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f16034ac624d60bdab58140876d186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c12886be585742e4a102fbae2c5629fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_486a619f925a40d5ae068bb517e113fe",
              "IPY_MODEL_1ef07dacd5de43008012e61e2753b594",
              "IPY_MODEL_9b68437fbde54343b15b7ad0eb2225f8"
            ],
            "layout": "IPY_MODEL_06c48a07a8c44065a14789fec7cbfe17"
          }
        },
        "486a619f925a40d5ae068bb517e113fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ea1bbf63f94123a8cf02426eef7337",
            "placeholder": "​",
            "style": "IPY_MODEL_ce85c8e9ee1143a38b19faf016d0ce5c",
            "value": "model.safetensors: 100%"
          }
        },
        "1ef07dacd5de43008012e61e2753b594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d39e7254c54a1982db56b1c5bc7ada",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dca16670fcc44c09ad967a4f69607e62",
            "value": 440449768
          }
        },
        "9b68437fbde54343b15b7ad0eb2225f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7548af65e84a47ee86e372989460f673",
            "placeholder": "​",
            "style": "IPY_MODEL_90b3c0ff693248aca2c55a2beea50170",
            "value": " 440M/440M [00:01&lt;00:00, 360MB/s]"
          }
        },
        "06c48a07a8c44065a14789fec7cbfe17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ea1bbf63f94123a8cf02426eef7337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce85c8e9ee1143a38b19faf016d0ce5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d39e7254c54a1982db56b1c5bc7ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca16670fcc44c09ad967a4f69607e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7548af65e84a47ee86e372989460f673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b3c0ff693248aca2c55a2beea50170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "800144e5993e4acf8bd05b0ba6fbd31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b19c9a48dc24012bd0ba2f0bb221f58",
              "IPY_MODEL_54acc53199d24370a2fe2faef1ca5275",
              "IPY_MODEL_4d606351426c43168aecf3048383aa03"
            ],
            "layout": "IPY_MODEL_8623b3745e594a32b885bf9a91b81a81"
          }
        },
        "2b19c9a48dc24012bd0ba2f0bb221f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938f93102f384b49aecd78c6c065204c",
            "placeholder": "​",
            "style": "IPY_MODEL_97705aa680574601b303b6803b7529f6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "54acc53199d24370a2fe2faef1ca5275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626a0c42d6b24e7fb2de9f168464b014",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90a5c5ac8ce94b17818d0fed9fe146c9",
            "value": 28
          }
        },
        "4d606351426c43168aecf3048383aa03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f17ce614d564e0fbd31e7b5b8d4c66b",
            "placeholder": "​",
            "style": "IPY_MODEL_56a73930f488416f98397960f3b689b6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.87kB/s]"
          }
        },
        "8623b3745e594a32b885bf9a91b81a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938f93102f384b49aecd78c6c065204c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97705aa680574601b303b6803b7529f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "626a0c42d6b24e7fb2de9f168464b014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a5c5ac8ce94b17818d0fed9fe146c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f17ce614d564e0fbd31e7b5b8d4c66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a73930f488416f98397960f3b689b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51470996d3464a2ca411606af99493e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feac808aa3b844e7b203f961ee549abf",
              "IPY_MODEL_d2b05cda255543d3ab9befc6c4c4a08f",
              "IPY_MODEL_af9b355a463849d98594b929332dda9d"
            ],
            "layout": "IPY_MODEL_5b39c5781f364eaaa30e7afb56090b9a"
          }
        },
        "feac808aa3b844e7b203f961ee549abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244c8f9fb99b4336b846ced5e6212b04",
            "placeholder": "​",
            "style": "IPY_MODEL_41336d8a4cff4a96b855683bc7a9db31",
            "value": "vocab.txt: 100%"
          }
        },
        "d2b05cda255543d3ab9befc6c4c4a08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2ae9889ef047fa89cb66cedd2b2900",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f041da53d2144e8fa485b4beac585298",
            "value": 231508
          }
        },
        "af9b355a463849d98594b929332dda9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b93ab18c4de047e2959633e018d46145",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef3c084439b4bb985575c1582cce4ab",
            "value": " 232k/232k [00:00&lt;00:00, 3.87MB/s]"
          }
        },
        "5b39c5781f364eaaa30e7afb56090b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244c8f9fb99b4336b846ced5e6212b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41336d8a4cff4a96b855683bc7a9db31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba2ae9889ef047fa89cb66cedd2b2900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f041da53d2144e8fa485b4beac585298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b93ab18c4de047e2959633e018d46145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef3c084439b4bb985575c1582cce4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b826e7ac82a64357973e80b61e779b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98851caa6d514384a7e20a0d849227e0",
              "IPY_MODEL_d94af9b99679465c80d1524f2bae6d99",
              "IPY_MODEL_d703ac92cdaf457aba7bee6d9a4a1519"
            ],
            "layout": "IPY_MODEL_0a807a2c9c9f4753be5f91913712056b"
          }
        },
        "98851caa6d514384a7e20a0d849227e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4e6454d0d9447c91681a160e6aca63",
            "placeholder": "​",
            "style": "IPY_MODEL_99bf4c1d28b0442bb6b351f901bb2b4d",
            "value": "tokenizer.json: 100%"
          }
        },
        "d94af9b99679465c80d1524f2bae6d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e11007e721439f8584973301ce995b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa1574f4baa494e9b717b1870fa5fd8",
            "value": 466062
          }
        },
        "d703ac92cdaf457aba7bee6d9a4a1519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4d2dd046f34cae89309312ab8ae33a",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8a5f6b0b5f4104a884ebee05b4fed3",
            "value": " 466k/466k [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "0a807a2c9c9f4753be5f91913712056b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4e6454d0d9447c91681a160e6aca63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99bf4c1d28b0442bb6b351f901bb2b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8e11007e721439f8584973301ce995b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa1574f4baa494e9b717b1870fa5fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f4d2dd046f34cae89309312ab8ae33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8a5f6b0b5f4104a884ebee05b4fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a31a7c7d974a279e9fb7dcef48e411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a031e36a599f4be7986481e0d24ceb29",
              "IPY_MODEL_2494ad301d514210ad6dd8ec52a9b4b2",
              "IPY_MODEL_ab710755e1e2418dbf7a3d8f08ea5426"
            ],
            "layout": "IPY_MODEL_9b223e3b483f46329dd6b74a8675c46d"
          }
        },
        "a031e36a599f4be7986481e0d24ceb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15726a20f4a4e619202a8f9686d7600",
            "placeholder": "​",
            "style": "IPY_MODEL_48e6ddab71d24b17968bc5d45e1319cd",
            "value": "config.json: 100%"
          }
        },
        "2494ad301d514210ad6dd8ec52a9b4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811c26ecb4e942d184bca5c180b7f49f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c4b11a405dd401c93796c36b2a63dd6",
            "value": 570
          }
        },
        "ab710755e1e2418dbf7a3d8f08ea5426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a133f78504d48a88974687e18537b89",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7d84082e754768a70f10e2b8933c06",
            "value": " 570/570 [00:00&lt;00:00, 30.6kB/s]"
          }
        },
        "9b223e3b483f46329dd6b74a8675c46d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15726a20f4a4e619202a8f9686d7600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e6ddab71d24b17968bc5d45e1319cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "811c26ecb4e942d184bca5c180b7f49f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4b11a405dd401c93796c36b2a63dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a133f78504d48a88974687e18537b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7d84082e754768a70f10e2b8933c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2b37d26c2c42018c7b627ffa2e2f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8173f57cd564e058ee3a20eded3036d",
              "IPY_MODEL_8b3ecb68cb0e4cd886a13d04d3169496",
              "IPY_MODEL_d59b8dabec02409a9971edf3b38fe23d"
            ],
            "layout": "IPY_MODEL_879d8f3c56444aea897f5165f7155a55"
          }
        },
        "d8173f57cd564e058ee3a20eded3036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3ef5b3a04e4fa884b802a4f1c905fd",
            "placeholder": "​",
            "style": "IPY_MODEL_cce203a320d54374b4125017db3250c9",
            "value": "model.safetensors: 100%"
          }
        },
        "8b3ecb68cb0e4cd886a13d04d3169496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9fd7c167afb4dfeaaebb1b0399f3536",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eeb40cd6cf24fea86c489db9c434efe",
            "value": 440449768
          }
        },
        "d59b8dabec02409a9971edf3b38fe23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a36fb9e0984d6ab7bad2f0f705afd9",
            "placeholder": "​",
            "style": "IPY_MODEL_9168a6d5fe404548897372824db940c8",
            "value": " 440M/440M [00:03&lt;00:00, 132MB/s]"
          }
        },
        "879d8f3c56444aea897f5165f7155a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3ef5b3a04e4fa884b802a4f1c905fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce203a320d54374b4125017db3250c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9fd7c167afb4dfeaaebb1b0399f3536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eeb40cd6cf24fea86c489db9c434efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3a36fb9e0984d6ab7bad2f0f705afd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9168a6d5fe404548897372824db940c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0785bbdbe964153866a09c7b74dc964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a6132dee6ec41b8932936e80e2b9411",
              "IPY_MODEL_6dca6f569c1641729592cbb11ca5091e",
              "IPY_MODEL_fa3da64e087241e1b231084a42aab1ce"
            ],
            "layout": "IPY_MODEL_c72ec63d62f349fe9890f290a19de971"
          }
        },
        "0a6132dee6ec41b8932936e80e2b9411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1f9947f20c483b959b7cf1b0332c99",
            "placeholder": "​",
            "style": "IPY_MODEL_a330e351fb2a457e9c395d7e684aa7a6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6dca6f569c1641729592cbb11ca5091e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c3344552dd41bc9d87b59aac49c8c6",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e9b3d39a68644d3b3bb9db5536474b7",
            "value": 28
          }
        },
        "fa3da64e087241e1b231084a42aab1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1a6f0df2134d72afa90c204d237682",
            "placeholder": "​",
            "style": "IPY_MODEL_ca4b403f7075413bbd77a2e5858c1723",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.30kB/s]"
          }
        },
        "c72ec63d62f349fe9890f290a19de971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1f9947f20c483b959b7cf1b0332c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a330e351fb2a457e9c395d7e684aa7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c3344552dd41bc9d87b59aac49c8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9b3d39a68644d3b3bb9db5536474b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d1a6f0df2134d72afa90c204d237682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca4b403f7075413bbd77a2e5858c1723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3699b957919747c2806c49f41fa54069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1d05b3fbea94fb7b20027696c79b50e",
              "IPY_MODEL_9aede4a77b77495fbd5c92bafbcd1fd1",
              "IPY_MODEL_b676bf26ca0d4e05b10ee7b9897c0eb2"
            ],
            "layout": "IPY_MODEL_622c2acb767d468eb215caba3ded95ce"
          }
        },
        "f1d05b3fbea94fb7b20027696c79b50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb2f5b41f1947abb209da8e1ee19477",
            "placeholder": "​",
            "style": "IPY_MODEL_79ba547d071e48fc9fe9a573de5e1de4",
            "value": "vocab.txt: 100%"
          }
        },
        "9aede4a77b77495fbd5c92bafbcd1fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa7c3bce4f8494288128970ba6eba5a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae5dcb31e4c74af9ae20c8247b4c6377",
            "value": 231508
          }
        },
        "b676bf26ca0d4e05b10ee7b9897c0eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7ab4bdf82a46198e11afaae54f0d46",
            "placeholder": "​",
            "style": "IPY_MODEL_735b8e88eef94b4f9603b6b56938c5ec",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "622c2acb767d468eb215caba3ded95ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb2f5b41f1947abb209da8e1ee19477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ba547d071e48fc9fe9a573de5e1de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfa7c3bce4f8494288128970ba6eba5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5dcb31e4c74af9ae20c8247b4c6377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c7ab4bdf82a46198e11afaae54f0d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735b8e88eef94b4f9603b6b56938c5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2edd840946aa4d70bca02a0fcb77b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0699a3405e34d9894b0169c1f1e9add",
              "IPY_MODEL_fdaed5172b434c37a323042f41fc032a",
              "IPY_MODEL_3aa2f7d8cbd14575b049a16d1a99c933"
            ],
            "layout": "IPY_MODEL_5afe89852ea94385bdd5d79dc45b6c22"
          }
        },
        "d0699a3405e34d9894b0169c1f1e9add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e35844f6ac4f0486c59e194012303d",
            "placeholder": "​",
            "style": "IPY_MODEL_f0755b54be7f48b6843d90496aeaa39c",
            "value": "tokenizer.json: 100%"
          }
        },
        "fdaed5172b434c37a323042f41fc032a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d77053e8bc448d906fbd4fc96f53b8",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46ff3d7cbad1464686b7dfc674289273",
            "value": 466062
          }
        },
        "3aa2f7d8cbd14575b049a16d1a99c933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d63c24d8fb4b67bf8d4412390ee672",
            "placeholder": "​",
            "style": "IPY_MODEL_93b925f2c0014b62ba4b94b0b97dccb6",
            "value": " 466k/466k [00:00&lt;00:00, 5.60MB/s]"
          }
        },
        "5afe89852ea94385bdd5d79dc45b6c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e35844f6ac4f0486c59e194012303d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0755b54be7f48b6843d90496aeaa39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d77053e8bc448d906fbd4fc96f53b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff3d7cbad1464686b7dfc674289273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7d63c24d8fb4b67bf8d4412390ee672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b925f2c0014b62ba4b94b0b97dccb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc363bf90264b47b64f3e4e40fb3308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a7cc8e7820b4e6498d93dd9b4641ac4",
              "IPY_MODEL_062d3ad82c614c65937176d82f58a2e7",
              "IPY_MODEL_672ac7ef8df94964996a5949eb6073bb"
            ],
            "layout": "IPY_MODEL_00a8b4c95af54f93b11af7aa49e717a7"
          }
        },
        "1a7cc8e7820b4e6498d93dd9b4641ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343e6ba2083b4a58a2585943b901abb9",
            "placeholder": "​",
            "style": "IPY_MODEL_50c16483b9fe4c1b912a42e8bce0bbb7",
            "value": "config.json: 100%"
          }
        },
        "062d3ad82c614c65937176d82f58a2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a499e85ac5e04b93ab0463a4a9e6f90a",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de605e7a46c14c7da03ec637ef79edee",
            "value": 570
          }
        },
        "672ac7ef8df94964996a5949eb6073bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd85e3a2018245d38e67d2ba9d24d492",
            "placeholder": "​",
            "style": "IPY_MODEL_c46dbe599ab243ff90144452a8fee316",
            "value": " 570/570 [00:00&lt;00:00, 27.0kB/s]"
          }
        },
        "00a8b4c95af54f93b11af7aa49e717a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343e6ba2083b4a58a2585943b901abb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c16483b9fe4c1b912a42e8bce0bbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a499e85ac5e04b93ab0463a4a9e6f90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de605e7a46c14c7da03ec637ef79edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd85e3a2018245d38e67d2ba9d24d492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46dbe599ab243ff90144452a8fee316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986bb766d3494218be7040b648ec4682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_985e756481384dda8edea4c12f7d06f5",
              "IPY_MODEL_2ad2bfaf09ab4252a806bc4cf99e265a",
              "IPY_MODEL_b1a23adf9960409cbfb388f18ee75557"
            ],
            "layout": "IPY_MODEL_e7f6d39eadd14902a5d5cf343914e846"
          }
        },
        "985e756481384dda8edea4c12f7d06f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85cf52cf1c7c4db68808440ba951d615",
            "placeholder": "​",
            "style": "IPY_MODEL_0f51ec8a90194990a0cf98567c50c05a",
            "value": "model.safetensors: 100%"
          }
        },
        "2ad2bfaf09ab4252a806bc4cf99e265a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deecde4e8baa45a0b93c8fbb098fad16",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8759f35b3fd9445d89b1967426ee6bbe",
            "value": 440449768
          }
        },
        "b1a23adf9960409cbfb388f18ee75557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3058c4ed23c4f9a866bcbf35225b971",
            "placeholder": "​",
            "style": "IPY_MODEL_3d3aaf17f17e4693a57cf553d04cf78b",
            "value": " 440M/440M [00:01&lt;00:00, 333MB/s]"
          }
        },
        "e7f6d39eadd14902a5d5cf343914e846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cf52cf1c7c4db68808440ba951d615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f51ec8a90194990a0cf98567c50c05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deecde4e8baa45a0b93c8fbb098fad16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8759f35b3fd9445d89b1967426ee6bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3058c4ed23c4f9a866bcbf35225b971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3aaf17f17e4693a57cf553d04cf78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7257e4f3d51843309f8a73c1b4434822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b758357636c4c5f9413e8b9d38b6cff",
              "IPY_MODEL_09da9858bf5447f8893ad56f401dacd5",
              "IPY_MODEL_d1867f9b9bcd4a0b887e2c8272b5e3ce"
            ],
            "layout": "IPY_MODEL_60a6dcb138ec4a7c81043aa9b826610d"
          }
        },
        "9b758357636c4c5f9413e8b9d38b6cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e79c19c623423bbd61826740038c3c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a1ca34602384c84a345ad0ae33889a7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "09da9858bf5447f8893ad56f401dacd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb1d0a3f216410c9bb01c51532c7965",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b2df60f04c84d76a6d65ac82807ada0",
            "value": 28
          }
        },
        "d1867f9b9bcd4a0b887e2c8272b5e3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bc25d6e0774855aaa61e87b4c385db",
            "placeholder": "​",
            "style": "IPY_MODEL_6629d806ed0c421c968b4ab2b9c61ad6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.58kB/s]"
          }
        },
        "60a6dcb138ec4a7c81043aa9b826610d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e79c19c623423bbd61826740038c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a1ca34602384c84a345ad0ae33889a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb1d0a3f216410c9bb01c51532c7965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2df60f04c84d76a6d65ac82807ada0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bc25d6e0774855aaa61e87b4c385db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6629d806ed0c421c968b4ab2b9c61ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ed2190dc4f443528c2b715543c93fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07531ee610a046be9d9306331823cd9a",
              "IPY_MODEL_02fa65ecca9b4e36b6d514cd54e78cf5",
              "IPY_MODEL_62be74c8627b4f32a849e778c3a42d5c"
            ],
            "layout": "IPY_MODEL_9ea3a79f512e4d46bd6204b047d089dd"
          }
        },
        "07531ee610a046be9d9306331823cd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c0bd12108c4380a65646537f8717fb",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6e0acdc5e14e9498880e1de55c57dc",
            "value": "vocab.txt: 100%"
          }
        },
        "02fa65ecca9b4e36b6d514cd54e78cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b4a5cd2e4240b98a164b708944b7f8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2bd9d45cb8c49289d0334ace5419300",
            "value": 231508
          }
        },
        "62be74c8627b4f32a849e778c3a42d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57095181912949689e209b0e8529faf6",
            "placeholder": "​",
            "style": "IPY_MODEL_5af42680915c4d00a4035de6af198965",
            "value": " 232k/232k [00:00&lt;00:00, 3.76MB/s]"
          }
        },
        "9ea3a79f512e4d46bd6204b047d089dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c0bd12108c4380a65646537f8717fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6e0acdc5e14e9498880e1de55c57dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00b4a5cd2e4240b98a164b708944b7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2bd9d45cb8c49289d0334ace5419300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57095181912949689e209b0e8529faf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af42680915c4d00a4035de6af198965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5777a45b0e3457cba9486587cb8acfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f348ddb5a9ad4c38a8908f777a422fcb",
              "IPY_MODEL_b25de63419904bcc97d1e355fd02958e",
              "IPY_MODEL_d1583dad5a1a42c18bbf4ea8186a2c77"
            ],
            "layout": "IPY_MODEL_532d7e41a65a4006b5d4980bfa7f54fd"
          }
        },
        "f348ddb5a9ad4c38a8908f777a422fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd860928cfd408e85d6e64048c0310f",
            "placeholder": "​",
            "style": "IPY_MODEL_de1e592ce6fc4dc5b9121c169b080efd",
            "value": "tokenizer.json: 100%"
          }
        },
        "b25de63419904bcc97d1e355fd02958e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18eb58adeab7469c932662eeacafd203",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fc6518aa1bf4f9c9e7a422b1f0ef217",
            "value": 466062
          }
        },
        "d1583dad5a1a42c18bbf4ea8186a2c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd3042e557d46e0b27a9195eecfcf1b",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b314ef52974613bc4886d1faf6f633",
            "value": " 466k/466k [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "532d7e41a65a4006b5d4980bfa7f54fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd860928cfd408e85d6e64048c0310f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1e592ce6fc4dc5b9121c169b080efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18eb58adeab7469c932662eeacafd203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc6518aa1bf4f9c9e7a422b1f0ef217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbd3042e557d46e0b27a9195eecfcf1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b314ef52974613bc4886d1faf6f633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886d1bf66e7343d78f5223e6d269c23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feebaf3082644270810a33cb3cd8f7ac",
              "IPY_MODEL_c29942236e3b41128ca3f9dc139427ef",
              "IPY_MODEL_c7c7c517a57b4a8e83143dd229843a8c"
            ],
            "layout": "IPY_MODEL_e7647ec20dc8451bb24d7a1822ce22ca"
          }
        },
        "feebaf3082644270810a33cb3cd8f7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_927f31f0f3ae4e09950e7b16743f4676",
            "placeholder": "​",
            "style": "IPY_MODEL_925946e641e147379010cc97a90e5749",
            "value": "config.json: 100%"
          }
        },
        "c29942236e3b41128ca3f9dc139427ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808ad27558b3451a9d981e6d6b7458fb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_666cb4109a3647ccae25e36002e8dd9b",
            "value": 570
          }
        },
        "c7c7c517a57b4a8e83143dd229843a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c46b109d8d24354854565ec96baf847",
            "placeholder": "​",
            "style": "IPY_MODEL_3c90b8887fd54d8795ce86ad076e410c",
            "value": " 570/570 [00:00&lt;00:00, 51.2kB/s]"
          }
        },
        "e7647ec20dc8451bb24d7a1822ce22ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "927f31f0f3ae4e09950e7b16743f4676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925946e641e147379010cc97a90e5749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808ad27558b3451a9d981e6d6b7458fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666cb4109a3647ccae25e36002e8dd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c46b109d8d24354854565ec96baf847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c90b8887fd54d8795ce86ad076e410c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1811b8fee39f4b3188cbb8869a3a13af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcdb0fd9e7064ccb88e7f0a0754dc340",
              "IPY_MODEL_3826c490fa56421eb67434d983796c9f",
              "IPY_MODEL_8137629d5e294ee086902ec57bbab591"
            ],
            "layout": "IPY_MODEL_fe157c1f4a5544c5859b30acf4e93a91"
          }
        },
        "fcdb0fd9e7064ccb88e7f0a0754dc340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f81e4c965164a798609aa7ae704b8e3",
            "placeholder": "​",
            "style": "IPY_MODEL_cc007374fcad4c19b2f25ce0f23ccff3",
            "value": "model.safetensors: 100%"
          }
        },
        "3826c490fa56421eb67434d983796c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d32c255303b411180ebe6fdb1a18fad",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e2b029042054cc9b71cb178cd573a2c",
            "value": 440449768
          }
        },
        "8137629d5e294ee086902ec57bbab591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870993d9d4c44fe9afeb73dc491d4b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_46b336be77df469196b40f9a02107d1a",
            "value": " 440M/440M [00:03&lt;00:00, 128MB/s]"
          }
        },
        "fe157c1f4a5544c5859b30acf4e93a91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f81e4c965164a798609aa7ae704b8e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc007374fcad4c19b2f25ce0f23ccff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d32c255303b411180ebe6fdb1a18fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2b029042054cc9b71cb178cd573a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "870993d9d4c44fe9afeb73dc491d4b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b336be77df469196b40f9a02107d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80b14c3893844d63b3fb7e79a4b52232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8563ee373bd4adb80224ab5894db734",
              "IPY_MODEL_15f72f37485d473a8c7e172fe832e961",
              "IPY_MODEL_b1194b30424e471286aa0b16dc86344c"
            ],
            "layout": "IPY_MODEL_100d2c6be03844538a9a2241cf66d803"
          }
        },
        "e8563ee373bd4adb80224ab5894db734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61234dd5ce614d5cb2e7811e3e532fb6",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb3087176724efab48c24b934ecd7b2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "15f72f37485d473a8c7e172fe832e961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0309b434dca64d768f2f4a1838211ef0",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cf79b87820944069db05bbc84b852a7",
            "value": 28
          }
        },
        "b1194b30424e471286aa0b16dc86344c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d955b3e67940e98dd7e5c54d7e6049",
            "placeholder": "​",
            "style": "IPY_MODEL_3d386b4a2c814e71a9d0dda61eeba5ce",
            "value": " 28.0/28.0 [00:00&lt;00:00, 2.19kB/s]"
          }
        },
        "100d2c6be03844538a9a2241cf66d803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61234dd5ce614d5cb2e7811e3e532fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb3087176724efab48c24b934ecd7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0309b434dca64d768f2f4a1838211ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf79b87820944069db05bbc84b852a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7d955b3e67940e98dd7e5c54d7e6049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d386b4a2c814e71a9d0dda61eeba5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26df0652170441bfa3ff1d5229e5f416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f555c5aa053843699792b1b5dc90b706",
              "IPY_MODEL_2aadfeacfab941f7b8fb98b650a91593",
              "IPY_MODEL_a50df560ab154879a875387b6bf23499"
            ],
            "layout": "IPY_MODEL_4724091d54254544b13f42da5e4e4b24"
          }
        },
        "f555c5aa053843699792b1b5dc90b706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903d2cb8556a49d5a4b35fd1464e1c67",
            "placeholder": "​",
            "style": "IPY_MODEL_7bde73e794cf4cd99fa73faa1d8c5bf4",
            "value": "vocab.txt: 100%"
          }
        },
        "2aadfeacfab941f7b8fb98b650a91593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b226e00e4f4b94a359e3fa2d11c0bb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64cfd2fb4f604860b4324cad9bb2c23d",
            "value": 231508
          }
        },
        "a50df560ab154879a875387b6bf23499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef14f25fd3e43268eb8a3975f76d966",
            "placeholder": "​",
            "style": "IPY_MODEL_257082b92b324d208e65b6e1b5d4d2a2",
            "value": " 232k/232k [00:00&lt;00:00, 3.83MB/s]"
          }
        },
        "4724091d54254544b13f42da5e4e4b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "903d2cb8556a49d5a4b35fd1464e1c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bde73e794cf4cd99fa73faa1d8c5bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b226e00e4f4b94a359e3fa2d11c0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cfd2fb4f604860b4324cad9bb2c23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bef14f25fd3e43268eb8a3975f76d966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257082b92b324d208e65b6e1b5d4d2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e3e875114a54172bd4efe8560fc98df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa47dcda1ea746e88b72829f0d2e1a86",
              "IPY_MODEL_8970b9ca2bf5461485ae6592e894b5a4",
              "IPY_MODEL_de0ee40f014a45e0a9a86b6c49d44002"
            ],
            "layout": "IPY_MODEL_ad81e0fa561045c1a65999d87d7216c3"
          }
        },
        "aa47dcda1ea746e88b72829f0d2e1a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf3c99055128424d9bc32675629d78c0",
            "placeholder": "​",
            "style": "IPY_MODEL_dfb3e1ddbaa440a18cba40cd59f57a9d",
            "value": "tokenizer.json: 100%"
          }
        },
        "8970b9ca2bf5461485ae6592e894b5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775d2254470f489791b0d637a47e5117",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99737f87dc00439d9032566a9ade20b6",
            "value": 466062
          }
        },
        "de0ee40f014a45e0a9a86b6c49d44002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d8dd7256434381857fd5167b15d83f",
            "placeholder": "​",
            "style": "IPY_MODEL_0a025beb2f2a46348934013d769150b8",
            "value": " 466k/466k [00:00&lt;00:00, 15.8MB/s]"
          }
        },
        "ad81e0fa561045c1a65999d87d7216c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3c99055128424d9bc32675629d78c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb3e1ddbaa440a18cba40cd59f57a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775d2254470f489791b0d637a47e5117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99737f87dc00439d9032566a9ade20b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38d8dd7256434381857fd5167b15d83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a025beb2f2a46348934013d769150b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66f6a22f8eb7419db887cea0a0f1391f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3527b97f57794d6d908c8eda4fc51a70",
              "IPY_MODEL_8ad331d275a24a2e9fbd3f445fd5d456",
              "IPY_MODEL_3bea704c052348a3b1f76fb5a14e12da"
            ],
            "layout": "IPY_MODEL_3750b995cb614cc28b863d8a229b5d41"
          }
        },
        "3527b97f57794d6d908c8eda4fc51a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01195e4e7654cb2a8e6aa6d03eecae8",
            "placeholder": "​",
            "style": "IPY_MODEL_ccc13e8276ad4417a6dc86a12b3eb5a0",
            "value": "config.json: 100%"
          }
        },
        "8ad331d275a24a2e9fbd3f445fd5d456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9cb41c3d2564b70a0d1e7abc3e2a13c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_363d668aea4040639fbd4ee6a806a7aa",
            "value": 570
          }
        },
        "3bea704c052348a3b1f76fb5a14e12da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48c837e557a4d02a73dda19b4f51ab5",
            "placeholder": "​",
            "style": "IPY_MODEL_a498187372494308b841704db0474579",
            "value": " 570/570 [00:00&lt;00:00, 43.8kB/s]"
          }
        },
        "3750b995cb614cc28b863d8a229b5d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01195e4e7654cb2a8e6aa6d03eecae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc13e8276ad4417a6dc86a12b3eb5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9cb41c3d2564b70a0d1e7abc3e2a13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363d668aea4040639fbd4ee6a806a7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c48c837e557a4d02a73dda19b4f51ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a498187372494308b841704db0474579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "515a29f87a5c4a059d54d7bf906024ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7000adcaa5d64a7297564202e96b35c8",
              "IPY_MODEL_86045387c5eb49ed85729a279cedd5a7",
              "IPY_MODEL_9a44bdedac564aea8521f41ed46cba97"
            ],
            "layout": "IPY_MODEL_688db4b48e5144cf800225b7a8930f00"
          }
        },
        "7000adcaa5d64a7297564202e96b35c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d468fa4d07f434a824a480eba2df571",
            "placeholder": "​",
            "style": "IPY_MODEL_2adf73d8341648a58d5e663573ccea17",
            "value": "model.safetensors: 100%"
          }
        },
        "86045387c5eb49ed85729a279cedd5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af651e2cd58a4e1f85a2a78e5aed36fe",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5261a733b7f7490894329e631518a73e",
            "value": 440449768
          }
        },
        "9a44bdedac564aea8521f41ed46cba97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba6368af9d684318b783ff657bf59c09",
            "placeholder": "​",
            "style": "IPY_MODEL_ac2b19d3cc134a278004670144a54c88",
            "value": " 440M/440M [00:03&lt;00:00, 128MB/s]"
          }
        },
        "688db4b48e5144cf800225b7a8930f00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d468fa4d07f434a824a480eba2df571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adf73d8341648a58d5e663573ccea17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af651e2cd58a4e1f85a2a78e5aed36fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5261a733b7f7490894329e631518a73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba6368af9d684318b783ff657bf59c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2b19d3cc134a278004670144a54c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiccoSy/BERT_Based_Multiclass_Text_Classification/blob/main/BERT_Multi_CLass_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxL0RsofBTbc",
        "outputId": "86473d12-6ce5-4ac1-d3c9-d3c5ebf04420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install beautifulsoup4\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_8hHz5rCzHG",
        "outputId": "99e1c3f9-8471-48e9-cc48-8c66991dc110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-5-b7b72f05ffaf>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment1\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926,
          "referenced_widgets": [
            "2e357431f12d4f34a8761354cc92adfa",
            "eb5b89a39b154ad8bd7643038970e12e",
            "37cc864cac3b48eb96d211ff3cd72130",
            "a812f713b3e14af9a1136b66383938ca",
            "129d2e082e4144ecae0d64f2d2c1d43a",
            "7ecdf3eca0934d309a43dda85cc9defb",
            "b24d4e3772fa4edaabf1346c7e977c51",
            "74baa462ec9b458aa01c6e5bb4993ac4",
            "d9d3438773894c5c9eaac114284055e4",
            "d7be02a7eb0f4a8e83172de445f246dd",
            "028c4445007547dcae3ded9b54f9194d",
            "8e190e2cdb8e4d9dba250c7f5e7b78a5",
            "27a9427f07844c3380ca9a4ea77bb523",
            "2354dacb441a47c6ad67888a41779a4c",
            "299b54d4eb5e464782fed027390f1e40",
            "995d9b7f422b41dbb52a594d4a35a99e",
            "a51a09a96f7444b2a6fee0bdca30ea07",
            "c46402d5d6684277b0b3b035a38d5cbb",
            "cc815194ea0c46c3a0492aae5906f209",
            "23bb530d490846d18642b077a022085e",
            "00481d115bc94b0c93ecba83a49539ff",
            "f34f3b5c5d3b4cb08040cc52cf5130cb",
            "2dbe1060c50a461e8f528d330135a0a8",
            "8fdfe5fb83534cb9b64e606c10c838cf",
            "993c19393ef745b5bbe1031cadbecfd9",
            "fb5c3c4f506b486a9f81448a1c83c1f9",
            "cf1a326f40ae41afa2407d6ec361d73b",
            "99ee45a17bb44f4db2daceb11369825b",
            "15715530d50f4686a9790f6a59fbbd8d",
            "f597d1699ba042c49d2e666e9935d248",
            "558f07e431204c2899b700831608b0b0",
            "69214210f9d843988f03c8525fb46d5c",
            "0866785b129f4ee593624b074a2bceb4",
            "96fb91a12b4e4b43be8062eb58e8d6f2",
            "4024de9d50b549218dce7f468ce57e43",
            "8d1bb49e3d054d8da8845ae836c01942",
            "ef52e6bdbd154cb1b53bf9881a49bf0b",
            "428e60dcbce943f2ab80f84b77d20646",
            "1e1f4c904b7c4a98a71277e403532886",
            "33998b7a81514a6598c1e4e3c818dea8",
            "e59ea811c8d44625bc87af5e6b5a5ddd",
            "ca9fd90ba5044eff9e95d4e22a248930",
            "06501d7dd83349bd84c0e9315c340bd0",
            "26f16034ac624d60bdab58140876d186",
            "c12886be585742e4a102fbae2c5629fc",
            "486a619f925a40d5ae068bb517e113fe",
            "1ef07dacd5de43008012e61e2753b594",
            "9b68437fbde54343b15b7ad0eb2225f8",
            "06c48a07a8c44065a14789fec7cbfe17",
            "39ea1bbf63f94123a8cf02426eef7337",
            "ce85c8e9ee1143a38b19faf016d0ce5c",
            "f8d39e7254c54a1982db56b1c5bc7ada",
            "dca16670fcc44c09ad967a4f69607e62",
            "7548af65e84a47ee86e372989460f673",
            "90b3c0ff693248aca2c55a2beea50170"
          ]
        },
        "id": "mO8tWDgYwpCe",
        "outputId": "fe46ac2c-4461-4343-c2ed-fa44db59ef79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e357431f12d4f34a8761354cc92adfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e190e2cdb8e4d9dba250c7f5e7b78a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dbe1060c50a461e8f528d330135a0a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96fb91a12b4e4b43be8062eb58e8d6f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c12886be585742e4a102fbae2c5629fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.6464433670043945, Average Training Loss: 1.6464433670043945, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.6103219985961914, Average Training Loss: 1.628382682800293, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.6604269742965698, Average Training Loss: 1.639064113299052, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/1, Batch Loss: 1.681720495223999, Average Training Loss: 1.6497282087802887, Training Accuracy: 0.1796875\n",
            "Epoch 1/1, Batch Loss: 1.6180360317230225, Average Training Loss: 1.6433897733688354, Training Accuracy: 0.16875\n",
            "Epoch 1/1, Batch Loss: 1.6258275508880615, Average Training Loss: 1.6404627362887065, Training Accuracy: 0.16666666666666666\n",
            "Epoch 1/1, Batch Loss: 1.6142746210098267, Average Training Loss: 1.6367215769631522, Training Accuracy: 0.17857142857142858\n",
            "Epoch 1/1, Batch Loss: 1.621942162513733, Average Training Loss: 1.6348741501569748, Training Accuracy: 0.17578125\n",
            "Epoch 1/1, Batch Loss: 1.569898009300232, Average Training Loss: 1.62765457895067, Training Accuracy: 0.1996527777777778\n",
            "Epoch 1/1, Batch Loss: 1.6128592491149902, Average Training Loss: 1.626175045967102, Training Accuracy: 0.1984375\n",
            "Epoch 1/1, Batch Loss: 1.5971461534500122, Average Training Loss: 1.6235360557382756, Training Accuracy: 0.20880681818181818\n",
            "Epoch 1/1, Batch Loss: 1.6122491359710693, Average Training Loss: 1.6225954790910084, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/1, Batch Loss: 1.6118199825286865, Average Training Loss: 1.6217665947400606, Training Accuracy: 0.21153846153846154\n",
            "Epoch 1/1, Batch Loss: 1.6026227474212646, Average Training Loss: 1.6203991770744324, Training Accuracy: 0.20982142857142858\n",
            "Epoch 1/1, Batch Loss: 1.5953216552734375, Average Training Loss: 1.6187273422876993, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/1, Batch Loss: 1.6120487451553345, Average Training Loss: 1.6183099299669266, Training Accuracy: 0.20703125\n",
            "Epoch 1/1, Batch Loss: 1.595627784729004, Average Training Loss: 1.6169756861294018, Training Accuracy: 0.2104779411764706\n",
            "Epoch 1/1, Batch Loss: 1.5837433338165283, Average Training Loss: 1.615129444334242, Training Accuracy: 0.2152777777777778\n",
            "Epoch 1/1, Batch Loss: 1.556571364402771, Average Training Loss: 1.6120474401273226, Training Accuracy: 0.2236842105263158\n",
            "Epoch 1/1, Batch Loss: 1.6044834852218628, Average Training Loss: 1.6116692423820496, Training Accuracy: 0.22421875\n",
            "Epoch 1/1, Batch Loss: 1.569442868232727, Average Training Loss: 1.6096584626606532, Training Accuracy: 0.2269345238095238\n",
            "Epoch 1/1, Batch Loss: 1.557652235031128, Average Training Loss: 1.6072945432229475, Training Accuracy: 0.23082386363636365\n",
            "Epoch 1/1, Batch Loss: 1.5605186223983765, Average Training Loss: 1.6052608075349226, Training Accuracy: 0.23573369565217392\n",
            "Epoch 1/1, Batch Loss: 1.5723012685775757, Average Training Loss: 1.6038874934117, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.536962866783142, Average Training Loss: 1.6012105083465575, Training Accuracy: 0.246875\n",
            "Epoch 1/1, Batch Loss: 1.5537043809890747, Average Training Loss: 1.599383349602039, Training Accuracy: 0.24879807692307693\n",
            "Epoch 1/1, Batch Loss: 1.5614060163497925, Average Training Loss: 1.5979767817038077, Training Accuracy: 0.2488425925925926\n",
            "Epoch 1/1, Batch Loss: 1.5607012510299683, Average Training Loss: 1.5966455127511705, Training Accuracy: 0.25279017857142855\n",
            "Epoch 1/1, Batch Loss: 1.530770182609558, Average Training Loss: 1.594373949642839, Training Accuracy: 0.25700431034482757\n",
            "Epoch 1/1, Average Training Loss: 1.594373949642839, Training Accuracy: 0.25700431034482757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - LR = 1e-5, batch size 64, max-length 128\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "800144e5993e4acf8bd05b0ba6fbd31c",
            "2b19c9a48dc24012bd0ba2f0bb221f58",
            "54acc53199d24370a2fe2faef1ca5275",
            "4d606351426c43168aecf3048383aa03",
            "8623b3745e594a32b885bf9a91b81a81",
            "938f93102f384b49aecd78c6c065204c",
            "97705aa680574601b303b6803b7529f6",
            "626a0c42d6b24e7fb2de9f168464b014",
            "90a5c5ac8ce94b17818d0fed9fe146c9",
            "2f17ce614d564e0fbd31e7b5b8d4c66b",
            "56a73930f488416f98397960f3b689b6",
            "51470996d3464a2ca411606af99493e4",
            "feac808aa3b844e7b203f961ee549abf",
            "d2b05cda255543d3ab9befc6c4c4a08f",
            "af9b355a463849d98594b929332dda9d",
            "5b39c5781f364eaaa30e7afb56090b9a",
            "244c8f9fb99b4336b846ced5e6212b04",
            "41336d8a4cff4a96b855683bc7a9db31",
            "ba2ae9889ef047fa89cb66cedd2b2900",
            "f041da53d2144e8fa485b4beac585298",
            "b93ab18c4de047e2959633e018d46145",
            "3ef3c084439b4bb985575c1582cce4ab",
            "b826e7ac82a64357973e80b61e779b79",
            "98851caa6d514384a7e20a0d849227e0",
            "d94af9b99679465c80d1524f2bae6d99",
            "d703ac92cdaf457aba7bee6d9a4a1519",
            "0a807a2c9c9f4753be5f91913712056b",
            "7e4e6454d0d9447c91681a160e6aca63",
            "99bf4c1d28b0442bb6b351f901bb2b4d",
            "f8e11007e721439f8584973301ce995b",
            "daa1574f4baa494e9b717b1870fa5fd8",
            "5f4d2dd046f34cae89309312ab8ae33a",
            "7a8a5f6b0b5f4104a884ebee05b4fed3",
            "e9a31a7c7d974a279e9fb7dcef48e411",
            "a031e36a599f4be7986481e0d24ceb29",
            "2494ad301d514210ad6dd8ec52a9b4b2",
            "ab710755e1e2418dbf7a3d8f08ea5426",
            "9b223e3b483f46329dd6b74a8675c46d",
            "e15726a20f4a4e619202a8f9686d7600",
            "48e6ddab71d24b17968bc5d45e1319cd",
            "811c26ecb4e942d184bca5c180b7f49f",
            "4c4b11a405dd401c93796c36b2a63dd6",
            "8a133f78504d48a88974687e18537b89",
            "ea7d84082e754768a70f10e2b8933c06",
            "fa2b37d26c2c42018c7b627ffa2e2f3a",
            "d8173f57cd564e058ee3a20eded3036d",
            "8b3ecb68cb0e4cd886a13d04d3169496",
            "d59b8dabec02409a9971edf3b38fe23d",
            "879d8f3c56444aea897f5165f7155a55",
            "6e3ef5b3a04e4fa884b802a4f1c905fd",
            "cce203a320d54374b4125017db3250c9",
            "a9fd7c167afb4dfeaaebb1b0399f3536",
            "1eeb40cd6cf24fea86c489db9c434efe",
            "b3a36fb9e0984d6ab7bad2f0f705afd9",
            "9168a6d5fe404548897372824db940c8"
          ]
        },
        "id": "yq1JkzsynSHN",
        "outputId": "9051a7e1-c1a9-4d16-9fae-4c4bc5ce8840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "800144e5993e4acf8bd05b0ba6fbd31c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51470996d3464a2ca411606af99493e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b826e7ac82a64357973e80b61e779b79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9a31a7c7d974a279e9fb7dcef48e411"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa2b37d26c2c42018c7b627ffa2e2f3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.5899323225021362, Average Training Loss: 1.5899323225021362, Training Accuracy: 0.171875\n",
            "Epoch 1/1, Batch Loss: 1.6367987394332886, Average Training Loss: 1.6133655309677124, Training Accuracy: 0.1640625\n",
            "Epoch 1/1, Batch Loss: 1.6447728872299194, Average Training Loss: 1.6238346497217815, Training Accuracy: 0.16145833333333334\n",
            "Epoch 1/1, Batch Loss: 1.6239815950393677, Average Training Loss: 1.623871386051178, Training Accuracy: 0.171875\n",
            "Epoch 1/1, Batch Loss: 1.6226438283920288, Average Training Loss: 1.6236258745193481, Training Accuracy: 0.178125\n",
            "Epoch 1/1, Batch Loss: 1.6658762693405151, Average Training Loss: 1.6306676069895427, Training Accuracy: 0.17447916666666666\n",
            "Epoch 1/1, Batch Loss: 1.5933986902236938, Average Training Loss: 1.6253434760229928, Training Accuracy: 0.17857142857142858\n",
            "Epoch 1/1, Batch Loss: 1.616764783859253, Average Training Loss: 1.6242711395025253, Training Accuracy: 0.181640625\n",
            "Epoch 1/1, Batch Loss: 1.5689927339553833, Average Training Loss: 1.6181290944417317, Training Accuracy: 0.1909722222222222\n",
            "Epoch 1/1, Batch Loss: 1.6372404098510742, Average Training Loss: 1.620040225982666, Training Accuracy: 0.1859375\n",
            "Epoch 1/1, Batch Loss: 1.5835919380187988, Average Training Loss: 1.616726745258678, Training Accuracy: 0.19886363636363635\n",
            "Epoch 1/1, Batch Loss: 1.593742847442627, Average Training Loss: 1.6148114204406738, Training Accuracy: 0.20052083333333334\n",
            "Epoch 1/1, Batch Loss: 1.5696016550064087, Average Training Loss: 1.6113337461764996, Training Accuracy: 0.20552884615384615\n",
            "Epoch 1/1, Batch Loss: 1.588822841644287, Average Training Loss: 1.6097258244241988, Training Accuracy: 0.20870535714285715\n",
            "Epoch 1/1, Batch Loss: 1.628171682357788, Average Training Loss: 1.610955548286438, Training Accuracy: 0.20625\n",
            "Epoch 1/1, Batch Loss: 1.5725034475326538, Average Training Loss: 1.6085522919893265, Training Accuracy: 0.2119140625\n",
            "Epoch 1/1, Batch Loss: 1.5885976552963257, Average Training Loss: 1.6073784898309147, Training Accuracy: 0.21323529411764705\n",
            "Epoch 1/1, Batch Loss: 1.5990062952041626, Average Training Loss: 1.6069133679072063, Training Accuracy: 0.21180555555555555\n",
            "Epoch 1/1, Batch Loss: 1.594786524772644, Average Training Loss: 1.6062751130053872, Training Accuracy: 0.21463815789473684\n",
            "Epoch 1/1, Batch Loss: 1.567464828491211, Average Training Loss: 1.6043345987796784, Training Accuracy: 0.21640625\n",
            "Epoch 1/1, Batch Loss: 1.540259599685669, Average Training Loss: 1.6012834083466303, Training Accuracy: 0.22395833333333334\n",
            "Epoch 1/1, Batch Loss: 1.593211054801941, Average Training Loss: 1.600916483185508, Training Accuracy: 0.22514204545454544\n",
            "Epoch 1/1, Batch Loss: 1.5682889223098755, Average Training Loss: 1.5994978935822197, Training Accuracy: 0.22554347826086957\n",
            "Epoch 1/1, Batch Loss: 1.5381968021392822, Average Training Loss: 1.5969436814387639, Training Accuracy: 0.23046875\n",
            "Epoch 1/1, Batch Loss: 1.5613093376159668, Average Training Loss: 1.5955183076858521, Training Accuracy: 0.23375\n",
            "Epoch 1/1, Batch Loss: 1.5404871702194214, Average Training Loss: 1.5934017254756048, Training Accuracy: 0.23677884615384615\n",
            "Epoch 1/1, Batch Loss: 1.5797096490859985, Average Training Loss: 1.592894611535249, Training Accuracy: 0.2378472222222222\n",
            "Epoch 1/1, Batch Loss: 1.5837091207504272, Average Training Loss: 1.5925665582929338, Training Accuracy: 0.23939732142857142\n",
            "Epoch 1/1, Batch Loss: 1.5525758266448975, Average Training Loss: 1.59118756754645, Training Accuracy: 0.2435344827586207\n",
            "Epoch 1/1, Average Training Loss: 1.59118756754645, Training Accuracy: 0.2435344827586207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    inputs, masks, labels = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    val_loss += loss.item()\n",
        "\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    predictions.extend(preds)\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n",
        "# Calculate validation accuracy and other metrics\n",
        "val_accuracy = accuracy_score(true_labels, predictions)\n",
        "val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "print(f'Validation Accuracy: {val_accuracy}')\n",
        "print('Classification Report:')\n",
        "print(val_classification_report)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Test_Data.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted_Label'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(test_df[['Responses', 'Predicted_Label']])\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)  # Use test_df instead of additional_test_df\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbtj6_wLJvoX",
        "outputId": "3d36ebc3-e295-46c8-9679-835556ac2fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3793103448275862\n",
            "Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.42      0.62      0.50        99\n",
            "                Educational Opportunity       0.29      0.32      0.30        87\n",
            "                         Family Support       0.35      0.56      0.43        93\n",
            "                      Financial Support       0.35      0.21      0.27        89\n",
            "                 Program Implementation       0.84      0.17      0.28        96\n",
            "\n",
            "                               accuracy                           0.38       464\n",
            "                              macro avg       0.45      0.38      0.36       464\n",
            "                           weighted avg       0.46      0.38      0.36       464\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b7b72f05ffaf>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Responses  \\\n",
            "0    \"We were able to save more money because of th...   \n",
            "1              \"It gives access to quality education.\"   \n",
            "2    \"It was honestly a big help since the budget f...   \n",
            "3    \"The UAQTE gave students the opportunity to en...   \n",
            "4    \"It has given my college experience a good one...   \n",
            "..                                                 ...   \n",
            "596  \"The UAQTE provides free access to education w...   \n",
            "597  \"Despite being free, quality education was sti...   \n",
            "598  \"I also like the fact that the selection proce...   \n",
            "599  \"The UAQTE Act made a significant difference i...   \n",
            "600  \"It opened doors to higher education that were...   \n",
            "\n",
            "                             Predicted_Label  \n",
            "0                             Family Support  \n",
            "1    Academic Focus and Personal Development  \n",
            "2                    Educational Opportunity  \n",
            "3                    Educational Opportunity  \n",
            "4                    Educational Opportunity  \n",
            "..                                       ...  \n",
            "596                  Educational Opportunity  \n",
            "597                  Educational Opportunity  \n",
            "598                  Educational Opportunity  \n",
            "599                           Family Support  \n",
            "600  Academic Focus and Personal Development  \n",
            "\n",
            "[601 rows x 2 columns]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1\n",
        "# Import libraries with Training, and Validation Accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEX8cJwLOJ6w",
        "outputId": "989407f3-94dc-4619-a7db-39c85541661f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-8-ed18fac1a13c>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.6376235485076904, Average Training Loss: 1.6376235485076904, Training Accuracy: 0.203125\n",
            "Epoch 1/1, Batch Loss: 1.6203571557998657, Average Training Loss: 1.628990352153778, Training Accuracy: 0.1796875\n",
            "Epoch 1/1, Batch Loss: 1.6203199625015259, Average Training Loss: 1.626100222269694, Training Accuracy: 0.19270833333333334\n",
            "Epoch 1/1, Batch Loss: 1.6546217203140259, Average Training Loss: 1.633230596780777, Training Accuracy: 0.19140625\n",
            "Epoch 1/1, Batch Loss: 1.5622313022613525, Average Training Loss: 1.619030737876892, Training Accuracy: 0.225\n",
            "Epoch 1/1, Batch Loss: 1.5757566690444946, Average Training Loss: 1.6118183930714924, Training Accuracy: 0.24479166666666666\n",
            "Epoch 1/1, Batch Loss: 1.6062955856323242, Average Training Loss: 1.6110294205801827, Training Accuracy: 0.24553571428571427\n",
            "Epoch 1/1, Batch Loss: 1.5952094793319702, Average Training Loss: 1.6090519279241562, Training Accuracy: 0.25390625\n",
            "Epoch 1/1, Batch Loss: 1.5746415853500366, Average Training Loss: 1.605228556527032, Training Accuracy: 0.2534722222222222\n",
            "Epoch 1/1, Batch Loss: 1.5513285398483276, Average Training Loss: 1.5998385548591614, Training Accuracy: 0.275\n",
            "Epoch 1/1, Batch Loss: 1.5927464962005615, Average Training Loss: 1.5991938222538342, Training Accuracy: 0.2727272727272727\n",
            "Epoch 1/1, Batch Loss: 1.549830675125122, Average Training Loss: 1.5950802266597748, Training Accuracy: 0.2734375\n",
            "Epoch 1/1, Batch Loss: 1.5651400089263916, Average Training Loss: 1.592777132987976, Training Accuracy: 0.27283653846153844\n",
            "Epoch 1/1, Batch Loss: 1.5435653924942017, Average Training Loss: 1.5892620086669922, Training Accuracy: 0.27566964285714285\n",
            "Epoch 1/1, Batch Loss: 1.5639077425003052, Average Training Loss: 1.5875717242558798, Training Accuracy: 0.27708333333333335\n",
            "Epoch 1/1, Batch Loss: 1.5492947101593018, Average Training Loss: 1.5851794108748436, Training Accuracy: 0.279296875\n",
            "Epoch 1/1, Batch Loss: 1.5579904317855835, Average Training Loss: 1.5835800591637106, Training Accuracy: 0.2803308823529412\n",
            "Epoch 1/1, Batch Loss: 1.555609107017517, Average Training Loss: 1.582026117377811, Training Accuracy: 0.2821180555555556\n",
            "Epoch 1/1, Batch Loss: 1.5369741916656494, Average Training Loss: 1.5796549633929604, Training Accuracy: 0.2837171052631579\n",
            "Epoch 1/1, Batch Loss: 1.5346691608428955, Average Training Loss: 1.577405673265457, Training Accuracy: 0.28671875\n",
            "Epoch 1/1, Batch Loss: 1.5403081178665161, Average Training Loss: 1.5756391230083646, Training Accuracy: 0.29017857142857145\n",
            "Epoch 1/1, Batch Loss: 1.5298959016799927, Average Training Loss: 1.5735598856752568, Training Accuracy: 0.29332386363636365\n",
            "Epoch 1/1, Batch Loss: 1.4601558446884155, Average Training Loss: 1.5686292751975681, Training Accuracy: 0.29959239130434784\n",
            "Epoch 1/1, Batch Loss: 1.5315600633621216, Average Training Loss: 1.5670847247044246, Training Accuracy: 0.302734375\n",
            "Epoch 1/1, Batch Loss: 1.5243018865585327, Average Training Loss: 1.5653734111785889, Training Accuracy: 0.306875\n",
            "Epoch 1/1, Batch Loss: 1.572510838508606, Average Training Loss: 1.5656479276143587, Training Accuracy: 0.3058894230769231\n",
            "Epoch 1/1, Batch Loss: 1.5394318103790283, Average Training Loss: 1.5646769603093464, Training Accuracy: 0.3072916666666667\n",
            "Epoch 1/1, Batch Loss: 1.5810494422912598, Average Training Loss: 1.5652616918087006, Training Accuracy: 0.30747767857142855\n",
            "Epoch 1/1, Batch Loss: 1.5217609405517578, Average Training Loss: 1.5637616659032887, Training Accuracy: 0.3098060344827586\n",
            "Epoch 1/1, Average Training Loss: 1.5637616659032887, Training Accuracy: 0.3098060344827586\n",
            "Epoch 1/1, Validation Loss: 11.916689276695251, Validation Accuracy: 0.4073275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.43      0.68      0.52        99\n",
            "                Educational Opportunity       0.29      0.06      0.10        87\n",
            "                         Family Support       0.71      0.05      0.10        93\n",
            "                      Financial Support       0.31      0.75      0.44        89\n",
            "                 Program Implementation       0.65      0.47      0.55        96\n",
            "\n",
            "                               accuracy                           0.41       464\n",
            "                              macro avg       0.48      0.40      0.34       464\n",
            "                           weighted avg       0.48      0.41      0.35       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2\n",
        "# Import libraries with Training, and Validation Accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5wUrPr2rI2K",
        "outputId": "ea746102-62ce-4a9f-d39f-641f83270538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-7-1b6973f4f936>:34: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.5988373756408691, Average Training Loss: 1.5988373756408691, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.655955195426941, Average Training Loss: 1.627396285533905, Training Accuracy: 0.1953125\n",
            "Epoch 1/1, Batch Loss: 1.6319937705993652, Average Training Loss: 1.628928780555725, Training Accuracy: 0.19270833333333334\n",
            "Epoch 1/1, Batch Loss: 1.635204553604126, Average Training Loss: 1.6304977238178253, Training Accuracy: 0.19140625\n",
            "Epoch 1/1, Batch Loss: 1.6025662422180176, Average Training Loss: 1.6249114274978638, Training Accuracy: 0.196875\n",
            "Epoch 1/1, Batch Loss: 1.5536514520645142, Average Training Loss: 1.613034764925639, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/1, Batch Loss: 1.546419620513916, Average Training Loss: 1.603518315723964, Training Accuracy: 0.22321428571428573\n",
            "Epoch 1/1, Batch Loss: 1.5574125051498413, Average Training Loss: 1.5977550894021988, Training Accuracy: 0.236328125\n",
            "Epoch 1/1, Batch Loss: 1.552504301071167, Average Training Loss: 1.5927272240320842, Training Accuracy: 0.24305555555555555\n",
            "Epoch 1/1, Batch Loss: 1.5216261148452759, Average Training Loss: 1.5856171131134034, Training Accuracy: 0.253125\n",
            "Epoch 1/1, Batch Loss: 1.5140080451965332, Average Training Loss: 1.5791071978482334, Training Accuracy: 0.2627840909090909\n",
            "Epoch 1/1, Batch Loss: 1.5215790271759033, Average Training Loss: 1.574313183625539, Training Accuracy: 0.2669270833333333\n",
            "Epoch 1/1, Batch Loss: 1.5354948043823242, Average Training Loss: 1.571327154452984, Training Accuracy: 0.27524038461538464\n",
            "Epoch 1/1, Batch Loss: 1.500260353088379, Average Training Loss: 1.5662509543555123, Training Accuracy: 0.2857142857142857\n",
            "Epoch 1/1, Batch Loss: 1.5331910848617554, Average Training Loss: 1.5640469630559286, Training Accuracy: 0.29375\n",
            "Epoch 1/1, Batch Loss: 1.4828795194625854, Average Training Loss: 1.5589739978313446, Training Accuracy: 0.2978515625\n",
            "Epoch 1/1, Batch Loss: 1.5470656156539917, Average Training Loss: 1.5582735047620886, Training Accuracy: 0.2959558823529412\n",
            "Epoch 1/1, Batch Loss: 1.4701199531555176, Average Training Loss: 1.5533760852283902, Training Accuracy: 0.2977430555555556\n",
            "Epoch 1/1, Batch Loss: 1.5400497913360596, Average Training Loss: 1.55267470133932, Training Accuracy: 0.29769736842105265\n",
            "Epoch 1/1, Batch Loss: 1.5455344915390015, Average Training Loss: 1.5523176908493042, Training Accuracy: 0.29921875\n",
            "Epoch 1/1, Batch Loss: 1.4573007822036743, Average Training Loss: 1.5477930761518932, Training Accuracy: 0.30282738095238093\n",
            "Epoch 1/1, Batch Loss: 1.540979266166687, Average Training Loss: 1.5474833575162021, Training Accuracy: 0.30113636363636365\n",
            "Epoch 1/1, Batch Loss: 1.4814053773880005, Average Training Loss: 1.544610401858454, Training Accuracy: 0.30434782608695654\n",
            "Epoch 1/1, Batch Loss: 1.3805651664733887, Average Training Loss: 1.5377751837174098, Training Accuracy: 0.3118489583333333\n",
            "Epoch 1/1, Batch Loss: 1.4061371088027954, Average Training Loss: 1.5325096607208253, Training Accuracy: 0.31625\n",
            "Epoch 1/1, Batch Loss: 1.380332350730896, Average Training Loss: 1.526656687259674, Training Accuracy: 0.3215144230769231\n",
            "Epoch 1/1, Batch Loss: 1.4849354028701782, Average Training Loss: 1.5251114545045075, Training Accuracy: 0.32407407407407407\n",
            "Epoch 1/1, Batch Loss: 1.483490228652954, Average Training Loss: 1.5236249821526664, Training Accuracy: 0.32700892857142855\n",
            "Epoch 1/1, Batch Loss: 1.4167566299438477, Average Training Loss: 1.5199398665592587, Training Accuracy: 0.33189655172413796\n",
            "Epoch 1/1, Average Training Loss: 1.5199398665592587, Training Accuracy: 0.33189655172413796\n",
            "Epoch 1/1, Validation Loss: 11.41764509677887, Validation Accuracy: 0.41810344827586204\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.21      0.33        99\n",
            "                Educational Opportunity       0.33      0.49      0.39        87\n",
            "                         Family Support       0.38      0.61      0.47        93\n",
            "                      Financial Support       0.44      0.17      0.24        89\n",
            "                 Program Implementation       0.49      0.60      0.54        96\n",
            "\n",
            "                               accuracy                           0.42       464\n",
            "                              macro avg       0.47      0.42      0.39       464\n",
            "                           weighted avg       0.48      0.42      0.40       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3\n",
        "# Import libraries with Training, and Validation Accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-4, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL9svA7ZxYRC",
        "outputId": "32e60995-b184-4259-8ed9-4c05f1c9850a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-8-d7a62926ddb0>:34: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.614174246788025, Average Training Loss: 1.614174246788025, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.7336703538894653, Average Training Loss: 1.6739223003387451, Training Accuracy: 0.1796875\n",
            "Epoch 1/1, Batch Loss: 1.6334284543991089, Average Training Loss: 1.6604243516921997, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.6856367588043213, Average Training Loss: 1.66672745347023, Training Accuracy: 0.23046875\n",
            "Epoch 1/1, Batch Loss: 1.620737075805664, Average Training Loss: 1.6575293779373168, Training Accuracy: 0.225\n",
            "Epoch 1/1, Batch Loss: 1.62464439868927, Average Training Loss: 1.6520485480626423, Training Accuracy: 0.22135416666666666\n",
            "Epoch 1/1, Batch Loss: 1.5947799682617188, Average Training Loss: 1.6438673223767961, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.6171149015426636, Average Training Loss: 1.6405232697725296, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.6198639869689941, Average Training Loss: 1.6382277939054701, Training Accuracy: 0.22569444444444445\n",
            "Epoch 1/1, Batch Loss: 1.6056160926818848, Average Training Loss: 1.6349666237831115, Training Accuracy: 0.225\n",
            "Epoch 1/1, Batch Loss: 1.6158483028411865, Average Training Loss: 1.633228594606573, Training Accuracy: 0.22301136363636365\n",
            "Epoch 1/1, Batch Loss: 1.6154727935791016, Average Training Loss: 1.6317489445209503, Training Accuracy: 0.21744791666666666\n",
            "Epoch 1/1, Batch Loss: 1.6480746269226074, Average Training Loss: 1.6330047662441547, Training Accuracy: 0.21514423076923078\n",
            "Epoch 1/1, Batch Loss: 1.6255439519882202, Average Training Loss: 1.6324718509401595, Training Accuracy: 0.21651785714285715\n",
            "Epoch 1/1, Batch Loss: 1.60140860080719, Average Training Loss: 1.6304009675979614, Training Accuracy: 0.22083333333333333\n",
            "Epoch 1/1, Batch Loss: 1.5861703157424927, Average Training Loss: 1.6276365518569946, Training Accuracy: 0.224609375\n",
            "Epoch 1/1, Batch Loss: 1.4877803325653076, Average Training Loss: 1.6194097154280718, Training Accuracy: 0.23253676470588236\n",
            "Epoch 1/1, Batch Loss: 1.585005760192871, Average Training Loss: 1.6174983845816717, Training Accuracy: 0.23350694444444445\n",
            "Epoch 1/1, Batch Loss: 1.5746479034423828, Average Training Loss: 1.6152430961006565, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.5376898050308228, Average Training Loss: 1.6113654315471648, Training Accuracy: 0.23671875\n",
            "Epoch 1/1, Batch Loss: 1.5490518808364868, Average Training Loss: 1.6083981196085613, Training Accuracy: 0.23735119047619047\n",
            "Epoch 1/1, Batch Loss: 1.5209938287734985, Average Training Loss: 1.6044251972978765, Training Accuracy: 0.23792613636363635\n",
            "Epoch 1/1, Batch Loss: 1.6179258823394775, Average Training Loss: 1.6050121836040332, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.6346441507339478, Average Training Loss: 1.6062468489011128, Training Accuracy: 0.23177083333333334\n",
            "Epoch 1/1, Batch Loss: 1.6187629699707031, Average Training Loss: 1.6067474937438966, Training Accuracy: 0.22875\n",
            "Epoch 1/1, Batch Loss: 1.598401427268982, Average Training Loss: 1.606426491187169, Training Accuracy: 0.2283653846153846\n",
            "Epoch 1/1, Batch Loss: 1.639336109161377, Average Training Loss: 1.6076453659269545, Training Accuracy: 0.22511574074074073\n",
            "Epoch 1/1, Batch Loss: 1.5575244426727295, Average Training Loss: 1.6058553329535894, Training Accuracy: 0.22767857142857142\n",
            "Epoch 1/1, Batch Loss: 1.6025891304016113, Average Training Loss: 1.6057427052793831, Training Accuracy: 0.22952586206896552\n",
            "Epoch 1/1, Average Training Loss: 1.6057427052793831, Training Accuracy: 0.22952586206896552\n",
            "Epoch 1/1, Validation Loss: 12.69301724433899, Validation Accuracy: 0.21551724137931033\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.00      0.00      0.00        99\n",
            "                Educational Opportunity       0.19      1.00      0.32        87\n",
            "                         Family Support       0.00      0.00      0.00        93\n",
            "                      Financial Support       0.00      0.00      0.00        89\n",
            "                 Program Implementation       0.93      0.14      0.24        96\n",
            "\n",
            "                               accuracy                           0.22       464\n",
            "                              macro avg       0.22      0.23      0.11       464\n",
            "                           weighted avg       0.23      0.22      0.11       464\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4\n",
        "# Import libraries with Training, and Validation Accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewsq7ovD8hUR",
        "outputId": "a0e637f4-3946-4ae7-94ea-e2461de07a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-9-b46c4898d9bf>:34: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.69524085521698, Average Training Loss: 1.69524085521698, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.6592140197753906, Average Training Loss: 1.6772274374961853, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.5950652360916138, Average Training Loss: 1.6498400370279949, Training Accuracy: 0.16666666666666666\n",
            "Epoch 1/1, Batch Loss: 1.589835524559021, Average Training Loss: 1.6348389089107513, Training Accuracy: 0.1640625\n",
            "Epoch 1/1, Batch Loss: 1.5901908874511719, Average Training Loss: 1.6259093046188355, Training Accuracy: 0.18125\n",
            "Epoch 1/1, Batch Loss: 1.610303521156311, Average Training Loss: 1.6233083407084148, Training Accuracy: 0.18229166666666666\n",
            "Epoch 1/1, Batch Loss: 1.6572777032852173, Average Training Loss: 1.628161106790815, Training Accuracy: 0.17857142857142858\n",
            "Epoch 1/1, Batch Loss: 1.5868165493011475, Average Training Loss: 1.6229930371046066, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.6302295923233032, Average Training Loss: 1.623797098795573, Training Accuracy: 0.19444444444444445\n",
            "Epoch 1/1, Batch Loss: 1.569961667060852, Average Training Loss: 1.6184135556221009, Training Accuracy: 0.203125\n",
            "Epoch 1/1, Batch Loss: 1.571184754371643, Average Training Loss: 1.6141200282356956, Training Accuracy: 0.21306818181818182\n",
            "Epoch 1/1, Batch Loss: 1.5649337768554688, Average Training Loss: 1.61002117395401, Training Accuracy: 0.21614583333333334\n",
            "Epoch 1/1, Batch Loss: 1.5801234245300293, Average Training Loss: 1.6077213470752423, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.588576078414917, Average Training Loss: 1.606353827885219, Training Accuracy: 0.21205357142857142\n",
            "Epoch 1/1, Batch Loss: 1.6162534952163696, Average Training Loss: 1.6070138057072958, Training Accuracy: 0.21041666666666667\n",
            "Epoch 1/1, Batch Loss: 1.6381014585494995, Average Training Loss: 1.6089567840099335, Training Accuracy: 0.2109375\n",
            "Epoch 1/1, Batch Loss: 1.6126831769943237, Average Training Loss: 1.6091759835972506, Training Accuracy: 0.20772058823529413\n",
            "Epoch 1/1, Batch Loss: 1.5719337463378906, Average Training Loss: 1.607106970416175, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/1, Batch Loss: 1.558771014213562, Average Training Loss: 1.6045629727213007, Training Accuracy: 0.21546052631578946\n",
            "Epoch 1/1, Batch Loss: 1.5493712425231934, Average Training Loss: 1.6018033862113952, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.5355087518692017, Average Training Loss: 1.598646498861767, Training Accuracy: 0.2261904761904762\n",
            "Epoch 1/1, Batch Loss: 1.5482051372528076, Average Training Loss: 1.5963537096977234, Training Accuracy: 0.23295454545454544\n",
            "Epoch 1/1, Batch Loss: 1.520506739616394, Average Training Loss: 1.5930560153463613, Training Accuracy: 0.23641304347826086\n",
            "Epoch 1/1, Batch Loss: 1.5032447576522827, Average Training Loss: 1.589313879609108, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.5361199378967285, Average Training Loss: 1.5871861219406127, Training Accuracy: 0.24125\n",
            "Epoch 1/1, Batch Loss: 1.4322786331176758, Average Training Loss: 1.581228141601269, Training Accuracy: 0.2512019230769231\n",
            "Epoch 1/1, Batch Loss: 1.44252610206604, Average Training Loss: 1.5760910290258903, Training Accuracy: 0.2604166666666667\n",
            "Epoch 1/1, Batch Loss: 1.517534852027893, Average Training Loss: 1.5739997369902474, Training Accuracy: 0.26674107142857145\n",
            "Epoch 1/1, Batch Loss: 1.501680612564087, Average Training Loss: 1.5715059740790005, Training Accuracy: 0.27262931034482757\n",
            "Epoch 1/1, Batch Loss: 1.584620714187622, Average Training Loss: 1.5719431320826212, Training Accuracy: 0.27291666666666664\n",
            "Epoch 1/1, Batch Loss: 1.4536389112472534, Average Training Loss: 1.5681268668943835, Training Accuracy: 0.2782258064516129\n",
            "Epoch 1/1, Batch Loss: 1.4858169555664062, Average Training Loss: 1.5655546821653843, Training Accuracy: 0.2822265625\n",
            "Epoch 1/1, Batch Loss: 1.4786412715911865, Average Training Loss: 1.5629209424510146, Training Accuracy: 0.2850378787878788\n",
            "Epoch 1/1, Batch Loss: 1.494418978691101, Average Training Loss: 1.5609061788110172, Training Accuracy: 0.28860294117647056\n",
            "Epoch 1/1, Batch Loss: 1.3597867488861084, Average Training Loss: 1.5551599093845911, Training Accuracy: 0.2955357142857143\n",
            "Epoch 1/1, Batch Loss: 1.3406870365142822, Average Training Loss: 1.5492023295826383, Training Accuracy: 0.3055555555555556\n",
            "Epoch 1/1, Batch Loss: 1.420754075050354, Average Training Loss: 1.5457307551358197, Training Accuracy: 0.3091216216216216\n",
            "Epoch 1/1, Batch Loss: 1.3705068826675415, Average Training Loss: 1.5411196005971808, Training Accuracy: 0.3149671052631579\n",
            "Epoch 1/1, Batch Loss: 1.4202271699905396, Average Training Loss: 1.53801979468419, Training Accuracy: 0.31650641025641024\n",
            "Epoch 1/1, Batch Loss: 1.365800142288208, Average Training Loss: 1.5337143033742904, Training Accuracy: 0.321875\n",
            "Epoch 1/1, Batch Loss: 1.362817645072937, Average Training Loss: 1.5295460921962087, Training Accuracy: 0.3254573170731707\n",
            "Epoch 1/1, Batch Loss: 1.3242268562316895, Average Training Loss: 1.5246575389589583, Training Accuracy: 0.33110119047619047\n",
            "Epoch 1/1, Batch Loss: 1.273938536643982, Average Training Loss: 1.5188268644865168, Training Accuracy: 0.3372093023255814\n",
            "Epoch 1/1, Batch Loss: 1.3724275827407837, Average Training Loss: 1.5154996080832048, Training Accuracy: 0.3387784090909091\n",
            "Epoch 1/1, Batch Loss: 1.4306129217147827, Average Training Loss: 1.5136132372750177, Training Accuracy: 0.3388888888888889\n",
            "Epoch 1/1, Batch Loss: 1.3140872716903687, Average Training Loss: 1.509275716284047, Training Accuracy: 0.343070652173913\n",
            "Epoch 1/1, Batch Loss: 1.209566354751587, Average Training Loss: 1.5028989213578245, Training Accuracy: 0.3484042553191489\n",
            "Epoch 1/1, Batch Loss: 1.2465795278549194, Average Training Loss: 1.4975589339931805, Training Accuracy: 0.3541666666666667\n",
            "Epoch 1/1, Batch Loss: 1.2851676940917969, Average Training Loss: 1.4932244188931523, Training Accuracy: 0.3596938775510204\n",
            "Epoch 1/1, Batch Loss: 1.2654184103012085, Average Training Loss: 1.4886682987213136, Training Accuracy: 0.36375\n",
            "Epoch 1/1, Batch Loss: 1.253478765487671, Average Training Loss: 1.4840567392461441, Training Accuracy: 0.36703431372549017\n",
            "Epoch 1/1, Batch Loss: 1.3791428804397583, Average Training Loss: 1.4820391650383289, Training Accuracy: 0.36959134615384615\n",
            "Epoch 1/1, Batch Loss: 1.321433186531067, Average Training Loss: 1.4790088635570597, Training Accuracy: 0.37264150943396224\n",
            "Epoch 1/1, Batch Loss: 1.2952542304992676, Average Training Loss: 1.4756059999819156, Training Accuracy: 0.3761574074074074\n",
            "Epoch 1/1, Batch Loss: 1.2818061113357544, Average Training Loss: 1.4720823656428943, Training Accuracy: 0.3806818181818182\n",
            "Epoch 1/1, Batch Loss: 1.2047998905181885, Average Training Loss: 1.4673094643013818, Training Accuracy: 0.38448660714285715\n",
            "Epoch 1/1, Batch Loss: 1.3799052238464355, Average Training Loss: 1.465776056574102, Training Accuracy: 0.38706140350877194\n",
            "Epoch 1/1, Batch Loss: 1.2737160921096802, Average Training Loss: 1.4624646778764396, Training Accuracy: 0.3890086206896552\n",
            "Epoch 1/1, Average Training Loss: 1.4624646778764396, Training Accuracy: 0.3890086206896552\n",
            "Epoch 1/1, Validation Loss: 18.07257091999054, Validation Accuracy: 0.6271551724137931\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.64      0.65        99\n",
            "                Educational Opportunity       0.45      0.39      0.42        87\n",
            "                         Family Support       0.67      0.90      0.77        93\n",
            "                      Financial Support       0.67      0.63      0.65        89\n",
            "                 Program Implementation       0.64      0.56      0.60        96\n",
            "\n",
            "                               accuracy                           0.63       464\n",
            "                              macro avg       0.62      0.62      0.62       464\n",
            "                           weighted avg       0.62      0.63      0.62       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n",
        "\n",
        "# ... (your subsequent code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTt3KxfAP1pq",
        "outputId": "8215de55-5351-4fab-9fe6-cc2aa76dc16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-12-f04af53c2927>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4                                make education easier\n",
            "5    experience free funded material module make st...\n",
            "6    great opportunity student study university wit...\n",
            "7                                        helpful study\n",
            "8      program made possible continue studying college\n",
            "9      scholarship serve stepping stone onward success\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.6628273725509644, Average Training Loss: 1.6628273725509644, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.617159366607666, Average Training Loss: 1.6399933695793152, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.5728716850280762, Average Training Loss: 1.617619474728902, Training Accuracy: 0.2604166666666667\n",
            "Epoch 1/5, Batch Loss: 1.6838949918746948, Average Training Loss: 1.6341883540153503, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.570866346359253, Average Training Loss: 1.621523952484131, Training Accuracy: 0.225\n",
            "Epoch 1/5, Batch Loss: 1.6272401809692383, Average Training Loss: 1.6224766572316487, Training Accuracy: 0.234375\n",
            "Epoch 1/5, Batch Loss: 1.642409324645996, Average Training Loss: 1.6253241811479842, Training Accuracy: 0.23660714285714285\n",
            "Epoch 1/5, Batch Loss: 1.5297448635101318, Average Training Loss: 1.6133767664432526, Training Accuracy: 0.25390625\n",
            "Epoch 1/5, Batch Loss: 1.5774245262145996, Average Training Loss: 1.6093820730845134, Training Accuracy: 0.2569444444444444\n",
            "Epoch 1/5, Batch Loss: 1.526642918586731, Average Training Loss: 1.601108157634735, Training Accuracy: 0.271875\n",
            "Epoch 1/5, Batch Loss: 1.5486465692520142, Average Training Loss: 1.596338922327215, Training Accuracy: 0.26704545454545453\n",
            "Epoch 1/5, Batch Loss: 1.5259878635406494, Average Training Loss: 1.5904763340950012, Training Accuracy: 0.265625\n",
            "Epoch 1/5, Batch Loss: 1.4506173133850098, Average Training Loss: 1.5797179478865404, Training Accuracy: 0.2764423076923077\n",
            "Epoch 1/5, Batch Loss: 1.5916030406951904, Average Training Loss: 1.5805668830871582, Training Accuracy: 0.27455357142857145\n",
            "Epoch 1/5, Batch Loss: 1.5536936521530151, Average Training Loss: 1.5787753343582154, Training Accuracy: 0.27708333333333335\n",
            "Epoch 1/5, Batch Loss: 1.5745025873184204, Average Training Loss: 1.5785082876682281, Training Accuracy: 0.279296875\n",
            "Epoch 1/5, Batch Loss: 1.5513406991958618, Average Training Loss: 1.5769101942286772, Training Accuracy: 0.2849264705882353\n",
            "Epoch 1/5, Batch Loss: 1.438658595085144, Average Training Loss: 1.5692295498318143, Training Accuracy: 0.2881944444444444\n",
            "Epoch 1/5, Batch Loss: 1.5018266439437866, Average Training Loss: 1.5656820284692865, Training Accuracy: 0.29276315789473684\n",
            "Epoch 1/5, Batch Loss: 1.4264806509017944, Average Training Loss: 1.5587219595909119, Training Accuracy: 0.303125\n",
            "Epoch 1/5, Batch Loss: 1.436820149421692, Average Training Loss: 1.5529171114876157, Training Accuracy: 0.30952380952380953\n",
            "Epoch 1/5, Batch Loss: 1.4846854209899902, Average Training Loss: 1.549815671010451, Training Accuracy: 0.31392045454545453\n",
            "Epoch 1/5, Batch Loss: 1.2430264949798584, Average Training Loss: 1.536477011183034, Training Accuracy: 0.328804347826087\n",
            "Epoch 1/5, Batch Loss: 1.2615313529968262, Average Training Loss: 1.5250209420919418, Training Accuracy: 0.33984375\n",
            "Epoch 1/5, Batch Loss: 1.4196323156356812, Average Training Loss: 1.5153719920378466, Training Accuracy: 0.34975961538461536\n",
            "Epoch 1/5, Batch Loss: 1.2574381828308105, Average Training Loss: 1.5058188879931416, Training Accuracy: 0.35648148148148145\n",
            "Epoch 1/5, Batch Loss: 1.1821272373199463, Average Training Loss: 1.4942584718976701, Training Accuracy: 0.36495535714285715\n",
            "Epoch 1/5, Batch Loss: 1.1275385618209839, Average Training Loss: 1.481612957757095, Training Accuracy: 0.3706896551724138\n",
            "Epoch 1/5, Batch Loss: 1.431204080581665, Average Training Loss: 1.4799326618512472, Training Accuracy: 0.36770833333333336\n",
            "Epoch 1/5, Batch Loss: 1.1412626504898071, Average Training Loss: 1.4690078227750716, Training Accuracy: 0.375\n",
            "Epoch 1/5, Batch Loss: 1.2692210674285889, Average Training Loss: 1.462764486670494, Training Accuracy: 0.380859375\n",
            "Epoch 1/5, Batch Loss: 1.226892352104187, Average Training Loss: 1.4556168462290908, Training Accuracy: 0.38446969696969696\n",
            "Epoch 1/5, Batch Loss: 1.1915342807769775, Average Training Loss: 1.4478497119510876, Training Accuracy: 0.38786764705882354\n",
            "Epoch 1/5, Batch Loss: 1.0465749502182007, Average Training Loss: 1.4363847187587193, Training Accuracy: 0.39464285714285713\n",
            "Epoch 1/5, Batch Loss: 1.1109998226165771, Average Training Loss: 1.4273462494214375, Training Accuracy: 0.3993055555555556\n",
            "Epoch 1/5, Batch Loss: 1.2654179334640503, Average Training Loss: 1.4229698084496163, Training Accuracy: 0.40202702702702703\n",
            "Epoch 1/5, Batch Loss: 1.1026400327682495, Average Training Loss: 1.414540077510633, Training Accuracy: 0.40625\n",
            "Epoch 1/5, Batch Loss: 1.3162720203399658, Average Training Loss: 1.4120203837370262, Training Accuracy: 0.40625\n",
            "Epoch 1/5, Batch Loss: 1.1559486389160156, Average Training Loss: 1.4056185901165008, Training Accuracy: 0.41171875\n",
            "Epoch 1/5, Batch Loss: 1.050180196762085, Average Training Loss: 1.3969493610102957, Training Accuracy: 0.41615853658536583\n",
            "Epoch 1/5, Batch Loss: 1.191551685333252, Average Training Loss: 1.392058940160842, Training Accuracy: 0.4174107142857143\n",
            "Epoch 1/5, Batch Loss: 1.0284185409545898, Average Training Loss: 1.3836021866909294, Training Accuracy: 0.42296511627906974\n",
            "Epoch 1/5, Batch Loss: 1.2001314163208008, Average Training Loss: 1.3794323964552446, Training Accuracy: 0.4240056818181818\n",
            "Epoch 1/5, Batch Loss: 1.0543376207351685, Average Training Loss: 1.3722080681059095, Training Accuracy: 0.42916666666666664\n",
            "Epoch 1/5, Batch Loss: 0.9464120864868164, Average Training Loss: 1.3629516337228857, Training Accuracy: 0.4327445652173913\n",
            "Epoch 1/5, Batch Loss: 0.8928876519203186, Average Training Loss: 1.3529502724079376, Training Accuracy: 0.43816489361702127\n",
            "Epoch 1/5, Batch Loss: 1.2537974119186401, Average Training Loss: 1.3508845878144105, Training Accuracy: 0.4381510416666667\n",
            "Epoch 1/5, Batch Loss: 1.1624592542648315, Average Training Loss: 1.347039172844011, Training Accuracy: 0.44005102040816324\n",
            "Epoch 1/5, Batch Loss: 0.920723021030426, Average Training Loss: 1.3385128498077392, Training Accuracy: 0.443125\n",
            "Epoch 1/5, Batch Loss: 1.1736823320388794, Average Training Loss: 1.335280878871095, Training Accuracy: 0.44424019607843135\n",
            "Epoch 1/5, Batch Loss: 1.0614222288131714, Average Training Loss: 1.330014366369981, Training Accuracy: 0.44471153846153844\n",
            "Epoch 1/5, Batch Loss: 1.0310661792755127, Average Training Loss: 1.3243738345380098, Training Accuracy: 0.44693396226415094\n",
            "Epoch 1/5, Batch Loss: 1.167822003364563, Average Training Loss: 1.3214747265533164, Training Accuracy: 0.45023148148148145\n",
            "Epoch 1/5, Batch Loss: 1.0302175283432007, Average Training Loss: 1.3161791411313144, Training Accuracy: 0.45340909090909093\n",
            "Epoch 1/5, Batch Loss: 1.1519502401351929, Average Training Loss: 1.313246482184955, Training Accuracy: 0.45479910714285715\n",
            "Epoch 1/5, Batch Loss: 0.9923174381256104, Average Training Loss: 1.3076161480786508, Training Accuracy: 0.45778508771929827\n",
            "Epoch 1/5, Batch Loss: 0.9544569849967957, Average Training Loss: 1.3015271969910325, Training Accuracy: 0.45905172413793105\n",
            "Epoch 1/5, Average Training Loss: 1.3015271969910325, Training Accuracy: 0.45905172413793105\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.42      0.23      0.29       358\n",
            "                Educational Opportunity       0.32      0.30      0.31       376\n",
            "                         Family Support       0.60      0.70      0.65       376\n",
            "                      Financial Support       0.42      0.54      0.47       376\n",
            "                 Program Implementation       0.50      0.51      0.51       370\n",
            "\n",
            "                               accuracy                           0.46      1856\n",
            "                              macro avg       0.45      0.46      0.45      1856\n",
            "                           weighted avg       0.45      0.46      0.45      1856\n",
            "\n",
            "Epoch 1/5, Validation Loss: 15.356707751750946, Validation Accuracy: 0.5991379310344828\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.44      0.83      0.58        99\n",
            "                Educational Opportunity       0.46      0.14      0.21        87\n",
            "                         Family Support       0.70      0.99      0.82        93\n",
            "                      Financial Support       0.74      0.56      0.64        89\n",
            "                 Program Implementation       0.79      0.44      0.56        96\n",
            "\n",
            "                               accuracy                           0.60       464\n",
            "                              macro avg       0.63      0.59      0.56       464\n",
            "                           weighted avg       0.63      0.60      0.57       464\n",
            "\n",
            "Epoch 2/5, Batch Loss: 1.088837742805481, Average Training Loss: 1.088837742805481, Training Accuracy: 0.5625\n",
            "Epoch 2/5, Batch Loss: 0.836051344871521, Average Training Loss: 0.962444543838501, Training Accuracy: 0.65625\n",
            "Epoch 2/5, Batch Loss: 1.18476402759552, Average Training Loss: 1.036551038424174, Training Accuracy: 0.625\n",
            "Epoch 2/5, Batch Loss: 0.6980612277984619, Average Training Loss: 0.951928585767746, Training Accuracy: 0.6640625\n",
            "Epoch 2/5, Batch Loss: 1.1084818840026855, Average Training Loss: 0.9832392454147338, Training Accuracy: 0.6625\n",
            "Epoch 2/5, Batch Loss: 0.8136913180351257, Average Training Loss: 0.9549812575181326, Training Accuracy: 0.671875\n",
            "Epoch 2/5, Batch Loss: 0.8708095550537109, Average Training Loss: 0.9429567285946437, Training Accuracy: 0.6651785714285714\n",
            "Epoch 2/5, Batch Loss: 1.0728471279144287, Average Training Loss: 0.9591930285096169, Training Accuracy: 0.65625\n",
            "Epoch 2/5, Batch Loss: 0.7925823330879211, Average Training Loss: 0.9406807290183173, Training Accuracy: 0.6701388888888888\n",
            "Epoch 2/5, Batch Loss: 0.9202073216438293, Average Training Loss: 0.9386333882808685, Training Accuracy: 0.665625\n",
            "Epoch 2/5, Batch Loss: 0.9700796008110046, Average Training Loss: 0.9414921348745172, Training Accuracy: 0.6676136363636364\n",
            "Epoch 2/5, Batch Loss: 0.9851808547973633, Average Training Loss: 0.9451328615347544, Training Accuracy: 0.6588541666666666\n",
            "Epoch 2/5, Batch Loss: 0.9981497526168823, Average Training Loss: 0.9492110839256873, Training Accuracy: 0.6586538461538461\n",
            "Epoch 2/5, Batch Loss: 0.8890219926834106, Average Training Loss: 0.9449118631226676, Training Accuracy: 0.6607142857142857\n",
            "Epoch 2/5, Batch Loss: 0.7064937353134155, Average Training Loss: 0.9290173212687175, Training Accuracy: 0.6645833333333333\n",
            "Epoch 2/5, Batch Loss: 0.850006103515625, Average Training Loss: 0.9240791201591492, Training Accuracy: 0.662109375\n",
            "Epoch 2/5, Batch Loss: 0.9898595213890076, Average Training Loss: 0.9279485555256114, Training Accuracy: 0.6654411764705882\n",
            "Epoch 2/5, Batch Loss: 0.9950862526893616, Average Training Loss: 0.9316784275902642, Training Accuracy: 0.6631944444444444\n",
            "Epoch 2/5, Batch Loss: 0.7355881929397583, Average Training Loss: 0.9213578889244481, Training Accuracy: 0.6644736842105263\n",
            "Epoch 2/5, Batch Loss: 1.0735111236572266, Average Training Loss: 0.928965550661087, Training Accuracy: 0.6640625\n",
            "Epoch 2/5, Batch Loss: 1.113275408744812, Average Training Loss: 0.9377422105698359, Training Accuracy: 0.6592261904761905\n",
            "Epoch 2/5, Batch Loss: 0.9390028715133667, Average Training Loss: 0.9377995133399963, Training Accuracy: 0.6590909090909091\n",
            "Epoch 2/5, Batch Loss: 0.8606857061386108, Average Training Loss: 0.9344467391138491, Training Accuracy: 0.6630434782608695\n",
            "Epoch 2/5, Batch Loss: 0.8143929243087769, Average Training Loss: 0.9294444968303045, Training Accuracy: 0.6653645833333334\n",
            "Epoch 2/5, Batch Loss: 1.0379315614700317, Average Training Loss: 0.9337839794158935, Training Accuracy: 0.6625\n",
            "Epoch 2/5, Batch Loss: 0.7188001275062561, Average Training Loss: 0.9255153697270614, Training Accuracy: 0.6682692307692307\n",
            "Epoch 2/5, Batch Loss: 0.8107185363769531, Average Training Loss: 0.9212636351585388, Training Accuracy: 0.6712962962962963\n",
            "Epoch 2/5, Batch Loss: 0.8183755874633789, Average Training Loss: 0.9175890620265689, Training Accuracy: 0.6741071428571429\n",
            "Epoch 2/5, Batch Loss: 0.758487343788147, Average Training Loss: 0.9121027958804163, Training Accuracy: 0.6756465517241379\n",
            "Epoch 2/5, Batch Loss: 1.1509082317352295, Average Training Loss: 0.9200629770755768, Training Accuracy: 0.6739583333333333\n",
            "Epoch 2/5, Batch Loss: 0.8235962390899658, Average Training Loss: 0.9169511468179764, Training Accuracy: 0.6754032258064516\n",
            "Epoch 2/5, Batch Loss: 0.805337131023407, Average Training Loss: 0.9134632088243961, Training Accuracy: 0.6767578125\n",
            "Epoch 2/5, Batch Loss: 0.8308889865875244, Average Training Loss: 0.910960959665703, Training Accuracy: 0.6761363636363636\n",
            "Epoch 2/5, Batch Loss: 1.0932002067565918, Average Training Loss: 0.9163209375213174, Training Accuracy: 0.6746323529411765\n",
            "Epoch 2/5, Batch Loss: 0.7430819272994995, Average Training Loss: 0.9113712515149798, Training Accuracy: 0.6767857142857143\n",
            "Epoch 2/5, Batch Loss: 1.166068196296692, Average Training Loss: 0.9184461666478051, Training Accuracy: 0.6710069444444444\n",
            "Epoch 2/5, Batch Loss: 1.0391528606414795, Average Training Loss: 0.9217085097287152, Training Accuracy: 0.6697635135135135\n",
            "Epoch 2/5, Batch Loss: 0.7468429207801819, Average Training Loss: 0.9171067837037539, Training Accuracy: 0.671875\n",
            "Epoch 2/5, Batch Loss: 0.7337212562561035, Average Training Loss: 0.9124045906922756, Training Accuracy: 0.6730769230769231\n",
            "Epoch 2/5, Batch Loss: 0.8921794295310974, Average Training Loss: 0.9118989616632461, Training Accuracy: 0.66953125\n",
            "Epoch 2/5, Batch Loss: 0.8988735675811768, Average Training Loss: 0.9115812691246591, Training Accuracy: 0.6714939024390244\n",
            "Epoch 2/5, Batch Loss: 0.6501068472862244, Average Training Loss: 0.9053556876523154, Training Accuracy: 0.6741071428571429\n",
            "Epoch 2/5, Batch Loss: 0.9537409543991089, Average Training Loss: 0.9064809264138688, Training Accuracy: 0.6744186046511628\n",
            "Epoch 2/5, Batch Loss: 0.7199687361717224, Average Training Loss: 0.9022420129992745, Training Accuracy: 0.6768465909090909\n",
            "Epoch 2/5, Batch Loss: 0.7512962222099304, Average Training Loss: 0.8988876620928447, Training Accuracy: 0.6777777777777778\n",
            "Epoch 2/5, Batch Loss: 0.863572895526886, Average Training Loss: 0.8981199497761934, Training Accuracy: 0.6766304347826086\n",
            "Epoch 2/5, Batch Loss: 0.9516059160232544, Average Training Loss: 0.8992579490580457, Training Accuracy: 0.6761968085106383\n",
            "Epoch 2/5, Batch Loss: 1.165898084640503, Average Training Loss: 0.9048129518826803, Training Accuracy: 0.673828125\n",
            "Epoch 2/5, Batch Loss: 0.7372526526451111, Average Training Loss: 0.9013933539390564, Training Accuracy: 0.6766581632653061\n",
            "Epoch 2/5, Batch Loss: 0.8256006836891174, Average Training Loss: 0.8998775005340576, Training Accuracy: 0.676875\n",
            "Epoch 2/5, Batch Loss: 0.9827462434768677, Average Training Loss: 0.9015023778466618, Training Accuracy: 0.6758578431372549\n",
            "Epoch 2/5, Batch Loss: 0.8550008535385132, Average Training Loss: 0.9006081177638128, Training Accuracy: 0.6754807692307693\n",
            "Epoch 2/5, Batch Loss: 0.8346003890037537, Average Training Loss: 0.8993626889192833, Training Accuracy: 0.6751179245283019\n",
            "Epoch 2/5, Batch Loss: 0.6888136863708496, Average Training Loss: 0.8954636333165346, Training Accuracy: 0.6759259259259259\n",
            "Epoch 2/5, Batch Loss: 0.9306967258453369, Average Training Loss: 0.8961042349988764, Training Accuracy: 0.6755681818181818\n",
            "Epoch 2/5, Batch Loss: 1.1246304512023926, Average Training Loss: 0.9001850602882249, Training Accuracy: 0.6735491071428571\n",
            "Epoch 2/5, Batch Loss: 0.829504132270813, Average Training Loss: 0.8989450440072176, Training Accuracy: 0.6737938596491229\n",
            "Epoch 2/5, Batch Loss: 0.8421245813369751, Average Training Loss: 0.8979653808577307, Training Accuracy: 0.6751077586206896\n",
            "Epoch 2/5, Average Training Loss: 0.8979653808577307, Training Accuracy: 0.6751077586206896\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.58      0.60      0.59       358\n",
            "                Educational Opportunity       0.52      0.42      0.47       376\n",
            "                         Family Support       0.80      0.95      0.87       376\n",
            "                      Financial Support       0.70      0.71      0.70       376\n",
            "                 Program Implementation       0.72      0.68      0.70       370\n",
            "\n",
            "                               accuracy                           0.68      1856\n",
            "                              macro avg       0.66      0.67      0.67      1856\n",
            "                           weighted avg       0.67      0.68      0.67      1856\n",
            "\n",
            "Epoch 2/5, Validation Loss: 13.463201522827148, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.65      0.67        99\n",
            "                Educational Opportunity       0.60      0.29      0.39        87\n",
            "                         Family Support       0.72      0.99      0.83        93\n",
            "                      Financial Support       0.60      0.73      0.66        89\n",
            "                 Program Implementation       0.66      0.66      0.66        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.66      0.64       464\n",
            "                           weighted avg       0.66      0.67      0.65       464\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.8484136462211609, Average Training Loss: 0.8484136462211609, Training Accuracy: 0.6875\n",
            "Epoch 3/5, Batch Loss: 0.5802502036094666, Average Training Loss: 0.7143319249153137, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.6577973365783691, Average Training Loss: 0.6954870621363322, Training Accuracy: 0.7395833333333334\n",
            "Epoch 3/5, Batch Loss: 0.5953906774520874, Average Training Loss: 0.670462965965271, Training Accuracy: 0.7578125\n",
            "Epoch 3/5, Batch Loss: 0.5223963260650635, Average Training Loss: 0.6408496379852295, Training Accuracy: 0.75625\n",
            "Epoch 3/5, Batch Loss: 0.6825910210609436, Average Training Loss: 0.6478065351645151, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.7847151160240173, Average Training Loss: 0.6673649038587298, Training Accuracy: 0.7589285714285714\n",
            "Epoch 3/5, Batch Loss: 0.5737185478210449, Average Training Loss: 0.6556591093540192, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.7682483196258545, Average Training Loss: 0.6681690216064453, Training Accuracy: 0.7673611111111112\n",
            "Epoch 3/5, Batch Loss: 0.7358967661857605, Average Training Loss: 0.6749417960643769, Training Accuracy: 0.759375\n",
            "Epoch 3/5, Batch Loss: 0.4920777380466461, Average Training Loss: 0.6583177907900377, Training Accuracy: 0.7727272727272727\n",
            "Epoch 3/5, Batch Loss: 0.985442578792572, Average Training Loss: 0.6855781897902489, Training Accuracy: 0.7578125\n",
            "Epoch 3/5, Batch Loss: 0.8049567341804504, Average Training Loss: 0.6947611547433413, Training Accuracy: 0.7572115384615384\n",
            "Epoch 3/5, Batch Loss: 0.5279822945594788, Average Training Loss: 0.6828483790159225, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.740257203578949, Average Training Loss: 0.686675633986791, Training Accuracy: 0.7604166666666666\n",
            "Epoch 3/5, Batch Loss: 0.6757233738899231, Average Training Loss: 0.6859911177307367, Training Accuracy: 0.759765625\n",
            "Epoch 3/5, Batch Loss: 0.8160321712493896, Average Training Loss: 0.6936405914671281, Training Accuracy: 0.7573529411764706\n",
            "Epoch 3/5, Batch Loss: 0.5865201950073242, Average Training Loss: 0.6876894583304723, Training Accuracy: 0.7604166666666666\n",
            "Epoch 3/5, Batch Loss: 0.755380392074585, Average Training Loss: 0.6912521390538466, Training Accuracy: 0.7631578947368421\n",
            "Epoch 3/5, Batch Loss: 0.6811290979385376, Average Training Loss: 0.6907459869980812, Training Accuracy: 0.7609375\n",
            "Epoch 3/5, Batch Loss: 0.6073923110961914, Average Training Loss: 0.6867767643360865, Training Accuracy: 0.7589285714285714\n",
            "Epoch 3/5, Batch Loss: 0.5770749449729919, Average Training Loss: 0.6817903180014003, Training Accuracy: 0.7627840909090909\n",
            "Epoch 3/5, Batch Loss: 0.48877742886543274, Average Training Loss: 0.6733984532563583, Training Accuracy: 0.7676630434782609\n",
            "Epoch 3/5, Batch Loss: 0.5342644453048706, Average Training Loss: 0.6676012029250463, Training Accuracy: 0.7682291666666666\n",
            "Epoch 3/5, Batch Loss: 0.7485707998275757, Average Training Loss: 0.6708399868011474, Training Accuracy: 0.76625\n",
            "Epoch 3/5, Batch Loss: 1.0727038383483887, Average Training Loss: 0.6862962887837336, Training Accuracy: 0.7596153846153846\n",
            "Epoch 3/5, Batch Loss: 0.667170524597168, Average Training Loss: 0.6855879271471942, Training Accuracy: 0.7569444444444444\n",
            "Epoch 3/5, Batch Loss: 0.7910034656524658, Average Training Loss: 0.6893527678080967, Training Accuracy: 0.7544642857142857\n",
            "Epoch 3/5, Batch Loss: 0.46923890709877014, Average Training Loss: 0.6817626346801889, Training Accuracy: 0.7586206896551724\n",
            "Epoch 3/5, Batch Loss: 0.7909432649612427, Average Training Loss: 0.6854019890228907, Training Accuracy: 0.7541666666666667\n",
            "Epoch 3/5, Batch Loss: 0.6301642656326294, Average Training Loss: 0.6836201269780436, Training Accuracy: 0.7550403225806451\n",
            "Epoch 3/5, Batch Loss: 0.48011884093284607, Average Training Loss: 0.6772607117891312, Training Accuracy: 0.755859375\n",
            "Epoch 3/5, Batch Loss: 0.7023122906684875, Average Training Loss: 0.678019850543051, Training Accuracy: 0.7556818181818182\n",
            "Epoch 3/5, Batch Loss: 0.49489712715148926, Average Training Loss: 0.6726338880903581, Training Accuracy: 0.7601102941176471\n",
            "Epoch 3/5, Batch Loss: 0.6696842312812805, Average Training Loss: 0.6725496121815273, Training Accuracy: 0.7598214285714285\n",
            "Epoch 3/5, Batch Loss: 0.7903343439102173, Average Training Loss: 0.675821410285102, Training Accuracy: 0.7586805555555556\n",
            "Epoch 3/5, Batch Loss: 0.8009085655212402, Average Training Loss: 0.679202144210403, Training Accuracy: 0.7584459459459459\n",
            "Epoch 3/5, Batch Loss: 0.7430292963981628, Average Training Loss: 0.6808818061100809, Training Accuracy: 0.759046052631579\n",
            "Epoch 3/5, Batch Loss: 0.49167224764823914, Average Training Loss: 0.6760302789700336, Training Accuracy: 0.7612179487179487\n",
            "Epoch 3/5, Batch Loss: 0.6360544562339783, Average Training Loss: 0.6750308834016323, Training Accuracy: 0.76171875\n",
            "Epoch 3/5, Batch Loss: 0.6304789781570435, Average Training Loss: 0.6739442515663985, Training Accuracy: 0.7614329268292683\n",
            "Epoch 3/5, Batch Loss: 0.8761379718780518, Average Training Loss: 0.678758387764295, Training Accuracy: 0.7596726190476191\n",
            "Epoch 3/5, Batch Loss: 0.43482428789138794, Average Training Loss: 0.673085501720739, Training Accuracy: 0.7616279069767442\n",
            "Epoch 3/5, Batch Loss: 0.5430618524551392, Average Training Loss: 0.6701304187828844, Training Accuracy: 0.7634943181818182\n",
            "Epoch 3/5, Batch Loss: 1.026045799255371, Average Training Loss: 0.6780396494600508, Training Accuracy: 0.7590277777777777\n",
            "Epoch 3/5, Batch Loss: 0.8299628496170044, Average Training Loss: 0.6813423277243323, Training Accuracy: 0.7581521739130435\n",
            "Epoch 3/5, Batch Loss: 0.6729310154914856, Average Training Loss: 0.6811633636342719, Training Accuracy: 0.7586436170212766\n",
            "Epoch 3/5, Batch Loss: 0.7616536021232605, Average Training Loss: 0.6828402436027924, Training Accuracy: 0.7591145833333334\n",
            "Epoch 3/5, Batch Loss: 0.4728037714958191, Average Training Loss: 0.6785537849883644, Training Accuracy: 0.7608418367346939\n",
            "Epoch 3/5, Batch Loss: 0.40112999081611633, Average Training Loss: 0.6730053091049194, Training Accuracy: 0.76375\n",
            "Epoch 3/5, Batch Loss: 0.6965587735176086, Average Training Loss: 0.6734671417404624, Training Accuracy: 0.7634803921568627\n",
            "Epoch 3/5, Batch Loss: 0.3826410174369812, Average Training Loss: 0.6678743316577032, Training Accuracy: 0.7668269230769231\n",
            "Epoch 3/5, Batch Loss: 0.6523645520210266, Average Training Loss: 0.6675816943060677, Training Accuracy: 0.7665094339622641\n",
            "Epoch 3/5, Batch Loss: 0.6789534091949463, Average Training Loss: 0.6677922816188248, Training Accuracy: 0.7662037037037037\n",
            "Epoch 3/5, Batch Loss: 0.6723875999450684, Average Training Loss: 0.6678758328611201, Training Accuracy: 0.7659090909090909\n",
            "Epoch 3/5, Batch Loss: 0.5231258273124695, Average Training Loss: 0.6652910113334656, Training Accuracy: 0.7672991071428571\n",
            "Epoch 3/5, Batch Loss: 0.6560713052749634, Average Training Loss: 0.6651292621043691, Training Accuracy: 0.7664473684210527\n",
            "Epoch 3/5, Batch Loss: 0.8851641416549683, Average Training Loss: 0.6689229669242069, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Average Training Loss: 0.6689229669242069, Training Accuracy: 0.765625\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.73      0.72       358\n",
            "                Educational Opportunity       0.63      0.57      0.60       376\n",
            "                         Family Support       0.85      0.98      0.91       376\n",
            "                      Financial Support       0.80      0.78      0.79       376\n",
            "                 Program Implementation       0.80      0.77      0.79       370\n",
            "\n",
            "                               accuracy                           0.77      1856\n",
            "                              macro avg       0.76      0.77      0.76      1856\n",
            "                           weighted avg       0.76      0.77      0.76      1856\n",
            "\n",
            "Epoch 3/5, Validation Loss: 13.20050048828125, Validation Accuracy: 0.6681034482758621\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.68      0.67        99\n",
            "                Educational Opportunity       0.47      0.47      0.47        87\n",
            "                         Family Support       0.80      0.90      0.85        93\n",
            "                      Financial Support       0.72      0.67      0.70        89\n",
            "                 Program Implementation       0.66      0.60      0.63        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.67      0.66       464\n",
            "                           weighted avg       0.67      0.67      0.67       464\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.4496602416038513, Average Training Loss: 0.4496602416038513, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.3968268632888794, Average Training Loss: 0.42324355244636536, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.3432430028915405, Average Training Loss: 0.3965767025947571, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.38747313618659973, Average Training Loss: 0.39430081099271774, Training Accuracy: 0.890625\n",
            "Epoch 4/5, Batch Loss: 0.5310454964637756, Average Training Loss: 0.42164974808692934, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.47123122215270996, Average Training Loss: 0.42991332709789276, Training Accuracy: 0.8697916666666666\n",
            "Epoch 4/5, Batch Loss: 0.6453313827514648, Average Training Loss: 0.46068733504840303, Training Accuracy: 0.8526785714285714\n",
            "Epoch 4/5, Batch Loss: 0.4950147569179535, Average Training Loss: 0.46497826278209686, Training Accuracy: 0.84765625\n",
            "Epoch 4/5, Batch Loss: 0.5946319103240967, Average Training Loss: 0.47938422362009686, Training Accuracy: 0.8402777777777778\n",
            "Epoch 4/5, Batch Loss: 0.6251190900802612, Average Training Loss: 0.4939577102661133, Training Accuracy: 0.8375\n",
            "Epoch 4/5, Batch Loss: 0.2753998339176178, Average Training Loss: 0.47408881241625006, Training Accuracy: 0.8494318181818182\n",
            "Epoch 4/5, Batch Loss: 0.5505563616752625, Average Training Loss: 0.48046110818783444, Training Accuracy: 0.8489583333333334\n",
            "Epoch 4/5, Batch Loss: 0.42551490664482117, Average Training Loss: 0.4762344772999103, Training Accuracy: 0.8461538461538461\n",
            "Epoch 4/5, Batch Loss: 0.3273214101791382, Average Training Loss: 0.4655978296484266, Training Accuracy: 0.8504464285714286\n",
            "Epoch 4/5, Batch Loss: 0.4730444848537445, Average Training Loss: 0.4660942733287811, Training Accuracy: 0.85\n",
            "Epoch 4/5, Batch Loss: 0.34726500511169434, Average Training Loss: 0.4586674440652132, Training Accuracy: 0.85546875\n",
            "Epoch 4/5, Batch Loss: 0.5400196313858032, Average Training Loss: 0.46345286684877735, Training Accuracy: 0.8511029411764706\n",
            "Epoch 4/5, Batch Loss: 0.427224725484848, Average Training Loss: 0.46144019232855904, Training Accuracy: 0.8489583333333334\n",
            "Epoch 4/5, Batch Loss: 0.5163569450378418, Average Training Loss: 0.46433054773431076, Training Accuracy: 0.8486842105263158\n",
            "Epoch 4/5, Batch Loss: 0.378172904253006, Average Training Loss: 0.4600226655602455, Training Accuracy: 0.85\n",
            "Epoch 4/5, Batch Loss: 0.4706253409385681, Average Training Loss: 0.4605275548639752, Training Accuracy: 0.8497023809523809\n",
            "Epoch 4/5, Batch Loss: 0.49633920192718506, Average Training Loss: 0.462155357003212, Training Accuracy: 0.8508522727272727\n",
            "Epoch 4/5, Batch Loss: 0.4404284656047821, Average Training Loss: 0.4612107095511063, Training Accuracy: 0.8532608695652174\n",
            "Epoch 4/5, Batch Loss: 0.2109987586736679, Average Training Loss: 0.4507852115978797, Training Accuracy: 0.8567708333333334\n",
            "Epoch 4/5, Batch Loss: 0.2563505470752716, Average Training Loss: 0.4430078250169754, Training Accuracy: 0.86125\n",
            "Epoch 4/5, Batch Loss: 0.5653361082077026, Average Training Loss: 0.4477127589858495, Training Accuracy: 0.859375\n",
            "Epoch 4/5, Batch Loss: 0.3312825858592987, Average Training Loss: 0.4434005303515328, Training Accuracy: 0.8622685185185185\n",
            "Epoch 4/5, Batch Loss: 0.30759119987487793, Average Training Loss: 0.43855019712022375, Training Accuracy: 0.8638392857142857\n",
            "Epoch 4/5, Batch Loss: 0.5636865496635437, Average Training Loss: 0.44286524375964853, Training Accuracy: 0.8620689655172413\n",
            "Epoch 4/5, Batch Loss: 0.18418902158737183, Average Training Loss: 0.43424270302057266, Training Accuracy: 0.865625\n",
            "Epoch 4/5, Batch Loss: 0.5719105005264282, Average Training Loss: 0.4386835997143099, Training Accuracy: 0.8639112903225806\n",
            "Epoch 4/5, Batch Loss: 0.5070704817771912, Average Training Loss: 0.440820689778775, Training Accuracy: 0.86328125\n",
            "Epoch 4/5, Batch Loss: 0.42033886909484863, Average Training Loss: 0.4402000285459287, Training Accuracy: 0.8626893939393939\n",
            "Epoch 4/5, Batch Loss: 0.5138143301010132, Average Training Loss: 0.4423651550622547, Training Accuracy: 0.8612132352941176\n",
            "Epoch 4/5, Batch Loss: 0.49379080533981323, Average Training Loss: 0.44383445935589927, Training Accuracy: 0.8616071428571429\n",
            "Epoch 4/5, Batch Loss: 0.5577957034111023, Average Training Loss: 0.44700004946854377, Training Accuracy: 0.8611111111111112\n",
            "Epoch 4/5, Batch Loss: 0.3952871263027191, Average Training Loss: 0.4456024028964945, Training Accuracy: 0.8606418918918919\n",
            "Epoch 4/5, Batch Loss: 0.3031018376350403, Average Training Loss: 0.44185238802119303, Training Accuracy: 0.8626644736842105\n",
            "Epoch 4/5, Batch Loss: 0.5459575057029724, Average Training Loss: 0.44452175001303357, Training Accuracy: 0.8605769230769231\n",
            "Epoch 4/5, Batch Loss: 0.23766788840293884, Average Training Loss: 0.4393504034727812, Training Accuracy: 0.86328125\n",
            "Epoch 4/5, Batch Loss: 0.3024219870567322, Average Training Loss: 0.436010685999219, Training Accuracy: 0.8635670731707317\n",
            "Epoch 4/5, Batch Loss: 0.4135265648365021, Average Training Loss: 0.43547534978105906, Training Accuracy: 0.8630952380952381\n",
            "Epoch 4/5, Batch Loss: 0.4460518956184387, Average Training Loss: 0.43572131596332375, Training Accuracy: 0.8611918604651163\n",
            "Epoch 4/5, Batch Loss: 0.4616784155368805, Average Training Loss: 0.4363112500445409, Training Accuracy: 0.8607954545454546\n",
            "Epoch 4/5, Batch Loss: 0.3062259554862976, Average Training Loss: 0.4334204657210244, Training Accuracy: 0.8618055555555556\n",
            "Epoch 4/5, Batch Loss: 0.4601130485534668, Average Training Loss: 0.43400073926086014, Training Accuracy: 0.860733695652174\n",
            "Epoch 4/5, Batch Loss: 0.7275474071502686, Average Training Loss: 0.44024641304574114, Training Accuracy: 0.8583776595744681\n",
            "Epoch 4/5, Batch Loss: 0.40894925594329834, Average Training Loss: 0.43959438893944025, Training Accuracy: 0.8587239583333334\n",
            "Epoch 4/5, Batch Loss: 0.3016863763332367, Average Training Loss: 0.43677993970257895, Training Accuracy: 0.8603316326530612\n",
            "Epoch 4/5, Batch Loss: 0.29619336128234863, Average Training Loss: 0.43396820813417436, Training Accuracy: 0.861875\n",
            "Epoch 4/5, Batch Loss: 0.39568451046943665, Average Training Loss: 0.4332175473956501, Training Accuracy: 0.8615196078431373\n",
            "Epoch 4/5, Batch Loss: 0.40305376052856445, Average Training Loss: 0.43263747457128304, Training Accuracy: 0.8611778846153846\n",
            "Epoch 4/5, Batch Loss: 0.6351966857910156, Average Training Loss: 0.4364593464810893, Training Accuracy: 0.8590801886792453\n",
            "Epoch 4/5, Batch Loss: 0.35989564657211304, Average Training Loss: 0.43504150018647864, Training Accuracy: 0.859375\n",
            "Epoch 4/5, Batch Loss: 0.41056913137435913, Average Training Loss: 0.4345965480262583, Training Accuracy: 0.8596590909090909\n",
            "Epoch 4/5, Batch Loss: 0.43788471817970276, Average Training Loss: 0.4346552653504269, Training Accuracy: 0.8588169642857143\n",
            "Epoch 4/5, Batch Loss: 0.5690518617630005, Average Training Loss: 0.43701310037520896, Training Accuracy: 0.8569078947368421\n",
            "Epoch 4/5, Batch Loss: 0.40155941247940063, Average Training Loss: 0.43640182989424675, Training Accuracy: 0.8566810344827587\n",
            "Epoch 4/5, Average Training Loss: 0.43640182989424675, Training Accuracy: 0.8566810344827587\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.83      0.84      0.83       358\n",
            "                Educational Opportunity       0.76      0.75      0.75       376\n",
            "                         Family Support       0.91      0.97      0.94       376\n",
            "                      Financial Support       0.90      0.86      0.88       376\n",
            "                 Program Implementation       0.88      0.87      0.88       370\n",
            "\n",
            "                               accuracy                           0.86      1856\n",
            "                              macro avg       0.86      0.86      0.86      1856\n",
            "                           weighted avg       0.86      0.86      0.86      1856\n",
            "\n",
            "Epoch 4/5, Validation Loss: 14.427714169025421, Validation Accuracy: 0.6530172413793104\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.69      0.66        99\n",
            "                Educational Opportunity       0.45      0.46      0.46        87\n",
            "                         Family Support       0.75      0.92      0.83        93\n",
            "                      Financial Support       0.66      0.66      0.66        89\n",
            "                 Program Implementation       0.76      0.52      0.62        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.66      0.65      0.65       464\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.20982447266578674, Average Training Loss: 0.20982447266578674, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.17715105414390564, Average Training Loss: 0.1934877634048462, Training Accuracy: 0.953125\n",
            "Epoch 5/5, Batch Loss: 0.25480350852012634, Average Training Loss: 0.21392634510993958, Training Accuracy: 0.9583333333333334\n",
            "Epoch 5/5, Batch Loss: 0.5278716683387756, Average Training Loss: 0.2924126759171486, Training Accuracy: 0.921875\n",
            "Epoch 5/5, Batch Loss: 0.21161460876464844, Average Training Loss: 0.27625306248664855, Training Accuracy: 0.93125\n",
            "Epoch 5/5, Batch Loss: 0.3320558965206146, Average Training Loss: 0.2855535348256429, Training Accuracy: 0.9270833333333334\n",
            "Epoch 5/5, Batch Loss: 0.32368484139442444, Average Training Loss: 0.29100086433546885, Training Accuracy: 0.9151785714285714\n",
            "Epoch 5/5, Batch Loss: 0.425942599773407, Average Training Loss: 0.3078685812652111, Training Accuracy: 0.91015625\n",
            "Epoch 5/5, Batch Loss: 0.3255901634693146, Average Training Loss: 0.30983764595455593, Training Accuracy: 0.9027777777777778\n",
            "Epoch 5/5, Batch Loss: 0.18683111667633057, Average Training Loss: 0.2975369930267334, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.23524285852909088, Average Training Loss: 0.2918738898905841, Training Accuracy: 0.9119318181818182\n",
            "Epoch 5/5, Batch Loss: 0.508878231048584, Average Training Loss: 0.3099575849870841, Training Accuracy: 0.9036458333333334\n",
            "Epoch 5/5, Batch Loss: 0.2285698652267456, Average Training Loss: 0.3036969911593657, Training Accuracy: 0.9038461538461539\n",
            "Epoch 5/5, Batch Loss: 0.17703361809253693, Average Training Loss: 0.29464960736887796, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.3806811571121216, Average Training Loss: 0.3003850440184275, Training Accuracy: 0.9041666666666667\n",
            "Epoch 5/5, Batch Loss: 0.3359844982624054, Average Training Loss: 0.30261000990867615, Training Accuracy: 0.904296875\n",
            "Epoch 5/5, Batch Loss: 0.26864588260650635, Average Training Loss: 0.30061212006737204, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.33405545353889465, Average Training Loss: 0.3024700830380122, Training Accuracy: 0.9079861111111112\n",
            "Epoch 5/5, Batch Loss: 0.5156463980674744, Average Training Loss: 0.3136898890921944, Training Accuracy: 0.9029605263157895\n",
            "Epoch 5/5, Batch Loss: 0.1786278784275055, Average Training Loss: 0.30693678855895995, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.2243475317955017, Average Training Loss: 0.3030039668083191, Training Accuracy: 0.9077380952380952\n",
            "Epoch 5/5, Batch Loss: 0.40619587898254395, Average Training Loss: 0.3076945082707839, Training Accuracy: 0.9076704545454546\n",
            "Epoch 5/5, Batch Loss: 0.33208975195884705, Average Training Loss: 0.3087551710398301, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.18319359421730042, Average Training Loss: 0.3035234386722247, Training Accuracy: 0.9088541666666666\n",
            "Epoch 5/5, Batch Loss: 0.29372379183769226, Average Training Loss: 0.3031314527988434, Training Accuracy: 0.91\n",
            "Epoch 5/5, Batch Loss: 0.5681001543998718, Average Training Loss: 0.3133225567065753, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.19918885827064514, Average Training Loss: 0.3090953826904297, Training Accuracy: 0.9085648148148148\n",
            "Epoch 5/5, Batch Loss: 0.2053273618221283, Average Training Loss: 0.3053893819451332, Training Accuracy: 0.9095982142857143\n",
            "Epoch 5/5, Batch Loss: 0.1771748960018158, Average Training Loss: 0.300968192774674, Training Accuracy: 0.9116379310344828\n",
            "Epoch 5/5, Batch Loss: 0.2666432559490204, Average Training Loss: 0.29982402821381887, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.3360511362552643, Average Training Loss: 0.3009926446022526, Training Accuracy: 0.9133064516129032\n",
            "Epoch 5/5, Batch Loss: 0.31682854890823364, Average Training Loss: 0.3014875166118145, Training Accuracy: 0.9130859375\n",
            "Epoch 5/5, Batch Loss: 0.17512184381484985, Average Training Loss: 0.2976582537997853, Training Accuracy: 0.9138257575757576\n",
            "Epoch 5/5, Batch Loss: 0.3310571312904358, Average Training Loss: 0.29864057372598085, Training Accuracy: 0.9136029411764706\n",
            "Epoch 5/5, Batch Loss: 0.3578495383262634, Average Training Loss: 0.3003322584288461, Training Accuracy: 0.9133928571428571\n",
            "Epoch 5/5, Batch Loss: 0.35632753372192383, Average Training Loss: 0.3018876827425427, Training Accuracy: 0.9123263888888888\n",
            "Epoch 5/5, Batch Loss: 0.4153516888618469, Average Training Loss: 0.3049542775025239, Training Accuracy: 0.910472972972973\n",
            "Epoch 5/5, Batch Loss: 0.48552292585372925, Average Training Loss: 0.3097060840380819, Training Accuracy: 0.9095394736842105\n",
            "Epoch 5/5, Batch Loss: 0.4590887129306793, Average Training Loss: 0.3135364078558408, Training Accuracy: 0.9078525641025641\n",
            "Epoch 5/5, Batch Loss: 0.2631300687789917, Average Training Loss: 0.3122762493789196, Training Accuracy: 0.90859375\n",
            "Epoch 5/5, Batch Loss: 0.2944886386394501, Average Training Loss: 0.3118424052145423, Training Accuracy: 0.9085365853658537\n",
            "Epoch 5/5, Batch Loss: 0.3006197214126587, Average Training Loss: 0.3115751984573546, Training Accuracy: 0.9092261904761905\n",
            "Epoch 5/5, Batch Loss: 0.15957364439964294, Average Training Loss: 0.30804027859554733, Training Accuracy: 0.9113372093023255\n",
            "Epoch 5/5, Batch Loss: 0.45378249883651733, Average Training Loss: 0.31135260178284213, Training Accuracy: 0.9105113636363636\n",
            "Epoch 5/5, Batch Loss: 0.21813742816448212, Average Training Loss: 0.3092811534802119, Training Accuracy: 0.9104166666666667\n",
            "Epoch 5/5, Batch Loss: 0.3579942584037781, Average Training Loss: 0.31034013402202854, Training Accuracy: 0.9096467391304348\n",
            "Epoch 5/5, Batch Loss: 0.3063082695007324, Average Training Loss: 0.31025434967051163, Training Accuracy: 0.9082446808510638\n",
            "Epoch 5/5, Batch Loss: 0.2758506238460541, Average Training Loss: 0.3095376053825021, Training Accuracy: 0.9088541666666666\n",
            "Epoch 5/5, Batch Loss: 0.362995445728302, Average Training Loss: 0.3106285817160898, Training Accuracy: 0.9088010204081632\n",
            "Epoch 5/5, Batch Loss: 0.2946910560131073, Average Training Loss: 0.3103098312020302, Training Accuracy: 0.908125\n",
            "Epoch 5/5, Batch Loss: 0.17111191153526306, Average Training Loss: 0.307580460228172, Training Accuracy: 0.9087009803921569\n",
            "Epoch 5/5, Batch Loss: 0.1838550567626953, Average Training Loss: 0.3052011255461436, Training Accuracy: 0.9104567307692307\n",
            "Epoch 5/5, Batch Loss: 0.22155356407165527, Average Training Loss: 0.3036228696692665, Training Accuracy: 0.9109669811320755\n",
            "Epoch 5/5, Batch Loss: 0.5007386803627014, Average Training Loss: 0.3072731624598856, Training Accuracy: 0.9091435185185185\n",
            "Epoch 5/5, Batch Loss: 0.658383309841156, Average Training Loss: 0.31365698332136327, Training Accuracy: 0.9068181818181819\n",
            "Epoch 5/5, Batch Loss: 0.47799524664878845, Average Training Loss: 0.3165915951664959, Training Accuracy: 0.9056919642857143\n",
            "Epoch 5/5, Batch Loss: 0.16364315152168274, Average Training Loss: 0.3139082891376395, Training Accuracy: 0.9073464912280702\n",
            "Epoch 5/5, Batch Loss: 0.32032185792922974, Average Training Loss: 0.3140188679099083, Training Accuracy: 0.9067887931034483\n",
            "Epoch 5/5, Average Training Loss: 0.3140188679099083, Training Accuracy: 0.9067887931034483\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.88      0.90      0.89       358\n",
            "                Educational Opportunity       0.84      0.82      0.83       376\n",
            "                         Family Support       0.92      0.99      0.96       376\n",
            "                      Financial Support       0.96      0.90      0.93       376\n",
            "                 Program Implementation       0.93      0.92      0.93       370\n",
            "\n",
            "                               accuracy                           0.91      1856\n",
            "                              macro avg       0.91      0.91      0.91      1856\n",
            "                           weighted avg       0.91      0.91      0.91      1856\n",
            "\n",
            "Epoch 5/5, Validation Loss: 14.428444623947144, Validation Accuracy: 0.6551724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.60      0.62        99\n",
            "                Educational Opportunity       0.46      0.53      0.49        87\n",
            "                         Family Support       0.78      0.91      0.84        93\n",
            "                      Financial Support       0.69      0.67      0.68        89\n",
            "                 Program Implementation       0.70      0.56      0.62        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 6 - Updated Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n",
        "\n",
        "# ... (your subsequent code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeaF7Bk4AJbH",
        "outputId": "cd6ed772-91c5-498d-f425-a96b90019ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-3-4291fc259992>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.5823429822921753, Average Training Loss: 1.5823429822921753, Training Accuracy: 0.34375\n",
            "Epoch 1/1, Batch Loss: 1.653638243675232, Average Training Loss: 1.6179906129837036, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.654285192489624, Average Training Loss: 1.6300888061523438, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.6669721603393555, Average Training Loss: 1.6393096446990967, Training Accuracy: 0.203125\n",
            "Epoch 1/1, Batch Loss: 1.7101249694824219, Average Training Loss: 1.6534727096557618, Training Accuracy: 0.19375\n",
            "Epoch 1/1, Batch Loss: 1.5623457431793213, Average Training Loss: 1.6382848819096882, Training Accuracy: 0.19791666666666666\n",
            "Epoch 1/1, Batch Loss: 1.553162693977356, Average Training Loss: 1.6261245693479265, Training Accuracy: 0.22321428571428573\n",
            "Epoch 1/1, Batch Loss: 1.638692855834961, Average Training Loss: 1.6276956051588058, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.609021782875061, Average Training Loss: 1.6256207360161676, Training Accuracy: 0.22569444444444445\n",
            "Epoch 1/1, Batch Loss: 1.5688695907592773, Average Training Loss: 1.6199456214904786, Training Accuracy: 0.228125\n",
            "Epoch 1/1, Batch Loss: 1.613204836845398, Average Training Loss: 1.6193328228863804, Training Accuracy: 0.23011363636363635\n",
            "Epoch 1/1, Batch Loss: 1.6149259805679321, Average Training Loss: 1.6189655860265095, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/1, Batch Loss: 1.6420619487762451, Average Training Loss: 1.6207422293149507, Training Accuracy: 0.22596153846153846\n",
            "Epoch 1/1, Batch Loss: 1.6209716796875, Average Training Loss: 1.6207586186272758, Training Accuracy: 0.22767857142857142\n",
            "Epoch 1/1, Batch Loss: 1.5776671171188354, Average Training Loss: 1.6178858518600463, Training Accuracy: 0.23541666666666666\n",
            "Epoch 1/1, Batch Loss: 1.605936884880066, Average Training Loss: 1.6171390414237976, Training Accuracy: 0.236328125\n",
            "Epoch 1/1, Batch Loss: 1.5798192024230957, Average Training Loss: 1.6149437567766975, Training Accuracy: 0.23897058823529413\n",
            "Epoch 1/1, Batch Loss: 1.60281503200531, Average Training Loss: 1.6142699387338426, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.578289270401001, Average Training Loss: 1.6123762193479036, Training Accuracy: 0.24671052631578946\n",
            "Epoch 1/1, Batch Loss: 1.5691641569137573, Average Training Loss: 1.6102156162261962, Training Accuracy: 0.2484375\n",
            "Epoch 1/1, Batch Loss: 1.5771737098693848, Average Training Loss: 1.608642192113967, Training Accuracy: 0.25148809523809523\n",
            "Epoch 1/1, Batch Loss: 1.550865650177002, Average Training Loss: 1.6060159856622869, Training Accuracy: 0.2556818181818182\n",
            "Epoch 1/1, Batch Loss: 1.5418823957443237, Average Training Loss: 1.603227568709332, Training Accuracy: 0.25679347826086957\n",
            "Epoch 1/1, Batch Loss: 1.5635581016540527, Average Training Loss: 1.6015746742486954, Training Accuracy: 0.2578125\n",
            "Epoch 1/1, Batch Loss: 1.579041600227356, Average Training Loss: 1.6006733512878417, Training Accuracy: 0.25875\n",
            "Epoch 1/1, Batch Loss: 1.5625170469284058, Average Training Loss: 1.599205801120171, Training Accuracy: 0.25600961538461536\n",
            "Epoch 1/1, Batch Loss: 1.5797337293624878, Average Training Loss: 1.598484613277294, Training Accuracy: 0.25925925925925924\n",
            "Epoch 1/1, Batch Loss: 1.4819705486297607, Average Training Loss: 1.5943233966827393, Training Accuracy: 0.2611607142857143\n",
            "Epoch 1/1, Batch Loss: 1.4818342924118042, Average Training Loss: 1.590444462052707, Training Accuracy: 0.2661637931034483\n",
            "Epoch 1/1, Batch Loss: 1.525089979171753, Average Training Loss: 1.5882659792900085, Training Accuracy: 0.26875\n",
            "Epoch 1/1, Batch Loss: 1.394782304763794, Average Training Loss: 1.582024570434324, Training Accuracy: 0.27318548387096775\n",
            "Epoch 1/1, Batch Loss: 1.3267607688903809, Average Training Loss: 1.574047576636076, Training Accuracy: 0.279296875\n",
            "Epoch 1/1, Batch Loss: 1.4987531900405884, Average Training Loss: 1.5717659285574248, Training Accuracy: 0.2831439393939394\n",
            "Epoch 1/1, Batch Loss: 1.325775384902954, Average Training Loss: 1.5645309125675875, Training Accuracy: 0.2849264705882353\n",
            "Epoch 1/1, Batch Loss: 1.3524138927459717, Average Training Loss: 1.55847042628697, Training Accuracy: 0.29017857142857145\n",
            "Epoch 1/1, Batch Loss: 1.43537437915802, Average Training Loss: 1.555051091644499, Training Accuracy: 0.2925347222222222\n",
            "Epoch 1/1, Batch Loss: 1.5438295602798462, Average Training Loss: 1.5547478070130218, Training Accuracy: 0.2922297297297297\n",
            "Epoch 1/1, Batch Loss: 1.2739791870117188, Average Training Loss: 1.5473591591182507, Training Accuracy: 0.3001644736842105\n",
            "Epoch 1/1, Batch Loss: 1.4084330797195435, Average Training Loss: 1.5437969519541814, Training Accuracy: 0.30448717948717946\n",
            "Epoch 1/1, Batch Loss: 1.3296762704849243, Average Training Loss: 1.53844393491745, Training Accuracy: 0.309375\n",
            "Epoch 1/1, Batch Loss: 1.3315496444702148, Average Training Loss: 1.5333977327114199, Training Accuracy: 0.3132621951219512\n",
            "Epoch 1/1, Batch Loss: 1.3373528718948364, Average Training Loss: 1.5287299979300726, Training Accuracy: 0.3169642857142857\n",
            "Epoch 1/1, Batch Loss: 1.2157893180847168, Average Training Loss: 1.5214523077011108, Training Accuracy: 0.3241279069767442\n",
            "Epoch 1/1, Batch Loss: 1.410627841949463, Average Training Loss: 1.5189335698431188, Training Accuracy: 0.3252840909090909\n",
            "Epoch 1/1, Batch Loss: 1.1170881986618042, Average Training Loss: 1.5100036727057562, Training Accuracy: 0.33125\n",
            "Epoch 1/1, Batch Loss: 1.11509108543396, Average Training Loss: 1.5014186164607173, Training Accuracy: 0.3383152173913043\n",
            "Epoch 1/1, Batch Loss: 1.1531071662902832, Average Training Loss: 1.4940077345421974, Training Accuracy: 0.34375\n",
            "Epoch 1/1, Batch Loss: 1.2499393224716187, Average Training Loss: 1.4889229759573936, Training Accuracy: 0.3470052083333333\n",
            "Epoch 1/1, Batch Loss: 1.3568912744522095, Average Training Loss: 1.4862284514368798, Training Accuracy: 0.35012755102040816\n",
            "Epoch 1/1, Batch Loss: 1.2157361507415771, Average Training Loss: 1.4808186054229737, Training Accuracy: 0.35625\n",
            "Epoch 1/1, Batch Loss: 1.276606559753418, Average Training Loss: 1.4768144476647471, Training Accuracy: 0.3590686274509804\n",
            "Epoch 1/1, Batch Loss: 1.2124290466308594, Average Training Loss: 1.47173011302948, Training Accuracy: 0.36177884615384615\n",
            "Epoch 1/1, Batch Loss: 1.1772313117980957, Average Training Loss: 1.4661735318741709, Training Accuracy: 0.36497641509433965\n",
            "Epoch 1/1, Batch Loss: 1.2259390354156494, Average Training Loss: 1.4617247449027166, Training Accuracy: 0.36863425925925924\n",
            "Epoch 1/1, Batch Loss: 1.0186890363693237, Average Training Loss: 1.4536695502021095, Training Accuracy: 0.3744318181818182\n",
            "Epoch 1/1, Batch Loss: 1.2100355625152588, Average Training Loss: 1.44931894327913, Training Accuracy: 0.37723214285714285\n",
            "Epoch 1/1, Batch Loss: 1.0613895654678345, Average Training Loss: 1.4425131647210372, Training Accuracy: 0.38377192982456143\n",
            "Epoch 1/1, Batch Loss: 1.1620573997497559, Average Training Loss: 1.4376777204973945, Training Accuracy: 0.3879310344827586\n",
            "Epoch 1/1, Batch Loss: 1.19539475440979, Average Training Loss: 1.433571229546757, Training Accuracy: 0.3914194915254237\n",
            "Epoch 1/1, Batch Loss: 1.0094757080078125, Average Training Loss: 1.4265029708544412, Training Accuracy: 0.3958333333333333\n",
            "Epoch 1/1, Batch Loss: 1.0603035688400269, Average Training Loss: 1.4204997019689591, Training Accuracy: 0.40061475409836067\n",
            "Epoch 1/1, Batch Loss: 1.1673604249954224, Average Training Loss: 1.4164168104048698, Training Accuracy: 0.4027217741935484\n",
            "Epoch 1/1, Batch Loss: 0.8760899305343628, Average Training Loss: 1.407840193264068, Training Accuracy: 0.4087301587301587\n",
            "Epoch 1/1, Batch Loss: 0.9654509425163269, Average Training Loss: 1.4009278612211347, Training Accuracy: 0.41259765625\n",
            "Epoch 1/1, Batch Loss: 0.9624385237693787, Average Training Loss: 1.3941818714141845, Training Accuracy: 0.4168269230769231\n",
            "Epoch 1/1, Batch Loss: 1.1139366626739502, Average Training Loss: 1.3899357318878174, Training Accuracy: 0.41950757575757575\n",
            "Epoch 1/1, Batch Loss: 1.2580814361572266, Average Training Loss: 1.4076645561514198, Training Accuracy: 0.4195837275307474\n",
            "Epoch 1/1, Average Training Loss: 1.3879677573246743, Training Accuracy: 0.4195837275307474\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.42      0.44      0.43       427\n",
            "                Educational Opportunity       0.29      0.38      0.33       451\n",
            "                         Family Support       0.62      0.44      0.52       396\n",
            "                      Financial Support       0.47      0.28      0.35       404\n",
            "                 Program Implementation       0.44      0.55      0.49       436\n",
            "\n",
            "                               accuracy                           0.42      2114\n",
            "                              macro avg       0.45      0.42      0.42      2114\n",
            "                           weighted avg       0.44      0.42      0.42      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 18.629739224910736, Validation Accuracy: 0.6275992438563327\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.51      0.78      0.61       113\n",
            "                Educational Opportunity       0.47      0.33      0.39       100\n",
            "                         Family Support       0.78      0.92      0.84       105\n",
            "                      Financial Support       0.68      0.58      0.63        97\n",
            "                 Program Implementation       0.74      0.51      0.60       114\n",
            "\n",
            "                               accuracy                           0.63       529\n",
            "                              macro avg       0.64      0.62      0.61       529\n",
            "                           weighted avg       0.64      0.63      0.62       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 6 - Updated Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n",
        "\n",
        "# ... (your subsequent code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COwihslSWITm",
        "outputId": "e534773f-f3c0-4e05-ebc5-c558bb85e12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-4-75437aa32f4a>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.7262786626815796, Average Training Loss: 1.7262786626815796, Training Accuracy: 0.15625\n",
            "Epoch 1/5, Batch Loss: 1.6001033782958984, Average Training Loss: 1.663191020488739, Training Accuracy: 0.15625\n",
            "Epoch 1/5, Batch Loss: 1.6564273834228516, Average Training Loss: 1.6609364748001099, Training Accuracy: 0.1875\n",
            "Epoch 1/5, Batch Loss: 1.619482398033142, Average Training Loss: 1.650572955608368, Training Accuracy: 0.203125\n",
            "Epoch 1/5, Batch Loss: 1.5746512413024902, Average Training Loss: 1.6353886127471924, Training Accuracy: 0.23125\n",
            "Epoch 1/5, Batch Loss: 1.573506474494934, Average Training Loss: 1.6250749230384827, Training Accuracy: 0.2552083333333333\n",
            "Epoch 1/5, Batch Loss: 1.6406912803649902, Average Training Loss: 1.6273058312279838, Training Accuracy: 0.23660714285714285\n",
            "Epoch 1/5, Batch Loss: 1.568924903869629, Average Training Loss: 1.6200082153081894, Training Accuracy: 0.25\n",
            "Epoch 1/5, Batch Loss: 1.4675315618515015, Average Training Loss: 1.603066364924113, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/5, Batch Loss: 1.5780850648880005, Average Training Loss: 1.6005682349205017, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.6224586963653564, Average Training Loss: 1.602558276870034, Training Accuracy: 0.2784090909090909\n",
            "Epoch 1/5, Batch Loss: 1.506201982498169, Average Training Loss: 1.5945285856723785, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.4962252378463745, Average Training Loss: 1.5869667896857629, Training Accuracy: 0.28846153846153844\n",
            "Epoch 1/5, Batch Loss: 1.4645262956619263, Average Training Loss: 1.5782210401126318, Training Accuracy: 0.296875\n",
            "Epoch 1/5, Batch Loss: 1.4300897121429443, Average Training Loss: 1.5683456182479858, Training Accuracy: 0.3145833333333333\n",
            "Epoch 1/5, Batch Loss: 1.449262022972107, Average Training Loss: 1.5609028935432434, Training Accuracy: 0.326171875\n",
            "Epoch 1/5, Batch Loss: 1.3632792234420776, Average Training Loss: 1.5492779717725866, Training Accuracy: 0.3382352941176471\n",
            "Epoch 1/5, Batch Loss: 1.3107032775878906, Average Training Loss: 1.536023822095659, Training Accuracy: 0.3524305555555556\n",
            "Epoch 1/5, Batch Loss: 1.4097590446472168, Average Training Loss: 1.5293783074931095, Training Accuracy: 0.3569078947368421\n",
            "Epoch 1/5, Batch Loss: 1.4013131856918335, Average Training Loss: 1.5229750514030456, Training Accuracy: 0.359375\n",
            "Epoch 1/5, Batch Loss: 1.252667784690857, Average Training Loss: 1.5101032767977034, Training Accuracy: 0.37351190476190477\n",
            "Epoch 1/5, Batch Loss: 1.2500053644180298, Average Training Loss: 1.498280644416809, Training Accuracy: 0.3821022727272727\n",
            "Epoch 1/5, Batch Loss: 1.179890751838684, Average Training Loss: 1.4844376056090645, Training Accuracy: 0.39402173913043476\n",
            "Epoch 1/5, Batch Loss: 1.3632352352142334, Average Training Loss: 1.4793875068426132, Training Accuracy: 0.3984375\n",
            "Epoch 1/5, Batch Loss: 1.141971230506897, Average Training Loss: 1.4658908557891845, Training Accuracy: 0.40875\n",
            "Epoch 1/5, Batch Loss: 1.3098423480987549, Average Training Loss: 1.4598889901087835, Training Accuracy: 0.4110576923076923\n",
            "Epoch 1/5, Batch Loss: 1.0597352981567383, Average Training Loss: 1.4450684829994485, Training Accuracy: 0.4212962962962963\n",
            "Epoch 1/5, Batch Loss: 1.2049328088760376, Average Training Loss: 1.4364922089236123, Training Accuracy: 0.4252232142857143\n",
            "Epoch 1/5, Batch Loss: 1.1584975719451904, Average Training Loss: 1.426906186958839, Training Accuracy: 0.42887931034482757\n",
            "Epoch 1/5, Batch Loss: 1.144528865814209, Average Training Loss: 1.4174936095873514, Training Accuracy: 0.43333333333333335\n",
            "Epoch 1/5, Batch Loss: 1.024305820465088, Average Training Loss: 1.4048101325188913, Training Accuracy: 0.4405241935483871\n",
            "Epoch 1/5, Batch Loss: 0.9895352721214294, Average Training Loss: 1.3918327931314707, Training Accuracy: 0.447265625\n",
            "Epoch 1/5, Batch Loss: 1.3609676361083984, Average Training Loss: 1.3908974853428928, Training Accuracy: 0.4498106060606061\n",
            "Epoch 1/5, Batch Loss: 0.9728536009788513, Average Training Loss: 1.3786020769792444, Training Accuracy: 0.4577205882352941\n",
            "Epoch 1/5, Batch Loss: 0.9643322825431824, Average Training Loss: 1.3667657971382141, Training Accuracy: 0.46517857142857144\n",
            "Epoch 1/5, Batch Loss: 0.8349478840827942, Average Training Loss: 1.351993077331119, Training Accuracy: 0.4748263888888889\n",
            "Epoch 1/5, Batch Loss: 1.0167917013168335, Average Training Loss: 1.3429335806820843, Training Accuracy: 0.4780405405405405\n",
            "Epoch 1/5, Batch Loss: 0.9865434765815735, Average Training Loss: 1.333554893732071, Training Accuracy: 0.48273026315789475\n",
            "Epoch 1/5, Batch Loss: 0.8909074664115906, Average Training Loss: 1.3222049596982124, Training Accuracy: 0.48717948717948717\n",
            "Epoch 1/5, Batch Loss: 0.9974709749221802, Average Training Loss: 1.3140866100788116, Training Accuracy: 0.490625\n",
            "Epoch 1/5, Batch Loss: 1.0643985271453857, Average Training Loss: 1.3079966568365329, Training Accuracy: 0.4954268292682927\n",
            "Epoch 1/5, Batch Loss: 1.1814218759536743, Average Training Loss: 1.3049829715774173, Training Accuracy: 0.49776785714285715\n",
            "Epoch 1/5, Batch Loss: 0.6903685927391052, Average Training Loss: 1.2906896139300146, Training Accuracy: 0.5050872093023255\n",
            "Epoch 1/5, Batch Loss: 0.8898510336875916, Average Training Loss: 1.2815796461972324, Training Accuracy: 0.5085227272727273\n",
            "Epoch 1/5, Batch Loss: 0.9681673645973206, Average Training Loss: 1.2746149288283455, Training Accuracy: 0.5131944444444444\n",
            "Epoch 1/5, Batch Loss: 0.9253401756286621, Average Training Loss: 1.267021999410961, Training Accuracy: 0.5149456521739131\n",
            "Epoch 1/5, Batch Loss: 0.6375958919525146, Average Training Loss: 1.2536299545714196, Training Accuracy: 0.5206117021276596\n",
            "Epoch 1/5, Batch Loss: 0.8229519724845886, Average Training Loss: 1.2446574966112773, Training Accuracy: 0.5247395833333334\n",
            "Epoch 1/5, Batch Loss: 0.7316469550132751, Average Training Loss: 1.234187893721522, Training Accuracy: 0.5293367346938775\n",
            "Epoch 1/5, Batch Loss: 0.744439423084259, Average Training Loss: 1.2243929243087768, Training Accuracy: 0.533125\n",
            "Epoch 1/5, Batch Loss: 0.9752935767173767, Average Training Loss: 1.219508623375612, Training Accuracy: 0.5355392156862745\n",
            "Epoch 1/5, Batch Loss: 0.8674799203872681, Average Training Loss: 1.2127388406258364, Training Accuracy: 0.5390625\n",
            "Epoch 1/5, Batch Loss: 1.0963873863220215, Average Training Loss: 1.2105435301672738, Training Accuracy: 0.5412735849056604\n",
            "Epoch 1/5, Batch Loss: 1.0805184841156006, Average Training Loss: 1.2081356589440946, Training Accuracy: 0.5428240740740741\n",
            "Epoch 1/5, Batch Loss: 0.774599552154541, Average Training Loss: 1.2002531842751936, Training Accuracy: 0.5465909090909091\n",
            "Epoch 1/5, Batch Loss: 1.0126968622207642, Average Training Loss: 1.1969039642385073, Training Accuracy: 0.5474330357142857\n",
            "Epoch 1/5, Batch Loss: 0.7645987868309021, Average Training Loss: 1.1893196628804792, Training Accuracy: 0.5504385964912281\n",
            "Epoch 1/5, Batch Loss: 0.643356442451477, Average Training Loss: 1.1799065039075654, Training Accuracy: 0.5533405172413793\n",
            "Epoch 1/5, Batch Loss: 0.6828318238258362, Average Training Loss: 1.171481509329909, Training Accuracy: 0.5566737288135594\n",
            "Epoch 1/5, Batch Loss: 0.8761183023452759, Average Training Loss: 1.1665587892134985, Training Accuracy: 0.5583333333333333\n",
            "Epoch 1/5, Batch Loss: 0.8019974231719971, Average Training Loss: 1.1605823733767524, Training Accuracy: 0.5594262295081968\n",
            "Epoch 1/5, Batch Loss: 0.5672447681427002, Average Training Loss: 1.1510124120020098, Training Accuracy: 0.5650201612903226\n",
            "Epoch 1/5, Batch Loss: 0.9480738043785095, Average Training Loss: 1.1477911642619543, Training Accuracy: 0.5649801587301587\n",
            "Epoch 1/5, Batch Loss: 0.9259153604507446, Average Training Loss: 1.144324354827404, Training Accuracy: 0.56640625\n",
            "Epoch 1/5, Batch Loss: 0.89124995470047, Average Training Loss: 1.1404309025177588, Training Accuracy: 0.5677884615384615\n",
            "Epoch 1/5, Batch Loss: 0.7294019460678101, Average Training Loss: 1.134203191056396, Training Accuracy: 0.5700757575757576\n",
            "Epoch 1/5, Batch Loss: 1.706832766532898, Average Training Loss: 1.158966787152394, Training Accuracy: 0.5700094607379376\n",
            "Epoch 1/5, Average Training Loss: 1.1427499011381348, Training Accuracy: 0.5700094607379376\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.50      0.54      0.52       427\n",
            "                Educational Opportunity       0.48      0.52      0.50       451\n",
            "                         Family Support       0.64      0.75      0.69       396\n",
            "                      Financial Support       0.59      0.54      0.56       404\n",
            "                 Program Implementation       0.69      0.51      0.59       436\n",
            "\n",
            "                               accuracy                           0.57      2114\n",
            "                              macro avg       0.58      0.57      0.57      2114\n",
            "                           weighted avg       0.58      0.57      0.57      2114\n",
            "\n",
            "Epoch 1/5, Validation Loss: 13.594579458236694, Validation Accuracy: 0.6994328922495274\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.61      0.66      0.64       113\n",
            "                Educational Opportunity       0.55      0.52      0.53       100\n",
            "                         Family Support       0.89      0.96      0.93       105\n",
            "                      Financial Support       0.63      0.81      0.71        97\n",
            "                 Program Implementation       0.88      0.55      0.68       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.71      0.70      0.70       529\n",
            "                           weighted avg       0.71      0.70      0.70       529\n",
            "\n",
            "Epoch 2/5, Batch Loss: 0.635685920715332, Average Training Loss: 0.635685920715332, Training Accuracy: 0.8125\n",
            "Epoch 2/5, Batch Loss: 0.5706316828727722, Average Training Loss: 0.6031588017940521, Training Accuracy: 0.828125\n",
            "Epoch 2/5, Batch Loss: 0.8875827789306641, Average Training Loss: 0.6979667941729227, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/5, Batch Loss: 1.1687394380569458, Average Training Loss: 0.8156599551439285, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.8138781189918518, Average Training Loss: 0.8153035879135132, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.7955446839332581, Average Training Loss: 0.8120104372501373, Training Accuracy: 0.6979166666666666\n",
            "Epoch 2/5, Batch Loss: 0.7841424345970154, Average Training Loss: 0.808029294013977, Training Accuracy: 0.6964285714285714\n",
            "Epoch 2/5, Batch Loss: 0.839599609375, Average Training Loss: 0.8119755834341049, Training Accuracy: 0.69921875\n",
            "Epoch 2/5, Batch Loss: 0.7667573690414429, Average Training Loss: 0.8069513373904758, Training Accuracy: 0.7013888888888888\n",
            "Epoch 2/5, Batch Loss: 0.8201790452003479, Average Training Loss: 0.8082741081714631, Training Accuracy: 0.7\n",
            "Epoch 2/5, Batch Loss: 0.586999773979187, Average Training Loss: 0.7881582596085288, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.6958104372024536, Average Training Loss: 0.7804626077413559, Training Accuracy: 0.7161458333333334\n",
            "Epoch 2/5, Batch Loss: 0.7766377925872803, Average Training Loss: 0.7801683911910424, Training Accuracy: 0.7139423076923077\n",
            "Epoch 2/5, Batch Loss: 0.8137497901916504, Average Training Loss: 0.7825670625482287, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.6523084044456482, Average Training Loss: 0.7738831520080567, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.7946866750717163, Average Training Loss: 0.7751833721995354, Training Accuracy: 0.720703125\n",
            "Epoch 2/5, Batch Loss: 0.460060179233551, Average Training Loss: 0.7566467137897716, Training Accuracy: 0.7316176470588235\n",
            "Epoch 2/5, Batch Loss: 0.4140441119670868, Average Training Loss: 0.7376132359107336, Training Accuracy: 0.7447916666666666\n",
            "Epoch 2/5, Batch Loss: 0.6773736476898193, Average Training Loss: 0.7344427312675276, Training Accuracy: 0.7467105263157895\n",
            "Epoch 2/5, Batch Loss: 0.4092612862586975, Average Training Loss: 0.718183659017086, Training Accuracy: 0.75625\n",
            "Epoch 2/5, Batch Loss: 0.7446541786193848, Average Training Loss: 0.7194441599505288, Training Accuracy: 0.7559523809523809\n",
            "Epoch 2/5, Batch Loss: 0.8638792634010315, Average Training Loss: 0.7260093919255517, Training Accuracy: 0.75\n",
            "Epoch 2/5, Batch Loss: 0.5698838829994202, Average Training Loss: 0.7192213263200677, Training Accuracy: 0.751358695652174\n",
            "Epoch 2/5, Batch Loss: 0.5168782472610474, Average Training Loss: 0.7107903646926085, Training Accuracy: 0.7552083333333334\n",
            "Epoch 2/5, Batch Loss: 0.7410711646080017, Average Training Loss: 0.7120015966892242, Training Accuracy: 0.75375\n",
            "Epoch 2/5, Batch Loss: 0.49687275290489197, Average Training Loss: 0.7037274103898269, Training Accuracy: 0.7560096153846154\n",
            "Epoch 2/5, Batch Loss: 0.6878630518913269, Average Training Loss: 0.7031398415565491, Training Accuracy: 0.7557870370370371\n",
            "Epoch 2/5, Batch Loss: 0.694424033164978, Average Training Loss: 0.7028285626854215, Training Accuracy: 0.7555803571428571\n",
            "Epoch 2/5, Batch Loss: 0.7677262425422668, Average Training Loss: 0.7050664137149679, Training Accuracy: 0.7532327586206896\n",
            "Epoch 2/5, Batch Loss: 0.5114048719406128, Average Training Loss: 0.6986110289891561, Training Accuracy: 0.7552083333333334\n",
            "Epoch 2/5, Batch Loss: 0.5773575901985168, Average Training Loss: 0.6946996277378451, Training Accuracy: 0.7590725806451613\n",
            "Epoch 2/5, Batch Loss: 0.9836190938949585, Average Training Loss: 0.7037283610552549, Training Accuracy: 0.7548828125\n",
            "Epoch 2/5, Batch Loss: 0.5587804317474365, Average Training Loss: 0.6993359995610786, Training Accuracy: 0.7575757575757576\n",
            "Epoch 2/5, Batch Loss: 0.3194303512573242, Average Training Loss: 0.6881623040227329, Training Accuracy: 0.7628676470588235\n",
            "Epoch 2/5, Batch Loss: 0.5359242558479309, Average Training Loss: 0.6838126455034529, Training Accuracy: 0.7651785714285714\n",
            "Epoch 2/5, Batch Loss: 0.6149641871452332, Average Training Loss: 0.6819001883268356, Training Accuracy: 0.7647569444444444\n",
            "Epoch 2/5, Batch Loss: 0.5588040947914124, Average Training Loss: 0.6785732668799322, Training Accuracy: 0.7660472972972973\n",
            "Epoch 2/5, Batch Loss: 0.925313413143158, Average Training Loss: 0.6850664286237014, Training Accuracy: 0.7648026315789473\n",
            "Epoch 2/5, Batch Loss: 0.46004295349121094, Average Training Loss: 0.6792965959279965, Training Accuracy: 0.7660256410256411\n",
            "Epoch 2/5, Batch Loss: 0.5391785502433777, Average Training Loss: 0.675793644785881, Training Accuracy: 0.7671875\n",
            "Epoch 2/5, Batch Loss: 0.6380064487457275, Average Training Loss: 0.6748720058580724, Training Accuracy: 0.7675304878048781\n",
            "Epoch 2/5, Batch Loss: 0.6172178983688354, Average Training Loss: 0.6734992890130906, Training Accuracy: 0.7686011904761905\n",
            "Epoch 2/5, Batch Loss: 0.49254748225212097, Average Training Loss: 0.6692911074605099, Training Accuracy: 0.7710755813953488\n",
            "Epoch 2/5, Batch Loss: 0.7503819465637207, Average Training Loss: 0.671134081076492, Training Accuracy: 0.7713068181818182\n",
            "Epoch 2/5, Batch Loss: 0.7337825298309326, Average Training Loss: 0.6725262688265906, Training Accuracy: 0.76875\n",
            "Epoch 2/5, Batch Loss: 0.4279685318470001, Average Training Loss: 0.667209796283556, Training Accuracy: 0.7703804347826086\n",
            "Epoch 2/5, Batch Loss: 0.6968995332717896, Average Training Loss: 0.6678414928152206, Training Accuracy: 0.7699468085106383\n",
            "Epoch 2/5, Batch Loss: 0.511224091053009, Average Training Loss: 0.6645786302785078, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/5, Batch Loss: 0.6165761351585388, Average Training Loss: 0.6635989875209575, Training Accuracy: 0.7710459183673469\n",
            "Epoch 2/5, Batch Loss: 0.7145520448684692, Average Training Loss: 0.6646180486679077, Training Accuracy: 0.77\n",
            "Epoch 2/5, Batch Loss: 0.6532208919525146, Average Training Loss: 0.6643945750068215, Training Accuracy: 0.7702205882352942\n",
            "Epoch 2/5, Batch Loss: 0.783393919467926, Average Training Loss: 0.6666830239387659, Training Accuracy: 0.7692307692307693\n",
            "Epoch 2/5, Batch Loss: 0.750515341758728, Average Training Loss: 0.6682647657844255, Training Accuracy: 0.7682783018867925\n",
            "Epoch 2/5, Batch Loss: 0.6607838273048401, Average Training Loss: 0.6681262298866555, Training Accuracy: 0.7685185185185185\n",
            "Epoch 2/5, Batch Loss: 0.4507630169391632, Average Training Loss: 0.6641741714694284, Training Accuracy: 0.76875\n",
            "Epoch 2/5, Batch Loss: 0.9357059001922607, Average Training Loss: 0.669022952339479, Training Accuracy: 0.7661830357142857\n",
            "Epoch 2/5, Batch Loss: 0.8357998132705688, Average Training Loss: 0.6719488621803752, Training Accuracy: 0.7648026315789473\n",
            "Epoch 2/5, Batch Loss: 0.5751330852508545, Average Training Loss: 0.6702796246471077, Training Accuracy: 0.765625\n",
            "Epoch 2/5, Batch Loss: 0.533921480178833, Average Training Loss: 0.6679684696561199, Training Accuracy: 0.7648305084745762\n",
            "Epoch 2/5, Batch Loss: 0.3149396479129791, Average Training Loss: 0.6620846559604009, Training Accuracy: 0.7671875\n",
            "Epoch 2/5, Batch Loss: 0.5407392382621765, Average Training Loss: 0.6600953868178071, Training Accuracy: 0.7674180327868853\n",
            "Epoch 2/5, Batch Loss: 0.7581456303596497, Average Training Loss: 0.6616768423588045, Training Accuracy: 0.7661290322580645\n",
            "Epoch 2/5, Batch Loss: 0.7974263429641724, Average Training Loss: 0.6638315963366676, Training Accuracy: 0.7663690476190477\n",
            "Epoch 2/5, Batch Loss: 0.7836487889289856, Average Training Loss: 0.6657037399709225, Training Accuracy: 0.765625\n",
            "Epoch 2/5, Batch Loss: 0.8392354249954224, Average Training Loss: 0.6683734582020686, Training Accuracy: 0.7649038461538461\n",
            "Epoch 2/5, Batch Loss: 0.6651353240013123, Average Training Loss: 0.6683243955626632, Training Accuracy: 0.7651515151515151\n",
            "Epoch 2/5, Batch Loss: 0.03722982481122017, Average Training Loss: 0.6682556659518939, Training Accuracy: 0.7653736991485336\n",
            "Epoch 2/5, Average Training Loss: 0.6589050736111491, Training Accuracy: 0.7653736991485336\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.74      0.73       427\n",
            "                Educational Opportunity       0.65      0.64      0.65       451\n",
            "                         Family Support       0.91      0.97      0.94       396\n",
            "                      Financial Support       0.75      0.84      0.79       404\n",
            "                 Program Implementation       0.81      0.67      0.73       436\n",
            "\n",
            "                               accuracy                           0.77      2114\n",
            "                              macro avg       0.77      0.77      0.77      2114\n",
            "                           weighted avg       0.77      0.77      0.76      2114\n",
            "\n",
            "Epoch 2/5, Validation Loss: 13.014962434768677, Validation Accuracy: 0.7277882797731569\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.79      0.56      0.65       113\n",
            "                Educational Opportunity       0.52      0.73      0.61       100\n",
            "                         Family Support       0.93      0.88      0.90       105\n",
            "                      Financial Support       0.73      0.76      0.75        97\n",
            "                 Program Implementation       0.76      0.73      0.74       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.75      0.73      0.73       529\n",
            "                           weighted avg       0.75      0.73      0.73       529\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.5050349235534668, Average Training Loss: 0.5050349235534668, Training Accuracy: 0.75\n",
            "Epoch 3/5, Batch Loss: 0.4631403982639313, Average Training Loss: 0.48408766090869904, Training Accuracy: 0.84375\n",
            "Epoch 3/5, Batch Loss: 0.3794693648815155, Average Training Loss: 0.4492148955663045, Training Accuracy: 0.8645833333333334\n",
            "Epoch 3/5, Batch Loss: 0.6219721436500549, Average Training Loss: 0.4924042075872421, Training Accuracy: 0.8359375\n",
            "Epoch 3/5, Batch Loss: 0.3152981400489807, Average Training Loss: 0.45698299407958987, Training Accuracy: 0.85\n",
            "Epoch 3/5, Batch Loss: 0.43310293555259705, Average Training Loss: 0.45300298432509106, Training Accuracy: 0.8489583333333334\n",
            "Epoch 3/5, Batch Loss: 0.4258098006248474, Average Training Loss: 0.4491182437964848, Training Accuracy: 0.8526785714285714\n",
            "Epoch 3/5, Batch Loss: 0.4291209876537323, Average Training Loss: 0.44661858677864075, Training Accuracy: 0.84765625\n",
            "Epoch 3/5, Batch Loss: 0.2911316156387329, Average Training Loss: 0.42934225665198433, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/5, Batch Loss: 0.5502570867538452, Average Training Loss: 0.4414337396621704, Training Accuracy: 0.846875\n",
            "Epoch 3/5, Batch Loss: 0.3020856976509094, Average Training Loss: 0.42876573584296485, Training Accuracy: 0.8579545454545454\n",
            "Epoch 3/5, Batch Loss: 0.40287360548973083, Average Training Loss: 0.4266080583135287, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/5, Batch Loss: 0.5148198008537292, Average Training Loss: 0.4333935769704672, Training Accuracy: 0.8509615384615384\n",
            "Epoch 3/5, Batch Loss: 0.4763079583644867, Average Training Loss: 0.4364588899271829, Training Accuracy: 0.8482142857142857\n",
            "Epoch 3/5, Batch Loss: 0.585396945476532, Average Training Loss: 0.4463880936304728, Training Accuracy: 0.8458333333333333\n",
            "Epoch 3/5, Batch Loss: 0.39302852749824524, Average Training Loss: 0.4430531207472086, Training Accuracy: 0.845703125\n",
            "Epoch 3/5, Batch Loss: 0.29869571328163147, Average Training Loss: 0.4345615085433511, Training Accuracy: 0.8511029411764706\n",
            "Epoch 3/5, Batch Loss: 0.6159636974334717, Average Training Loss: 0.4446394079261356, Training Accuracy: 0.8454861111111112\n",
            "Epoch 3/5, Batch Loss: 0.32085323333740234, Average Training Loss: 0.43812434610567597, Training Accuracy: 0.8486842105263158\n",
            "Epoch 3/5, Batch Loss: 0.4322602152824402, Average Training Loss: 0.43783113956451414, Training Accuracy: 0.8515625\n",
            "Epoch 3/5, Batch Loss: 0.46672552824020386, Average Training Loss: 0.4392070628347851, Training Accuracy: 0.8511904761904762\n",
            "Epoch 3/5, Batch Loss: 0.45976966619491577, Average Training Loss: 0.44014172662388196, Training Accuracy: 0.8536931818181818\n",
            "Epoch 3/5, Batch Loss: 0.43701261281967163, Average Training Loss: 0.44000567819761194, Training Accuracy: 0.8505434782608695\n",
            "Epoch 3/5, Batch Loss: 0.5578182935714722, Average Training Loss: 0.4449145371715228, Training Accuracy: 0.8489583333333334\n",
            "Epoch 3/5, Batch Loss: 0.5048108696937561, Average Training Loss: 0.4473103904724121, Training Accuracy: 0.8475\n",
            "Epoch 3/5, Batch Loss: 0.5288079977035522, Average Training Loss: 0.45044491382745594, Training Accuracy: 0.8461538461538461\n",
            "Epoch 3/5, Batch Loss: 0.45238369703292847, Average Training Loss: 0.4505167206128438, Training Accuracy: 0.8472222222222222\n",
            "Epoch 3/5, Batch Loss: 0.47118014097213745, Average Training Loss: 0.45125469991139006, Training Accuracy: 0.8470982142857143\n",
            "Epoch 3/5, Batch Loss: 0.4427372217178345, Average Training Loss: 0.45096099376678467, Training Accuracy: 0.8469827586206896\n",
            "Epoch 3/5, Batch Loss: 0.430403470993042, Average Training Loss: 0.45027574300765993, Training Accuracy: 0.8458333333333333\n",
            "Epoch 3/5, Batch Loss: 0.5028344988822937, Average Training Loss: 0.4519711867455513, Training Accuracy: 0.8457661290322581\n",
            "Epoch 3/5, Batch Loss: 0.39121517539024353, Average Training Loss: 0.45007256139069796, Training Accuracy: 0.845703125\n",
            "Epoch 3/5, Batch Loss: 0.43310078978538513, Average Training Loss: 0.44955826528144605, Training Accuracy: 0.8456439393939394\n",
            "Epoch 3/5, Batch Loss: 0.3773931860923767, Average Training Loss: 0.44743576295235576, Training Accuracy: 0.8455882352941176\n",
            "Epoch 3/5, Batch Loss: 0.3495487868785858, Average Training Loss: 0.44463899220739095, Training Accuracy: 0.8473214285714286\n",
            "Epoch 3/5, Batch Loss: 0.5647603273391724, Average Training Loss: 0.4479756959610515, Training Accuracy: 0.8454861111111112\n",
            "Epoch 3/5, Batch Loss: 0.4104674160480499, Average Training Loss: 0.44696195866610555, Training Accuracy: 0.8462837837837838\n",
            "Epoch 3/5, Batch Loss: 0.4352186918258667, Average Training Loss: 0.4466529253282045, Training Accuracy: 0.8470394736842105\n",
            "Epoch 3/5, Batch Loss: 0.5549432635307312, Average Training Loss: 0.4494296006667308, Training Accuracy: 0.8453525641025641\n",
            "Epoch 3/5, Batch Loss: 0.476299524307251, Average Training Loss: 0.4501013487577438, Training Accuracy: 0.8453125\n",
            "Epoch 3/5, Batch Loss: 0.25918853282928467, Average Training Loss: 0.44544493861314727, Training Accuracy: 0.8483231707317073\n",
            "Epoch 3/5, Batch Loss: 0.5030470490455627, Average Training Loss: 0.4468164174329667, Training Accuracy: 0.8474702380952381\n",
            "Epoch 3/5, Batch Loss: 0.49976712465286255, Average Training Loss: 0.4480478292287782, Training Accuracy: 0.846656976744186\n",
            "Epoch 3/5, Batch Loss: 0.44648438692092896, Average Training Loss: 0.4480122964490544, Training Accuracy: 0.8465909090909091\n",
            "Epoch 3/5, Batch Loss: 0.5929965972900391, Average Training Loss: 0.4512341698010763, Training Accuracy: 0.8451388888888889\n",
            "Epoch 3/5, Batch Loss: 0.2445649951696396, Average Training Loss: 0.4467413616569146, Training Accuracy: 0.8457880434782609\n",
            "Epoch 3/5, Batch Loss: 0.38595640659332275, Average Training Loss: 0.44544806474066795, Training Accuracy: 0.8464095744680851\n",
            "Epoch 3/5, Batch Loss: 0.260898232460022, Average Training Loss: 0.4416032765681545, Training Accuracy: 0.84765625\n",
            "Epoch 3/5, Batch Loss: 0.5863276124000549, Average Training Loss: 0.4445568344422749, Training Accuracy: 0.8456632653061225\n",
            "Epoch 3/5, Batch Loss: 0.514845073223114, Average Training Loss: 0.4459625992178917, Training Accuracy: 0.845\n",
            "Epoch 3/5, Batch Loss: 0.37468421459198, Average Training Loss: 0.4445649838330699, Training Accuracy: 0.8455882352941176\n",
            "Epoch 3/5, Batch Loss: 0.716256856918335, Average Training Loss: 0.4497898275462481, Training Accuracy: 0.8431490384615384\n",
            "Epoch 3/5, Batch Loss: 0.3315180540084839, Average Training Loss: 0.44755828464930913, Training Accuracy: 0.8431603773584906\n",
            "Epoch 3/5, Batch Loss: 0.419904500246048, Average Training Loss: 0.4470461775307302, Training Accuracy: 0.8431712962962963\n",
            "Epoch 3/5, Batch Loss: 0.28933054208755493, Average Training Loss: 0.4441786205226725, Training Accuracy: 0.8448863636363636\n",
            "Epoch 3/5, Batch Loss: 0.4427395164966583, Average Training Loss: 0.44415292223649366, Training Accuracy: 0.8454241071428571\n",
            "Epoch 3/5, Batch Loss: 0.3376808762550354, Average Training Loss: 0.44228499160524, Training Accuracy: 0.8453947368421053\n",
            "Epoch 3/5, Batch Loss: 0.29803407192230225, Average Training Loss: 0.43979790678312036, Training Accuracy: 0.8469827586206896\n",
            "Epoch 3/5, Batch Loss: 0.4398384392261505, Average Training Loss: 0.4397985937736802, Training Accuracy: 0.847457627118644\n",
            "Epoch 3/5, Batch Loss: 0.40404316782951355, Average Training Loss: 0.4392026700079441, Training Accuracy: 0.8473958333333333\n",
            "Epoch 3/5, Batch Loss: 0.45864585041999817, Average Training Loss: 0.4395214106704368, Training Accuracy: 0.8468237704918032\n",
            "Epoch 3/5, Batch Loss: 0.2756565511226654, Average Training Loss: 0.4368784290648276, Training Accuracy: 0.8477822580645161\n",
            "Epoch 3/5, Batch Loss: 0.455395370721817, Average Training Loss: 0.4371723487736687, Training Accuracy: 0.8472222222222222\n",
            "Epoch 3/5, Batch Loss: 0.35579830408096313, Average Training Loss: 0.43590087932534516, Training Accuracy: 0.84814453125\n",
            "Epoch 3/5, Batch Loss: 0.6306850910186768, Average Training Loss: 0.43889755950524256, Training Accuracy: 0.8475961538461538\n",
            "Epoch 3/5, Batch Loss: 0.5171800255775452, Average Training Loss: 0.440083657476035, Training Accuracy: 0.8475378787878788\n",
            "Epoch 3/5, Batch Loss: 0.027104228734970093, Average Training Loss: 0.44007758746873465, Training Accuracy: 0.847682119205298\n",
            "Epoch 3/5, Average Training Loss: 0.4339197854052729, Training Accuracy: 0.847682119205298\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.85      0.87      0.86       427\n",
            "                Educational Opportunity       0.75      0.76      0.76       451\n",
            "                         Family Support       0.93      0.97      0.95       396\n",
            "                      Financial Support       0.86      0.89      0.88       404\n",
            "                 Program Implementation       0.85      0.77      0.80       436\n",
            "\n",
            "                               accuracy                           0.85      2114\n",
            "                              macro avg       0.85      0.85      0.85      2114\n",
            "                           weighted avg       0.85      0.85      0.85      2114\n",
            "\n",
            "Epoch 3/5, Validation Loss: 13.821199029684067, Validation Accuracy: 0.7164461247637051\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.63      0.67       113\n",
            "                Educational Opportunity       0.46      0.70      0.55       100\n",
            "                         Family Support       0.89      0.96      0.93       105\n",
            "                      Financial Support       0.77      0.66      0.71        97\n",
            "                 Program Implementation       0.90      0.64      0.75       114\n",
            "\n",
            "                               accuracy                           0.72       529\n",
            "                              macro avg       0.75      0.72      0.72       529\n",
            "                           weighted avg       0.75      0.72      0.72       529\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.3467502295970917, Average Training Loss: 0.3467502295970917, Training Accuracy: 0.84375\n",
            "Epoch 4/5, Batch Loss: 0.19820243120193481, Average Training Loss: 0.27247633039951324, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.4210337698459625, Average Training Loss: 0.321995476881663, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/5, Batch Loss: 0.17833451926708221, Average Training Loss: 0.2860802374780178, Training Accuracy: 0.9140625\n",
            "Epoch 4/5, Batch Loss: 0.41063034534454346, Average Training Loss: 0.31099025905132294, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.2890746295452118, Average Training Loss: 0.3073376541336377, Training Accuracy: 0.9010416666666666\n",
            "Epoch 4/5, Batch Loss: 0.27580785751342773, Average Training Loss: 0.30283339747360777, Training Accuracy: 0.9017857142857143\n",
            "Epoch 4/5, Batch Loss: 0.10973144322633743, Average Training Loss: 0.27869565319269896, Training Accuracy: 0.9140625\n",
            "Epoch 4/5, Batch Loss: 0.2311292141675949, Average Training Loss: 0.27341049330102074, Training Accuracy: 0.9097222222222222\n",
            "Epoch 4/5, Batch Loss: 0.5024137496948242, Average Training Loss: 0.29631081894040107, Training Accuracy: 0.896875\n",
            "Epoch 4/5, Batch Loss: 0.273296594619751, Average Training Loss: 0.2942186167294329, Training Accuracy: 0.9034090909090909\n",
            "Epoch 4/5, Batch Loss: 0.23364785313606262, Average Training Loss: 0.28917105309665203, Training Accuracy: 0.9036458333333334\n",
            "Epoch 4/5, Batch Loss: 0.24922175705432892, Average Training Loss: 0.28609803032416564, Training Accuracy: 0.9038461538461539\n",
            "Epoch 4/5, Batch Loss: 0.3052380084991455, Average Training Loss: 0.2874651716223785, Training Accuracy: 0.9040178571428571\n",
            "Epoch 4/5, Batch Loss: 0.3295195400714874, Average Training Loss: 0.29026879618565243, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.3456636369228363, Average Training Loss: 0.2937309737317264, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.37852832674980164, Average Training Loss: 0.29871905332102494, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.37248432636260986, Average Training Loss: 0.30281712404555744, Training Accuracy: 0.9027777777777778\n",
            "Epoch 4/5, Batch Loss: 0.6234155297279358, Average Training Loss: 0.31969072434463, Training Accuracy: 0.8930921052631579\n",
            "Epoch 4/5, Batch Loss: 0.22655044496059418, Average Training Loss: 0.3150337103754282, Training Accuracy: 0.89375\n",
            "Epoch 4/5, Batch Loss: 0.29735538363456726, Average Training Loss: 0.31419188529253006, Training Accuracy: 0.8928571428571429\n",
            "Epoch 4/5, Batch Loss: 0.18550848960876465, Average Training Loss: 0.3083426400341771, Training Accuracy: 0.8948863636363636\n",
            "Epoch 4/5, Batch Loss: 0.3440520763397217, Average Training Loss: 0.30989522422137467, Training Accuracy: 0.8926630434782609\n",
            "Epoch 4/5, Batch Loss: 0.12902289628982544, Average Training Loss: 0.3023588772242268, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/5, Batch Loss: 0.38215070962905884, Average Training Loss: 0.30555055052042007, Training Accuracy: 0.89625\n",
            "Epoch 4/5, Batch Loss: 0.24026724696159363, Average Training Loss: 0.303039654229696, Training Accuracy: 0.8966346153846154\n",
            "Epoch 4/5, Batch Loss: 0.3180156946182251, Average Training Loss: 0.3035943223922341, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/5, Batch Loss: 0.19561907649040222, Average Training Loss: 0.2997380636100258, Training Accuracy: 0.8984375\n",
            "Epoch 4/5, Batch Loss: 0.5012004375457764, Average Training Loss: 0.3066850420216034, Training Accuracy: 0.8976293103448276\n",
            "Epoch 4/5, Batch Loss: 0.2555913031101227, Average Training Loss: 0.3049819173912207, Training Accuracy: 0.8979166666666667\n",
            "Epoch 4/5, Batch Loss: 0.26117637753486633, Average Training Loss: 0.3035688354603706, Training Accuracy: 0.8981854838709677\n",
            "Epoch 4/5, Batch Loss: 0.4259294271469116, Average Training Loss: 0.307392603950575, Training Accuracy: 0.896484375\n",
            "Epoch 4/5, Batch Loss: 0.13915646076202393, Average Training Loss: 0.3022945390054674, Training Accuracy: 0.8977272727272727\n",
            "Epoch 4/5, Batch Loss: 0.17689156532287598, Average Training Loss: 0.29860621625009703, Training Accuracy: 0.8979779411764706\n",
            "Epoch 4/5, Batch Loss: 0.22892169654369354, Average Training Loss: 0.29661522997277123, Training Accuracy: 0.8991071428571429\n",
            "Epoch 4/5, Batch Loss: 0.10150445997714996, Average Training Loss: 0.2911954863617818, Training Accuracy: 0.9019097222222222\n",
            "Epoch 4/5, Batch Loss: 0.18699027597904205, Average Training Loss: 0.2883791293244104, Training Accuracy: 0.9028716216216216\n",
            "Epoch 4/5, Batch Loss: 0.149139866232872, Average Training Loss: 0.28471493819042254, Training Accuracy: 0.9046052631578947\n",
            "Epoch 4/5, Batch Loss: 0.3951932489871979, Average Training Loss: 0.28754771539033985, Training Accuracy: 0.9030448717948718\n",
            "Epoch 4/5, Batch Loss: 0.40127041935920715, Average Training Loss: 0.29039078298956156, Training Accuracy: 0.9015625\n",
            "Epoch 4/5, Batch Loss: 0.2534657418727875, Average Training Loss: 0.28949017223061585, Training Accuracy: 0.9016768292682927\n",
            "Epoch 4/5, Batch Loss: 0.36294955015182495, Average Training Loss: 0.29123920503826367, Training Accuracy: 0.9010416666666666\n",
            "Epoch 4/5, Batch Loss: 0.1644137054681778, Average Training Loss: 0.28828977481570356, Training Accuracy: 0.9018895348837209\n",
            "Epoch 4/5, Batch Loss: 0.2189008742570877, Average Training Loss: 0.2867127543484623, Training Accuracy: 0.9034090909090909\n",
            "Epoch 4/5, Batch Loss: 0.3698990046977997, Average Training Loss: 0.28856133768955866, Training Accuracy: 0.9027777777777778\n",
            "Epoch 4/5, Batch Loss: 0.30548086762428284, Average Training Loss: 0.2889291535577048, Training Accuracy: 0.9028532608695652\n",
            "Epoch 4/5, Batch Loss: 0.29879915714263916, Average Training Loss: 0.28913915363398, Training Accuracy: 0.9029255319148937\n",
            "Epoch 4/5, Batch Loss: 0.22053629159927368, Average Training Loss: 0.28770992734159034, Training Accuracy: 0.9029947916666666\n",
            "Epoch 4/5, Batch Loss: 0.12651877105236053, Average Training Loss: 0.28442031190711625, Training Accuracy: 0.9043367346938775\n",
            "Epoch 4/5, Batch Loss: 0.21647092700004578, Average Training Loss: 0.28306132420897484, Training Accuracy: 0.905625\n",
            "Epoch 4/5, Batch Loss: 0.4894929826259613, Average Training Loss: 0.28710900378577847, Training Accuracy: 0.9044117647058824\n",
            "Epoch 4/5, Batch Loss: 0.23506033420562744, Average Training Loss: 0.2861080678323141, Training Accuracy: 0.9044471153846154\n",
            "Epoch 4/5, Batch Loss: 0.18961447477340698, Average Training Loss: 0.2842874340010139, Training Accuracy: 0.9050707547169812\n",
            "Epoch 4/5, Batch Loss: 0.1186119094491005, Average Training Loss: 0.281219368731534, Training Accuracy: 0.90625\n",
            "Epoch 4/5, Batch Loss: 0.19828598201274872, Average Training Loss: 0.2797114889730107, Training Accuracy: 0.9068181818181819\n",
            "Epoch 4/5, Batch Loss: 0.15387016534805298, Average Training Loss: 0.27746432247970787, Training Accuracy: 0.9084821428571429\n",
            "Epoch 4/5, Batch Loss: 0.16343697905540466, Average Training Loss: 0.27546384277050956, Training Accuracy: 0.9089912280701754\n",
            "Epoch 4/5, Batch Loss: 0.4021061658859253, Average Training Loss: 0.27764733110008566, Training Accuracy: 0.9084051724137931\n",
            "Epoch 4/5, Batch Loss: 0.13408216834068298, Average Training Loss: 0.27521402325670596, Training Accuracy: 0.909427966101695\n",
            "Epoch 4/5, Batch Loss: 0.32271283864974976, Average Training Loss: 0.2760056701799234, Training Accuracy: 0.9088541666666666\n",
            "Epoch 4/5, Batch Loss: 0.2707864046096802, Average Training Loss: 0.2759201084492636, Training Accuracy: 0.9082991803278688\n",
            "Epoch 4/5, Batch Loss: 0.222499281167984, Average Training Loss: 0.2750584822027914, Training Accuracy: 0.9087701612903226\n",
            "Epoch 4/5, Batch Loss: 0.5425821542739868, Average Training Loss: 0.279304889695985, Training Accuracy: 0.9072420634920635\n",
            "Epoch 4/5, Batch Loss: 0.16487519443035126, Average Training Loss: 0.27751692570745945, Training Accuracy: 0.9072265625\n",
            "Epoch 4/5, Batch Loss: 0.2798342704772949, Average Training Loss: 0.2775525771654569, Training Accuracy: 0.9072115384615385\n",
            "Epoch 4/5, Batch Loss: 0.12145012617111206, Average Training Loss: 0.27518738851402746, Training Accuracy: 0.9081439393939394\n",
            "Epoch 4/5, Batch Loss: 0.7284029126167297, Average Training Loss: 0.28595300744813684, Training Accuracy: 0.9077578051087984\n",
            "Epoch 4/5, Average Training Loss: 0.28195179932153047, Training Accuracy: 0.9077578051087984\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.93      0.94      0.93       427\n",
            "                Educational Opportunity       0.82      0.86      0.84       451\n",
            "                         Family Support       0.98      0.99      0.98       396\n",
            "                      Financial Support       0.92      0.93      0.93       404\n",
            "                 Program Implementation       0.91      0.83      0.87       436\n",
            "\n",
            "                               accuracy                           0.91      2114\n",
            "                              macro avg       0.91      0.91      0.91      2114\n",
            "                           weighted avg       0.91      0.91      0.91      2114\n",
            "\n",
            "Epoch 4/5, Validation Loss: 14.09956830739975, Validation Accuracy: 0.7391304347826086\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.68      0.67       113\n",
            "                Educational Opportunity       0.58      0.51      0.54       100\n",
            "                         Family Support       0.92      0.92      0.92       105\n",
            "                      Financial Support       0.73      0.78      0.76        97\n",
            "                 Program Implementation       0.78      0.79      0.78       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.73      0.74      0.74       529\n",
            "                           weighted avg       0.74      0.74      0.74       529\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.18610309064388275, Average Training Loss: 0.18610309064388275, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.2340451180934906, Average Training Loss: 0.21007410436868668, Training Accuracy: 0.921875\n",
            "Epoch 5/5, Batch Loss: 0.2056587189435959, Average Training Loss: 0.20860230922698975, Training Accuracy: 0.9270833333333334\n",
            "Epoch 5/5, Batch Loss: 0.18859340250492096, Average Training Loss: 0.20360008254647255, Training Accuracy: 0.9296875\n",
            "Epoch 5/5, Batch Loss: 0.13053609430789948, Average Training Loss: 0.18898728489875793, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.2111910879611969, Average Training Loss: 0.19268791874249777, Training Accuracy: 0.9322916666666666\n",
            "Epoch 5/5, Batch Loss: 0.2257808893918991, Average Training Loss: 0.19741548597812653, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.07440651208162308, Average Training Loss: 0.1820393642410636, Training Accuracy: 0.9453125\n",
            "Epoch 5/5, Batch Loss: 0.29894882440567017, Average Training Loss: 0.19502930425935322, Training Accuracy: 0.9409722222222222\n",
            "Epoch 5/5, Batch Loss: 0.3167351484298706, Average Training Loss: 0.20719988867640496, Training Accuracy: 0.940625\n",
            "Epoch 5/5, Batch Loss: 0.11894689500331879, Average Training Loss: 0.19917688925157895, Training Accuracy: 0.9431818181818182\n",
            "Epoch 5/5, Batch Loss: 0.11737969517707825, Average Training Loss: 0.19236045641203722, Training Accuracy: 0.9479166666666666\n",
            "Epoch 5/5, Batch Loss: 0.2775250971317291, Average Training Loss: 0.19891158262124428, Training Accuracy: 0.9447115384615384\n",
            "Epoch 5/5, Batch Loss: 0.4023131728172302, Average Training Loss: 0.2134402676352433, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.37079739570617676, Average Training Loss: 0.2239307428399722, Training Accuracy: 0.9270833333333334\n",
            "Epoch 5/5, Batch Loss: 0.2318851202726364, Average Training Loss: 0.2244278914295137, Training Accuracy: 0.927734375\n",
            "Epoch 5/5, Batch Loss: 0.07031804323196411, Average Training Loss: 0.21536260624142253, Training Accuracy: 0.9319852941176471\n",
            "Epoch 5/5, Batch Loss: 0.179093599319458, Average Training Loss: 0.2133476614124245, Training Accuracy: 0.9305555555555556\n",
            "Epoch 5/5, Batch Loss: 0.1904117316007614, Average Training Loss: 0.21214050721181066, Training Accuracy: 0.930921052631579\n",
            "Epoch 5/5, Batch Loss: 0.10016392916440964, Average Training Loss: 0.20654167830944062, Training Accuracy: 0.9328125\n",
            "Epoch 5/5, Batch Loss: 0.1204848513007164, Average Training Loss: 0.20244373416616804, Training Accuracy: 0.9360119047619048\n",
            "Epoch 5/5, Batch Loss: 0.35821735858917236, Average Training Loss: 0.2095243534581228, Training Accuracy: 0.9318181818181818\n",
            "Epoch 5/5, Batch Loss: 0.07966186106204987, Average Training Loss: 0.20387815813655438, Training Accuracy: 0.9347826086956522\n",
            "Epoch 5/5, Batch Loss: 0.1410522609949112, Average Training Loss: 0.20126041242231926, Training Accuracy: 0.9348958333333334\n",
            "Epoch 5/5, Batch Loss: 0.0966106727719307, Average Training Loss: 0.19707442283630372, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.21307644248008728, Average Training Loss: 0.1976898851302954, Training Accuracy: 0.9350961538461539\n",
            "Epoch 5/5, Batch Loss: 0.10501052439212799, Average Training Loss: 0.19425731621406697, Training Accuracy: 0.9363425925925926\n",
            "Epoch 5/5, Batch Loss: 0.1644098311662674, Average Training Loss: 0.19319133460521698, Training Accuracy: 0.9363839285714286\n",
            "Epoch 5/5, Batch Loss: 0.23867860436439514, Average Training Loss: 0.19475986114863691, Training Accuracy: 0.9364224137931034\n",
            "Epoch 5/5, Batch Loss: 0.20949941873550415, Average Training Loss: 0.19525117973486583, Training Accuracy: 0.9364583333333333\n",
            "Epoch 5/5, Batch Loss: 0.12376448512077332, Average Training Loss: 0.1929451573279596, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.22541460394859314, Average Training Loss: 0.1939598275348544, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.36732572317123413, Average Training Loss: 0.1992133395238356, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.24928095936775208, Average Training Loss: 0.20068591657806845, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.10818170011043549, Average Training Loss: 0.1980429389647075, Training Accuracy: 0.9383928571428571\n",
            "Epoch 5/5, Batch Loss: 0.16012533009052277, Average Training Loss: 0.19698967205153572, Training Accuracy: 0.9383680555555556\n",
            "Epoch 5/5, Batch Loss: 0.11934114247560501, Average Training Loss: 0.1948910631440781, Training Accuracy: 0.9391891891891891\n",
            "Epoch 5/5, Batch Loss: 0.28048768639564514, Average Training Loss: 0.19714360586122462, Training Accuracy: 0.9391447368421053\n",
            "Epoch 5/5, Batch Loss: 0.22868938744068146, Average Training Loss: 0.19795247205556968, Training Accuracy: 0.9399038461538461\n",
            "Epoch 5/5, Batch Loss: 0.14246882498264313, Average Training Loss: 0.1965653808787465, Training Accuracy: 0.93984375\n",
            "Epoch 5/5, Batch Loss: 0.21481579542160034, Average Training Loss: 0.19701051294076732, Training Accuracy: 0.9397865853658537\n",
            "Epoch 5/5, Batch Loss: 0.11854903399944305, Average Training Loss: 0.1951423824897834, Training Accuracy: 0.9404761904761905\n",
            "Epoch 5/5, Batch Loss: 0.15168766677379608, Average Training Loss: 0.1941318077056907, Training Accuracy: 0.9411337209302325\n",
            "Epoch 5/5, Batch Loss: 0.08046280592679977, Average Training Loss: 0.191548421301625, Training Accuracy: 0.9424715909090909\n",
            "Epoch 5/5, Batch Loss: 0.08758439123630524, Average Training Loss: 0.18923810952239567, Training Accuracy: 0.9430555555555555\n",
            "Epoch 5/5, Batch Loss: 0.19814737141132355, Average Training Loss: 0.1894317891286767, Training Accuracy: 0.9429347826086957\n",
            "Epoch 5/5, Batch Loss: 0.20519310235977173, Average Training Loss: 0.1897671362187, Training Accuracy: 0.9428191489361702\n",
            "Epoch 5/5, Batch Loss: 0.2918713688850403, Average Training Loss: 0.1918943077325821, Training Accuracy: 0.9420572916666666\n",
            "Epoch 5/5, Batch Loss: 0.21335655450820923, Average Training Loss: 0.19233231276881937, Training Accuracy: 0.9406887755102041\n",
            "Epoch 5/5, Batch Loss: 0.14876119792461395, Average Training Loss: 0.19146089047193526, Training Accuracy: 0.94125\n",
            "Epoch 5/5, Batch Loss: 0.13327325880527496, Average Training Loss: 0.19031995651768704, Training Accuracy: 0.9417892156862745\n",
            "Epoch 5/5, Batch Loss: 0.1791597157716751, Average Training Loss: 0.19010533650334066, Training Accuracy: 0.9417067307692307\n",
            "Epoch 5/5, Batch Loss: 0.12688857316970825, Average Training Loss: 0.18891256738383816, Training Accuracy: 0.9422169811320755\n",
            "Epoch 5/5, Batch Loss: 0.2569434940814972, Average Training Loss: 0.19017239935972072, Training Accuracy: 0.9415509259259259\n",
            "Epoch 5/5, Batch Loss: 0.15577220916748047, Average Training Loss: 0.18954694135622543, Training Accuracy: 0.9414772727272728\n",
            "Epoch 5/5, Batch Loss: 0.10270736366510391, Average Training Loss: 0.18799623461174114, Training Accuracy: 0.9425223214285714\n",
            "Epoch 5/5, Batch Loss: 0.08347287029027939, Average Training Loss: 0.1861624913780313, Training Accuracy: 0.9435307017543859\n",
            "Epoch 5/5, Batch Loss: 0.11697325855493546, Average Training Loss: 0.1849695735707365, Training Accuracy: 0.943426724137931\n",
            "Epoch 5/5, Batch Loss: 0.13874654471874237, Average Training Loss: 0.18418613240375356, Training Accuracy: 0.9438559322033898\n",
            "Epoch 5/5, Batch Loss: 0.12585559487342834, Average Training Loss: 0.18321395677824814, Training Accuracy: 0.94375\n",
            "Epoch 5/5, Batch Loss: 0.11905249953269958, Average Training Loss: 0.18216212961028833, Training Accuracy: 0.944672131147541\n",
            "Epoch 5/5, Batch Loss: 0.3030058443546295, Average Training Loss: 0.18411122178358416, Training Accuracy: 0.9445564516129032\n",
            "Epoch 5/5, Batch Loss: 0.20582760870456696, Average Training Loss: 0.1844559263378855, Training Accuracy: 0.9439484126984127\n",
            "Epoch 5/5, Batch Loss: 0.21149392426013947, Average Training Loss: 0.1848783950554207, Training Accuracy: 0.943359375\n",
            "Epoch 5/5, Batch Loss: 0.12995018064975739, Average Training Loss: 0.18403334560302587, Training Accuracy: 0.94375\n",
            "Epoch 5/5, Batch Loss: 0.19995015859603882, Average Training Loss: 0.18427450943625334, Training Accuracy: 0.9441287878787878\n",
            "Epoch 5/5, Batch Loss: 0.026537690311670303, Average Training Loss: 0.1845018779656294, Training Accuracy: 0.9441816461684012\n",
            "Epoch 5/5, Average Training Loss: 0.1819202285537969, Training Accuracy: 0.9441816461684012\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.95      0.97      0.96       427\n",
            "                Educational Opportunity       0.90      0.90      0.90       451\n",
            "                         Family Support       0.98      0.99      0.99       396\n",
            "                      Financial Support       0.97      0.96      0.96       404\n",
            "                 Program Implementation       0.93      0.91      0.92       436\n",
            "\n",
            "                               accuracy                           0.94      2114\n",
            "                              macro avg       0.95      0.95      0.95      2114\n",
            "                           weighted avg       0.94      0.94      0.94      2114\n",
            "\n",
            "Epoch 5/5, Validation Loss: 14.485881268978119, Validation Accuracy: 0.7429111531190926\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.69      0.68       113\n",
            "                Educational Opportunity       0.55      0.60      0.57       100\n",
            "                         Family Support       0.91      0.92      0.92       105\n",
            "                      Financial Support       0.74      0.77      0.76        97\n",
            "                 Program Implementation       0.86      0.73      0.79       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.75      0.74      0.74       529\n",
            "                           weighted avg       0.75      0.74      0.74       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 6 - Updated Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n",
        "\n",
        "# ... (your subsequent code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Prek4J4exJ",
        "outputId": "cc57c32e-4109-443c-d039-53a7e9164c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-5-43c2a672f237>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch Loss: 1.6463478803634644, Average Training Loss: 1.6463478803634644, Training Accuracy: 0.28125\n",
            "Epoch 1/10, Batch Loss: 1.6296244859695435, Average Training Loss: 1.637986183166504, Training Accuracy: 0.234375\n",
            "Epoch 1/10, Batch Loss: 1.643173098564148, Average Training Loss: 1.6397151549657185, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/10, Batch Loss: 1.5889431238174438, Average Training Loss: 1.62702214717865, Training Accuracy: 0.21875\n",
            "Epoch 1/10, Batch Loss: 1.6176304817199707, Average Training Loss: 1.625143814086914, Training Accuracy: 0.20625\n",
            "Epoch 1/10, Batch Loss: 1.602550745010376, Average Training Loss: 1.6213783025741577, Training Accuracy: 0.21354166666666666\n",
            "Epoch 1/10, Batch Loss: 1.5920034646987915, Average Training Loss: 1.6171818971633911, Training Accuracy: 0.19642857142857142\n",
            "Epoch 1/10, Batch Loss: 1.622205138206482, Average Training Loss: 1.6178098022937775, Training Accuracy: 0.1953125\n",
            "Epoch 1/10, Batch Loss: 1.554190993309021, Average Training Loss: 1.6107410457399156, Training Accuracy: 0.21180555555555555\n",
            "Epoch 1/10, Batch Loss: 1.5629823207855225, Average Training Loss: 1.6059651732444764, Training Accuracy: 0.221875\n",
            "Epoch 1/10, Batch Loss: 1.5631026029586792, Average Training Loss: 1.6020685759457676, Training Accuracy: 0.23011363636363635\n",
            "Epoch 1/10, Batch Loss: 1.5316239595413208, Average Training Loss: 1.5961981912453969, Training Accuracy: 0.2421875\n",
            "Epoch 1/10, Batch Loss: 1.540087103843689, Average Training Loss: 1.5918819537529578, Training Accuracy: 0.24519230769230768\n",
            "Epoch 1/10, Batch Loss: 1.5669726133346558, Average Training Loss: 1.5901027151516505, Training Accuracy: 0.25669642857142855\n",
            "Epoch 1/10, Batch Loss: 1.5721238851547241, Average Training Loss: 1.5889041264851889, Training Accuracy: 0.2604166666666667\n",
            "Epoch 1/10, Batch Loss: 1.4690557718276978, Average Training Loss: 1.5814136043190956, Training Accuracy: 0.267578125\n",
            "Epoch 1/10, Batch Loss: 1.5020794868469238, Average Training Loss: 1.576746891526615, Training Accuracy: 0.2757352941176471\n",
            "Epoch 1/10, Batch Loss: 1.5038938522338867, Average Training Loss: 1.5726995004547968, Training Accuracy: 0.2795138888888889\n",
            "Epoch 1/10, Batch Loss: 1.4761645793914795, Average Training Loss: 1.5676187151356746, Training Accuracy: 0.27631578947368424\n",
            "Epoch 1/10, Batch Loss: 1.4997131824493408, Average Training Loss: 1.564223438501358, Training Accuracy: 0.2765625\n",
            "Epoch 1/10, Batch Loss: 1.613109827041626, Average Training Loss: 1.5665513617651803, Training Accuracy: 0.27529761904761907\n",
            "Epoch 1/10, Batch Loss: 1.3073581457138062, Average Training Loss: 1.5547698519446633, Training Accuracy: 0.2840909090909091\n",
            "Epoch 1/10, Batch Loss: 1.3777467012405396, Average Training Loss: 1.547073193218397, Training Accuracy: 0.2907608695652174\n",
            "Epoch 1/10, Batch Loss: 1.3751457929611206, Average Training Loss: 1.5399095515410106, Training Accuracy: 0.2955729166666667\n",
            "Epoch 1/10, Batch Loss: 1.4522265195846558, Average Training Loss: 1.5364022302627562, Training Accuracy: 0.2975\n",
            "Epoch 1/10, Batch Loss: 1.2697007656097412, Average Training Loss: 1.5261444816222558, Training Accuracy: 0.30528846153846156\n",
            "Epoch 1/10, Batch Loss: 1.3479399681091309, Average Training Loss: 1.519544314455103, Training Accuracy: 0.3148148148148148\n",
            "Epoch 1/10, Batch Loss: 1.2615482807159424, Average Training Loss: 1.5103301703929901, Training Accuracy: 0.3236607142857143\n",
            "Epoch 1/10, Batch Loss: 1.2772780656814575, Average Training Loss: 1.5022938909201786, Training Accuracy: 0.3286637931034483\n",
            "Epoch 1/10, Batch Loss: 1.2272402048110962, Average Training Loss: 1.4931254347165426, Training Accuracy: 0.3375\n",
            "Epoch 1/10, Batch Loss: 1.1501989364624023, Average Training Loss: 1.4820632896115702, Training Accuracy: 0.3467741935483871\n",
            "Epoch 1/10, Batch Loss: 1.2710168361663818, Average Training Loss: 1.4754680879414082, Training Accuracy: 0.3525390625\n",
            "Epoch 1/10, Batch Loss: 1.0658352375030518, Average Training Loss: 1.463054971261458, Training Accuracy: 0.36174242424242425\n",
            "Epoch 1/10, Batch Loss: 1.1499598026275635, Average Training Loss: 1.4538462898310494, Training Accuracy: 0.3704044117647059\n",
            "Epoch 1/10, Batch Loss: 1.2002893686294556, Average Training Loss: 1.4466018063681467, Training Accuracy: 0.3732142857142857\n",
            "Epoch 1/10, Batch Loss: 1.2450504302978516, Average Training Loss: 1.4410031570328607, Training Accuracy: 0.375\n",
            "Epoch 1/10, Batch Loss: 0.9932868480682373, Average Training Loss: 1.428902716250033, Training Accuracy: 0.3842905405405405\n",
            "Epoch 1/10, Batch Loss: 0.944305419921875, Average Training Loss: 1.4161501558203446, Training Accuracy: 0.39226973684210525\n",
            "Epoch 1/10, Batch Loss: 1.2414708137512207, Average Training Loss: 1.4116711983313928, Training Accuracy: 0.3958333333333333\n",
            "Epoch 1/10, Batch Loss: 1.0085713863372803, Average Training Loss: 1.40159370303154, Training Accuracy: 0.4015625\n",
            "Epoch 1/10, Batch Loss: 1.1377094984054565, Average Training Loss: 1.3951575029187087, Training Accuracy: 0.4054878048780488\n",
            "Epoch 1/10, Batch Loss: 0.9535322189331055, Average Training Loss: 1.3846426152047657, Training Accuracy: 0.41220238095238093\n",
            "Epoch 1/10, Batch Loss: 0.9071173071861267, Average Training Loss: 1.373537375483402, Training Accuracy: 0.42078488372093026\n",
            "Epoch 1/10, Batch Loss: 1.0972180366516113, Average Training Loss: 1.367257390509952, Training Accuracy: 0.4247159090909091\n",
            "Epoch 1/10, Batch Loss: 1.0530120134353638, Average Training Loss: 1.3602741599082946, Training Accuracy: 0.42916666666666664\n",
            "Epoch 1/10, Batch Loss: 1.0782698392868042, Average Training Loss: 1.354143631199132, Training Accuracy: 0.4313858695652174\n",
            "Epoch 1/10, Batch Loss: 0.9511961340904236, Average Training Loss: 1.3455702801968188, Training Accuracy: 0.43550531914893614\n",
            "Epoch 1/10, Batch Loss: 1.1423035860061646, Average Training Loss: 1.3413355574011803, Training Accuracy: 0.4381510416666667\n",
            "Epoch 1/10, Batch Loss: 0.8547377586364746, Average Training Loss: 1.3314049900794516, Training Accuracy: 0.4451530612244898\n",
            "Epoch 1/10, Batch Loss: 0.9825066328048706, Average Training Loss: 1.3244270229339599, Training Accuracy: 0.446875\n",
            "Epoch 1/10, Batch Loss: 0.9915837645530701, Average Training Loss: 1.3179006845343346, Training Accuracy: 0.4522058823529412\n",
            "Epoch 1/10, Batch Loss: 0.9944953918457031, Average Training Loss: 1.3116813519826303, Training Accuracy: 0.45492788461538464\n",
            "Epoch 1/10, Batch Loss: 1.143699049949646, Average Training Loss: 1.3085118745857816, Training Accuracy: 0.45872641509433965\n",
            "Epoch 1/10, Batch Loss: 0.7478145360946655, Average Training Loss: 1.2981285905396496, Training Accuracy: 0.4652777777777778\n",
            "Epoch 1/10, Batch Loss: 0.9087358713150024, Average Training Loss: 1.2910487229173833, Training Accuracy: 0.4681818181818182\n",
            "Epoch 1/10, Batch Loss: 0.970868706703186, Average Training Loss: 1.2853312226278442, Training Accuracy: 0.47098214285714285\n",
            "Epoch 1/10, Batch Loss: 0.9820349216461182, Average Training Loss: 1.2800102348913227, Training Accuracy: 0.47368421052631576\n",
            "Epoch 1/10, Batch Loss: 0.8560218214988708, Average Training Loss: 1.272700089832832, Training Accuracy: 0.47790948275862066\n",
            "Epoch 1/10, Batch Loss: 0.9606146812438965, Average Training Loss: 1.2674105066364094, Training Accuracy: 0.4809322033898305\n",
            "Epoch 1/10, Batch Loss: 0.9113163352012634, Average Training Loss: 1.261475603779157, Training Accuracy: 0.48541666666666666\n",
            "Epoch 1/10, Batch Loss: 0.7268945574760437, Average Training Loss: 1.2527119800692699, Training Accuracy: 0.4882172131147541\n",
            "Epoch 1/10, Batch Loss: 0.8602227568626404, Average Training Loss: 1.2463815087272274, Training Accuracy: 0.4909274193548387\n",
            "Epoch 1/10, Batch Loss: 1.0195047855377197, Average Training Loss: 1.2427802908988226, Training Accuracy: 0.49206349206349204\n",
            "Epoch 1/10, Batch Loss: 0.7102006077766418, Average Training Loss: 1.2344587333500385, Training Accuracy: 0.49609375\n",
            "Epoch 1/10, Batch Loss: 0.7654774188995361, Average Training Loss: 1.2272436362046462, Training Accuracy: 0.49951923076923077\n",
            "Epoch 1/10, Batch Loss: 0.7738949656486511, Average Training Loss: 1.2203747169537977, Training Accuracy: 0.5014204545454546\n",
            "Epoch 1/10, Batch Loss: 0.2736635208129883, Average Training Loss: 1.2233626465810958, Training Accuracy: 0.5018921475875118\n",
            "Epoch 1/10, Average Training Loss: 1.20624469910095, Training Accuracy: 0.5018921475875118\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.46      0.44      0.45       427\n",
            "                Educational Opportunity       0.35      0.43      0.39       451\n",
            "                         Family Support       0.65      0.66      0.66       396\n",
            "                      Financial Support       0.58      0.47      0.52       404\n",
            "                 Program Implementation       0.55      0.51      0.53       436\n",
            "\n",
            "                               accuracy                           0.50      2114\n",
            "                              macro avg       0.52      0.50      0.51      2114\n",
            "                           weighted avg       0.51      0.50      0.50      2114\n",
            "\n",
            "Epoch 1/10, Validation Loss: 13.985904276371002, Validation Accuracy: 0.6956521739130435\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.65      0.52      0.58       113\n",
            "                Educational Opportunity       0.49      0.67      0.56       100\n",
            "                         Family Support       0.83      1.00      0.91       105\n",
            "                      Financial Support       0.73      0.71      0.72        97\n",
            "                 Program Implementation       0.85      0.60      0.70       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.71      0.70      0.69       529\n",
            "                           weighted avg       0.71      0.70      0.69       529\n",
            "\n",
            "Epoch 2/10, Batch Loss: 0.8907301425933838, Average Training Loss: 0.8907301425933838, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.667650580406189, Average Training Loss: 0.7791903614997864, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.8942055702209473, Average Training Loss: 0.81752876440684, Training Accuracy: 0.71875\n",
            "Epoch 2/10, Batch Loss: 0.8787668943405151, Average Training Loss: 0.8328382968902588, Training Accuracy: 0.703125\n",
            "Epoch 2/10, Batch Loss: 0.6783387064933777, Average Training Loss: 0.8019383788108826, Training Accuracy: 0.71875\n",
            "Epoch 2/10, Batch Loss: 0.516460120677948, Average Training Loss: 0.7543586691220602, Training Accuracy: 0.734375\n",
            "Epoch 2/10, Batch Loss: 0.8052870631217957, Average Training Loss: 0.7616341539791652, Training Accuracy: 0.7321428571428571\n",
            "Epoch 2/10, Batch Loss: 0.4522760510444641, Average Training Loss: 0.7229643911123276, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.6561288237571716, Average Training Loss: 0.7155382169617547, Training Accuracy: 0.7534722222222222\n",
            "Epoch 2/10, Batch Loss: 0.6253963708877563, Average Training Loss: 0.7065240323543549, Training Accuracy: 0.759375\n",
            "Epoch 2/10, Batch Loss: 0.650310218334198, Average Training Loss: 0.7014136856252496, Training Accuracy: 0.7556818181818182\n",
            "Epoch 2/10, Batch Loss: 0.8494666814804077, Average Training Loss: 0.7137514352798462, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.6185309290885925, Average Training Loss: 0.706426780957442, Training Accuracy: 0.7548076923076923\n",
            "Epoch 2/10, Batch Loss: 0.5285449624061584, Average Training Loss: 0.6937209367752075, Training Accuracy: 0.7611607142857143\n",
            "Epoch 2/10, Batch Loss: 0.7539968490600586, Average Training Loss: 0.6977393309275309, Training Accuracy: 0.75625\n",
            "Epoch 2/10, Batch Loss: 0.5096886157989502, Average Training Loss: 0.6859861612319946, Training Accuracy: 0.76171875\n",
            "Epoch 2/10, Batch Loss: 0.6265126466751099, Average Training Loss: 0.6824877191992367, Training Accuracy: 0.7610294117647058\n",
            "Epoch 2/10, Batch Loss: 0.615117609500885, Average Training Loss: 0.678744935327106, Training Accuracy: 0.765625\n",
            "Epoch 2/10, Batch Loss: 0.635159432888031, Average Training Loss: 0.6764509615145231, Training Accuracy: 0.7648026315789473\n",
            "Epoch 2/10, Batch Loss: 0.6263079643249512, Average Training Loss: 0.6739438116550446, Training Accuracy: 0.7640625\n",
            "Epoch 2/10, Batch Loss: 0.5913060903549194, Average Training Loss: 0.6700086820693243, Training Accuracy: 0.7648809523809523\n",
            "Epoch 2/10, Batch Loss: 0.7090089321136475, Average Training Loss: 0.6717814207077026, Training Accuracy: 0.7642045454545454\n",
            "Epoch 2/10, Batch Loss: 0.7637488842010498, Average Training Loss: 0.6757800060769786, Training Accuracy: 0.7622282608695652\n",
            "Epoch 2/10, Batch Loss: 0.7647103667259216, Average Training Loss: 0.6794854377706846, Training Accuracy: 0.76171875\n",
            "Epoch 2/10, Batch Loss: 0.5085659623146057, Average Training Loss: 0.6726486587524414, Training Accuracy: 0.76375\n",
            "Epoch 2/10, Batch Loss: 0.6183879971504211, Average Training Loss: 0.6705617102292868, Training Accuracy: 0.7632211538461539\n",
            "Epoch 2/10, Batch Loss: 0.5529361367225647, Average Training Loss: 0.6662052075068156, Training Accuracy: 0.7662037037037037\n",
            "Epoch 2/10, Batch Loss: 0.47803518176078796, Average Training Loss: 0.6594848494444575, Training Accuracy: 0.7700892857142857\n",
            "Epoch 2/10, Batch Loss: 0.6436846852302551, Average Training Loss: 0.6589400161956919, Training Accuracy: 0.7704741379310345\n",
            "Epoch 2/10, Batch Loss: 0.7607797980308533, Average Training Loss: 0.6623346755901972, Training Accuracy: 0.7697916666666667\n",
            "Epoch 2/10, Batch Loss: 0.8774129152297974, Average Training Loss: 0.6692726833205069, Training Accuracy: 0.7681451612903226\n",
            "Epoch 2/10, Batch Loss: 0.5912550091743469, Average Training Loss: 0.6668346310034394, Training Accuracy: 0.7666015625\n",
            "Epoch 2/10, Batch Loss: 0.49736613035202026, Average Training Loss: 0.6616992218927904, Training Accuracy: 0.7679924242424242\n",
            "Epoch 2/10, Batch Loss: 0.6938846707344055, Average Training Loss: 0.6626458527410731, Training Accuracy: 0.7674632352941176\n",
            "Epoch 2/10, Batch Loss: 0.8525568842887878, Average Training Loss: 0.668071882213865, Training Accuracy: 0.7651785714285714\n",
            "Epoch 2/10, Batch Loss: 0.44878220558166504, Average Training Loss: 0.661980502307415, Training Accuracy: 0.7682291666666666\n",
            "Epoch 2/10, Batch Loss: 0.4380077123641968, Average Training Loss: 0.655927183660301, Training Accuracy: 0.7711148648648649\n",
            "Epoch 2/10, Batch Loss: 0.5764058828353882, Average Training Loss: 0.6538345178491191, Training Accuracy: 0.7705592105263158\n",
            "Epoch 2/10, Batch Loss: 0.5492891669273376, Average Training Loss: 0.6511538678254837, Training Accuracy: 0.7724358974358975\n",
            "Epoch 2/10, Batch Loss: 0.7813637852668762, Average Training Loss: 0.6544091157615185, Training Accuracy: 0.771875\n",
            "Epoch 2/10, Batch Loss: 0.7364886999130249, Average Training Loss: 0.6564110568383845, Training Accuracy: 0.7721036585365854\n",
            "Epoch 2/10, Batch Loss: 0.7159198522567749, Average Training Loss: 0.6578279329197747, Training Accuracy: 0.7715773809523809\n",
            "Epoch 2/10, Batch Loss: 0.9124035835266113, Average Training Loss: 0.6637482968873756, Training Accuracy: 0.7688953488372093\n",
            "Epoch 2/10, Batch Loss: 0.9280084371566772, Average Training Loss: 0.6697542091662233, Training Accuracy: 0.7663352272727273\n",
            "Epoch 2/10, Batch Loss: 0.6696937680244446, Average Training Loss: 0.6697528660297394, Training Accuracy: 0.7652777777777777\n",
            "Epoch 2/10, Batch Loss: 0.5879789590835571, Average Training Loss: 0.6679751724004745, Training Accuracy: 0.7663043478260869\n",
            "Epoch 2/10, Batch Loss: 0.7869698405265808, Average Training Loss: 0.6705069738499662, Training Accuracy: 0.7659574468085106\n",
            "Epoch 2/10, Batch Loss: 0.7310511469841003, Average Training Loss: 0.6717683107902607, Training Accuracy: 0.7643229166666666\n",
            "Epoch 2/10, Batch Loss: 0.8007481694221497, Average Training Loss: 0.6744005528031564, Training Accuracy: 0.7621173469387755\n",
            "Epoch 2/10, Batch Loss: 0.91850745677948, Average Training Loss: 0.6792826908826828, Training Accuracy: 0.76\n",
            "Epoch 2/10, Batch Loss: 0.6045728921890259, Average Training Loss: 0.6778177928690817, Training Accuracy: 0.7604166666666666\n",
            "Epoch 2/10, Batch Loss: 0.6401817202568054, Average Training Loss: 0.6770940222419225, Training Accuracy: 0.7608173076923077\n",
            "Epoch 2/10, Batch Loss: 0.6768810749053955, Average Training Loss: 0.6770900043676484, Training Accuracy: 0.7606132075471698\n",
            "Epoch 2/10, Batch Loss: 0.7105327248573303, Average Training Loss: 0.6777093140063463, Training Accuracy: 0.7598379629629629\n",
            "Epoch 2/10, Batch Loss: 0.8026130795478821, Average Training Loss: 0.6799802915616469, Training Accuracy: 0.7579545454545454\n",
            "Epoch 2/10, Batch Loss: 0.527652382850647, Average Training Loss: 0.6772601503346648, Training Accuracy: 0.7589285714285714\n",
            "Epoch 2/10, Batch Loss: 0.6901971101760864, Average Training Loss: 0.677487114542409, Training Accuracy: 0.7593201754385965\n",
            "Epoch 2/10, Batch Loss: 0.530875563621521, Average Training Loss: 0.674959329181704, Training Accuracy: 0.7607758620689655\n",
            "Epoch 2/10, Batch Loss: 0.8770424127578735, Average Training Loss: 0.6783844661914696, Training Accuracy: 0.7595338983050848\n",
            "Epoch 2/10, Batch Loss: 0.9171897172927856, Average Training Loss: 0.6823645537098249, Training Accuracy: 0.759375\n",
            "Epoch 2/10, Batch Loss: 0.7206124067306519, Average Training Loss: 0.6829915676937729, Training Accuracy: 0.7592213114754098\n",
            "Epoch 2/10, Batch Loss: 0.6680400967597961, Average Training Loss: 0.6827504149367732, Training Accuracy: 0.7595766129032258\n",
            "Epoch 2/10, Batch Loss: 0.4710579812526703, Average Training Loss: 0.6793902175767081, Training Accuracy: 0.7599206349206349\n",
            "Epoch 2/10, Batch Loss: 0.5430495738983154, Average Training Loss: 0.6772598950192332, Training Accuracy: 0.76123046875\n",
            "Epoch 2/10, Batch Loss: 0.5228722095489502, Average Training Loss: 0.6748846998581519, Training Accuracy: 0.7625\n",
            "Epoch 2/10, Batch Loss: 0.6784793138504028, Average Training Loss: 0.6749391637065194, Training Accuracy: 0.7608901515151515\n",
            "Epoch 2/10, Batch Loss: 0.6468449831008911, Average Training Loss: 0.684092030845505, Training Accuracy: 0.760643330179754\n",
            "Epoch 2/10, Average Training Loss: 0.6745198475780771, Training Accuracy: 0.760643330179754\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.73      0.71      0.72       427\n",
            "                Educational Opportunity       0.62      0.63      0.62       451\n",
            "                         Family Support       0.88      0.97      0.93       396\n",
            "                      Financial Support       0.78      0.84      0.81       404\n",
            "                 Program Implementation       0.81      0.67      0.73       436\n",
            "\n",
            "                               accuracy                           0.76      2114\n",
            "                              macro avg       0.76      0.77      0.76      2114\n",
            "                           weighted avg       0.76      0.76      0.76      2114\n",
            "\n",
            "Epoch 2/10, Validation Loss: 14.233042240142822, Validation Accuracy: 0.6918714555765595\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.65      0.66       113\n",
            "                Educational Opportunity       0.45      0.72      0.55       100\n",
            "                         Family Support       0.85      0.99      0.91       105\n",
            "                      Financial Support       0.81      0.57      0.67        97\n",
            "                 Program Implementation       0.92      0.54      0.68       114\n",
            "\n",
            "                               accuracy                           0.69       529\n",
            "                              macro avg       0.74      0.69      0.69       529\n",
            "                           weighted avg       0.74      0.69      0.69       529\n",
            "\n",
            "Epoch 3/10, Batch Loss: 0.31962335109710693, Average Training Loss: 0.31962335109710693, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.5906680226325989, Average Training Loss: 0.4551456868648529, Training Accuracy: 0.859375\n",
            "Epoch 3/10, Batch Loss: 0.5224209427833557, Average Training Loss: 0.4775707721710205, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.48662543296813965, Average Training Loss: 0.4798344373703003, Training Accuracy: 0.8515625\n",
            "Epoch 3/10, Batch Loss: 0.6662006974220276, Average Training Loss: 0.5171076893806458, Training Accuracy: 0.8375\n",
            "Epoch 3/10, Batch Loss: 0.9865080714225769, Average Training Loss: 0.5953410863876343, Training Accuracy: 0.8072916666666666\n",
            "Epoch 3/10, Batch Loss: 0.9124598503112793, Average Training Loss: 0.640643766948155, Training Accuracy: 0.7857142857142857\n",
            "Epoch 3/10, Batch Loss: 0.3169270157814026, Average Training Loss: 0.6001791730523109, Training Accuracy: 0.80078125\n",
            "Epoch 3/10, Batch Loss: 0.5047475695610046, Average Training Loss: 0.5895756615532769, Training Accuracy: 0.7986111111111112\n",
            "Epoch 3/10, Batch Loss: 0.48316919803619385, Average Training Loss: 0.5789350152015686, Training Accuracy: 0.803125\n",
            "Epoch 3/10, Batch Loss: 0.4874836504459381, Average Training Loss: 0.5706212547692385, Training Accuracy: 0.8068181818181818\n",
            "Epoch 3/10, Batch Loss: 0.39403820037841797, Average Training Loss: 0.5559060002366701, Training Accuracy: 0.8046875\n",
            "Epoch 3/10, Batch Loss: 0.4037984311580658, Average Training Loss: 0.5442054179998544, Training Accuracy: 0.8076923076923077\n",
            "Epoch 3/10, Batch Loss: 0.6304009556770325, Average Training Loss: 0.5503622421196529, Training Accuracy: 0.8058035714285714\n",
            "Epoch 3/10, Batch Loss: 0.6054725646972656, Average Training Loss: 0.554036263624827, Training Accuracy: 0.8041666666666667\n",
            "Epoch 3/10, Batch Loss: 0.4781341254711151, Average Training Loss: 0.5492923799902201, Training Accuracy: 0.8046875\n",
            "Epoch 3/10, Batch Loss: 0.5767902135848999, Average Training Loss: 0.5509098996134365, Training Accuracy: 0.8069852941176471\n",
            "Epoch 3/10, Batch Loss: 0.5766595602035522, Average Training Loss: 0.5523404363128874, Training Accuracy: 0.8055555555555556\n",
            "Epoch 3/10, Batch Loss: 0.4675794243812561, Average Training Loss: 0.547879330421749, Training Accuracy: 0.8075657894736842\n",
            "Epoch 3/10, Batch Loss: 0.6762397885322571, Average Training Loss: 0.5542973533272744, Training Accuracy: 0.8046875\n",
            "Epoch 3/10, Batch Loss: 0.3653542101383209, Average Training Loss: 0.545300060794467, Training Accuracy: 0.8080357142857143\n",
            "Epoch 3/10, Batch Loss: 0.30346420407295227, Average Training Loss: 0.53430752185258, Training Accuracy: 0.8110795454545454\n",
            "Epoch 3/10, Batch Loss: 0.4281654357910156, Average Training Loss: 0.5296926485455554, Training Accuracy: 0.8165760869565217\n",
            "Epoch 3/10, Batch Loss: 0.4750182032585144, Average Training Loss: 0.5274145466585954, Training Accuracy: 0.81640625\n",
            "Epoch 3/10, Batch Loss: 0.3983662724494934, Average Training Loss: 0.5222526156902313, Training Accuracy: 0.81875\n",
            "Epoch 3/10, Batch Loss: 0.5572473406791687, Average Training Loss: 0.5235985666513443, Training Accuracy: 0.8173076923076923\n",
            "Epoch 3/10, Batch Loss: 0.4383949935436249, Average Training Loss: 0.5204428787584658, Training Accuracy: 0.8182870370370371\n",
            "Epoch 3/10, Batch Loss: 0.33669325709342957, Average Training Loss: 0.5138803922704288, Training Accuracy: 0.8203125\n",
            "Epoch 3/10, Batch Loss: 0.427921861410141, Average Training Loss: 0.5109163049993843, Training Accuracy: 0.8211206896551724\n",
            "Epoch 3/10, Batch Loss: 0.5460725426673889, Average Training Loss: 0.5120881795883179, Training Accuracy: 0.8229166666666666\n",
            "Epoch 3/10, Batch Loss: 0.3274260461330414, Average Training Loss: 0.5061313365736315, Training Accuracy: 0.8245967741935484\n",
            "Epoch 3/10, Batch Loss: 0.6218293905258179, Average Training Loss: 0.5097469007596374, Training Accuracy: 0.82421875\n",
            "Epoch 3/10, Batch Loss: 0.3142482340335846, Average Training Loss: 0.5038226987376357, Training Accuracy: 0.8267045454545454\n",
            "Epoch 3/10, Batch Loss: 0.3142779767513275, Average Training Loss: 0.4982478539733326, Training Accuracy: 0.8290441176470589\n",
            "Epoch 3/10, Batch Loss: 0.37513476610183716, Average Training Loss: 0.49473033717700415, Training Accuracy: 0.8303571428571429\n",
            "Epoch 3/10, Batch Loss: 0.4690336585044861, Average Training Loss: 0.49401654054721195, Training Accuracy: 0.8298611111111112\n",
            "Epoch 3/10, Batch Loss: 0.7065192461013794, Average Training Loss: 0.4997598569135408, Training Accuracy: 0.8268581081081081\n",
            "Epoch 3/10, Batch Loss: 0.39778971672058105, Average Training Loss: 0.49707643217162084, Training Accuracy: 0.828125\n",
            "Epoch 3/10, Batch Loss: 0.805147647857666, Average Training Loss: 0.5049756941122886, Training Accuracy: 0.8261217948717948\n",
            "Epoch 3/10, Batch Loss: 0.7098963856697083, Average Training Loss: 0.5100987114012241, Training Accuracy: 0.825\n",
            "Epoch 3/10, Batch Loss: 0.5578337907791138, Average Training Loss: 0.5112629816299532, Training Accuracy: 0.8239329268292683\n",
            "Epoch 3/10, Batch Loss: 0.2906975746154785, Average Training Loss: 0.5060114243200847, Training Accuracy: 0.8258928571428571\n",
            "Epoch 3/10, Batch Loss: 0.4877871870994568, Average Training Loss: 0.5055876048498376, Training Accuracy: 0.8263081395348837\n",
            "Epoch 3/10, Batch Loss: 0.4227433502674103, Average Training Loss: 0.5037047808820551, Training Accuracy: 0.828125\n",
            "Epoch 3/10, Batch Loss: 0.4901857376098633, Average Training Loss: 0.5034043576982287, Training Accuracy: 0.8284722222222223\n",
            "Epoch 3/10, Batch Loss: 0.4051983654499054, Average Training Loss: 0.5012694448232651, Training Accuracy: 0.828125\n",
            "Epoch 3/10, Batch Loss: 0.30828672647476196, Average Training Loss: 0.49716342953925435, Training Accuracy: 0.8297872340425532\n",
            "Epoch 3/10, Batch Loss: 0.5761960744857788, Average Training Loss: 0.4988099429756403, Training Accuracy: 0.8287760416666666\n",
            "Epoch 3/10, Batch Loss: 0.26552116870880127, Average Training Loss: 0.4940489475824395, Training Accuracy: 0.829719387755102\n",
            "Epoch 3/10, Batch Loss: 0.45318129658699036, Average Training Loss: 0.4932315945625305, Training Accuracy: 0.830625\n",
            "Epoch 3/10, Batch Loss: 0.21366415917873383, Average Training Loss: 0.4877498801432404, Training Accuracy: 0.8333333333333334\n",
            "Epoch 3/10, Batch Loss: 0.3565096855163574, Average Training Loss: 0.4852260302465696, Training Accuracy: 0.8347355769230769\n",
            "Epoch 3/10, Batch Loss: 0.4508648216724396, Average Training Loss: 0.48457770555649166, Training Accuracy: 0.8349056603773585\n",
            "Epoch 3/10, Batch Loss: 0.36435776948928833, Average Training Loss: 0.48235141044413604, Training Accuracy: 0.8350694444444444\n",
            "Epoch 3/10, Batch Loss: 0.6200430393218994, Average Training Loss: 0.4848548946055499, Training Accuracy: 0.8329545454545455\n",
            "Epoch 3/10, Batch Loss: 0.4507935643196106, Average Training Loss: 0.48424665656472954, Training Accuracy: 0.8337053571428571\n",
            "Epoch 3/10, Batch Loss: 0.2181132584810257, Average Training Loss: 0.4795776495808049, Training Accuracy: 0.8355263157894737\n",
            "Epoch 3/10, Batch Loss: 0.4573659598827362, Average Training Loss: 0.47919468941359683, Training Accuracy: 0.8351293103448276\n",
            "Epoch 3/10, Batch Loss: 0.2953549027442932, Average Training Loss: 0.47607876082598155, Training Accuracy: 0.8363347457627118\n",
            "Epoch 3/10, Batch Loss: 0.522249162197113, Average Training Loss: 0.4768482675155004, Training Accuracy: 0.8369791666666667\n",
            "Epoch 3/10, Batch Loss: 0.3172028958797455, Average Training Loss: 0.47423113027556996, Training Accuracy: 0.8376024590163934\n",
            "Epoch 3/10, Batch Loss: 0.2888752222061157, Average Training Loss: 0.4712415188550949, Training Accuracy: 0.8382056451612904\n",
            "Epoch 3/10, Batch Loss: 0.49994686245918274, Average Training Loss: 0.47169715922976296, Training Accuracy: 0.8382936507936508\n",
            "Epoch 3/10, Batch Loss: 0.27565082907676697, Average Training Loss: 0.4686339353211224, Training Accuracy: 0.83984375\n",
            "Epoch 3/10, Batch Loss: 0.46148765087127686, Average Training Loss: 0.46852399248343246, Training Accuracy: 0.8399038461538462\n",
            "Epoch 3/10, Batch Loss: 0.4471149146556854, Average Training Loss: 0.4681996125163454, Training Accuracy: 0.8404356060606061\n",
            "Epoch 3/10, Batch Loss: 2.523460865020752, Average Training Loss: 0.5059547442361332, Training Accuracy: 0.8401135288552507\n",
            "Epoch 3/10, Average Training Loss: 0.4988751535985007, Training Accuracy: 0.8401135288552507\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.84      0.86      0.85       427\n",
            "                Educational Opportunity       0.74      0.77      0.75       451\n",
            "                         Family Support       0.92      0.97      0.94       396\n",
            "                      Financial Support       0.86      0.88      0.87       404\n",
            "                 Program Implementation       0.86      0.73      0.79       436\n",
            "\n",
            "                               accuracy                           0.84      2114\n",
            "                              macro avg       0.84      0.84      0.84      2114\n",
            "                           weighted avg       0.84      0.84      0.84      2114\n",
            "\n",
            "Epoch 3/10, Validation Loss: 14.02737820148468, Validation Accuracy: 0.7372400756143668\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.74      0.61      0.67       113\n",
            "                Educational Opportunity       0.51      0.68      0.58       100\n",
            "                         Family Support       0.91      0.97      0.94       105\n",
            "                      Financial Support       0.78      0.64      0.70        97\n",
            "                 Program Implementation       0.79      0.78      0.79       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.75      0.74      0.74       529\n",
            "                           weighted avg       0.75      0.74      0.74       529\n",
            "\n",
            "Epoch 4/10, Batch Loss: 0.1095656082034111, Average Training Loss: 0.1095656082034111, Training Accuracy: 1.0\n",
            "Epoch 4/10, Batch Loss: 0.3061131238937378, Average Training Loss: 0.20783936604857445, Training Accuracy: 0.953125\n",
            "Epoch 4/10, Batch Loss: 0.46698063611984253, Average Training Loss: 0.2942197894056638, Training Accuracy: 0.9166666666666666\n",
            "Epoch 4/10, Batch Loss: 0.19820818305015564, Average Training Loss: 0.27021688781678677, Training Accuracy: 0.9296875\n",
            "Epoch 4/10, Batch Loss: 0.25195154547691345, Average Training Loss: 0.2665638193488121, Training Accuracy: 0.93125\n",
            "Epoch 4/10, Batch Loss: 0.4252062141895294, Average Training Loss: 0.29300421848893166, Training Accuracy: 0.9166666666666666\n",
            "Epoch 4/10, Batch Loss: 0.10304739326238632, Average Training Loss: 0.26586752917085377, Training Accuracy: 0.9285714285714286\n",
            "Epoch 4/10, Batch Loss: 0.22547169029712677, Average Training Loss: 0.2608180493116379, Training Accuracy: 0.9296875\n",
            "Epoch 4/10, Batch Loss: 0.308710515499115, Average Training Loss: 0.2661394344435798, Training Accuracy: 0.9270833333333334\n",
            "Epoch 4/10, Batch Loss: 0.20177066326141357, Average Training Loss: 0.2597025573253632, Training Accuracy: 0.928125\n",
            "Epoch 4/10, Batch Loss: 0.5312291383743286, Average Training Loss: 0.2843867919661782, Training Accuracy: 0.9147727272727273\n",
            "Epoch 4/10, Batch Loss: 0.16501052677631378, Average Training Loss: 0.2744387698670228, Training Accuracy: 0.9192708333333334\n",
            "Epoch 4/10, Batch Loss: 0.4127466678619385, Average Training Loss: 0.2850778389435548, Training Accuracy: 0.9158653846153846\n",
            "Epoch 4/10, Batch Loss: 0.30997154116630554, Average Training Loss: 0.2868559605308941, Training Accuracy: 0.9151785714285714\n",
            "Epoch 4/10, Batch Loss: 0.23150648176670074, Average Training Loss: 0.2831659952799479, Training Accuracy: 0.9125\n",
            "Epoch 4/10, Batch Loss: 0.13231855630874634, Average Training Loss: 0.2737380303442478, Training Accuracy: 0.916015625\n",
            "Epoch 4/10, Batch Loss: 0.44661930203437805, Average Training Loss: 0.2839075169142555, Training Accuracy: 0.9117647058823529\n",
            "Epoch 4/10, Batch Loss: 0.5571253299713135, Average Training Loss: 0.29908628430631423, Training Accuracy: 0.9097222222222222\n",
            "Epoch 4/10, Batch Loss: 0.4070033133029938, Average Training Loss: 0.30476612793771846, Training Accuracy: 0.90625\n",
            "Epoch 4/10, Batch Loss: 0.39466118812561035, Average Training Loss: 0.309260880947113, Training Accuracy: 0.90625\n",
            "Epoch 4/10, Batch Loss: 0.406587690114975, Average Training Loss: 0.3138954909074874, Training Accuracy: 0.9032738095238095\n",
            "Epoch 4/10, Batch Loss: 0.3555801808834076, Average Training Loss: 0.31579024954275653, Training Accuracy: 0.9019886363636364\n",
            "Epoch 4/10, Batch Loss: 0.43577244877815247, Average Training Loss: 0.3210068669008172, Training Accuracy: 0.8980978260869565\n",
            "Epoch 4/10, Batch Loss: 0.23346298933029175, Average Training Loss: 0.31735920533537865, Training Accuracy: 0.8984375\n",
            "Epoch 4/10, Batch Loss: 0.4213396906852722, Average Training Loss: 0.32151842474937437, Training Accuracy: 0.895\n",
            "Epoch 4/10, Batch Loss: 0.19246137142181396, Average Training Loss: 0.3165546919290836, Training Accuracy: 0.8966346153846154\n",
            "Epoch 4/10, Batch Loss: 0.37112098932266235, Average Training Loss: 0.31857566590662356, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/10, Batch Loss: 0.3438100218772888, Average Training Loss: 0.3194768929055759, Training Accuracy: 0.8939732142857143\n",
            "Epoch 4/10, Batch Loss: 0.20074568688869476, Average Training Loss: 0.3153827133877524, Training Accuracy: 0.896551724137931\n",
            "Epoch 4/10, Batch Loss: 0.2817333936691284, Average Training Loss: 0.3142610693971316, Training Accuracy: 0.8979166666666667\n",
            "Epoch 4/10, Batch Loss: 0.24001891911029816, Average Training Loss: 0.31186616132336276, Training Accuracy: 0.8991935483870968\n",
            "Epoch 4/10, Batch Loss: 0.16175991296768188, Average Training Loss: 0.30717534106224775, Training Accuracy: 0.9013671875\n",
            "Epoch 4/10, Batch Loss: 0.26067572832107544, Average Training Loss: 0.30576626188827283, Training Accuracy: 0.9024621212121212\n",
            "Epoch 4/10, Batch Loss: 0.23302523791790009, Average Training Loss: 0.3036268200067913, Training Accuracy: 0.9025735294117647\n",
            "Epoch 4/10, Batch Loss: 0.2578034996986389, Average Training Loss: 0.3023175822837012, Training Accuracy: 0.9026785714285714\n",
            "Epoch 4/10, Batch Loss: 0.23542648553848267, Average Training Loss: 0.3004594962630007, Training Accuracy: 0.9036458333333334\n",
            "Epoch 4/10, Batch Loss: 0.2047233283519745, Average Training Loss: 0.2978720322654054, Training Accuracy: 0.9045608108108109\n",
            "Epoch 4/10, Batch Loss: 0.358396977186203, Average Training Loss: 0.29946479397384745, Training Accuracy: 0.9046052631578947\n",
            "Epoch 4/10, Batch Loss: 0.22712081670761108, Average Training Loss: 0.2976098201977901, Training Accuracy: 0.9038461538461539\n",
            "Epoch 4/10, Batch Loss: 0.26130691170692444, Average Training Loss: 0.29670224748551843, Training Accuracy: 0.90390625\n",
            "Epoch 4/10, Batch Loss: 0.22262991964817047, Average Training Loss: 0.29489560534314413, Training Accuracy: 0.9047256097560976\n",
            "Epoch 4/10, Batch Loss: 0.2680104076862335, Average Training Loss: 0.2942554815894082, Training Accuracy: 0.9047619047619048\n",
            "Epoch 4/10, Batch Loss: 0.3091583847999573, Average Training Loss: 0.29460206073383954, Training Accuracy: 0.904796511627907\n",
            "Epoch 4/10, Batch Loss: 0.28837287425994873, Average Training Loss: 0.29446048831397836, Training Accuracy: 0.9055397727272727\n",
            "Epoch 4/10, Batch Loss: 0.6643866896629333, Average Training Loss: 0.3026810705661774, Training Accuracy: 0.9034722222222222\n",
            "Epoch 4/10, Batch Loss: 0.3596934974193573, Average Training Loss: 0.30392047114994214, Training Accuracy: 0.9021739130434783\n",
            "Epoch 4/10, Batch Loss: 0.4006829261779785, Average Training Loss: 0.30597924678883653, Training Accuracy: 0.901595744680851\n",
            "Epoch 4/10, Batch Loss: 0.37550121545791626, Average Training Loss: 0.30742762113610905, Training Accuracy: 0.900390625\n",
            "Epoch 4/10, Batch Loss: 0.3164064288139343, Average Training Loss: 0.30761086210912586, Training Accuracy: 0.9011479591836735\n",
            "Epoch 4/10, Batch Loss: 0.384313702583313, Average Training Loss: 0.3091449189186096, Training Accuracy: 0.899375\n",
            "Epoch 4/10, Batch Loss: 0.15774841606616974, Average Training Loss: 0.30617636003915, Training Accuracy: 0.8995098039215687\n",
            "Epoch 4/10, Batch Loss: 0.4842274785041809, Average Training Loss: 0.3096004200096314, Training Accuracy: 0.8984375\n",
            "Epoch 4/10, Batch Loss: 0.20671778917312622, Average Training Loss: 0.30765923829573505, Training Accuracy: 0.8991745283018868\n",
            "Epoch 4/10, Batch Loss: 0.21573978662490845, Average Training Loss: 0.3059570262277568, Training Accuracy: 0.8998842592592593\n",
            "Epoch 4/10, Batch Loss: 0.3011661469936371, Average Training Loss: 0.30586991933259094, Training Accuracy: 0.9005681818181818\n",
            "Epoch 4/10, Batch Loss: 0.22559751570224762, Average Training Loss: 0.3044364835534777, Training Accuracy: 0.9012276785714286\n",
            "Epoch 4/10, Batch Loss: 0.2627650499343872, Average Training Loss: 0.3037054057706866, Training Accuracy: 0.9013157894736842\n",
            "Epoch 4/10, Batch Loss: 0.16371813416481018, Average Training Loss: 0.3012918321223095, Training Accuracy: 0.9019396551724138\n",
            "Epoch 4/10, Batch Loss: 0.1300331950187683, Average Training Loss: 0.29838914335784267, Training Accuracy: 0.903072033898305\n",
            "Epoch 4/10, Batch Loss: 0.30264705419540405, Average Training Loss: 0.29846010853846866, Training Accuracy: 0.903125\n",
            "Epoch 4/10, Batch Loss: 0.2164068967103958, Average Training Loss: 0.29711497391833636, Training Accuracy: 0.9026639344262295\n",
            "Epoch 4/10, Batch Loss: 0.17067836225032806, Average Training Loss: 0.29507567373014265, Training Accuracy: 0.9037298387096774\n",
            "Epoch 4/10, Batch Loss: 0.19910763204097748, Average Training Loss: 0.2935523714811083, Training Accuracy: 0.904265873015873\n",
            "Epoch 4/10, Batch Loss: 0.20770587027072906, Average Training Loss: 0.2922110198996961, Training Accuracy: 0.9052734375\n",
            "Epoch 4/10, Batch Loss: 0.2760954797267914, Average Training Loss: 0.29196308851242064, Training Accuracy: 0.9052884615384615\n",
            "Epoch 4/10, Batch Loss: 0.06854899227619171, Average Training Loss: 0.2885780264482354, Training Accuracy: 0.9067234848484849\n",
            "Epoch 4/10, Batch Loss: 0.03477735072374344, Average Training Loss: 0.28883144138213473, Training Accuracy: 0.9068117313150426\n",
            "Epoch 4/10, Average Training Loss: 0.28478995666130263, Training Accuracy: 0.9068117313150426\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.93      0.90      0.92       427\n",
            "                Educational Opportunity       0.83      0.87      0.85       451\n",
            "                         Family Support       0.95      0.98      0.97       396\n",
            "                      Financial Support       0.93      0.94      0.93       404\n",
            "                 Program Implementation       0.91      0.85      0.88       436\n",
            "\n",
            "                               accuracy                           0.91      2114\n",
            "                              macro avg       0.91      0.91      0.91      2114\n",
            "                           weighted avg       0.91      0.91      0.91      2114\n",
            "\n",
            "Epoch 4/10, Validation Loss: 14.734795182943344, Validation Accuracy: 0.7410207939508506\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.74      0.70       113\n",
            "                Educational Opportunity       0.54      0.55      0.54       100\n",
            "                         Family Support       0.90      0.97      0.94       105\n",
            "                      Financial Support       0.75      0.73      0.74        97\n",
            "                 Program Implementation       0.86      0.70      0.77       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.74      0.74      0.74       529\n",
            "                           weighted avg       0.75      0.74      0.74       529\n",
            "\n",
            "Epoch 5/10, Batch Loss: 0.19825968146324158, Average Training Loss: 0.19825968146324158, Training Accuracy: 0.9375\n",
            "Epoch 5/10, Batch Loss: 0.10541598498821259, Average Training Loss: 0.15183783322572708, Training Accuracy: 0.953125\n",
            "Epoch 5/10, Batch Loss: 0.10228888690471649, Average Training Loss: 0.13532151778539023, Training Accuracy: 0.9479166666666666\n",
            "Epoch 5/10, Batch Loss: 0.15811939537525177, Average Training Loss: 0.1410209871828556, Training Accuracy: 0.9453125\n",
            "Epoch 5/10, Batch Loss: 0.10201894491910934, Average Training Loss: 0.13322057873010634, Training Accuracy: 0.95\n",
            "Epoch 5/10, Batch Loss: 0.05414396896958351, Average Training Loss: 0.12004114377001922, Training Accuracy: 0.9583333333333334\n",
            "Epoch 5/10, Batch Loss: 0.07529548555612564, Average Training Loss: 0.11364890688232013, Training Accuracy: 0.9598214285714286\n",
            "Epoch 5/10, Batch Loss: 0.20594243705272675, Average Training Loss: 0.12518559815362096, Training Accuracy: 0.953125\n",
            "Epoch 5/10, Batch Loss: 0.23241686820983887, Average Training Loss: 0.13710018371542296, Training Accuracy: 0.9479166666666666\n",
            "Epoch 5/10, Batch Loss: 0.11090213805437088, Average Training Loss: 0.13448037914931774, Training Accuracy: 0.95\n",
            "Epoch 5/10, Batch Loss: 0.10044821351766586, Average Training Loss: 0.13138654591007667, Training Accuracy: 0.9517045454545454\n",
            "Epoch 5/10, Batch Loss: 0.11542974412441254, Average Training Loss: 0.13005681242793798, Training Accuracy: 0.9557291666666666\n",
            "Epoch 5/10, Batch Loss: 0.10560494661331177, Average Training Loss: 0.12817589967296675, Training Accuracy: 0.9567307692307693\n",
            "Epoch 5/10, Batch Loss: 0.05267402529716492, Average Training Loss: 0.12278290864612375, Training Accuracy: 0.9598214285714286\n",
            "Epoch 5/10, Batch Loss: 0.07400542497634888, Average Training Loss: 0.11953107640147209, Training Accuracy: 0.9625\n",
            "Epoch 5/10, Batch Loss: 0.05870065838098526, Average Training Loss: 0.11572917527519166, Training Accuracy: 0.96484375\n",
            "Epoch 5/10, Batch Loss: 0.2323230504989624, Average Training Loss: 0.12258763852364876, Training Accuracy: 0.9632352941176471\n",
            "Epoch 5/10, Batch Loss: 0.17464467883110046, Average Training Loss: 0.1254796963185072, Training Accuracy: 0.9618055555555556\n",
            "Epoch 5/10, Batch Loss: 0.1558169424533844, Average Training Loss: 0.12707639348350072, Training Accuracy: 0.962171052631579\n",
            "Epoch 5/10, Batch Loss: 0.0967906266450882, Average Training Loss: 0.12556210514158012, Training Accuracy: 0.9625\n",
            "Epoch 5/10, Batch Loss: 0.06960663944482803, Average Training Loss: 0.12289755915602048, Training Accuracy: 0.9642857142857143\n",
            "Epoch 5/10, Batch Loss: 0.12792430818080902, Average Training Loss: 0.12312604774805633, Training Accuracy: 0.9630681818181818\n",
            "Epoch 5/10, Batch Loss: 0.11880490928888321, Average Training Loss: 0.12293817216287488, Training Accuracy: 0.9633152173913043\n",
            "Epoch 5/10, Batch Loss: 0.17097800970077515, Average Training Loss: 0.1249398320602874, Training Accuracy: 0.9635416666666666\n",
            "Epoch 5/10, Batch Loss: 0.1266406625509262, Average Training Loss: 0.12500786527991295, Training Accuracy: 0.96375\n",
            "Epoch 5/10, Batch Loss: 0.3459894061088562, Average Training Loss: 0.13350715531179538, Training Accuracy: 0.9579326923076923\n",
            "Epoch 5/10, Batch Loss: 0.3132416307926178, Average Training Loss: 0.14016398773701103, Training Accuracy: 0.9560185185185185\n",
            "Epoch 5/10, Batch Loss: 0.07886692881584167, Average Training Loss: 0.13797480706125498, Training Accuracy: 0.9564732142857143\n",
            "Epoch 5/10, Batch Loss: 0.1551441252231598, Average Training Loss: 0.13856685251511378, Training Accuracy: 0.9568965517241379\n",
            "Epoch 5/10, Batch Loss: 0.052902836352586746, Average Training Loss: 0.1357113853096962, Training Accuracy: 0.9583333333333334\n",
            "Epoch 5/10, Batch Loss: 0.0791756734251976, Average Training Loss: 0.13388765266826075, Training Accuracy: 0.9586693548387096\n",
            "Epoch 5/10, Batch Loss: 0.12719808518886566, Average Training Loss: 0.13367860368452966, Training Accuracy: 0.958984375\n",
            "Epoch 5/10, Batch Loss: 0.1707484871149063, Average Training Loss: 0.13480193348545016, Training Accuracy: 0.9573863636363636\n",
            "Epoch 5/10, Batch Loss: 0.09705553948879242, Average Training Loss: 0.13369174542672493, Training Accuracy: 0.9577205882352942\n",
            "Epoch 5/10, Batch Loss: 0.11547764390707016, Average Training Loss: 0.13317134252616336, Training Accuracy: 0.9580357142857143\n",
            "Epoch 5/10, Batch Loss: 0.18719753623008728, Average Training Loss: 0.13467207012905014, Training Accuracy: 0.9565972222222222\n",
            "Epoch 5/10, Batch Loss: 0.16995476186275482, Average Training Loss: 0.13562565639212326, Training Accuracy: 0.9552364864864865\n",
            "Epoch 5/10, Batch Loss: 0.33448001742362976, Average Training Loss: 0.14085866589295237, Training Accuracy: 0.953125\n",
            "Epoch 5/10, Batch Loss: 0.1475140005350113, Average Training Loss: 0.141029315499159, Training Accuracy: 0.9527243589743589\n",
            "Epoch 5/10, Batch Loss: 0.04480978474020958, Average Training Loss: 0.13862382723018526, Training Accuracy: 0.95390625\n",
            "Epoch 5/10, Batch Loss: 0.12799184024333954, Average Training Loss: 0.13836451047440854, Training Accuracy: 0.9542682926829268\n",
            "Epoch 5/10, Batch Loss: 0.03146817162632942, Average Training Loss: 0.1358193595494543, Training Accuracy: 0.9553571428571429\n",
            "Epoch 5/10, Batch Loss: 0.11198709160089493, Average Training Loss: 0.1352651207599529, Training Accuracy: 0.9549418604651163\n",
            "Epoch 5/10, Batch Loss: 0.06745362281799316, Average Training Loss: 0.1337239503521811, Training Accuracy: 0.9559659090909091\n",
            "Epoch 5/10, Batch Loss: 0.38955458998680115, Average Training Loss: 0.13940907567739486, Training Accuracy: 0.9541666666666667\n",
            "Epoch 5/10, Batch Loss: 0.19552162289619446, Average Training Loss: 0.14062891366041225, Training Accuracy: 0.953125\n",
            "Epoch 5/10, Batch Loss: 0.21991798281669617, Average Training Loss: 0.14231591513182254, Training Accuracy: 0.9527925531914894\n",
            "Epoch 5/10, Batch Loss: 0.14398124814033508, Average Training Loss: 0.14235060956949988, Training Accuracy: 0.9524739583333334\n",
            "Epoch 5/10, Batch Loss: 0.42842739820480347, Average Training Loss: 0.14818891137838364, Training Accuracy: 0.9496173469387755\n",
            "Epoch 5/10, Batch Loss: 0.12116070836782455, Average Training Loss: 0.14764834731817245, Training Accuracy: 0.95\n",
            "Epoch 5/10, Batch Loss: 0.03447379171848297, Average Training Loss: 0.1454292383848452, Training Accuracy: 0.9509803921568627\n",
            "Epoch 5/10, Batch Loss: 0.11383935064077377, Average Training Loss: 0.14482174054361308, Training Accuracy: 0.9513221153846154\n",
            "Epoch 5/10, Batch Loss: 0.2015889585018158, Average Training Loss: 0.1458928201277301, Training Accuracy: 0.9516509433962265\n",
            "Epoch 5/10, Batch Loss: 0.06918308138847351, Average Training Loss: 0.14447226941033645, Training Accuracy: 0.9525462962962963\n",
            "Epoch 5/10, Batch Loss: 0.17009516060352325, Average Training Loss: 0.14493814015930348, Training Accuracy: 0.9522727272727273\n",
            "Epoch 5/10, Batch Loss: 0.17234620451927185, Average Training Loss: 0.1454275698800172, Training Accuracy: 0.9520089285714286\n",
            "Epoch 5/10, Batch Loss: 0.08253501355648041, Average Training Loss: 0.14432419169890254, Training Accuracy: 0.9523026315789473\n",
            "Epoch 5/10, Batch Loss: 0.21078024804592133, Average Training Loss: 0.14546998577385112, Training Accuracy: 0.9525862068965517\n",
            "Epoch 5/10, Batch Loss: 0.23203592002391815, Average Training Loss: 0.14693720499842855, Training Accuracy: 0.9518008474576272\n",
            "Epoch 5/10, Batch Loss: 0.31456172466278076, Average Training Loss: 0.1497309469928344, Training Accuracy: 0.9510416666666667\n",
            "Epoch 5/10, Batch Loss: 0.06631073355674744, Average Training Loss: 0.1483634025102756, Training Accuracy: 0.951844262295082\n",
            "Epoch 5/10, Batch Loss: 0.07855984568595886, Average Training Loss: 0.14723753869052855, Training Accuracy: 0.9526209677419355\n",
            "Epoch 5/10, Batch Loss: 0.1543755680322647, Average Training Loss: 0.147350840743572, Training Accuracy: 0.9528769841269841\n",
            "Epoch 5/10, Batch Loss: 0.19521000981330872, Average Training Loss: 0.14809864026028663, Training Accuracy: 0.95263671875\n",
            "Epoch 5/10, Batch Loss: 0.1882680505514145, Average Training Loss: 0.14871663118784245, Training Accuracy: 0.9524038461538461\n",
            "Epoch 5/10, Batch Loss: 0.13823090493679047, Average Training Loss: 0.148557756547675, Training Accuracy: 0.9521780303030303\n",
            "Epoch 5/10, Batch Loss: 0.01933823712170124, Average Training Loss: 0.14870993633707852, Training Accuracy: 0.9522232734153264\n",
            "Epoch 5/10, Average Training Loss: 0.14662910700400375, Training Accuracy: 0.9522232734153264\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.97      0.97      0.97       427\n",
            "                Educational Opportunity       0.90      0.94      0.92       451\n",
            "                         Family Support       0.98      0.99      0.98       396\n",
            "                      Financial Support       0.97      0.96      0.97       404\n",
            "                 Program Implementation       0.96      0.90      0.93       436\n",
            "\n",
            "                               accuracy                           0.95      2114\n",
            "                              macro avg       0.95      0.95      0.95      2114\n",
            "                           weighted avg       0.95      0.95      0.95      2114\n",
            "\n",
            "Epoch 5/10, Validation Loss: 16.358764111995697, Validation Accuracy: 0.7372400756143668\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.71      0.69       113\n",
            "                Educational Opportunity       0.55      0.54      0.54       100\n",
            "                         Family Support       0.93      0.95      0.94       105\n",
            "                      Financial Support       0.71      0.76      0.74        97\n",
            "                 Program Implementation       0.82      0.72      0.77       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.74      0.74      0.74       529\n",
            "                           weighted avg       0.74      0.74      0.74       529\n",
            "\n",
            "Epoch 6/10, Batch Loss: 0.026814201846718788, Average Training Loss: 0.026814201846718788, Training Accuracy: 1.0\n",
            "Epoch 6/10, Batch Loss: 0.06191079691052437, Average Training Loss: 0.04436249937862158, Training Accuracy: 1.0\n",
            "Epoch 6/10, Batch Loss: 0.19936658442020416, Average Training Loss: 0.09603052772581577, Training Accuracy: 0.9895833333333334\n",
            "Epoch 6/10, Batch Loss: 0.07216394692659378, Average Training Loss: 0.09006388252601027, Training Accuracy: 0.9921875\n",
            "Epoch 6/10, Batch Loss: 0.12188924103975296, Average Training Loss: 0.09642895422875881, Training Accuracy: 0.9875\n",
            "Epoch 6/10, Batch Loss: 0.07632209360599518, Average Training Loss: 0.09307781079163154, Training Accuracy: 0.9895833333333334\n",
            "Epoch 6/10, Batch Loss: 0.020002499222755432, Average Training Loss: 0.08263848056750638, Training Accuracy: 0.9910714285714286\n",
            "Epoch 6/10, Batch Loss: 0.10258476436138153, Average Training Loss: 0.08513176604174078, Training Accuracy: 0.98828125\n",
            "Epoch 6/10, Batch Loss: 0.061194974929094315, Average Training Loss: 0.08247212258478005, Training Accuracy: 0.9895833333333334\n",
            "Epoch 6/10, Batch Loss: 0.1593981683254242, Average Training Loss: 0.09016472715884447, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.040682319551706314, Average Training Loss: 0.08566632646728646, Training Accuracy: 0.9857954545454546\n",
            "Epoch 6/10, Batch Loss: 0.11558381468057632, Average Training Loss: 0.08815945048506062, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.038004230707883835, Average Training Loss: 0.08430135665604702, Training Accuracy: 0.9855769230769231\n",
            "Epoch 6/10, Batch Loss: 0.03264734894037247, Average Training Loss: 0.08061178467635598, Training Accuracy: 0.9866071428571429\n",
            "Epoch 6/10, Batch Loss: 0.021550076082348824, Average Training Loss: 0.0766743374367555, Training Accuracy: 0.9875\n",
            "Epoch 6/10, Batch Loss: 0.044391483068466187, Average Training Loss: 0.07465665903873742, Training Accuracy: 0.98828125\n",
            "Epoch 6/10, Batch Loss: 0.1340799182653427, Average Training Loss: 0.07815214487559655, Training Accuracy: 0.9852941176470589\n",
            "Epoch 6/10, Batch Loss: 0.07674549520015717, Average Training Loss: 0.07807399767140548, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.07262247800827026, Average Training Loss: 0.07778707558387205, Training Accuracy: 0.9835526315789473\n",
            "Epoch 6/10, Batch Loss: 0.033436037600040436, Average Training Loss: 0.07556952368468046, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.035919785499572754, Average Training Loss: 0.07368144091396105, Training Accuracy: 0.9851190476190477\n",
            "Epoch 6/10, Batch Loss: 0.03970875218510628, Average Training Loss: 0.0721372277899222, Training Accuracy: 0.9857954545454546\n",
            "Epoch 6/10, Batch Loss: 0.10697674751281738, Average Training Loss: 0.07365198951700459, Training Accuracy: 0.9836956521739131\n",
            "Epoch 6/10, Batch Loss: 0.04060768708586693, Average Training Loss: 0.07227514358237386, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.041676267981529236, Average Training Loss: 0.07105118855834007, Training Accuracy: 0.985\n",
            "Epoch 6/10, Batch Loss: 0.08670101314783096, Average Training Loss: 0.0716531048887051, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.20055146515369415, Average Training Loss: 0.07642711823185284, Training Accuracy: 0.9837962962962963\n",
            "Epoch 6/10, Batch Loss: 0.038949284702539444, Average Training Loss: 0.07508862417723451, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.2622930407524109, Average Training Loss: 0.08154394888672335, Training Accuracy: 0.9827586206896551\n",
            "Epoch 6/10, Batch Loss: 0.07962259650230408, Average Training Loss: 0.08147990380724271, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.046357229351997375, Average Training Loss: 0.08034691430868642, Training Accuracy: 0.9818548387096774\n",
            "Epoch 6/10, Batch Loss: 0.06617418676614761, Average Training Loss: 0.07990401657298207, Training Accuracy: 0.9814453125\n",
            "Epoch 6/10, Batch Loss: 0.04057568684220314, Average Training Loss: 0.0787122490053827, Training Accuracy: 0.9820075757575758\n",
            "Epoch 6/10, Batch Loss: 0.05825701355934143, Average Training Loss: 0.07811062443344031, Training Accuracy: 0.9816176470588235\n",
            "Epoch 6/10, Batch Loss: 0.03343972563743591, Average Training Loss: 0.07683431303926877, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.028544655069708824, Average Training Loss: 0.07549293365122543, Training Accuracy: 0.9826388888888888\n",
            "Epoch 6/10, Batch Loss: 0.09013115614652634, Average Training Loss: 0.07588856128623357, Training Accuracy: 0.9822635135135135\n",
            "Epoch 6/10, Batch Loss: 0.05870060250163078, Average Training Loss: 0.0754362465813756, Training Accuracy: 0.9819078947368421\n",
            "Epoch 6/10, Batch Loss: 0.03476482629776001, Average Training Loss: 0.07439338965102649, Training Accuracy: 0.9823717948717948\n",
            "Epoch 6/10, Batch Loss: 0.152509868144989, Average Training Loss: 0.07634630161337555, Training Accuracy: 0.98046875\n",
            "Epoch 6/10, Batch Loss: 0.019059142097830772, Average Training Loss: 0.07494905382031347, Training Accuracy: 0.9809451219512195\n",
            "Epoch 6/10, Batch Loss: 0.19053912162780762, Average Training Loss: 0.07770119829192049, Training Accuracy: 0.9784226190476191\n",
            "Epoch 6/10, Batch Loss: 0.049596644937992096, Average Training Loss: 0.07704760402787564, Training Accuracy: 0.9781976744186046\n",
            "Epoch 6/10, Batch Loss: 0.08461783826351166, Average Training Loss: 0.07721965480595827, Training Accuracy: 0.9772727272727273\n",
            "Epoch 6/10, Batch Loss: 0.11104899644851685, Average Training Loss: 0.07797141795357068, Training Accuracy: 0.9763888888888889\n",
            "Epoch 6/10, Batch Loss: 0.13673827052116394, Average Training Loss: 0.07924895822677923, Training Accuracy: 0.9762228260869565\n",
            "Epoch 6/10, Batch Loss: 0.2087121158838272, Average Training Loss: 0.08200349349607812, Training Accuracy: 0.9753989361702128\n",
            "Epoch 6/10, Batch Loss: 0.021767668426036835, Average Training Loss: 0.0807485804737856, Training Accuracy: 0.9759114583333334\n",
            "Epoch 6/10, Batch Loss: 0.05758063122630119, Average Training Loss: 0.08027576518302061, Training Accuracy: 0.9757653061224489\n",
            "Epoch 6/10, Batch Loss: 0.029582370072603226, Average Training Loss: 0.07926189728081226, Training Accuracy: 0.97625\n",
            "Epoch 6/10, Batch Loss: 0.10554477572441101, Average Training Loss: 0.07977724783852988, Training Accuracy: 0.9761029411764706\n",
            "Epoch 6/10, Batch Loss: 0.04387372359633446, Average Training Loss: 0.0790867954492569, Training Accuracy: 0.9765625\n",
            "Epoch 6/10, Batch Loss: 0.026851272210478783, Average Training Loss: 0.07810121953909127, Training Accuracy: 0.9770047169811321\n",
            "Epoch 6/10, Batch Loss: 0.06731339544057846, Average Training Loss: 0.07790144501874845, Training Accuracy: 0.9774305555555556\n",
            "Epoch 6/10, Batch Loss: 0.06677114963531494, Average Training Loss: 0.07769907601177692, Training Accuracy: 0.977840909090909\n",
            "Epoch 6/10, Batch Loss: 0.024738702923059464, Average Training Loss: 0.07675335506376411, Training Accuracy: 0.9782366071428571\n",
            "Epoch 6/10, Batch Loss: 0.07230597734451294, Average Training Loss: 0.07667533089325093, Training Accuracy: 0.9780701754385965\n",
            "Epoch 6/10, Batch Loss: 0.06297258287668228, Average Training Loss: 0.0764390766171032, Training Accuracy: 0.9779094827586207\n",
            "Epoch 6/10, Batch Loss: 0.17477494478225708, Average Training Loss: 0.07810578624702107, Training Accuracy: 0.9772245762711864\n",
            "Epoch 6/10, Batch Loss: 0.0769253671169281, Average Training Loss: 0.07808611259485285, Training Accuracy: 0.9770833333333333\n",
            "Epoch 6/10, Batch Loss: 0.04360304772853851, Average Training Loss: 0.07752081644950343, Training Accuracy: 0.9774590163934426\n",
            "Epoch 6/10, Batch Loss: 0.20321209728717804, Average Training Loss: 0.07954809517269174, Training Accuracy: 0.9768145161290323\n",
            "Epoch 6/10, Batch Loss: 0.08348283916711807, Average Training Loss: 0.07961055142657152, Training Accuracy: 0.9766865079365079\n",
            "Epoch 6/10, Batch Loss: 0.19781546294689178, Average Training Loss: 0.08145750316907652, Training Accuracy: 0.97607421875\n",
            "Epoch 6/10, Batch Loss: 0.053847845643758774, Average Training Loss: 0.08103273920714855, Training Accuracy: 0.9764423076923077\n",
            "Epoch 6/10, Batch Loss: 0.16095316410064697, Average Training Loss: 0.08224365473583792, Training Accuracy: 0.9758522727272727\n",
            "Epoch 6/10, Batch Loss: 0.01143763866275549, Average Training Loss: 0.08233897977261015, Training Accuracy: 0.9758751182592242\n",
            "Epoch 6/10, Average Training Loss: 0.08118684852579192, Training Accuracy: 0.9758751182592242\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.98      0.99      0.98       427\n",
            "                Educational Opportunity       0.95      0.96      0.96       451\n",
            "                         Family Support       0.99      1.00      0.99       396\n",
            "                      Financial Support       0.99      0.99      0.99       404\n",
            "                 Program Implementation       0.97      0.94      0.96       436\n",
            "\n",
            "                               accuracy                           0.98      2114\n",
            "                              macro avg       0.98      0.98      0.98      2114\n",
            "                           weighted avg       0.98      0.98      0.98      2114\n",
            "\n",
            "Epoch 6/10, Validation Loss: 18.51513648033142, Validation Accuracy: 0.7277882797731569\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.68      0.68       113\n",
            "                Educational Opportunity       0.51      0.56      0.54       100\n",
            "                         Family Support       0.92      0.96      0.94       105\n",
            "                      Financial Support       0.76      0.67      0.71        97\n",
            "                 Program Implementation       0.79      0.75      0.77       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.73      0.73      0.73       529\n",
            "                           weighted avg       0.73      0.73      0.73       529\n",
            "\n",
            "Epoch 7/10, Batch Loss: 0.04961422085762024, Average Training Loss: 0.04961422085762024, Training Accuracy: 0.96875\n",
            "Epoch 7/10, Batch Loss: 0.03612871095538139, Average Training Loss: 0.042871465906500816, Training Accuracy: 0.984375\n",
            "Epoch 7/10, Batch Loss: 0.017773477360606194, Average Training Loss: 0.03450546972453594, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.04789124056696892, Average Training Loss: 0.037851912435144186, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.04161123186349869, Average Training Loss: 0.03860377632081509, Training Accuracy: 0.99375\n",
            "Epoch 7/10, Batch Loss: 0.0359678752720356, Average Training Loss: 0.03816445947935184, Training Accuracy: 0.9947916666666666\n",
            "Epoch 7/10, Batch Loss: 0.06598293781280518, Average Training Loss: 0.04213852781270232, Training Accuracy: 0.9910714285714286\n",
            "Epoch 7/10, Batch Loss: 0.109361931681633, Average Training Loss: 0.05054145329631865, Training Accuracy: 0.98828125\n",
            "Epoch 7/10, Batch Loss: 0.06849654763936996, Average Training Loss: 0.05253646377887991, Training Accuracy: 0.9861111111111112\n",
            "Epoch 7/10, Batch Loss: 0.10747380554676056, Average Training Loss: 0.058030197955667974, Training Accuracy: 0.984375\n",
            "Epoch 7/10, Batch Loss: 0.036859333515167236, Average Training Loss: 0.05610557391562245, Training Accuracy: 0.9857954545454546\n",
            "Epoch 7/10, Batch Loss: 0.10536818951368332, Average Training Loss: 0.06021079188212752, Training Accuracy: 0.984375\n",
            "Epoch 7/10, Batch Loss: 0.02779966965317726, Average Training Loss: 0.057717628633746736, Training Accuracy: 0.9855769230769231\n",
            "Epoch 7/10, Batch Loss: 0.03975538909435272, Average Training Loss: 0.05643461152379002, Training Accuracy: 0.9866071428571429\n",
            "Epoch 7/10, Batch Loss: 0.025152914226055145, Average Training Loss: 0.05434916503727436, Training Accuracy: 0.9875\n",
            "Epoch 7/10, Batch Loss: 0.023811880499124527, Average Training Loss: 0.052440584753639996, Training Accuracy: 0.98828125\n",
            "Epoch 7/10, Batch Loss: 0.020606297999620438, Average Training Loss: 0.05056797965046238, Training Accuracy: 0.9889705882352942\n",
            "Epoch 7/10, Batch Loss: 0.026845743879675865, Average Training Loss: 0.04925007766319646, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.09322993457317352, Average Training Loss: 0.05156480697424788, Training Accuracy: 0.9884868421052632\n",
            "Epoch 7/10, Batch Loss: 0.0196023341268301, Average Training Loss: 0.049966683331876996, Training Accuracy: 0.9890625\n",
            "Epoch 7/10, Batch Loss: 0.01803714409470558, Average Training Loss: 0.04844622908248788, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.01669318601489067, Average Training Loss: 0.04700290894305164, Training Accuracy: 0.9900568181818182\n",
            "Epoch 7/10, Batch Loss: 0.032205916941165924, Average Training Loss: 0.046359561464708786, Training Accuracy: 0.9904891304347826\n",
            "Epoch 7/10, Batch Loss: 0.024313680827617645, Average Training Loss: 0.04544098310482999, Training Accuracy: 0.9908854166666666\n",
            "Epoch 7/10, Batch Loss: 0.017883548513054848, Average Training Loss: 0.04433868572115898, Training Accuracy: 0.99125\n",
            "Epoch 7/10, Batch Loss: 0.03872518613934517, Average Training Loss: 0.044122781891089216, Training Accuracy: 0.9915865384615384\n",
            "Epoch 7/10, Batch Loss: 0.03463325649499893, Average Training Loss: 0.04377131798753032, Training Accuracy: 0.9918981481481481\n",
            "Epoch 7/10, Batch Loss: 0.021100739017128944, Average Training Loss: 0.04296165445287313, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.09856943786144257, Average Training Loss: 0.04487916422558242, Training Accuracy: 0.9913793103448276\n",
            "Epoch 7/10, Batch Loss: 0.03385915979743004, Average Training Loss: 0.04451183074464401, Training Accuracy: 0.9916666666666667\n",
            "Epoch 7/10, Batch Loss: 0.05510684847831726, Average Training Loss: 0.04485360551024637, Training Accuracy: 0.9919354838709677\n",
            "Epoch 7/10, Batch Loss: 0.027839941903948784, Average Training Loss: 0.04432192852254957, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.03927084803581238, Average Training Loss: 0.044168865477496926, Training Accuracy: 0.9924242424242424\n",
            "Epoch 7/10, Batch Loss: 0.040208082646131516, Average Training Loss: 0.04405237186480971, Training Accuracy: 0.9926470588235294\n",
            "Epoch 7/10, Batch Loss: 0.08840549737215042, Average Training Loss: 0.0453196040221623, Training Accuracy: 0.9919642857142857\n",
            "Epoch 7/10, Batch Loss: 0.019167477265000343, Average Training Loss: 0.04459315605668558, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.015293797478079796, Average Training Loss: 0.04380128150050704, Training Accuracy: 0.9923986486486487\n",
            "Epoch 7/10, Batch Loss: 0.017421219497919083, Average Training Loss: 0.043107069342544206, Training Accuracy: 0.9925986842105263\n",
            "Epoch 7/10, Batch Loss: 0.049871962517499924, Average Training Loss: 0.043280528141902044, Training Accuracy: 0.9919871794871795\n",
            "Epoch 7/10, Batch Loss: 0.017875438556075096, Average Training Loss: 0.04264540090225637, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.061495352536439896, Average Training Loss: 0.043105155820163284, Training Accuracy: 0.9916158536585366\n",
            "Epoch 7/10, Batch Loss: 0.012965147383511066, Average Training Loss: 0.04238753657167157, Training Accuracy: 0.9918154761904762\n",
            "Epoch 7/10, Batch Loss: 0.02340579219162464, Average Training Loss: 0.04194610065585652, Training Accuracy: 0.9920058139534884\n",
            "Epoch 7/10, Batch Loss: 0.039973776787519455, Average Training Loss: 0.041901275113394316, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.06140999495983124, Average Training Loss: 0.04233480222109291, Training Accuracy: 0.9916666666666667\n",
            "Epoch 7/10, Batch Loss: 0.15022198855876923, Average Training Loss: 0.044680175837129354, Training Accuracy: 0.9911684782608695\n",
            "Epoch 7/10, Batch Loss: 0.019694264978170395, Average Training Loss: 0.044148560712470655, Training Accuracy: 0.9913563829787234\n",
            "Epoch 7/10, Batch Loss: 0.013689890503883362, Average Training Loss: 0.043514005083125085, Training Accuracy: 0.9915364583333334\n",
            "Epoch 7/10, Batch Loss: 0.20701372623443604, Average Training Loss: 0.04685073408621306, Training Accuracy: 0.9910714285714286\n",
            "Epoch 7/10, Batch Loss: 0.05723162740468979, Average Training Loss: 0.047058351952582594, Training Accuracy: 0.990625\n",
            "Epoch 7/10, Batch Loss: 0.019092490896582603, Average Training Loss: 0.046510001735798286, Training Accuracy: 0.9908088235294118\n",
            "Epoch 7/10, Batch Loss: 0.06535889953374863, Average Training Loss: 0.04687248053960502, Training Accuracy: 0.9903846153846154\n",
            "Epoch 7/10, Batch Loss: 0.10432519763708115, Average Training Loss: 0.04795649406974608, Training Accuracy: 0.9899764150943396\n",
            "Epoch 7/10, Batch Loss: 0.047073978930711746, Average Training Loss: 0.047940151196801, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.07757708430290222, Average Training Loss: 0.04847900452600284, Training Accuracy: 0.9892045454545455\n",
            "Epoch 7/10, Batch Loss: 0.015449860133230686, Average Training Loss: 0.04788919837613191, Training Accuracy: 0.9893973214285714\n",
            "Epoch 7/10, Batch Loss: 0.02389434352517128, Average Training Loss: 0.047468236010325585, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.01393868401646614, Average Training Loss: 0.04689014028629352, Training Accuracy: 0.9897629310344828\n",
            "Epoch 7/10, Batch Loss: 0.09080460667610168, Average Training Loss: 0.04763445327595129, Training Accuracy: 0.989406779661017\n",
            "Epoch 7/10, Batch Loss: 0.05347661301493645, Average Training Loss: 0.047731822604934374, Training Accuracy: 0.9890625\n",
            "Epoch 7/10, Batch Loss: 0.17848704755306244, Average Training Loss: 0.04987535088277254, Training Accuracy: 0.9887295081967213\n",
            "Epoch 7/10, Batch Loss: 0.03175325691699982, Average Training Loss: 0.049583059044614915, Training Accuracy: 0.9889112903225806\n",
            "Epoch 7/10, Batch Loss: 0.010834833607077599, Average Training Loss: 0.04896800784719369, Training Accuracy: 0.9890873015873016\n",
            "Epoch 7/10, Batch Loss: 0.06032849848270416, Average Training Loss: 0.04914551551337354, Training Accuracy: 0.9892578125\n",
            "Epoch 7/10, Batch Loss: 0.013249270617961884, Average Training Loss: 0.04859326559190567, Training Accuracy: 0.989423076923077\n",
            "Epoch 7/10, Batch Loss: 0.020835349336266518, Average Training Loss: 0.04817269110318386, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.007655682973563671, Average Training Loss: 0.04824300163910991, Training Accuracy: 0.9895931882686849\n",
            "Epoch 7/10, Average Training Loss: 0.04756795963856267, Training Accuracy: 0.9895931882686849\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.98      0.98      0.98       451\n",
            "                         Family Support       0.99      0.99      0.99       396\n",
            "                      Financial Support       0.99      1.00      0.99       404\n",
            "                 Program Implementation       0.99      0.98      0.98       436\n",
            "\n",
            "                               accuracy                           0.99      2114\n",
            "                              macro avg       0.99      0.99      0.99      2114\n",
            "                           weighted avg       0.99      0.99      0.99      2114\n",
            "\n",
            "Epoch 7/10, Validation Loss: 20.07032972574234, Validation Accuracy: 0.722117202268431\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.65      0.68       113\n",
            "                Educational Opportunity       0.50      0.61      0.55       100\n",
            "                         Family Support       0.93      0.94      0.93       105\n",
            "                      Financial Support       0.76      0.61      0.67        97\n",
            "                 Program Implementation       0.76      0.79      0.77       114\n",
            "\n",
            "                               accuracy                           0.72       529\n",
            "                              macro avg       0.73      0.72      0.72       529\n",
            "                           weighted avg       0.73      0.72      0.72       529\n",
            "\n",
            "Epoch 8/10, Batch Loss: 0.030490344390273094, Average Training Loss: 0.030490344390273094, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.02072489634156227, Average Training Loss: 0.025607620365917683, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.015244744718074799, Average Training Loss: 0.022153328483303387, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.015695473179221153, Average Training Loss: 0.02053886465728283, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.019231563434004784, Average Training Loss: 0.02027740441262722, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.025202756747603416, Average Training Loss: 0.021098296468456585, Training Accuracy: 1.0\n",
            "Epoch 8/10, Batch Loss: 0.08804316073656082, Average Training Loss: 0.03066184850675719, Training Accuracy: 0.9955357142857143\n",
            "Epoch 8/10, Batch Loss: 0.05855821073055267, Average Training Loss: 0.034148893784731627, Training Accuracy: 0.9921875\n",
            "Epoch 8/10, Batch Loss: 0.014668891206383705, Average Training Loss: 0.03198444905380408, Training Accuracy: 0.9930555555555556\n",
            "Epoch 8/10, Batch Loss: 0.01824803836643696, Average Training Loss: 0.030610807985067368, Training Accuracy: 0.99375\n",
            "Epoch 8/10, Batch Loss: 0.011041300371289253, Average Training Loss: 0.028831761838360268, Training Accuracy: 0.9943181818181818\n",
            "Epoch 8/10, Batch Loss: 0.026185525581240654, Average Training Loss: 0.028611242150266964, Training Accuracy: 0.9947916666666666\n",
            "Epoch 8/10, Batch Loss: 0.04835273697972298, Average Training Loss: 0.030129818675609734, Training Accuracy: 0.9927884615384616\n",
            "Epoch 8/10, Batch Loss: 0.05596351623535156, Average Training Loss: 0.03197508278701987, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.032530516386032104, Average Training Loss: 0.032012111693620685, Training Accuracy: 0.9916666666666667\n",
            "Epoch 8/10, Batch Loss: 0.07461132109165192, Average Training Loss: 0.034674562280997634, Training Accuracy: 0.990234375\n",
            "Epoch 8/10, Batch Loss: 0.046033792197704315, Average Training Loss: 0.035342752276098024, Training Accuracy: 0.9889705882352942\n",
            "Epoch 8/10, Batch Loss: 0.01614266447722912, Average Training Loss: 0.034276080731716424, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.06381487846374512, Average Training Loss: 0.03583075429656004, Training Accuracy: 0.9884868421052632\n",
            "Epoch 8/10, Batch Loss: 0.013984818942844868, Average Training Loss: 0.03473845752887428, Training Accuracy: 0.9890625\n",
            "Epoch 8/10, Batch Loss: 0.1362437605857849, Average Training Loss: 0.03957204338872716, Training Accuracy: 0.9880952380952381\n",
            "Epoch 8/10, Batch Loss: 0.028781602159142494, Average Training Loss: 0.039081568787382406, Training Accuracy: 0.9886363636363636\n",
            "Epoch 8/10, Batch Loss: 0.07229499518871307, Average Training Loss: 0.04052563080483157, Training Accuracy: 0.9877717391304348\n",
            "Epoch 8/10, Batch Loss: 0.011144038289785385, Average Training Loss: 0.03930139778337131, Training Accuracy: 0.98828125\n",
            "Epoch 8/10, Batch Loss: 0.010910727083683014, Average Training Loss: 0.03816577095538378, Training Accuracy: 0.98875\n",
            "Epoch 8/10, Batch Loss: 0.037978123873472214, Average Training Loss: 0.03815855375992564, Training Accuracy: 0.9891826923076923\n",
            "Epoch 8/10, Batch Loss: 0.01807270757853985, Average Training Loss: 0.037414633530985425, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.017434878274798393, Average Training Loss: 0.03670107084326446, Training Accuracy: 0.9899553571428571\n",
            "Epoch 8/10, Batch Loss: 0.034463878720998764, Average Training Loss: 0.03662392628732426, Training Accuracy: 0.990301724137931\n",
            "Epoch 8/10, Batch Loss: 0.03233211487531662, Average Training Loss: 0.03648086590692401, Training Accuracy: 0.990625\n",
            "Epoch 8/10, Batch Loss: 0.02075020596385002, Average Training Loss: 0.03597342526359904, Training Accuracy: 0.9909274193548387\n",
            "Epoch 8/10, Batch Loss: 0.020094284787774086, Average Training Loss: 0.03547720212372951, Training Accuracy: 0.9912109375\n",
            "Epoch 8/10, Batch Loss: 0.023214006796479225, Average Training Loss: 0.035105590144115864, Training Accuracy: 0.9914772727272727\n",
            "Epoch 8/10, Batch Loss: 0.014312990941107273, Average Training Loss: 0.03449404310873326, Training Accuracy: 0.9917279411764706\n",
            "Epoch 8/10, Batch Loss: 0.01233820803463459, Average Training Loss: 0.0338610192494733, Training Accuracy: 0.9919642857142857\n",
            "Epoch 8/10, Batch Loss: 0.020554078742861748, Average Training Loss: 0.033491382013178535, Training Accuracy: 0.9921875\n",
            "Epoch 8/10, Batch Loss: 0.012605826370418072, Average Training Loss: 0.03292690753634717, Training Accuracy: 0.9923986486486487\n",
            "Epoch 8/10, Batch Loss: 0.01095331646502018, Average Training Loss: 0.032348655139733305, Training Accuracy: 0.9925986842105263\n",
            "Epoch 8/10, Batch Loss: 0.04775509610772133, Average Training Loss: 0.03274369208763043, Training Accuracy: 0.9927884615384616\n",
            "Epoch 8/10, Batch Loss: 0.015125568956136703, Average Training Loss: 0.032303239009343086, Training Accuracy: 0.99296875\n",
            "Epoch 8/10, Batch Loss: 0.01537563931196928, Average Training Loss: 0.031890370724041286, Training Accuracy: 0.993140243902439\n",
            "Epoch 8/10, Batch Loss: 0.01166119147092104, Average Training Loss: 0.031408723598966994, Training Accuracy: 0.9933035714285714\n",
            "Epoch 8/10, Batch Loss: 0.028882909566164017, Average Training Loss: 0.03134998373773902, Training Accuracy: 0.9934593023255814\n",
            "Epoch 8/10, Batch Loss: 0.02902313694357872, Average Training Loss: 0.031297100856053556, Training Accuracy: 0.9936079545454546\n",
            "Epoch 8/10, Batch Loss: 0.008355870842933655, Average Training Loss: 0.030787295744650892, Training Accuracy: 0.99375\n",
            "Epoch 8/10, Batch Loss: 0.034786008298397064, Average Training Loss: 0.030874224278427984, Training Accuracy: 0.9938858695652174\n",
            "Epoch 8/10, Batch Loss: 0.01809876598417759, Average Training Loss: 0.030602406016848188, Training Accuracy: 0.9940159574468085\n",
            "Epoch 8/10, Batch Loss: 0.010717225261032581, Average Training Loss: 0.030188131417768698, Training Accuracy: 0.994140625\n",
            "Epoch 8/10, Batch Loss: 0.011315256357192993, Average Training Loss: 0.029802970702246745, Training Accuracy: 0.9942602040816326\n",
            "Epoch 8/10, Batch Loss: 0.023481227457523346, Average Training Loss: 0.029676535837352275, Training Accuracy: 0.994375\n",
            "Epoch 8/10, Batch Loss: 0.03137771412730217, Average Training Loss: 0.029709892274410118, Training Accuracy: 0.9944852941176471\n",
            "Epoch 8/10, Batch Loss: 0.018290389329195023, Average Training Loss: 0.029490286448540595, Training Accuracy: 0.9945913461538461\n",
            "Epoch 8/10, Batch Loss: 0.022461535409092903, Average Training Loss: 0.029357668504400074, Training Accuracy: 0.9946933962264151\n",
            "Epoch 8/10, Batch Loss: 0.03767004609107971, Average Training Loss: 0.02951160142267192, Training Accuracy: 0.9947916666666666\n",
            "Epoch 8/10, Batch Loss: 0.038337308913469315, Average Training Loss: 0.029672068831595507, Training Accuracy: 0.9943181818181818\n",
            "Epoch 8/10, Batch Loss: 0.05545270815491676, Average Training Loss: 0.03013243739094053, Training Accuracy: 0.9938616071428571\n",
            "Epoch 8/10, Batch Loss: 0.01639508455991745, Average Training Loss: 0.02989143120092258, Training Accuracy: 0.9939692982456141\n",
            "Epoch 8/10, Batch Loss: 0.01588202826678753, Average Training Loss: 0.029649889771023702, Training Accuracy: 0.994073275862069\n",
            "Epoch 8/10, Batch Loss: 0.0172109492123127, Average Training Loss: 0.0294390602700286, Training Accuracy: 0.9941737288135594\n",
            "Epoch 8/10, Batch Loss: 0.01285290066152811, Average Training Loss: 0.02916262427655359, Training Accuracy: 0.9942708333333333\n",
            "Epoch 8/10, Batch Loss: 0.023043271154165268, Average Training Loss: 0.029062307012252143, Training Accuracy: 0.9943647540983607\n",
            "Epoch 8/10, Batch Loss: 0.040756531059741974, Average Training Loss: 0.02925092352914714, Training Accuracy: 0.9939516129032258\n",
            "Epoch 8/10, Batch Loss: 0.1987958699464798, Average Training Loss: 0.03194211315481909, Training Accuracy: 0.9935515873015873\n",
            "Epoch 8/10, Batch Loss: 0.014107716269791126, Average Training Loss: 0.031663450703490525, Training Accuracy: 0.99365234375\n",
            "Epoch 8/10, Batch Loss: 0.012638765387237072, Average Training Loss: 0.031370763237086624, Training Accuracy: 0.99375\n",
            "Epoch 8/10, Batch Loss: 0.06835564225912094, Average Training Loss: 0.03193114019196593, Training Accuracy: 0.9933712121212122\n",
            "Epoch 8/10, Batch Loss: 0.010159937664866447, Average Training Loss: 0.03205472378936035, Training Accuracy: 0.9933774834437086\n",
            "Epoch 8/10, Average Training Loss: 0.03160619687066594, Training Accuracy: 0.9933774834437086\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.99      0.99      0.99       451\n",
            "                         Family Support       1.00      0.99      1.00       396\n",
            "                      Financial Support       1.00      1.00      1.00       404\n",
            "                 Program Implementation       0.98      0.99      0.99       436\n",
            "\n",
            "                               accuracy                           0.99      2114\n",
            "                              macro avg       0.99      0.99      0.99      2114\n",
            "                           weighted avg       0.99      0.99      0.99      2114\n",
            "\n",
            "Epoch 8/10, Validation Loss: 20.57126772403717, Validation Accuracy: 0.718336483931947\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.66      0.68       113\n",
            "                Educational Opportunity       0.50      0.58      0.53       100\n",
            "                         Family Support       0.93      0.95      0.94       105\n",
            "                      Financial Support       0.74      0.66      0.70        97\n",
            "                 Program Implementation       0.77      0.73      0.75       114\n",
            "\n",
            "                               accuracy                           0.72       529\n",
            "                              macro avg       0.72      0.72      0.72       529\n",
            "                           weighted avg       0.72      0.72      0.72       529\n",
            "\n",
            "Epoch 9/10, Batch Loss: 0.11319492757320404, Average Training Loss: 0.11319492757320404, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.009398874826729298, Average Training Loss: 0.06129690119996667, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.01269825454801321, Average Training Loss: 0.045097352315982185, Training Accuracy: 0.9791666666666666\n",
            "Epoch 9/10, Batch Loss: 0.014924527145922184, Average Training Loss: 0.03755414602346718, Training Accuracy: 0.984375\n",
            "Epoch 9/10, Batch Loss: 0.011681866832077503, Average Training Loss: 0.03237969018518925, Training Accuracy: 0.9875\n",
            "Epoch 9/10, Batch Loss: 0.0075345393270254135, Average Training Loss: 0.02823883170882861, Training Accuracy: 0.9895833333333334\n",
            "Epoch 9/10, Batch Loss: 0.015533466823399067, Average Training Loss: 0.026423779582338675, Training Accuracy: 0.9910714285714286\n",
            "Epoch 9/10, Batch Loss: 0.020877694711089134, Average Training Loss: 0.02573051897343248, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.05003121867775917, Average Training Loss: 0.028430596718357667, Training Accuracy: 0.9895833333333334\n",
            "Epoch 9/10, Batch Loss: 0.027610931545495987, Average Training Loss: 0.0283486302010715, Training Accuracy: 0.990625\n",
            "Epoch 9/10, Batch Loss: 0.008790305815637112, Average Training Loss: 0.026570600711486557, Training Accuracy: 0.9914772727272727\n",
            "Epoch 9/10, Batch Loss: 0.016641883179545403, Average Training Loss: 0.025743207583824795, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.014050809666514397, Average Training Loss: 0.024843792359416302, Training Accuracy: 0.9927884615384616\n",
            "Epoch 9/10, Batch Loss: 0.12090417742729187, Average Training Loss: 0.031705248435693126, Training Accuracy: 0.9910714285714286\n",
            "Epoch 9/10, Batch Loss: 0.011945527046918869, Average Training Loss: 0.03038793367644151, Training Accuracy: 0.9916666666666667\n",
            "Epoch 9/10, Batch Loss: 0.015693748369812965, Average Training Loss: 0.029469547094777226, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.05357810854911804, Average Training Loss: 0.03088769776856198, Training Accuracy: 0.9908088235294118\n",
            "Epoch 9/10, Batch Loss: 0.014967348426580429, Average Training Loss: 0.030003233916229673, Training Accuracy: 0.9913194444444444\n",
            "Epoch 9/10, Batch Loss: 0.0157454926520586, Average Training Loss: 0.029252826481273298, Training Accuracy: 0.9917763157894737\n",
            "Epoch 9/10, Batch Loss: 0.012757595628499985, Average Training Loss: 0.028428064938634635, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.017130054533481598, Average Training Loss: 0.027890064443151157, Training Accuracy: 0.9925595238095238\n",
            "Epoch 9/10, Batch Loss: 0.008052696473896503, Average Training Loss: 0.026988365899094126, Training Accuracy: 0.9928977272727273\n",
            "Epoch 9/10, Batch Loss: 0.010558896698057652, Average Training Loss: 0.026274041151222977, Training Accuracy: 0.9932065217391305\n",
            "Epoch 9/10, Batch Loss: 0.015016035176813602, Average Training Loss: 0.025804957568955917, Training Accuracy: 0.9934895833333334\n",
            "Epoch 9/10, Batch Loss: 0.0501953549683094, Average Training Loss: 0.026780573464930058, Training Accuracy: 0.9925\n",
            "Epoch 9/10, Batch Loss: 0.011426839977502823, Average Training Loss: 0.026190045253875163, Training Accuracy: 0.9927884615384616\n",
            "Epoch 9/10, Batch Loss: 0.012121833860874176, Average Training Loss: 0.02566900038746772, Training Accuracy: 0.9930555555555556\n",
            "Epoch 9/10, Batch Loss: 0.010705957189202309, Average Training Loss: 0.02513460598752967, Training Accuracy: 0.9933035714285714\n",
            "Epoch 9/10, Batch Loss: 0.016367508098483086, Average Training Loss: 0.02483229226721772, Training Accuracy: 0.9935344827586207\n",
            "Epoch 9/10, Batch Loss: 0.009057648479938507, Average Training Loss: 0.024306470807641745, Training Accuracy: 0.99375\n",
            "Epoch 9/10, Batch Loss: 0.010357072576880455, Average Training Loss: 0.023856490219552672, Training Accuracy: 0.9939516129032258\n",
            "Epoch 9/10, Batch Loss: 0.0412944070994854, Average Training Loss: 0.02440142512205057, Training Accuracy: 0.9931640625\n",
            "Epoch 9/10, Batch Loss: 0.016089871525764465, Average Training Loss: 0.02414955986155705, Training Accuracy: 0.9933712121212122\n",
            "Epoch 9/10, Batch Loss: 0.03044762648642063, Average Training Loss: 0.024334797115229508, Training Accuracy: 0.9935661764705882\n",
            "Epoch 9/10, Batch Loss: 0.09722675383090973, Average Training Loss: 0.026417424449963228, Training Accuracy: 0.9928571428571429\n",
            "Epoch 9/10, Batch Loss: 0.1051473543047905, Average Training Loss: 0.028604366945930652, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.0779799148440361, Average Training Loss: 0.029938841213447018, Training Accuracy: 0.9915540540540541\n",
            "Epoch 9/10, Batch Loss: 0.01052134484052658, Average Training Loss: 0.029427854466791217, Training Accuracy: 0.9917763157894737\n",
            "Epoch 9/10, Batch Loss: 0.012890156358480453, Average Training Loss: 0.02900381092555248, Training Accuracy: 0.9919871794871795\n",
            "Epoch 9/10, Batch Loss: 0.01445036195218563, Average Training Loss: 0.028639974701218308, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.06810104101896286, Average Training Loss: 0.029602439733358417, Training Accuracy: 0.9916158536585366\n",
            "Epoch 9/10, Batch Loss: 0.008923472836613655, Average Training Loss: 0.029110083378674018, Training Accuracy: 0.9918154761904762\n",
            "Epoch 9/10, Batch Loss: 0.019384076818823814, Average Training Loss: 0.028883897179607734, Training Accuracy: 0.9920058139534884\n",
            "Epoch 9/10, Batch Loss: 0.02542831003665924, Average Training Loss: 0.028805361108177087, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.01586645096540451, Average Training Loss: 0.02851782977167103, Training Accuracy: 0.9923611111111111\n",
            "Epoch 9/10, Batch Loss: 0.03741975873708725, Average Training Loss: 0.028711349966571383, Training Accuracy: 0.9918478260869565\n",
            "Epoch 9/10, Batch Loss: 0.013294816948473454, Average Training Loss: 0.028383338625760788, Training Accuracy: 0.9920212765957447\n",
            "Epoch 9/10, Batch Loss: 0.011499319225549698, Average Training Loss: 0.028031588221589725, Training Accuracy: 0.9921875\n",
            "Epoch 9/10, Batch Loss: 0.021822554990649223, Average Training Loss: 0.027904873257692978, Training Accuracy: 0.9923469387755102\n",
            "Epoch 9/10, Batch Loss: 0.010146301239728928, Average Training Loss: 0.027549701817333697, Training Accuracy: 0.9925\n",
            "Epoch 9/10, Batch Loss: 0.021140513941645622, Average Training Loss: 0.02742403146683001, Training Accuracy: 0.9926470588235294\n",
            "Epoch 9/10, Batch Loss: 0.012105971574783325, Average Training Loss: 0.027129453391982958, Training Accuracy: 0.9927884615384616\n",
            "Epoch 9/10, Batch Loss: 0.016381485387682915, Average Training Loss: 0.02692666154284522, Training Accuracy: 0.9929245283018868\n",
            "Epoch 9/10, Batch Loss: 0.02327481284737587, Average Training Loss: 0.026859034715151345, Training Accuracy: 0.9930555555555556\n",
            "Epoch 9/10, Batch Loss: 0.00766118336468935, Average Training Loss: 0.026509982872415672, Training Accuracy: 0.9931818181818182\n",
            "Epoch 9/10, Batch Loss: 0.011876767501235008, Average Training Loss: 0.026248675455073162, Training Accuracy: 0.9933035714285714\n",
            "Epoch 9/10, Batch Loss: 0.029323093593120575, Average Training Loss: 0.026302612615389784, Training Accuracy: 0.993421052631579\n",
            "Epoch 9/10, Batch Loss: 0.011045340448617935, Average Training Loss: 0.0260395561987213, Training Accuracy: 0.9935344827586207\n",
            "Epoch 9/10, Batch Loss: 0.11764028668403625, Average Training Loss: 0.027592110952709692, Training Accuracy: 0.993114406779661\n",
            "Epoch 9/10, Batch Loss: 0.01789693906903267, Average Training Loss: 0.027430524754648408, Training Accuracy: 0.9932291666666667\n",
            "Epoch 9/10, Batch Loss: 0.019018439576029778, Average Training Loss: 0.027292621718933346, Training Accuracy: 0.9933401639344263\n",
            "Epoch 9/10, Batch Loss: 0.05850810930132866, Average Training Loss: 0.027796097325101014, Training Accuracy: 0.9929435483870968\n",
            "Epoch 9/10, Batch Loss: 0.02777159959077835, Average Training Loss: 0.027795708472175256, Training Accuracy: 0.9930555555555556\n",
            "Epoch 9/10, Batch Loss: 0.01158955879509449, Average Training Loss: 0.02754248738347087, Training Accuracy: 0.9931640625\n",
            "Epoch 9/10, Batch Loss: 0.18328197300434113, Average Training Loss: 0.029938479469945798, Training Accuracy: 0.9927884615384616\n",
            "Epoch 9/10, Batch Loss: 0.010598134249448776, Average Training Loss: 0.029645443936301905, Training Accuracy: 0.9928977272727273\n",
            "Epoch 9/10, Batch Loss: 0.010466602630913258, Average Training Loss: 0.029775832014029727, Training Accuracy: 0.9929044465468306\n",
            "Epoch 9/10, Average Training Loss: 0.02935919257353491, Training Accuracy: 0.9929044465468306\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.99      0.99      0.99       451\n",
            "                         Family Support       1.00      1.00      1.00       396\n",
            "                      Financial Support       0.99      0.99      0.99       404\n",
            "                 Program Implementation       0.99      0.99      0.99       436\n",
            "\n",
            "                               accuracy                           0.99      2114\n",
            "                              macro avg       0.99      0.99      0.99      2114\n",
            "                           weighted avg       0.99      0.99      0.99      2114\n",
            "\n",
            "Epoch 9/10, Validation Loss: 21.79709106683731, Validation Accuracy: 0.7107750472589792\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.70      0.68       113\n",
            "                Educational Opportunity       0.49      0.57      0.53       100\n",
            "                         Family Support       0.92      0.93      0.93       105\n",
            "                      Financial Support       0.80      0.61      0.69        97\n",
            "                 Program Implementation       0.74      0.73      0.73       114\n",
            "\n",
            "                               accuracy                           0.71       529\n",
            "                              macro avg       0.72      0.71      0.71       529\n",
            "                           weighted avg       0.72      0.71      0.71       529\n",
            "\n",
            "Epoch 10/10, Batch Loss: 0.03163324296474457, Average Training Loss: 0.03163324296474457, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.011572048999369144, Average Training Loss: 0.021602645982056856, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.04589119181036949, Average Training Loss: 0.029698827924827736, Training Accuracy: 0.9895833333333334\n",
            "Epoch 10/10, Batch Loss: 0.009090505540370941, Average Training Loss: 0.024546747328713536, Training Accuracy: 0.9921875\n",
            "Epoch 10/10, Batch Loss: 0.01876247487962246, Average Training Loss: 0.02338989283889532, Training Accuracy: 0.99375\n",
            "Epoch 10/10, Batch Loss: 0.014303432777523994, Average Training Loss: 0.021875482828666765, Training Accuracy: 0.9947916666666666\n",
            "Epoch 10/10, Batch Loss: 0.04490493983030319, Average Training Loss: 0.02516540525747197, Training Accuracy: 0.9955357142857143\n",
            "Epoch 10/10, Batch Loss: 0.007513859309256077, Average Training Loss: 0.022958962013944983, Training Accuracy: 0.99609375\n",
            "Epoch 10/10, Batch Loss: 0.01457752101123333, Average Training Loss: 0.022027690791421466, Training Accuracy: 0.9965277777777778\n",
            "Epoch 10/10, Batch Loss: 0.020284220576286316, Average Training Loss: 0.02185334376990795, Training Accuracy: 0.996875\n",
            "Epoch 10/10, Batch Loss: 0.01740448921918869, Average Training Loss: 0.02144890244711529, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.015424847602844238, Average Training Loss: 0.02094689787675937, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.023783614858984947, Average Training Loss: 0.021165106875392106, Training Accuracy: 0.9975961538461539\n",
            "Epoch 10/10, Batch Loss: 0.055288441479206085, Average Training Loss: 0.023602487918521677, Training Accuracy: 0.9955357142857143\n",
            "Epoch 10/10, Batch Loss: 0.014022137969732285, Average Training Loss: 0.022963797921935716, Training Accuracy: 0.9958333333333333\n",
            "Epoch 10/10, Batch Loss: 0.02425544336438179, Average Training Loss: 0.023044525762088597, Training Accuracy: 0.99609375\n",
            "Epoch 10/10, Batch Loss: 0.010980171151459217, Average Training Loss: 0.02233485784381628, Training Accuracy: 0.9963235294117647\n",
            "Epoch 10/10, Batch Loss: 0.007933517917990685, Average Training Loss: 0.021534783403492637, Training Accuracy: 0.9965277777777778\n",
            "Epoch 10/10, Batch Loss: 0.014169328846037388, Average Training Loss: 0.021147127900468677, Training Accuracy: 0.9967105263157895\n",
            "Epoch 10/10, Batch Loss: 0.010685687884688377, Average Training Loss: 0.02062405589967966, Training Accuracy: 0.996875\n",
            "Epoch 10/10, Batch Loss: 0.015194788575172424, Average Training Loss: 0.02036551936041741, Training Accuracy: 0.9970238095238095\n",
            "Epoch 10/10, Batch Loss: 0.00875014252960682, Average Training Loss: 0.019837547686289658, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.07260187715291977, Average Training Loss: 0.022131648967447487, Training Accuracy: 0.9959239130434783\n",
            "Epoch 10/10, Batch Loss: 0.09541349858045578, Average Training Loss: 0.0251850593679895, Training Accuracy: 0.9947916666666666\n",
            "Epoch 10/10, Batch Loss: 0.015592982061207294, Average Training Loss: 0.024801376275718212, Training Accuracy: 0.995\n",
            "Epoch 10/10, Batch Loss: 0.009685005992650986, Average Training Loss: 0.024219977418677166, Training Accuracy: 0.9951923076923077\n",
            "Epoch 10/10, Batch Loss: 0.010489273816347122, Average Training Loss: 0.02371143284081309, Training Accuracy: 0.9953703703703703\n",
            "Epoch 10/10, Batch Loss: 0.014637292362749577, Average Training Loss: 0.023387356395167962, Training Accuracy: 0.9955357142857143\n",
            "Epoch 10/10, Batch Loss: 0.023539068177342415, Average Training Loss: 0.0233925878359326, Training Accuracy: 0.9956896551724138\n",
            "Epoch 10/10, Batch Loss: 0.011664338409900665, Average Training Loss: 0.023001646188398204, Training Accuracy: 0.9958333333333333\n",
            "Epoch 10/10, Batch Loss: 0.017064042389392853, Average Training Loss: 0.022810110581978675, Training Accuracy: 0.9959677419354839\n",
            "Epoch 10/10, Batch Loss: 0.038796134293079376, Average Training Loss: 0.023309673822950572, Training Accuracy: 0.9951171875\n",
            "Epoch 10/10, Batch Loss: 0.007974722422659397, Average Training Loss: 0.02284497832597205, Training Accuracy: 0.9952651515151515\n",
            "Epoch 10/10, Batch Loss: 0.012374463491141796, Average Training Loss: 0.022537022007300574, Training Accuracy: 0.9954044117647058\n",
            "Epoch 10/10, Batch Loss: 0.011874771676957607, Average Training Loss: 0.02223238628357649, Training Accuracy: 0.9955357142857143\n",
            "Epoch 10/10, Batch Loss: 0.020508836954832077, Average Training Loss: 0.022184509913333587, Training Accuracy: 0.9956597222222222\n",
            "Epoch 10/10, Batch Loss: 0.013013479299843311, Average Training Loss: 0.021936644221077096, Training Accuracy: 0.995777027027027\n",
            "Epoch 10/10, Batch Loss: 0.16701745986938477, Average Training Loss: 0.02575456042234835, Training Accuracy: 0.9950657894736842\n",
            "Epoch 10/10, Batch Loss: 0.012501517310738564, Average Training Loss: 0.025414738804101944, Training Accuracy: 0.9951923076923077\n",
            "Epoch 10/10, Batch Loss: 0.009419812820851803, Average Training Loss: 0.025014865654520692, Training Accuracy: 0.9953125\n",
            "Epoch 10/10, Batch Loss: 0.04411734640598297, Average Training Loss: 0.025480779819190502, Training Accuracy: 0.9946646341463414\n",
            "Epoch 10/10, Batch Loss: 0.010040486231446266, Average Training Loss: 0.02511315378138707, Training Accuracy: 0.9947916666666666\n",
            "Epoch 10/10, Batch Loss: 0.008884483017027378, Average Training Loss: 0.024735742833378704, Training Accuracy: 0.9949127906976745\n",
            "Epoch 10/10, Batch Loss: 0.011810880154371262, Average Training Loss: 0.02444199595431035, Training Accuracy: 0.9950284090909091\n",
            "Epoch 10/10, Batch Loss: 0.009757492691278458, Average Training Loss: 0.02411567365957631, Training Accuracy: 0.9951388888888889\n",
            "Epoch 10/10, Batch Loss: 0.010356118902564049, Average Training Loss: 0.023816552903989086, Training Accuracy: 0.9952445652173914\n",
            "Epoch 10/10, Batch Loss: 0.01143552828580141, Average Training Loss: 0.023553126848282965, Training Accuracy: 0.995345744680851\n",
            "Epoch 10/10, Batch Loss: 0.01615280471742153, Average Training Loss: 0.023398953470556687, Training Accuracy: 0.9954427083333334\n",
            "Epoch 10/10, Batch Loss: 0.011557109653949738, Average Training Loss: 0.023157283188585117, Training Accuracy: 0.9955357142857143\n",
            "Epoch 10/10, Batch Loss: 0.012064795941114426, Average Training Loss: 0.022935433443635703, Training Accuracy: 0.995625\n",
            "Epoch 10/10, Batch Loss: 0.012524432502686977, Average Training Loss: 0.022731296170283768, Training Accuracy: 0.9957107843137255\n",
            "Epoch 10/10, Batch Loss: 0.009330122731626034, Average Training Loss: 0.022473581296463426, Training Accuracy: 0.9957932692307693\n",
            "Epoch 10/10, Batch Loss: 0.008828755468130112, Average Training Loss: 0.02221613175253261, Training Accuracy: 0.995872641509434\n",
            "Epoch 10/10, Batch Loss: 0.01037128921598196, Average Training Loss: 0.02199678281667056, Training Accuracy: 0.9959490740740741\n",
            "Epoch 10/10, Batch Loss: 0.015187636017799377, Average Training Loss: 0.021872980147600175, Training Accuracy: 0.9960227272727272\n",
            "Epoch 10/10, Batch Loss: 0.029831791296601295, Average Training Loss: 0.02201510177526091, Training Accuracy: 0.99609375\n",
            "Epoch 10/10, Batch Loss: 0.03105631284415722, Average Training Loss: 0.02217371951331172, Training Accuracy: 0.9961622807017544\n",
            "Epoch 10/10, Batch Loss: 0.010200630873441696, Average Training Loss: 0.021967286950555342, Training Accuracy: 0.9962284482758621\n",
            "Epoch 10/10, Batch Loss: 0.017021354287862778, Average Training Loss: 0.02188345758339106, Training Accuracy: 0.996292372881356\n",
            "Epoch 10/10, Batch Loss: 0.013756681233644485, Average Training Loss: 0.021748011310895283, Training Accuracy: 0.9963541666666667\n",
            "Epoch 10/10, Batch Loss: 0.013158115558326244, Average Training Loss: 0.021607193347738415, Training Accuracy: 0.9964139344262295\n",
            "Epoch 10/10, Batch Loss: 0.010909177362918854, Average Training Loss: 0.02143464470282197, Training Accuracy: 0.9964717741935484\n",
            "Epoch 10/10, Batch Loss: 0.008637980557978153, Average Training Loss: 0.021231523049729212, Training Accuracy: 0.9965277777777778\n",
            "Epoch 10/10, Batch Loss: 0.008541150949895382, Average Training Loss: 0.021033235985669307, Training Accuracy: 0.99658203125\n",
            "Epoch 10/10, Batch Loss: 0.04018796980381012, Average Training Loss: 0.02132792419825609, Training Accuracy: 0.9961538461538462\n",
            "Epoch 10/10, Batch Loss: 0.01677456684410572, Average Training Loss: 0.021258933935314417, Training Accuracy: 0.9962121212121212\n",
            "Epoch 10/10, Batch Loss: 0.010853389278054237, Average Training Loss: 0.021403111129745404, Training Accuracy: 0.9962157048249763\n",
            "Epoch 10/10, Average Training Loss: 0.02110362729863889, Training Accuracy: 0.9962157048249763\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.99      0.99      0.99       451\n",
            "                         Family Support       1.00      1.00      1.00       396\n",
            "                      Financial Support       1.00      1.00      1.00       404\n",
            "                 Program Implementation       0.99      0.99      0.99       436\n",
            "\n",
            "                               accuracy                           1.00      2114\n",
            "                              macro avg       1.00      1.00      1.00      2114\n",
            "                           weighted avg       1.00      1.00      1.00      2114\n",
            "\n",
            "Epoch 10/10, Validation Loss: 21.39837646484375, Validation Accuracy: 0.7164461247637051\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.70      0.68       113\n",
            "                Educational Opportunity       0.50      0.54      0.52       100\n",
            "                         Family Support       0.92      0.93      0.93       105\n",
            "                      Financial Support       0.77      0.64      0.70        97\n",
            "                 Program Implementation       0.75      0.75      0.75       114\n",
            "\n",
            "                               accuracy                           0.72       529\n",
            "                              macro avg       0.72      0.71      0.72       529\n",
            "                           weighted avg       0.72      0.72      0.72       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 6 - Updated Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n",
        "\n",
        "# ... (your subsequent code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0785bbdbe964153866a09c7b74dc964",
            "0a6132dee6ec41b8932936e80e2b9411",
            "6dca6f569c1641729592cbb11ca5091e",
            "fa3da64e087241e1b231084a42aab1ce",
            "c72ec63d62f349fe9890f290a19de971",
            "1b1f9947f20c483b959b7cf1b0332c99",
            "a330e351fb2a457e9c395d7e684aa7a6",
            "48c3344552dd41bc9d87b59aac49c8c6",
            "5e9b3d39a68644d3b3bb9db5536474b7",
            "0d1a6f0df2134d72afa90c204d237682",
            "ca4b403f7075413bbd77a2e5858c1723",
            "3699b957919747c2806c49f41fa54069",
            "f1d05b3fbea94fb7b20027696c79b50e",
            "9aede4a77b77495fbd5c92bafbcd1fd1",
            "b676bf26ca0d4e05b10ee7b9897c0eb2",
            "622c2acb767d468eb215caba3ded95ce",
            "acb2f5b41f1947abb209da8e1ee19477",
            "79ba547d071e48fc9fe9a573de5e1de4",
            "dfa7c3bce4f8494288128970ba6eba5a",
            "ae5dcb31e4c74af9ae20c8247b4c6377",
            "7c7ab4bdf82a46198e11afaae54f0d46",
            "735b8e88eef94b4f9603b6b56938c5ec",
            "2edd840946aa4d70bca02a0fcb77b585",
            "d0699a3405e34d9894b0169c1f1e9add",
            "fdaed5172b434c37a323042f41fc032a",
            "3aa2f7d8cbd14575b049a16d1a99c933",
            "5afe89852ea94385bdd5d79dc45b6c22",
            "d1e35844f6ac4f0486c59e194012303d",
            "f0755b54be7f48b6843d90496aeaa39c",
            "16d77053e8bc448d906fbd4fc96f53b8",
            "46ff3d7cbad1464686b7dfc674289273",
            "f7d63c24d8fb4b67bf8d4412390ee672",
            "93b925f2c0014b62ba4b94b0b97dccb6",
            "cdc363bf90264b47b64f3e4e40fb3308",
            "1a7cc8e7820b4e6498d93dd9b4641ac4",
            "062d3ad82c614c65937176d82f58a2e7",
            "672ac7ef8df94964996a5949eb6073bb",
            "00a8b4c95af54f93b11af7aa49e717a7",
            "343e6ba2083b4a58a2585943b901abb9",
            "50c16483b9fe4c1b912a42e8bce0bbb7",
            "a499e85ac5e04b93ab0463a4a9e6f90a",
            "de605e7a46c14c7da03ec637ef79edee",
            "bd85e3a2018245d38e67d2ba9d24d492",
            "c46dbe599ab243ff90144452a8fee316",
            "986bb766d3494218be7040b648ec4682",
            "985e756481384dda8edea4c12f7d06f5",
            "2ad2bfaf09ab4252a806bc4cf99e265a",
            "b1a23adf9960409cbfb388f18ee75557",
            "e7f6d39eadd14902a5d5cf343914e846",
            "85cf52cf1c7c4db68808440ba951d615",
            "0f51ec8a90194990a0cf98567c50c05a",
            "deecde4e8baa45a0b93c8fbb098fad16",
            "8759f35b3fd9445d89b1967426ee6bbe",
            "a3058c4ed23c4f9a866bcbf35225b971",
            "3d3aaf17f17e4693a57cf553d04cf78b"
          ]
        },
        "id": "_Ps36Y_28u-f",
        "outputId": "ab9ced88-608e-4717-e7ab-e65bb8f809b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<ipython-input-4-0f7a71b74230>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0785bbdbe964153866a09c7b74dc964"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3699b957919747c2806c49f41fa54069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2edd840946aa4d70bca02a0fcb77b585"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdc363bf90264b47b64f3e4e40fb3308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "986bb766d3494218be7040b648ec4682"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.6251158714294434, Average Training Loss: 1.6251158714294434, Training Accuracy: 0.375\n",
            "Epoch 1/5, Batch Loss: 1.5659782886505127, Average Training Loss: 1.595547080039978, Training Accuracy: 0.3125\n",
            "Epoch 1/5, Batch Loss: 1.6158950328826904, Average Training Loss: 1.6023297309875488, Training Accuracy: 0.2708333333333333\n",
            "Epoch 1/5, Batch Loss: 1.6136127710342407, Average Training Loss: 1.6051504909992218, Training Accuracy: 0.296875\n",
            "Epoch 1/5, Batch Loss: 1.6251236200332642, Average Training Loss: 1.6091451168060302, Training Accuracy: 0.3\n",
            "Epoch 1/5, Batch Loss: 1.4833487272262573, Average Training Loss: 1.5881790518760681, Training Accuracy: 0.3229166666666667\n",
            "Epoch 1/5, Batch Loss: 1.5462197065353394, Average Training Loss: 1.5821848596845354, Training Accuracy: 0.3125\n",
            "Epoch 1/5, Batch Loss: 1.6894651651382446, Average Training Loss: 1.595594897866249, Training Accuracy: 0.296875\n",
            "Epoch 1/5, Batch Loss: 1.5930513143539429, Average Training Loss: 1.595312277475993, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/5, Batch Loss: 1.521341323852539, Average Training Loss: 1.5879151821136475, Training Accuracy: 0.29375\n",
            "Epoch 1/5, Batch Loss: 1.5359021425247192, Average Training Loss: 1.5831867239691995, Training Accuracy: 0.2840909090909091\n",
            "Epoch 1/5, Batch Loss: 1.5279998779296875, Average Training Loss: 1.5785878201325734, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/5, Batch Loss: 1.6156357526779175, Average Training Loss: 1.5814376610976, Training Accuracy: 0.27403846153846156\n",
            "Epoch 1/5, Batch Loss: 1.5443775653839111, Average Training Loss: 1.578790511403765, Training Accuracy: 0.26785714285714285\n",
            "Epoch 1/5, Batch Loss: 1.4829429388046265, Average Training Loss: 1.5724006732304892, Training Accuracy: 0.26666666666666666\n",
            "Epoch 1/5, Batch Loss: 1.5113613605499268, Average Training Loss: 1.568585716187954, Training Accuracy: 0.265625\n",
            "Epoch 1/5, Batch Loss: 1.5092014074325562, Average Training Loss: 1.5650925215552836, Training Accuracy: 0.26838235294117646\n",
            "Epoch 1/5, Batch Loss: 1.3943475484848022, Average Training Loss: 1.5556066897180345, Training Accuracy: 0.2777777777777778\n",
            "Epoch 1/5, Batch Loss: 1.3197131156921387, Average Training Loss: 1.5431912384535138, Training Accuracy: 0.2894736842105263\n",
            "Epoch 1/5, Batch Loss: 1.3823094367980957, Average Training Loss: 1.5351471483707428, Training Accuracy: 0.3\n",
            "Epoch 1/5, Batch Loss: 1.5568946599960327, Average Training Loss: 1.5361827441624232, Training Accuracy: 0.29464285714285715\n",
            "Epoch 1/5, Batch Loss: 1.4898266792297363, Average Training Loss: 1.5340756503018467, Training Accuracy: 0.2897727272727273\n",
            "Epoch 1/5, Batch Loss: 1.5733895301818848, Average Training Loss: 1.5357849494270657, Training Accuracy: 0.2907608695652174\n",
            "Epoch 1/5, Batch Loss: 1.4289343357086182, Average Training Loss: 1.5313328405221303, Training Accuracy: 0.2994791666666667\n",
            "Epoch 1/5, Batch Loss: 1.5733673572540283, Average Training Loss: 1.5330142211914062, Training Accuracy: 0.295\n",
            "Epoch 1/5, Batch Loss: 1.314434289932251, Average Training Loss: 1.5246073007583618, Training Accuracy: 0.30528846153846156\n",
            "Epoch 1/5, Batch Loss: 1.5067249536514282, Average Training Loss: 1.523944991606253, Training Accuracy: 0.30787037037037035\n",
            "Epoch 1/5, Batch Loss: 1.424917459487915, Average Training Loss: 1.5204082940305983, Training Accuracy: 0.30580357142857145\n",
            "Epoch 1/5, Batch Loss: 1.5879008769989014, Average Training Loss: 1.522735624477781, Training Accuracy: 0.30603448275862066\n",
            "Epoch 1/5, Batch Loss: 1.4193174839019775, Average Training Loss: 1.5192883531252543, Training Accuracy: 0.30833333333333335\n",
            "Epoch 1/5, Batch Loss: 1.549297571182251, Average Training Loss: 1.5202563924174155, Training Accuracy: 0.30443548387096775\n",
            "Epoch 1/5, Batch Loss: 1.442883014678955, Average Training Loss: 1.5178384743630886, Training Accuracy: 0.30859375\n",
            "Epoch 1/5, Batch Loss: 1.438813328742981, Average Training Loss: 1.5154437729806611, Training Accuracy: 0.3143939393939394\n",
            "Epoch 1/5, Batch Loss: 1.4576799869537354, Average Training Loss: 1.5137448380975163, Training Accuracy: 0.31985294117647056\n",
            "Epoch 1/5, Batch Loss: 1.3702987432479858, Average Training Loss: 1.5096463782446725, Training Accuracy: 0.3267857142857143\n",
            "Epoch 1/5, Batch Loss: 1.374394416809082, Average Training Loss: 1.505889379315906, Training Accuracy: 0.3315972222222222\n",
            "Epoch 1/5, Batch Loss: 1.2483844757080078, Average Training Loss: 1.4989297873265035, Training Accuracy: 0.33783783783783783\n",
            "Epoch 1/5, Batch Loss: 1.3564996719360352, Average Training Loss: 1.4951816263951754, Training Accuracy: 0.33881578947368424\n",
            "Epoch 1/5, Batch Loss: 1.3689885139465332, Average Training Loss: 1.4919459055631588, Training Accuracy: 0.34134615384615385\n",
            "Epoch 1/5, Batch Loss: 1.3537888526916504, Average Training Loss: 1.488491979241371, Training Accuracy: 0.346875\n",
            "Epoch 1/5, Batch Loss: 1.4116227626800537, Average Training Loss: 1.4866171203008511, Training Accuracy: 0.34603658536585363\n",
            "Epoch 1/5, Batch Loss: 1.1023800373077393, Average Training Loss: 1.4774686183248247, Training Accuracy: 0.35267857142857145\n",
            "Epoch 1/5, Batch Loss: 1.3262288570404053, Average Training Loss: 1.4739514145740242, Training Accuracy: 0.35174418604651164\n",
            "Epoch 1/5, Batch Loss: 1.2652199268341064, Average Training Loss: 1.4692075171253898, Training Accuracy: 0.3522727272727273\n",
            "Epoch 1/5, Batch Loss: 1.119682788848877, Average Training Loss: 1.4614403009414674, Training Accuracy: 0.35694444444444445\n",
            "Epoch 1/5, Batch Loss: 1.111335039138794, Average Training Loss: 1.4538293169892353, Training Accuracy: 0.36277173913043476\n",
            "Epoch 1/5, Batch Loss: 1.181670904159546, Average Training Loss: 1.448038712460944, Training Accuracy: 0.3670212765957447\n",
            "Epoch 1/5, Batch Loss: 1.3109087944030762, Average Training Loss: 1.4451818391680717, Training Accuracy: 0.3645833333333333\n",
            "Epoch 1/5, Batch Loss: 1.2763735055923462, Average Training Loss: 1.4417367711359141, Training Accuracy: 0.36862244897959184\n",
            "Epoch 1/5, Batch Loss: 1.3317731618881226, Average Training Loss: 1.4395374989509582, Training Accuracy: 0.37125\n",
            "Epoch 1/5, Batch Loss: 0.883994996547699, Average Training Loss: 1.428644508707757, Training Accuracy: 0.3786764705882353\n",
            "Epoch 1/5, Batch Loss: 1.2440530061721802, Average Training Loss: 1.4250946721205344, Training Accuracy: 0.38100961538461536\n",
            "Epoch 1/5, Batch Loss: 1.4182931184768677, Average Training Loss: 1.4249663409197106, Training Accuracy: 0.38325471698113206\n",
            "Epoch 1/5, Batch Loss: 1.284510612487793, Average Training Loss: 1.422365308911712, Training Accuracy: 0.38657407407407407\n",
            "Epoch 1/5, Batch Loss: 0.9992638230323792, Average Training Loss: 1.414672554622997, Training Accuracy: 0.39204545454545453\n",
            "Epoch 1/5, Batch Loss: 1.4582072496414185, Average Training Loss: 1.415449959891183, Training Accuracy: 0.39174107142857145\n",
            "Epoch 1/5, Batch Loss: 1.039639949798584, Average Training Loss: 1.408856801819383, Training Accuracy: 0.39473684210526316\n",
            "Epoch 1/5, Batch Loss: 1.0639044046401978, Average Training Loss: 1.402909346695604, Training Accuracy: 0.39870689655172414\n",
            "Epoch 1/5, Batch Loss: 0.6915304064750671, Average Training Loss: 1.3908520765223746, Training Accuracy: 0.4057203389830508\n",
            "Epoch 1/5, Batch Loss: 1.1481226682662964, Average Training Loss: 1.3868065863847732, Training Accuracy: 0.41041666666666665\n",
            "Epoch 1/5, Batch Loss: 1.13140070438385, Average Training Loss: 1.382619604712627, Training Accuracy: 0.41290983606557374\n",
            "Epoch 1/5, Batch Loss: 0.801591157913208, Average Training Loss: 1.373248178151346, Training Accuracy: 0.41935483870967744\n",
            "Epoch 1/5, Batch Loss: 0.6048897504806519, Average Training Loss: 1.3610520126327637, Training Accuracy: 0.42857142857142855\n",
            "Epoch 1/5, Batch Loss: 1.2685315608978271, Average Training Loss: 1.3596063805744052, Training Accuracy: 0.4287109375\n",
            "Epoch 1/5, Batch Loss: 1.0438151359558105, Average Training Loss: 1.3547480537341192, Training Accuracy: 0.43173076923076925\n",
            "Epoch 1/5, Batch Loss: 0.7218827605247498, Average Training Loss: 1.3451591856551892, Training Accuracy: 0.4365530303030303\n",
            "Epoch 1/5, Batch Loss: 1.219592571258545, Average Training Loss: 1.343285057082105, Training Accuracy: 0.43843283582089554\n",
            "Epoch 1/5, Batch Loss: 0.6985711455345154, Average Training Loss: 1.3338039701475817, Training Accuracy: 0.4430147058823529\n",
            "Epoch 1/5, Batch Loss: 0.7897493243217468, Average Training Loss: 1.325919120208077, Training Accuracy: 0.447463768115942\n",
            "Epoch 1/5, Batch Loss: 1.1263151168823242, Average Training Loss: 1.3230676344462804, Training Accuracy: 0.44910714285714287\n",
            "Epoch 1/5, Batch Loss: 0.9310280680656433, Average Training Loss: 1.3175459504127502, Training Accuracy: 0.4515845070422535\n",
            "Epoch 1/5, Batch Loss: 0.8938507437705994, Average Training Loss: 1.3116612947649426, Training Accuracy: 0.4539930555555556\n",
            "Epoch 1/5, Batch Loss: 0.8652067184448242, Average Training Loss: 1.3055454786509684, Training Accuracy: 0.4563356164383562\n",
            "Epoch 1/5, Batch Loss: 0.6427565217018127, Average Training Loss: 1.2965888711246285, Training Accuracy: 0.46199324324324326\n",
            "Epoch 1/5, Batch Loss: 0.9480161666870117, Average Training Loss: 1.2919412350654602, Training Accuracy: 0.46416666666666667\n",
            "Epoch 1/5, Batch Loss: 1.190270185470581, Average Training Loss: 1.2906034580971066, Training Accuracy: 0.46710526315789475\n",
            "Epoch 1/5, Batch Loss: 0.6355416774749756, Average Training Loss: 1.282096162244871, Training Accuracy: 0.4724025974025974\n",
            "Epoch 1/5, Batch Loss: 0.8260916471481323, Average Training Loss: 1.2762499505128615, Training Accuracy: 0.47596153846153844\n",
            "Epoch 1/5, Batch Loss: 0.972707986831665, Average Training Loss: 1.272407647175125, Training Accuracy: 0.4778481012658228\n",
            "Epoch 1/5, Batch Loss: 0.8820622563362122, Average Training Loss: 1.2675283297896385, Training Accuracy: 0.48046875\n",
            "Epoch 1/5, Batch Loss: 0.9210050106048584, Average Training Loss: 1.2632502641206906, Training Accuracy: 0.4837962962962963\n",
            "Epoch 1/5, Batch Loss: 0.9368823766708374, Average Training Loss: 1.2592701679322778, Training Accuracy: 0.4847560975609756\n",
            "Epoch 1/5, Batch Loss: 1.0816333293914795, Average Training Loss: 1.2571299650582923, Training Accuracy: 0.4879518072289157\n",
            "Epoch 1/5, Batch Loss: 1.0522806644439697, Average Training Loss: 1.2546912829081218, Training Accuracy: 0.49107142857142855\n",
            "Epoch 1/5, Batch Loss: 1.477229356765747, Average Training Loss: 1.257309377894682, Training Accuracy: 0.4919117647058823\n",
            "Epoch 1/5, Batch Loss: 0.9274790287017822, Average Training Loss: 1.2534741412761599, Training Accuracy: 0.4941860465116279\n",
            "Epoch 1/5, Batch Loss: 1.0771019458770752, Average Training Loss: 1.2514468746623775, Training Accuracy: 0.4956896551724138\n",
            "Epoch 1/5, Batch Loss: 1.061905026435852, Average Training Loss: 1.2492929900234395, Training Accuracy: 0.49644886363636365\n",
            "Epoch 1/5, Batch Loss: 0.6536175608634949, Average Training Loss: 1.242600007673328, Training Accuracy: 0.5007022471910112\n",
            "Epoch 1/5, Batch Loss: 0.830685555934906, Average Training Loss: 1.2380231804317898, Training Accuracy: 0.5034722222222222\n",
            "Epoch 1/5, Batch Loss: 0.7432029843330383, Average Training Loss: 1.232585595859276, Training Accuracy: 0.5054945054945055\n",
            "Epoch 1/5, Batch Loss: 1.214493989944458, Average Training Loss: 1.2323889479688976, Training Accuracy: 0.5074728260869565\n",
            "Epoch 1/5, Batch Loss: 0.6604740619659424, Average Training Loss: 1.2262393255387583, Training Accuracy: 0.5100806451612904\n",
            "Epoch 1/5, Batch Loss: 0.6369775533676147, Average Training Loss: 1.2199705832816186, Training Accuracy: 0.5132978723404256\n",
            "Epoch 1/5, Batch Loss: 0.7411378622055054, Average Training Loss: 1.2149302388492385, Training Accuracy: 0.5157894736842106\n",
            "Epoch 1/5, Batch Loss: 1.2368581295013428, Average Training Loss: 1.2151586543768644, Training Accuracy: 0.515625\n",
            "Epoch 1/5, Batch Loss: 0.9000412821769714, Average Training Loss: 1.2119100216737728, Training Accuracy: 0.5173969072164949\n",
            "Epoch 1/5, Batch Loss: 0.6258305311203003, Average Training Loss: 1.2059296187089414, Training Accuracy: 0.5204081632653061\n",
            "Epoch 1/5, Batch Loss: 1.0297702550888062, Average Training Loss: 1.2041502311976269, Training Accuracy: 0.5220959595959596\n",
            "Epoch 1/5, Batch Loss: 0.7378318905830383, Average Training Loss: 1.199487047791481, Training Accuracy: 0.52375\n",
            "Epoch 1/5, Batch Loss: 1.0687767267227173, Average Training Loss: 1.1981928861967408, Training Accuracy: 0.5241336633663366\n",
            "Epoch 1/5, Batch Loss: 0.8278805017471313, Average Training Loss: 1.1945623726237053, Training Accuracy: 0.5257352941176471\n",
            "Epoch 1/5, Batch Loss: 0.7475221157073975, Average Training Loss: 1.190222175954615, Training Accuracy: 0.5273058252427184\n",
            "Epoch 1/5, Batch Loss: 0.7998292446136475, Average Training Loss: 1.186468397768644, Training Accuracy: 0.5288461538461539\n",
            "Epoch 1/5, Batch Loss: 0.7731936573982239, Average Training Loss: 1.1825324478603545, Training Accuracy: 0.530952380952381\n",
            "Epoch 1/5, Batch Loss: 0.7693166732788086, Average Training Loss: 1.1786341858360003, Training Accuracy: 0.5324292452830188\n",
            "Epoch 1/5, Batch Loss: 0.5670827031135559, Average Training Loss: 1.1729187514180335, Training Accuracy: 0.5344626168224299\n",
            "Epoch 1/5, Batch Loss: 0.8123814463615417, Average Training Loss: 1.169580443037881, Training Accuracy: 0.5364583333333334\n",
            "Epoch 1/5, Batch Loss: 0.6756234169006348, Average Training Loss: 1.1650487272017593, Training Accuracy: 0.5389908256880734\n",
            "Epoch 1/5, Batch Loss: 1.1055481433868408, Average Training Loss: 1.1645078128034418, Training Accuracy: 0.5397727272727273\n",
            "Epoch 1/5, Batch Loss: 0.6631281971931458, Average Training Loss: 1.159990879329475, Training Accuracy: 0.5416666666666666\n",
            "Epoch 1/5, Batch Loss: 0.5570416450500488, Average Training Loss: 1.154607404023409, Training Accuracy: 0.5440848214285714\n",
            "Epoch 1/5, Batch Loss: 1.3710355758666992, Average Training Loss: 1.1565226975795442, Training Accuracy: 0.5442477876106194\n",
            "Epoch 1/5, Batch Loss: 0.880399763584137, Average Training Loss: 1.1541005665795845, Training Accuracy: 0.5455043859649122\n",
            "Epoch 1/5, Batch Loss: 1.2714110612869263, Average Training Loss: 1.1551206578379092, Training Accuracy: 0.5451086956521739\n",
            "Epoch 1/5, Batch Loss: 0.28641626238822937, Average Training Loss: 1.1476318268426533, Training Accuracy: 0.5484913793103449\n",
            "Epoch 1/5, Batch Loss: 1.244382619857788, Average Training Loss: 1.1484587566974835, Training Accuracy: 0.5480769230769231\n",
            "Epoch 1/5, Batch Loss: 1.3448330163955688, Average Training Loss: 1.1501229453389927, Training Accuracy: 0.5471398305084746\n",
            "Epoch 1/5, Batch Loss: 0.668094277381897, Average Training Loss: 1.146072284263723, Training Accuracy: 0.5488445378151261\n",
            "Epoch 1/5, Batch Loss: 0.6964934468269348, Average Training Loss: 1.1423257939517497, Training Accuracy: 0.55\n",
            "Epoch 1/5, Batch Loss: 0.9950206279754639, Average Training Loss: 1.1411083958858301, Training Accuracy: 0.5511363636363636\n",
            "Epoch 1/5, Batch Loss: 0.4082731306552887, Average Training Loss: 1.1351015494495142, Training Accuracy: 0.5537909836065574\n",
            "Epoch 1/5, Batch Loss: 0.6304786205291748, Average Training Loss: 1.1309989240111373, Training Accuracy: 0.5558943089430894\n",
            "Epoch 1/5, Batch Loss: 0.6280195713043213, Average Training Loss: 1.1269426389086632, Training Accuracy: 0.5569556451612904\n",
            "Epoch 1/5, Batch Loss: 0.4390745162963867, Average Training Loss: 1.1214396939277649, Training Accuracy: 0.5595\n",
            "Epoch 1/5, Batch Loss: 0.5310808420181274, Average Training Loss: 1.1167543062141962, Training Accuracy: 0.5610119047619048\n",
            "Epoch 1/5, Batch Loss: 0.9736450910568237, Average Training Loss: 1.1156274620003588, Training Accuracy: 0.5615157480314961\n",
            "Epoch 1/5, Batch Loss: 0.7582323551177979, Average Training Loss: 1.1128353127278388, Training Accuracy: 0.56201171875\n",
            "Epoch 1/5, Batch Loss: 0.82370924949646, Average Training Loss: 1.1105940254159676, Training Accuracy: 0.562984496124031\n",
            "Epoch 1/5, Batch Loss: 1.2907465696334839, Average Training Loss: 1.1119798142176407, Training Accuracy: 0.5629807692307692\n",
            "Epoch 1/5, Batch Loss: 0.7542880177497864, Average Training Loss: 1.1092493424888785, Training Accuracy: 0.5648854961832062\n",
            "Epoch 1/5, Batch Loss: 0.6329023241996765, Average Training Loss: 1.1056406529563847, Training Accuracy: 0.5672348484848485\n",
            "Epoch 1/5, Batch Loss: 0.6625028848648071, Average Training Loss: 1.1096088482505777, Training Accuracy: 0.5671712393566698\n",
            "Epoch 1/5, Average Training Loss: 1.1023087900384028, Training Accuracy: 0.5671712393566698\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.51      0.50      0.50       427\n",
            "                Educational Opportunity       0.45      0.51      0.48       451\n",
            "                         Family Support       0.75      0.67      0.71       396\n",
            "                      Financial Support       0.61      0.54      0.57       404\n",
            "                 Program Implementation       0.58      0.62      0.60       436\n",
            "\n",
            "                               accuracy                           0.57      2114\n",
            "                              macro avg       0.58      0.57      0.57      2114\n",
            "                           weighted avg       0.57      0.57      0.57      2114\n",
            "\n",
            "Epoch 1/5, Validation Loss: 30.465643376111984, Validation Accuracy: 0.6616257088846881\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.51      0.70      0.59       113\n",
            "                Educational Opportunity       0.52      0.36      0.43       100\n",
            "                         Family Support       0.95      0.88      0.91       105\n",
            "                      Financial Support       0.58      0.75      0.65        97\n",
            "                 Program Implementation       0.85      0.61      0.71       114\n",
            "\n",
            "                               accuracy                           0.66       529\n",
            "                              macro avg       0.68      0.66      0.66       529\n",
            "                           weighted avg       0.69      0.66      0.66       529\n",
            "\n",
            "Epoch 2/5, Batch Loss: 0.7409569025039673, Average Training Loss: 0.7409569025039673, Training Accuracy: 0.6875\n",
            "Epoch 2/5, Batch Loss: 0.7755461931228638, Average Training Loss: 0.7582515478134155, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.4676479697227478, Average Training Loss: 0.6613836884498596, Training Accuracy: 0.8125\n",
            "Epoch 2/5, Batch Loss: 0.7732040882110596, Average Training Loss: 0.6893387883901596, Training Accuracy: 0.765625\n",
            "Epoch 2/5, Batch Loss: 0.44562220573425293, Average Training Loss: 0.6405954718589782, Training Accuracy: 0.775\n",
            "Epoch 2/5, Batch Loss: 0.5896445512771606, Average Training Loss: 0.6321036517620087, Training Accuracy: 0.78125\n",
            "Epoch 2/5, Batch Loss: 0.6531315445899963, Average Training Loss: 0.6351076364517212, Training Accuracy: 0.7767857142857143\n",
            "Epoch 2/5, Batch Loss: 0.5503132343292236, Average Training Loss: 0.624508336186409, Training Accuracy: 0.7890625\n",
            "Epoch 2/5, Batch Loss: 0.3316078186035156, Average Training Loss: 0.5919638342327542, Training Accuracy: 0.8055555555555556\n",
            "Epoch 2/5, Batch Loss: 0.7271061539649963, Average Training Loss: 0.6054780662059784, Training Accuracy: 0.8125\n",
            "Epoch 2/5, Batch Loss: 0.5461840033531189, Average Training Loss: 0.6000876968557184, Training Accuracy: 0.8181818181818182\n",
            "Epoch 2/5, Batch Loss: 0.6634686589241028, Average Training Loss: 0.6053694436947504, Training Accuracy: 0.8125\n",
            "Epoch 2/5, Batch Loss: 0.5068259835243225, Average Training Loss: 0.5977891775277945, Training Accuracy: 0.8173076923076923\n",
            "Epoch 2/5, Batch Loss: 0.9571397304534912, Average Training Loss: 0.6234570741653442, Training Accuracy: 0.8035714285714286\n",
            "Epoch 2/5, Batch Loss: 0.7534198760986328, Average Training Loss: 0.6321212609608968, Training Accuracy: 0.7958333333333333\n",
            "Epoch 2/5, Batch Loss: 0.4177321493625641, Average Training Loss: 0.618721941486001, Training Accuracy: 0.8046875\n",
            "Epoch 2/5, Batch Loss: 0.9258525967597961, Average Training Loss: 0.6367884506197536, Training Accuracy: 0.7941176470588235\n",
            "Epoch 2/5, Batch Loss: 0.35061541199684143, Average Training Loss: 0.6208899484740363, Training Accuracy: 0.8020833333333334\n",
            "Epoch 2/5, Batch Loss: 0.8280808925628662, Average Training Loss: 0.6317947350050274, Training Accuracy: 0.8026315789473685\n",
            "Epoch 2/5, Batch Loss: 0.9265653491020203, Average Training Loss: 0.646533265709877, Training Accuracy: 0.796875\n",
            "Epoch 2/5, Batch Loss: 0.6661126017570496, Average Training Loss: 0.6474656150454566, Training Accuracy: 0.7916666666666666\n",
            "Epoch 2/5, Batch Loss: 0.7614892721176147, Average Training Loss: 0.6526485085487366, Training Accuracy: 0.7869318181818182\n",
            "Epoch 2/5, Batch Loss: 0.40893131494522095, Average Training Loss: 0.6420521088268446, Training Accuracy: 0.7907608695652174\n",
            "Epoch 2/5, Batch Loss: 0.42072662711143494, Average Training Loss: 0.6328302137553692, Training Accuracy: 0.796875\n",
            "Epoch 2/5, Batch Loss: 1.1792749166488647, Average Training Loss: 0.654688001871109, Training Accuracy: 0.785\n",
            "Epoch 2/5, Batch Loss: 0.710272490978241, Average Training Loss: 0.6568258668367679, Training Accuracy: 0.78125\n",
            "Epoch 2/5, Batch Loss: 0.6229872107505798, Average Training Loss: 0.6555725832780203, Training Accuracy: 0.7824074074074074\n",
            "Epoch 2/5, Batch Loss: 0.4792815148830414, Average Training Loss: 0.6492764736924853, Training Accuracy: 0.7857142857142857\n",
            "Epoch 2/5, Batch Loss: 0.5463870167732239, Average Training Loss: 0.6457285613849245, Training Accuracy: 0.7866379310344828\n",
            "Epoch 2/5, Batch Loss: 0.9391759634017944, Average Training Loss: 0.6555101414521535, Training Accuracy: 0.7833333333333333\n",
            "Epoch 2/5, Batch Loss: 0.9148721694946289, Average Training Loss: 0.6638766584857818, Training Accuracy: 0.780241935483871\n",
            "Epoch 2/5, Batch Loss: 0.9095569849014282, Average Training Loss: 0.6715541686862707, Training Accuracy: 0.77734375\n",
            "Epoch 2/5, Batch Loss: 0.26800671219825745, Average Training Loss: 0.6593254578836036, Training Accuracy: 0.7821969696969697\n",
            "Epoch 2/5, Batch Loss: 0.7251673936843872, Average Training Loss: 0.6612619854071561, Training Accuracy: 0.7794117647058824\n",
            "Epoch 2/5, Batch Loss: 0.44679009914398193, Average Training Loss: 0.6551342172282083, Training Accuracy: 0.7821428571428571\n",
            "Epoch 2/5, Batch Loss: 0.3947877585887909, Average Training Loss: 0.6479023711548911, Training Accuracy: 0.7847222222222222\n",
            "Epoch 2/5, Batch Loss: 0.8890746831893921, Average Training Loss: 0.6544205417504182, Training Accuracy: 0.7820945945945946\n",
            "Epoch 2/5, Batch Loss: 0.2318151444196701, Average Training Loss: 0.6432993470838195, Training Accuracy: 0.7861842105263158\n",
            "Epoch 2/5, Batch Loss: 0.29501694440841675, Average Training Loss: 0.6343690290665015, Training Accuracy: 0.7900641025641025\n",
            "Epoch 2/5, Batch Loss: 0.6051461696624756, Average Training Loss: 0.6336384575814009, Training Accuracy: 0.7890625\n",
            "Epoch 2/5, Batch Loss: 0.9191356301307678, Average Training Loss: 0.6406018032533366, Training Accuracy: 0.7850609756097561\n",
            "Epoch 2/5, Batch Loss: 0.3328894078731537, Average Training Loss: 0.6332753176490465, Training Accuracy: 0.7886904761904762\n",
            "Epoch 2/5, Batch Loss: 0.30168330669403076, Average Training Loss: 0.6255638755338137, Training Accuracy: 0.7892441860465116\n",
            "Epoch 2/5, Batch Loss: 1.1128123998641968, Average Training Loss: 0.6366377056322314, Training Accuracy: 0.7855113636363636\n",
            "Epoch 2/5, Batch Loss: 0.6242493987083435, Average Training Loss: 0.6363624099228117, Training Accuracy: 0.7847222222222222\n",
            "Epoch 2/5, Batch Loss: 0.6900584697723389, Average Training Loss: 0.6375297155717145, Training Accuracy: 0.7866847826086957\n",
            "Epoch 2/5, Batch Loss: 0.6418412923812866, Average Training Loss: 0.6376214512485139, Training Accuracy: 0.7845744680851063\n",
            "Epoch 2/5, Batch Loss: 0.313683420419693, Average Training Loss: 0.6308727422729135, Training Accuracy: 0.7864583333333334\n",
            "Epoch 2/5, Batch Loss: 0.42460304498672485, Average Training Loss: 0.6266631566140116, Training Accuracy: 0.7882653061224489\n",
            "Epoch 2/5, Batch Loss: 0.5629589557647705, Average Training Loss: 0.6253890725970268, Training Accuracy: 0.79\n",
            "Epoch 2/5, Batch Loss: 0.2539483606815338, Average Training Loss: 0.6181059213829976, Training Accuracy: 0.7928921568627451\n",
            "Epoch 2/5, Batch Loss: 0.7496410608291626, Average Training Loss: 0.6206354432954237, Training Accuracy: 0.7920673076923077\n",
            "Epoch 2/5, Batch Loss: 0.3836681544780731, Average Training Loss: 0.6161643623743417, Training Accuracy: 0.7948113207547169\n",
            "Epoch 2/5, Batch Loss: 0.684191107749939, Average Training Loss: 0.6174241169183342, Training Accuracy: 0.7939814814814815\n",
            "Epoch 2/5, Batch Loss: 0.40879783034324646, Average Training Loss: 0.6136309117078781, Training Accuracy: 0.7965909090909091\n",
            "Epoch 2/5, Batch Loss: 0.6275043487548828, Average Training Loss: 0.6138786516551461, Training Accuracy: 0.7979910714285714\n",
            "Epoch 2/5, Batch Loss: 0.325458288192749, Average Training Loss: 0.6088186452786127, Training Accuracy: 0.7993421052631579\n",
            "Epoch 2/5, Batch Loss: 0.9073280096054077, Average Training Loss: 0.613965358456661, Training Accuracy: 0.7963362068965517\n",
            "Epoch 2/5, Batch Loss: 0.8658472299575806, Average Training Loss: 0.6182345427193884, Training Accuracy: 0.7944915254237288\n",
            "Epoch 2/5, Batch Loss: 0.20319855213165283, Average Training Loss: 0.6113172762095929, Training Accuracy: 0.796875\n",
            "Epoch 2/5, Batch Loss: 0.45872825384140015, Average Training Loss: 0.6088158168265076, Training Accuracy: 0.7971311475409836\n",
            "Epoch 2/5, Batch Loss: 0.602643609046936, Average Training Loss: 0.6087162650881275, Training Accuracy: 0.7973790322580645\n",
            "Epoch 2/5, Batch Loss: 0.7216472625732422, Average Training Loss: 0.6105088206037642, Training Accuracy: 0.7946428571428571\n",
            "Epoch 2/5, Batch Loss: 0.6861175894737244, Average Training Loss: 0.6116902076173574, Training Accuracy: 0.7939453125\n",
            "Epoch 2/5, Batch Loss: 0.7523854374885559, Average Training Loss: 0.6138547496153758, Training Accuracy: 0.7932692307692307\n",
            "Epoch 2/5, Batch Loss: 0.9631519317626953, Average Training Loss: 0.6191471311630625, Training Accuracy: 0.790719696969697\n",
            "Epoch 2/5, Batch Loss: 0.45555949211120605, Average Training Loss: 0.6167055246100497, Training Accuracy: 0.7910447761194029\n",
            "Epoch 2/5, Batch Loss: 0.7542573809623718, Average Training Loss: 0.6187283460269956, Training Accuracy: 0.7904411764705882\n",
            "Epoch 2/5, Batch Loss: 0.9150316715240479, Average Training Loss: 0.6230225971211558, Training Accuracy: 0.7889492753623188\n",
            "Epoch 2/5, Batch Loss: 0.5760942101478577, Average Training Loss: 0.6223521915929658, Training Accuracy: 0.7901785714285714\n",
            "Epoch 2/5, Batch Loss: 0.8083048462867737, Average Training Loss: 0.6249712430675265, Training Accuracy: 0.7887323943661971\n",
            "Epoch 2/5, Batch Loss: 0.9697487354278564, Average Training Loss: 0.6297598193503089, Training Accuracy: 0.7873263888888888\n",
            "Epoch 2/5, Batch Loss: 0.46645811200141907, Average Training Loss: 0.627522809660598, Training Accuracy: 0.788527397260274\n",
            "Epoch 2/5, Batch Loss: 0.5433111190795898, Average Training Loss: 0.6263848138419358, Training Accuracy: 0.7896959459459459\n",
            "Epoch 2/5, Batch Loss: 0.6863449215888977, Average Training Loss: 0.6271842819452286, Training Accuracy: 0.7891666666666667\n",
            "Epoch 2/5, Batch Loss: 0.6701319813728333, Average Training Loss: 0.6277493832534865, Training Accuracy: 0.7886513157894737\n",
            "Epoch 2/5, Batch Loss: 0.5698264837265015, Average Training Loss: 0.6269971378050841, Training Accuracy: 0.7897727272727273\n",
            "Epoch 2/5, Batch Loss: 0.37419670820236206, Average Training Loss: 0.6237561066563313, Training Accuracy: 0.7908653846153846\n",
            "Epoch 2/5, Batch Loss: 0.8229321837425232, Average Training Loss: 0.6262773228219792, Training Accuracy: 0.7887658227848101\n",
            "Epoch 2/5, Batch Loss: 0.7047163844108582, Average Training Loss: 0.6272578110918403, Training Accuracy: 0.78828125\n",
            "Epoch 2/5, Batch Loss: 0.7084749937057495, Average Training Loss: 0.6282604923586786, Training Accuracy: 0.7878086419753086\n",
            "Epoch 2/5, Batch Loss: 0.5263529419898987, Average Training Loss: 0.6270177173541813, Training Accuracy: 0.788109756097561\n",
            "Epoch 2/5, Batch Loss: 0.6620354056358337, Average Training Loss: 0.6274396172129965, Training Accuracy: 0.7876506024096386\n",
            "Epoch 2/5, Batch Loss: 0.46095550060272217, Average Training Loss: 0.6254576634438265, Training Accuracy: 0.7879464285714286\n",
            "Epoch 2/5, Batch Loss: 0.8047235012054443, Average Training Loss: 0.6275666732998455, Training Accuracy: 0.7867647058823529\n",
            "Epoch 2/5, Batch Loss: 0.36365148425102234, Average Training Loss: 0.6244978920318359, Training Accuracy: 0.7885174418604651\n",
            "Epoch 2/5, Batch Loss: 0.8802546262741089, Average Training Loss: 0.6274376246093334, Training Accuracy: 0.7880747126436781\n",
            "Epoch 2/5, Batch Loss: 0.46536189317703247, Average Training Loss: 0.6255958549339663, Training Accuracy: 0.7883522727272727\n",
            "Epoch 2/5, Batch Loss: 0.5042098164558411, Average Training Loss: 0.6242319668611783, Training Accuracy: 0.788623595505618\n",
            "Epoch 2/5, Batch Loss: 0.7304788827896118, Average Training Loss: 0.6254124881492721, Training Accuracy: 0.7875\n",
            "Epoch 2/5, Batch Loss: 0.43533068895339966, Average Training Loss: 0.6233236771690976, Training Accuracy: 0.7884615384615384\n",
            "Epoch 2/5, Batch Loss: 0.2576122581958771, Average Training Loss: 0.6193485530498235, Training Accuracy: 0.7900815217391305\n",
            "Epoch 2/5, Batch Loss: 0.7564778923988342, Average Training Loss: 0.6208230620750816, Training Accuracy: 0.7889784946236559\n",
            "Epoch 2/5, Batch Loss: 0.7085694074630737, Average Training Loss: 0.6217565338345284, Training Accuracy: 0.788563829787234\n",
            "Epoch 2/5, Batch Loss: 0.33569401502609253, Average Training Loss: 0.6187453494260186, Training Accuracy: 0.7894736842105263\n",
            "Epoch 2/5, Batch Loss: 1.0924344062805176, Average Training Loss: 0.6236796104349196, Training Accuracy: 0.7858072916666666\n",
            "Epoch 2/5, Batch Loss: 0.20419469475746155, Average Training Loss: 0.6193550236753582, Training Accuracy: 0.7873711340206185\n",
            "Epoch 2/5, Batch Loss: 0.6970027685165405, Average Training Loss: 0.620147347602309, Training Accuracy: 0.7863520408163265\n",
            "Epoch 2/5, Batch Loss: 1.0696067810058594, Average Training Loss: 0.6246873418791126, Training Accuracy: 0.7853535353535354\n",
            "Epoch 2/5, Batch Loss: 1.1026561260223389, Average Training Loss: 0.6294670297205448, Training Accuracy: 0.784375\n",
            "Epoch 2/5, Batch Loss: 0.7376313209533691, Average Training Loss: 0.6305379632971074, Training Accuracy: 0.7840346534653465\n",
            "Epoch 2/5, Batch Loss: 0.477753609418869, Average Training Loss: 0.6290400774747718, Training Accuracy: 0.7849264705882353\n",
            "Epoch 2/5, Batch Loss: 0.8971996307373047, Average Training Loss: 0.6316435682831458, Training Accuracy: 0.7839805825242718\n",
            "Epoch 2/5, Batch Loss: 0.9822273254394531, Average Training Loss: 0.6350145659481103, Training Accuracy: 0.7824519230769231\n",
            "Epoch 2/5, Batch Loss: 0.6800357699394226, Average Training Loss: 0.6354433393194562, Training Accuracy: 0.7827380952380952\n",
            "Epoch 2/5, Batch Loss: 0.6299116611480713, Average Training Loss: 0.6353911536763299, Training Accuracy: 0.7830188679245284\n",
            "Epoch 2/5, Batch Loss: 0.24655798077583313, Average Training Loss: 0.6317571987894094, Training Accuracy: 0.7838785046728972\n",
            "Epoch 2/5, Batch Loss: 0.40711814165115356, Average Training Loss: 0.6296772075196108, Training Accuracy: 0.7841435185185185\n",
            "Epoch 2/5, Batch Loss: 0.47956588864326477, Average Training Loss: 0.628300039456525, Training Accuracy: 0.7849770642201835\n",
            "Epoch 2/5, Batch Loss: 0.5056878924369812, Average Training Loss: 0.6271853835745291, Training Accuracy: 0.7852272727272728\n",
            "Epoch 2/5, Batch Loss: 0.39259427785873413, Average Training Loss: 0.6250719501897022, Training Accuracy: 0.786036036036036\n",
            "Epoch 2/5, Batch Loss: 0.43775230646133423, Average Training Loss: 0.6233994533706989, Training Accuracy: 0.7873883928571429\n",
            "Epoch 2/5, Batch Loss: 0.6444302201271057, Average Training Loss: 0.6235855663508441, Training Accuracy: 0.7876106194690266\n",
            "Epoch 2/5, Batch Loss: 0.7315291166305542, Average Training Loss: 0.6245324395989117, Training Accuracy: 0.7872807017543859\n",
            "Epoch 2/5, Batch Loss: 0.4138428270816803, Average Training Loss: 0.6227003560118053, Training Accuracy: 0.7880434782608695\n",
            "Epoch 2/5, Batch Loss: 0.4452897906303406, Average Training Loss: 0.621170954586103, Training Accuracy: 0.7887931034482759\n",
            "Epoch 2/5, Batch Loss: 0.3430527448654175, Average Training Loss: 0.6187938758705416, Training Accuracy: 0.7895299145299145\n",
            "Epoch 2/5, Batch Loss: 0.3416905403137207, Average Training Loss: 0.6164455425183651, Training Accuracy: 0.7907838983050848\n",
            "Epoch 2/5, Batch Loss: 0.6026651859283447, Average Training Loss: 0.6163297412024826, Training Accuracy: 0.7904411764705882\n",
            "Epoch 2/5, Batch Loss: 0.728986918926239, Average Training Loss: 0.6172685510168473, Training Accuracy: 0.790625\n",
            "Epoch 2/5, Batch Loss: 0.392831027507782, Average Training Loss: 0.6154136954506567, Training Accuracy: 0.7913223140495868\n",
            "Epoch 2/5, Batch Loss: 0.6165322065353394, Average Training Loss: 0.6154228635743016, Training Accuracy: 0.7914959016393442\n",
            "Epoch 2/5, Batch Loss: 0.6534150838851929, Average Training Loss: 0.6157317434142275, Training Accuracy: 0.7911585365853658\n",
            "Epoch 2/5, Batch Loss: 0.6611571907997131, Average Training Loss: 0.6160980776673363, Training Accuracy: 0.7903225806451613\n",
            "Epoch 2/5, Batch Loss: 0.29604336619377136, Average Training Loss: 0.6135376399755478, Training Accuracy: 0.791\n",
            "Epoch 2/5, Batch Loss: 0.8739516735076904, Average Training Loss: 0.6156044180194536, Training Accuracy: 0.7906746031746031\n",
            "Epoch 2/5, Batch Loss: 0.7524484395980835, Average Training Loss: 0.6166819300003877, Training Accuracy: 0.7898622047244095\n",
            "Epoch 2/5, Batch Loss: 0.7424115538597107, Average Training Loss: 0.6176641926867887, Training Accuracy: 0.7890625\n",
            "Epoch 2/5, Batch Loss: 0.9605309367179871, Average Training Loss: 0.6203220744234647, Training Accuracy: 0.7887596899224806\n",
            "Epoch 2/5, Batch Loss: 0.46141475439071655, Average Training Loss: 0.6190997104232128, Training Accuracy: 0.7899038461538461\n",
            "Epoch 2/5, Batch Loss: 0.1572643667459488, Average Training Loss: 0.6155742497844551, Training Accuracy: 0.7915076335877863\n",
            "Epoch 2/5, Batch Loss: 0.3401672840118408, Average Training Loss: 0.6134878333770868, Training Accuracy: 0.7926136363636364\n",
            "Epoch 2/5, Batch Loss: 0.07969542592763901, Average Training Loss: 0.6135106106467595, Training Accuracy: 0.7928098391674551\n",
            "Epoch 2/5, Average Training Loss: 0.6094743566293466, Training Accuracy: 0.7928098391674551\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.77      0.78      0.78       427\n",
            "                Educational Opportunity       0.68      0.69      0.69       451\n",
            "                         Family Support       0.91      0.95      0.93       396\n",
            "                      Financial Support       0.80      0.83      0.81       404\n",
            "                 Program Implementation       0.81      0.74      0.77       436\n",
            "\n",
            "                               accuracy                           0.79      2114\n",
            "                              macro avg       0.80      0.80      0.80      2114\n",
            "                           weighted avg       0.79      0.79      0.79      2114\n",
            "\n",
            "Epoch 2/5, Validation Loss: 24.77075758576393, Validation Accuracy: 0.7353497164461248\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.65      0.65       113\n",
            "                Educational Opportunity       0.53      0.55      0.54       100\n",
            "                         Family Support       0.89      0.99      0.94       105\n",
            "                      Financial Support       0.75      0.78      0.76        97\n",
            "                 Program Implementation       0.84      0.71      0.77       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.73      0.74      0.73       529\n",
            "                           weighted avg       0.74      0.74      0.73       529\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.336156964302063, Average Training Loss: 0.336156964302063, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.3307707607746124, Average Training Loss: 0.3334638625383377, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.3743050694465637, Average Training Loss: 0.347077598174413, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.5391507744789124, Average Training Loss: 0.3950958922505379, Training Accuracy: 0.859375\n",
            "Epoch 3/5, Batch Loss: 0.116903156042099, Average Training Loss: 0.3394573450088501, Training Accuracy: 0.8875\n",
            "Epoch 3/5, Batch Loss: 0.5256660580635071, Average Training Loss: 0.3704921305179596, Training Accuracy: 0.8645833333333334\n",
            "Epoch 3/5, Batch Loss: 0.8715318441390991, Average Training Loss: 0.44206923246383667, Training Accuracy: 0.8571428571428571\n",
            "Epoch 3/5, Batch Loss: 0.19665181636810303, Average Training Loss: 0.41139205545186996, Training Accuracy: 0.8671875\n",
            "Epoch 3/5, Batch Loss: 0.31292924284935, Average Training Loss: 0.40045174294047886, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.3178209364414215, Average Training Loss: 0.39218866229057314, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.24675780534744263, Average Training Loss: 0.3789676752957431, Training Accuracy: 0.8806818181818182\n",
            "Epoch 3/5, Batch Loss: 0.38217711448669434, Average Training Loss: 0.3792351285616557, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.3367339074611664, Average Training Loss: 0.37596580386161804, Training Accuracy: 0.8701923076923077\n",
            "Epoch 3/5, Batch Loss: 0.16587701439857483, Average Training Loss: 0.36095946175711496, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.290888249874115, Average Training Loss: 0.3562880476315816, Training Accuracy: 0.8791666666666667\n",
            "Epoch 3/5, Batch Loss: 0.5186185240745544, Average Training Loss: 0.3664337024092674, Training Accuracy: 0.87890625\n",
            "Epoch 3/5, Batch Loss: 0.5476005673408508, Average Training Loss: 0.37709057681700764, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.36322298645973206, Average Training Loss: 0.37632015513049233, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.4431352913379669, Average Training Loss: 0.3798367412466752, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.6062784194946289, Average Training Loss: 0.39115882515907285, Training Accuracy: 0.86875\n",
            "Epoch 3/5, Batch Loss: 0.43627068400382996, Average Training Loss: 0.3933070089135851, Training Accuracy: 0.8690476190476191\n",
            "Epoch 3/5, Batch Loss: 0.6372283697128296, Average Training Loss: 0.40439434349536896, Training Accuracy: 0.8579545454545454\n",
            "Epoch 3/5, Batch Loss: 0.21975792944431305, Average Training Loss: 0.3963666733192361, Training Accuracy: 0.8614130434782609\n",
            "Epoch 3/5, Batch Loss: 0.5706029534339905, Average Training Loss: 0.4036265183240175, Training Accuracy: 0.859375\n",
            "Epoch 3/5, Batch Loss: 0.2870316207408905, Average Training Loss: 0.3989627224206924, Training Accuracy: 0.8575\n",
            "Epoch 3/5, Batch Loss: 0.2740611433982849, Average Training Loss: 0.39415881553521526, Training Accuracy: 0.8605769230769231\n",
            "Epoch 3/5, Batch Loss: 0.38955414295196533, Average Training Loss: 0.39398827210620596, Training Accuracy: 0.8611111111111112\n",
            "Epoch 3/5, Batch Loss: 0.44155409932136536, Average Training Loss: 0.39568705164960455, Training Accuracy: 0.8616071428571429\n",
            "Epoch 3/5, Batch Loss: 0.3149776756763458, Average Training Loss: 0.39290396971949215, Training Accuracy: 0.8642241379310345\n",
            "Epoch 3/5, Batch Loss: 0.12532323598861694, Average Training Loss: 0.383984611928463, Training Accuracy: 0.86875\n",
            "Epoch 3/5, Batch Loss: 0.35811251401901245, Average Training Loss: 0.3831500281249323, Training Accuracy: 0.8689516129032258\n",
            "Epoch 3/5, Batch Loss: 0.3005131185054779, Average Training Loss: 0.38056762469932437, Training Accuracy: 0.87109375\n",
            "Epoch 3/5, Batch Loss: 0.3707994222640991, Average Training Loss: 0.3802716185649236, Training Accuracy: 0.8712121212121212\n",
            "Epoch 3/5, Batch Loss: 0.470936119556427, Average Training Loss: 0.3829382215352619, Training Accuracy: 0.8694852941176471\n",
            "Epoch 3/5, Batch Loss: 0.8570057153701782, Average Training Loss: 0.3964830070734024, Training Accuracy: 0.8660714285714286\n",
            "Epoch 3/5, Batch Loss: 0.24505269527435303, Average Training Loss: 0.3922766095234288, Training Accuracy: 0.8680555555555556\n",
            "Epoch 3/5, Batch Loss: 0.4112671911716461, Average Training Loss: 0.3927898684868941, Training Accuracy: 0.8665540540540541\n",
            "Epoch 3/5, Batch Loss: 0.37660467624664307, Average Training Loss: 0.3923639423753086, Training Accuracy: 0.8667763157894737\n",
            "Epoch 3/5, Batch Loss: 0.3344533443450928, Average Training Loss: 0.3908790552463287, Training Accuracy: 0.8669871794871795\n",
            "Epoch 3/5, Batch Loss: 0.42315417528152466, Average Training Loss: 0.3916859332472086, Training Accuracy: 0.8671875\n",
            "Epoch 3/5, Batch Loss: 0.6310068964958191, Average Training Loss: 0.3975230299118089, Training Accuracy: 0.8673780487804879\n",
            "Epoch 3/5, Batch Loss: 0.3948795795440674, Average Training Loss: 0.39746009061733883, Training Accuracy: 0.8675595238095238\n",
            "Epoch 3/5, Batch Loss: 0.2643079161643982, Average Training Loss: 0.3943635284207588, Training Accuracy: 0.8691860465116279\n",
            "Epoch 3/5, Batch Loss: 0.18286824226379395, Average Training Loss: 0.38955681737173686, Training Accuracy: 0.8707386363636364\n",
            "Epoch 3/5, Batch Loss: 0.3648507595062256, Average Training Loss: 0.3890077938636144, Training Accuracy: 0.8722222222222222\n",
            "Epoch 3/5, Batch Loss: 0.4854946732521057, Average Training Loss: 0.39110533471988596, Training Accuracy: 0.8709239130434783\n",
            "Epoch 3/5, Batch Loss: 0.3040507137775421, Average Training Loss: 0.3892531087423893, Training Accuracy: 0.8710106382978723\n",
            "Epoch 3/5, Batch Loss: 0.3915708363056183, Average Training Loss: 0.3893013947332899, Training Accuracy: 0.8697916666666666\n",
            "Epoch 3/5, Batch Loss: 0.27376043796539307, Average Training Loss: 0.38694341602374094, Training Accuracy: 0.8711734693877551\n",
            "Epoch 3/5, Batch Loss: 0.2880116403102875, Average Training Loss: 0.3849647805094719, Training Accuracy: 0.87125\n",
            "Epoch 3/5, Batch Loss: 0.32258546352386475, Average Training Loss: 0.383741656647009, Training Accuracy: 0.8713235294117647\n",
            "Epoch 3/5, Batch Loss: 0.33947205543518066, Average Training Loss: 0.3828903181621662, Training Accuracy: 0.8725961538461539\n",
            "Epoch 3/5, Batch Loss: 0.512115478515625, Average Training Loss: 0.38532852873487294, Training Accuracy: 0.8691037735849056\n",
            "Epoch 3/5, Batch Loss: 0.18716561794281006, Average Training Loss: 0.3816588452016866, Training Accuracy: 0.8703703703703703\n",
            "Epoch 3/5, Batch Loss: 0.12728023529052734, Average Training Loss: 0.37703377956693823, Training Accuracy: 0.8727272727272727\n",
            "Epoch 3/5, Batch Loss: 0.40587642788887024, Average Training Loss: 0.3775488268584013, Training Accuracy: 0.8727678571428571\n",
            "Epoch 3/5, Batch Loss: 0.2937569320201874, Average Training Loss: 0.37607879361562563, Training Accuracy: 0.8739035087719298\n",
            "Epoch 3/5, Batch Loss: 0.31908056139945984, Average Training Loss: 0.37509606547396757, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.44324779510498047, Average Training Loss: 0.3762511795355102, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.3435659110546112, Average Training Loss: 0.3757064250608285, Training Accuracy: 0.8760416666666667\n",
            "Epoch 3/5, Batch Loss: 0.11230521649122238, Average Training Loss: 0.3713883724613268, Training Accuracy: 0.8780737704918032\n",
            "Epoch 3/5, Batch Loss: 0.48599720001220703, Average Training Loss: 0.3732369019379539, Training Accuracy: 0.8770161290322581\n",
            "Epoch 3/5, Batch Loss: 0.37691447138786316, Average Training Loss: 0.37329527605620644, Training Accuracy: 0.875\n",
            "Epoch 3/5, Batch Loss: 0.1372910887002945, Average Training Loss: 0.3696077106287703, Training Accuracy: 0.876953125\n",
            "Epoch 3/5, Batch Loss: 0.4689618945121765, Average Training Loss: 0.3711362365346689, Training Accuracy: 0.8769230769230769\n",
            "Epoch 3/5, Batch Loss: 0.26227784156799316, Average Training Loss: 0.36948686691396165, Training Accuracy: 0.8768939393939394\n",
            "Epoch 3/5, Batch Loss: 0.13464681804180145, Average Training Loss: 0.36598179155766075, Training Accuracy: 0.8777985074626866\n",
            "Epoch 3/5, Batch Loss: 0.07560288906097412, Average Training Loss: 0.3617115135797683, Training Accuracy: 0.8795955882352942\n",
            "Epoch 3/5, Batch Loss: 0.27435916662216187, Average Training Loss: 0.36044553753690445, Training Accuracy: 0.8804347826086957\n",
            "Epoch 3/5, Batch Loss: 0.5528243780136108, Average Training Loss: 0.36319380668657164, Training Accuracy: 0.8794642857142857\n",
            "Epoch 3/5, Batch Loss: 0.17075996100902557, Average Training Loss: 0.36048347083195836, Training Accuracy: 0.8811619718309859\n",
            "Epoch 3/5, Batch Loss: 0.2775285243988037, Average Training Loss: 0.35933131879816455, Training Accuracy: 0.8810763888888888\n",
            "Epoch 3/5, Batch Loss: 0.38313764333724976, Average Training Loss: 0.3596574328329465, Training Accuracy: 0.8809931506849316\n",
            "Epoch 3/5, Batch Loss: 0.13670775294303894, Average Training Loss: 0.35664459932092074, Training Accuracy: 0.8826013513513513\n",
            "Epoch 3/5, Batch Loss: 0.23709475994110107, Average Training Loss: 0.35505060146252315, Training Accuracy: 0.8833333333333333\n",
            "Epoch 3/5, Batch Loss: 0.27453795075416565, Average Training Loss: 0.3539912244795184, Training Accuracy: 0.884046052631579\n",
            "Epoch 3/5, Batch Loss: 0.1880698800086975, Average Training Loss: 0.35183640182405324, Training Accuracy: 0.8847402597402597\n",
            "Epoch 3/5, Batch Loss: 0.38783103227615356, Average Training Loss: 0.352297871445234, Training Accuracy: 0.8830128205128205\n",
            "Epoch 3/5, Batch Loss: 0.22567439079284668, Average Training Loss: 0.3506950425762164, Training Accuracy: 0.8837025316455697\n",
            "Epoch 3/5, Batch Loss: 0.32349899411201477, Average Training Loss: 0.3503550919704139, Training Accuracy: 0.88359375\n",
            "Epoch 3/5, Batch Loss: 0.3433643877506256, Average Training Loss: 0.35026878698004615, Training Accuracy: 0.8842592592592593\n",
            "Epoch 3/5, Batch Loss: 0.5698545575141907, Average Training Loss: 0.35294666223046256, Training Accuracy: 0.8833841463414634\n",
            "Epoch 3/5, Batch Loss: 0.6879767179489136, Average Training Loss: 0.35698316892586557, Training Accuracy: 0.8817771084337349\n",
            "Epoch 3/5, Batch Loss: 0.19934603571891785, Average Training Loss: 0.35510653638768763, Training Accuracy: 0.8824404761904762\n",
            "Epoch 3/5, Batch Loss: 0.15117864310741425, Average Training Loss: 0.3527073847020374, Training Accuracy: 0.8830882352941176\n",
            "Epoch 3/5, Batch Loss: 0.14694799482822418, Average Training Loss: 0.350314833656993, Training Accuracy: 0.8844476744186046\n",
            "Epoch 3/5, Batch Loss: 0.11503274738788605, Average Training Loss: 0.34761044186079637, Training Accuracy: 0.8857758620689655\n",
            "Epoch 3/5, Batch Loss: 0.31745797395706177, Average Training Loss: 0.34726780018007214, Training Accuracy: 0.8856534090909091\n",
            "Epoch 3/5, Batch Loss: 0.15515226125717163, Average Training Loss: 0.3451091986191407, Training Accuracy: 0.8862359550561798\n",
            "Epoch 3/5, Batch Loss: 0.32466113567352295, Average Training Loss: 0.34488199791974494, Training Accuracy: 0.8854166666666666\n",
            "Epoch 3/5, Batch Loss: 0.10507867485284805, Average Training Loss: 0.34224679656736146, Training Accuracy: 0.8866758241758241\n",
            "Epoch 3/5, Batch Loss: 0.08233669400215149, Average Training Loss: 0.33942168675687, Training Accuracy: 0.8879076086956522\n",
            "Epoch 3/5, Batch Loss: 0.08147773146629333, Average Training Loss: 0.33664809583976707, Training Accuracy: 0.8891129032258065\n",
            "Epoch 3/5, Batch Loss: 0.12312095612287521, Average Training Loss: 0.3343765305236299, Training Accuracy: 0.8902925531914894\n",
            "Epoch 3/5, Batch Loss: 0.3061046302318573, Average Training Loss: 0.3340789315731902, Training Accuracy: 0.8901315789473684\n",
            "Epoch 3/5, Batch Loss: 0.36451682448387146, Average Training Loss: 0.33439599295767647, Training Accuracy: 0.890625\n",
            "Epoch 3/5, Batch Loss: 0.4236358404159546, Average Training Loss: 0.3353159913850814, Training Accuracy: 0.8898195876288659\n",
            "Epoch 3/5, Batch Loss: 0.08914609998464584, Average Training Loss: 0.33280405371773, Training Accuracy: 0.8909438775510204\n",
            "Epoch 3/5, Batch Loss: 0.13179396092891693, Average Training Loss: 0.3307736487400652, Training Accuracy: 0.8914141414141414\n",
            "Epoch 3/5, Batch Loss: 0.7472161650657654, Average Training Loss: 0.3349380739033222, Training Accuracy: 0.889375\n",
            "Epoch 3/5, Batch Loss: 0.5487104654312134, Average Training Loss: 0.33705463223528154, Training Accuracy: 0.8886138613861386\n",
            "Epoch 3/5, Batch Loss: 0.6724182367324829, Average Training Loss: 0.3403425107107443, Training Accuracy: 0.8878676470588235\n",
            "Epoch 3/5, Batch Loss: 0.21560260653495789, Average Training Loss: 0.33913144367991144, Training Accuracy: 0.8883495145631068\n",
            "Epoch 3/5, Batch Loss: 0.4727308750152588, Average Training Loss: 0.34041605359659743, Training Accuracy: 0.8882211538461539\n",
            "Epoch 3/5, Batch Loss: 0.29819726943969727, Average Training Loss: 0.3400139699379603, Training Accuracy: 0.888095238095238\n",
            "Epoch 3/5, Batch Loss: 0.15852254629135132, Average Training Loss: 0.3383017866960112, Training Accuracy: 0.8885613207547169\n",
            "Epoch 3/5, Batch Loss: 0.31365060806274414, Average Training Loss: 0.3380714018489713, Training Accuracy: 0.889018691588785\n",
            "Epoch 3/5, Batch Loss: 0.32932502031326294, Average Training Loss: 0.3379904168347518, Training Accuracy: 0.8894675925925926\n",
            "Epoch 3/5, Batch Loss: 0.22874048352241516, Average Training Loss: 0.33698812386858357, Training Accuracy: 0.8899082568807339\n",
            "Epoch 3/5, Batch Loss: 0.5709702968597412, Average Training Loss: 0.33911523453213954, Training Accuracy: 0.8886363636363637\n",
            "Epoch 3/5, Batch Loss: 0.26243093609809875, Average Training Loss: 0.3384243849966977, Training Accuracy: 0.8879504504504504\n",
            "Epoch 3/5, Batch Loss: 0.5751265287399292, Average Training Loss: 0.3405377969944051, Training Accuracy: 0.8872767857142857\n",
            "Epoch 3/5, Batch Loss: 0.32712095975875854, Average Training Loss: 0.3404190639215233, Training Accuracy: 0.8866150442477876\n",
            "Epoch 3/5, Batch Loss: 0.10609413683414459, Average Training Loss: 0.33836358210496736, Training Accuracy: 0.887609649122807\n",
            "Epoch 3/5, Batch Loss: 0.5912852883338928, Average Training Loss: 0.3405629012895667, Training Accuracy: 0.8875\n",
            "Epoch 3/5, Batch Loss: 0.14737994968891144, Average Training Loss: 0.33889753101714726, Training Accuracy: 0.8884698275862069\n",
            "Epoch 3/5, Batch Loss: 0.4110754132270813, Average Training Loss: 0.33951443599330056, Training Accuracy: 0.8883547008547008\n",
            "Epoch 3/5, Batch Loss: 0.768711268901825, Average Training Loss: 0.34315169728913547, Training Accuracy: 0.8871822033898306\n",
            "Epoch 3/5, Batch Loss: 0.5007357597351074, Average Training Loss: 0.3444759331080092, Training Accuracy: 0.8865546218487395\n",
            "Epoch 3/5, Batch Loss: 0.15156149864196777, Average Training Loss: 0.3428683128207922, Training Accuracy: 0.8875\n",
            "Epoch 3/5, Batch Loss: 0.23099032044410706, Average Training Loss: 0.34194370131354684, Training Accuracy: 0.8868801652892562\n",
            "Epoch 3/5, Batch Loss: 0.17998284101486206, Average Training Loss: 0.34061615327831174, Training Accuracy: 0.8872950819672131\n",
            "Epoch 3/5, Batch Loss: 0.20267388224601746, Average Training Loss: 0.3394946714000004, Training Accuracy: 0.8877032520325203\n",
            "Epoch 3/5, Batch Loss: 0.585944652557373, Average Training Loss: 0.34148217124804375, Training Accuracy: 0.8870967741935484\n",
            "Epoch 3/5, Batch Loss: 0.2294096201658249, Average Training Loss: 0.340585590839386, Training Accuracy: 0.8875\n",
            "Epoch 3/5, Batch Loss: 0.6239855289459229, Average Training Loss: 0.3428347966973744, Training Accuracy: 0.8869047619047619\n",
            "Epoch 3/5, Batch Loss: 0.35645121335983276, Average Training Loss: 0.34294201257660634, Training Accuracy: 0.8873031496062992\n",
            "Epoch 3/5, Batch Loss: 0.15813881158828735, Average Training Loss: 0.3414982375688851, Training Accuracy: 0.8876953125\n",
            "Epoch 3/5, Batch Loss: 0.22346089780330658, Average Training Loss: 0.3405832194311674, Training Accuracy: 0.8880813953488372\n",
            "Epoch 3/5, Batch Loss: 0.08418996632099152, Average Training Loss: 0.33861096363801224, Training Accuracy: 0.8889423076923076\n",
            "Epoch 3/5, Batch Loss: 0.09882164001464844, Average Training Loss: 0.33678051078592547, Training Accuracy: 0.8897900763358778\n",
            "Epoch 3/5, Batch Loss: 0.35618487000465393, Average Training Loss: 0.3369275135072795, Training Accuracy: 0.8901515151515151\n",
            "Epoch 3/5, Batch Loss: 0.046007491648197174, Average Training Loss: 0.33695696707367334, Training Accuracy: 0.8902554399243141\n",
            "Epoch 3/5, Average Training Loss: 0.3347401449218729, Training Accuracy: 0.8902554399243141\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.89      0.89      0.89       427\n",
            "                Educational Opportunity       0.81      0.81      0.81       451\n",
            "                         Family Support       0.94      0.98      0.96       396\n",
            "                      Financial Support       0.91      0.92      0.91       404\n",
            "                 Program Implementation       0.91      0.86      0.88       436\n",
            "\n",
            "                               accuracy                           0.89      2114\n",
            "                              macro avg       0.89      0.89      0.89      2114\n",
            "                           weighted avg       0.89      0.89      0.89      2114\n",
            "\n",
            "Epoch 3/5, Validation Loss: 30.62790299206972, Validation Accuracy: 0.6956521739130435\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.61      0.64       113\n",
            "                Educational Opportunity       0.44      0.72      0.54       100\n",
            "                         Family Support       0.91      0.92      0.92       105\n",
            "                      Financial Support       0.78      0.64      0.70        97\n",
            "                 Program Implementation       0.92      0.60      0.72       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.74      0.70      0.70       529\n",
            "                           weighted avg       0.75      0.70      0.71       529\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.09960928559303284, Average Training Loss: 0.09960928559303284, Training Accuracy: 1.0\n",
            "Epoch 4/5, Batch Loss: 0.08865668624639511, Average Training Loss: 0.09413298591971397, Training Accuracy: 1.0\n",
            "Epoch 4/5, Batch Loss: 0.26652562618255615, Average Training Loss: 0.15159719934066138, Training Accuracy: 0.9583333333333334\n",
            "Epoch 4/5, Batch Loss: 0.2766607999801636, Average Training Loss: 0.18286309950053692, Training Accuracy: 0.953125\n",
            "Epoch 4/5, Batch Loss: 0.15757998824119568, Average Training Loss: 0.17780647724866866, Training Accuracy: 0.95\n",
            "Epoch 4/5, Batch Loss: 0.11414583772420883, Average Training Loss: 0.1671963706612587, Training Accuracy: 0.9583333333333334\n",
            "Epoch 4/5, Batch Loss: 0.1328638195991516, Average Training Loss: 0.1622917205095291, Training Accuracy: 0.9642857142857143\n",
            "Epoch 4/5, Batch Loss: 0.07865852117538452, Average Training Loss: 0.15183757059276104, Training Accuracy: 0.96875\n",
            "Epoch 4/5, Batch Loss: 0.2554716467857361, Average Training Loss: 0.16335246794753605, Training Accuracy: 0.9652777777777778\n",
            "Epoch 4/5, Batch Loss: 0.04596780240535736, Average Training Loss: 0.15161400139331818, Training Accuracy: 0.96875\n",
            "Epoch 4/5, Batch Loss: 0.10294082015752792, Average Training Loss: 0.14718916673551907, Training Accuracy: 0.9659090909090909\n",
            "Epoch 4/5, Batch Loss: 0.1822911947965622, Average Training Loss: 0.15011433574060598, Training Accuracy: 0.9635416666666666\n",
            "Epoch 4/5, Batch Loss: 0.09341230988502502, Average Training Loss: 0.14575264144402283, Training Accuracy: 0.9663461538461539\n",
            "Epoch 4/5, Batch Loss: 0.09938780218362808, Average Training Loss: 0.1424408672111375, Training Accuracy: 0.96875\n",
            "Epoch 4/5, Batch Loss: 0.15738853812217712, Average Training Loss: 0.1434373786052068, Training Accuracy: 0.9708333333333333\n",
            "Epoch 4/5, Batch Loss: 0.05244998633861542, Average Training Loss: 0.13775066658854485, Training Accuracy: 0.97265625\n",
            "Epoch 4/5, Batch Loss: 0.05624391511082649, Average Training Loss: 0.1329561517957379, Training Accuracy: 0.9742647058823529\n",
            "Epoch 4/5, Batch Loss: 0.27201521396636963, Average Training Loss: 0.14068165524966186, Training Accuracy: 0.96875\n",
            "Epoch 4/5, Batch Loss: 0.07394114881753922, Average Training Loss: 0.13716899701639226, Training Accuracy: 0.9703947368421053\n",
            "Epoch 4/5, Batch Loss: 0.2685225307941437, Average Training Loss: 0.14373667370527982, Training Accuracy: 0.96875\n",
            "Epoch 4/5, Batch Loss: 0.07916802167892456, Average Training Loss: 0.1406619759897391, Training Accuracy: 0.9702380952380952\n",
            "Epoch 4/5, Batch Loss: 0.3842014670372009, Average Training Loss: 0.15173195285553281, Training Accuracy: 0.9659090909090909\n",
            "Epoch 4/5, Batch Loss: 0.09343814849853516, Average Training Loss: 0.1491974396226199, Training Accuracy: 0.9646739130434783\n",
            "Epoch 4/5, Batch Loss: 0.3024854362010956, Average Training Loss: 0.15558443948005637, Training Accuracy: 0.9609375\n",
            "Epoch 4/5, Batch Loss: 0.03762797266244888, Average Training Loss: 0.15086618080735206, Training Accuracy: 0.9625\n",
            "Epoch 4/5, Batch Loss: 0.05389045923948288, Average Training Loss: 0.14713634536243403, Training Accuracy: 0.9639423076923077\n",
            "Epoch 4/5, Batch Loss: 0.11303285509347916, Average Training Loss: 0.1458732531302505, Training Accuracy: 0.9652777777777778\n",
            "Epoch 4/5, Batch Loss: 0.08549737185239792, Average Training Loss: 0.1437169716560415, Training Accuracy: 0.9665178571428571\n",
            "Epoch 4/5, Batch Loss: 0.2443658709526062, Average Training Loss: 0.14718762335592303, Training Accuracy: 0.9633620689655172\n",
            "Epoch 4/5, Batch Loss: 0.15463325381278992, Average Training Loss: 0.14743581103781858, Training Accuracy: 0.9625\n",
            "Epoch 4/5, Batch Loss: 0.4723668098449707, Average Training Loss: 0.15791745616062994, Training Accuracy: 0.9596774193548387\n",
            "Epoch 4/5, Batch Loss: 0.03637208417057991, Average Training Loss: 0.15411916328594089, Training Accuracy: 0.9609375\n",
            "Epoch 4/5, Batch Loss: 0.5179078578948975, Average Training Loss: 0.16514306312257593, Training Accuracy: 0.9545454545454546\n",
            "Epoch 4/5, Batch Loss: 0.06735527515411377, Average Training Loss: 0.1622669517117388, Training Accuracy: 0.9558823529411765\n",
            "Epoch 4/5, Batch Loss: 0.20630663633346558, Average Training Loss: 0.16352522841521672, Training Accuracy: 0.9553571428571429\n",
            "Epoch 4/5, Batch Loss: 0.14152246713638306, Average Training Loss: 0.16291404060191578, Training Accuracy: 0.9548611111111112\n",
            "Epoch 4/5, Batch Loss: 0.1752484142780304, Average Training Loss: 0.1632474020526216, Training Accuracy: 0.9543918918918919\n",
            "Epoch 4/5, Batch Loss: 0.19206956028938293, Average Training Loss: 0.1640058799009574, Training Accuracy: 0.9539473684210527\n",
            "Epoch 4/5, Batch Loss: 0.37156376242637634, Average Training Loss: 0.16932787688878867, Training Accuracy: 0.9519230769230769\n",
            "Epoch 4/5, Batch Loss: 0.13531354069709778, Average Training Loss: 0.1684775184839964, Training Accuracy: 0.953125\n",
            "Epoch 4/5, Batch Loss: 0.2357921302318573, Average Training Loss: 0.1701193382827247, Training Accuracy: 0.9527439024390244\n",
            "Epoch 4/5, Batch Loss: 0.0751141756772995, Average Training Loss: 0.16785731060164316, Training Accuracy: 0.9538690476190477\n",
            "Epoch 4/5, Batch Loss: 0.30433139204978943, Average Training Loss: 0.17103112644927446, Training Accuracy: 0.9505813953488372\n",
            "Epoch 4/5, Batch Loss: 0.16303233802318573, Average Training Loss: 0.170849335803227, Training Accuracy: 0.9502840909090909\n",
            "Epoch 4/5, Batch Loss: 0.23168456554412842, Average Training Loss: 0.17220122979746924, Training Accuracy: 0.95\n",
            "Epoch 4/5, Batch Loss: 0.1231769472360611, Average Training Loss: 0.17113548452439514, Training Accuracy: 0.9497282608695652\n",
            "Epoch 4/5, Batch Loss: 0.07438744604587555, Average Training Loss: 0.16907701562059688, Training Accuracy: 0.9507978723404256\n",
            "Epoch 4/5, Batch Loss: 0.15880224108695984, Average Training Loss: 0.16886295781781277, Training Accuracy: 0.9518229166666666\n",
            "Epoch 4/5, Batch Loss: 0.2520783543586731, Average Training Loss: 0.17056123121660582, Training Accuracy: 0.951530612244898\n",
            "Epoch 4/5, Batch Loss: 0.24432231485843658, Average Training Loss: 0.17203645288944244, Training Accuracy: 0.95\n",
            "Epoch 4/5, Batch Loss: 0.10787175595760345, Average Training Loss: 0.17077832157705344, Training Accuracy: 0.9497549019607843\n",
            "Epoch 4/5, Batch Loss: 0.15707987546920776, Average Training Loss: 0.17051488992113334, Training Accuracy: 0.9495192307692307\n",
            "Epoch 4/5, Batch Loss: 0.1393945962190628, Average Training Loss: 0.16992771456826408, Training Accuracy: 0.9492924528301887\n",
            "Epoch 4/5, Batch Loss: 0.0269707590341568, Average Training Loss: 0.16728036353985468, Training Accuracy: 0.9502314814814815\n",
            "Epoch 4/5, Batch Loss: 0.1413245052099228, Average Training Loss: 0.16680843884294683, Training Accuracy: 0.95\n",
            "Epoch 4/5, Batch Loss: 0.26534250378608704, Average Training Loss: 0.16856797571693147, Training Accuracy: 0.9497767857142857\n",
            "Epoch 4/5, Batch Loss: 0.028403786942362785, Average Training Loss: 0.16610895486123728, Training Accuracy: 0.9506578947368421\n",
            "Epoch 4/5, Batch Loss: 0.060529448091983795, Average Training Loss: 0.16428861853762947, Training Accuracy: 0.9515086206896551\n",
            "Epoch 4/5, Batch Loss: 0.12219301611185074, Average Training Loss: 0.16357513375075186, Training Accuracy: 0.951271186440678\n",
            "Epoch 4/5, Batch Loss: 0.2423499971628189, Average Training Loss: 0.16488804814095298, Training Accuracy: 0.9489583333333333\n",
            "Epoch 4/5, Batch Loss: 0.35446226596832275, Average Training Loss: 0.16799582220369674, Training Accuracy: 0.9477459016393442\n",
            "Epoch 4/5, Batch Loss: 0.15628860890865326, Average Training Loss: 0.16780699618280895, Training Accuracy: 0.9475806451612904\n",
            "Epoch 4/5, Batch Loss: 0.1852695643901825, Average Training Loss: 0.16808417980514823, Training Accuracy: 0.9464285714285714\n",
            "Epoch 4/5, Batch Loss: 0.3020206689834595, Average Training Loss: 0.17017693744855933, Training Accuracy: 0.9462890625\n",
            "Epoch 4/5, Batch Loss: 0.09930474311113358, Average Training Loss: 0.16908659599721432, Training Accuracy: 0.9461538461538461\n",
            "Epoch 4/5, Batch Loss: 0.0602634996175766, Average Training Loss: 0.16743776120358345, Training Accuracy: 0.946969696969697\n",
            "Epoch 4/5, Batch Loss: 0.1666087955236435, Average Training Loss: 0.16742538858149478, Training Accuracy: 0.9468283582089553\n",
            "Epoch 4/5, Batch Loss: 0.09712595492601395, Average Training Loss: 0.1663915733806789, Training Accuracy: 0.9476102941176471\n",
            "Epoch 4/5, Batch Loss: 0.029951443895697594, Average Training Loss: 0.16441418019973714, Training Accuracy: 0.9483695652173914\n",
            "Epoch 4/5, Batch Loss: 0.06930842250585556, Average Training Loss: 0.16305552651839597, Training Accuracy: 0.9491071428571428\n",
            "Epoch 4/5, Batch Loss: 0.21250098943710327, Average Training Loss: 0.16375194148908198, Training Accuracy: 0.9480633802816901\n",
            "Epoch 4/5, Batch Loss: 0.05235498026013374, Average Training Loss: 0.16220476147201326, Training Accuracy: 0.9487847222222222\n",
            "Epoch 4/5, Batch Loss: 0.27394208312034607, Average Training Loss: 0.16373540971377123, Training Accuracy: 0.9477739726027398\n",
            "Epoch 4/5, Batch Loss: 0.037416428327560425, Average Training Loss: 0.16202839645179543, Training Accuracy: 0.9484797297297297\n",
            "Epoch 4/5, Batch Loss: 0.10276906192302704, Average Training Loss: 0.16123827199141186, Training Accuracy: 0.9491666666666667\n",
            "Epoch 4/5, Batch Loss: 0.18402718007564545, Average Training Loss: 0.16153812604515175, Training Accuracy: 0.9490131578947368\n",
            "Epoch 4/5, Batch Loss: 0.11533848941326141, Average Training Loss: 0.16093813076421812, Training Accuracy: 0.9488636363636364\n",
            "Epoch 4/5, Batch Loss: 0.07474743574857712, Average Training Loss: 0.1598331218537612, Training Accuracy: 0.9495192307692307\n",
            "Epoch 4/5, Batch Loss: 0.3582034111022949, Average Training Loss: 0.16234413817336288, Training Accuracy: 0.9485759493670886\n",
            "Epoch 4/5, Batch Loss: 0.06704502552747726, Average Training Loss: 0.1611528992652893, Training Accuracy: 0.94921875\n",
            "Epoch 4/5, Batch Loss: 0.0594332292675972, Average Training Loss: 0.15989710087025608, Training Accuracy: 0.9498456790123457\n",
            "Epoch 4/5, Batch Loss: 0.1233292669057846, Average Training Loss: 0.1594511516755674, Training Accuracy: 0.9496951219512195\n",
            "Epoch 4/5, Batch Loss: 0.18665625154972076, Average Training Loss: 0.1597789239632078, Training Accuracy: 0.9495481927710844\n",
            "Epoch 4/5, Batch Loss: 0.3880056142807007, Average Training Loss: 0.16249590837174938, Training Accuracy: 0.9494047619047619\n",
            "Epoch 4/5, Batch Loss: 0.17639568448066711, Average Training Loss: 0.16265943514950135, Training Accuracy: 0.9492647058823529\n",
            "Epoch 4/5, Batch Loss: 0.14606809616088867, Average Training Loss: 0.16246651260312214, Training Accuracy: 0.9491279069767442\n",
            "Epoch 4/5, Batch Loss: 0.11486537754535675, Average Training Loss: 0.16191937311969953, Training Accuracy: 0.9497126436781609\n",
            "Epoch 4/5, Batch Loss: 0.06617768853902817, Average Training Loss: 0.16083139943128283, Training Accuracy: 0.9502840909090909\n",
            "Epoch 4/5, Batch Loss: 0.031165454536676407, Average Training Loss: 0.15937447870212995, Training Accuracy: 0.9508426966292135\n",
            "Epoch 4/5, Batch Loss: 0.2091284543275833, Average Training Loss: 0.15992730065352387, Training Accuracy: 0.9506944444444444\n",
            "Epoch 4/5, Batch Loss: 0.19942618906497955, Average Training Loss: 0.16036135437233107, Training Accuracy: 0.9505494505494505\n",
            "Epoch 4/5, Batch Loss: 0.6202112436294556, Average Training Loss: 0.16535972273382155, Training Accuracy: 0.9490489130434783\n",
            "Epoch 4/5, Batch Loss: 0.04061226546764374, Average Training Loss: 0.1640183522255831, Training Accuracy: 0.9495967741935484\n",
            "Epoch 4/5, Batch Loss: 0.058971937745809555, Average Training Loss: 0.16290083717792592, Training Accuracy: 0.9501329787234043\n",
            "Epoch 4/5, Batch Loss: 0.19582705199718475, Average Training Loss: 0.16324742891286548, Training Accuracy: 0.95\n",
            "Epoch 4/5, Batch Loss: 0.1784300059080124, Average Training Loss: 0.16340558075656494, Training Accuracy: 0.9498697916666666\n",
            "Epoch 4/5, Batch Loss: 0.13199806213378906, Average Training Loss: 0.16308179190478375, Training Accuracy: 0.9497422680412371\n",
            "Epoch 4/5, Batch Loss: 0.6407437920570374, Average Training Loss: 0.16795589394715368, Training Accuracy: 0.9483418367346939\n",
            "Epoch 4/5, Batch Loss: 0.056920990347862244, Average Training Loss: 0.16683432926433256, Training Accuracy: 0.9488636363636364\n",
            "Epoch 4/5, Batch Loss: 0.17689025402069092, Average Training Loss: 0.16693488851189614, Training Accuracy: 0.948125\n",
            "Epoch 4/5, Batch Loss: 0.24951721727848053, Average Training Loss: 0.16775253533136728, Training Accuracy: 0.948019801980198\n",
            "Epoch 4/5, Batch Loss: 0.35107898712158203, Average Training Loss: 0.1695498534861733, Training Accuracy: 0.9473039215686274\n",
            "Epoch 4/5, Batch Loss: 0.5364475250244141, Average Training Loss: 0.17311196680207855, Training Accuracy: 0.9466019417475728\n",
            "Epoch 4/5, Batch Loss: 0.027167467400431633, Average Training Loss: 0.17170865430783194, Training Accuracy: 0.9471153846153846\n",
            "Epoch 4/5, Batch Loss: 0.6348971128463745, Average Training Loss: 0.17611997296057996, Training Accuracy: 0.9464285714285714\n",
            "Epoch 4/5, Batch Loss: 0.05168052017688751, Average Training Loss: 0.174946015858847, Training Accuracy: 0.9469339622641509\n",
            "Epoch 4/5, Batch Loss: 0.03848836198449135, Average Training Loss: 0.17367071068245116, Training Accuracy: 0.947429906542056\n",
            "Epoch 4/5, Batch Loss: 0.37385493516921997, Average Training Loss: 0.1755242683165879, Training Accuracy: 0.9467592592592593\n",
            "Epoch 4/5, Batch Loss: 0.09613063931465149, Average Training Loss: 0.17479588639913896, Training Accuracy: 0.9466743119266054\n",
            "Epoch 4/5, Batch Loss: 0.38980111479759216, Average Training Loss: 0.17675047938457944, Training Accuracy: 0.9460227272727273\n",
            "Epoch 4/5, Batch Loss: 0.04706248268485069, Average Training Loss: 0.17558211905395124, Training Accuracy: 0.946509009009009\n",
            "Epoch 4/5, Batch Loss: 0.1738031506538391, Average Training Loss: 0.17556623540752167, Training Accuracy: 0.9464285714285714\n",
            "Epoch 4/5, Batch Loss: 0.21736544370651245, Average Training Loss: 0.17593613990574283, Training Accuracy: 0.9463495575221239\n",
            "Epoch 4/5, Batch Loss: 0.1353679597377777, Average Training Loss: 0.1755802786761993, Training Accuracy: 0.9468201754385965\n",
            "Epoch 4/5, Batch Loss: 0.0351543202996254, Average Training Loss: 0.1743591833859682, Training Accuracy: 0.9472826086956522\n",
            "Epoch 4/5, Batch Loss: 0.07303661853075027, Average Training Loss: 0.1734857129992853, Training Accuracy: 0.9477370689655172\n",
            "Epoch 4/5, Batch Loss: 0.3014483153820038, Average Training Loss: 0.17457941045554784, Training Accuracy: 0.9476495726495726\n",
            "Epoch 4/5, Batch Loss: 0.03093632124364376, Average Training Loss: 0.17336209614019274, Training Accuracy: 0.948093220338983\n",
            "Epoch 4/5, Batch Loss: 0.21267040073871613, Average Training Loss: 0.17369241802757526, Training Accuracy: 0.9480042016806722\n",
            "Epoch 4/5, Batch Loss: 0.0735986977815628, Average Training Loss: 0.17285830369219185, Training Accuracy: 0.9484375\n",
            "Epoch 4/5, Batch Loss: 0.1631575971841812, Average Training Loss: 0.17277813256402647, Training Accuracy: 0.9478305785123967\n",
            "Epoch 4/5, Batch Loss: 0.24022828042507172, Average Training Loss: 0.17333100262846127, Training Accuracy: 0.9477459016393442\n",
            "Epoch 4/5, Batch Loss: 0.06287582218647003, Average Training Loss: 0.1724329930313719, Training Accuracy: 0.948170731707317\n",
            "Epoch 4/5, Batch Loss: 0.19130750000476837, Average Training Loss: 0.1725852067972864, Training Accuracy: 0.9480846774193549\n",
            "Epoch 4/5, Batch Loss: 0.25927144289016724, Average Training Loss: 0.17327869668602944, Training Accuracy: 0.948\n",
            "Epoch 4/5, Batch Loss: 0.03746431693434715, Average Training Loss: 0.1722008047832383, Training Accuracy: 0.9484126984126984\n",
            "Epoch 4/5, Batch Loss: 0.16763168573379517, Average Training Loss: 0.17216482746788836, Training Accuracy: 0.9483267716535433\n",
            "Epoch 4/5, Batch Loss: 0.10243381559848785, Average Training Loss: 0.17162005393765867, Training Accuracy: 0.94873046875\n",
            "Epoch 4/5, Batch Loss: 0.08886489272117615, Average Training Loss: 0.1709785410600115, Training Accuracy: 0.9491279069767442\n",
            "Epoch 4/5, Batch Loss: 0.5752278566360474, Average Training Loss: 0.17408815117982718, Training Accuracy: 0.948076923076923\n",
            "Epoch 4/5, Batch Loss: 0.0531478151679039, Average Training Loss: 0.17316494250798042, Training Accuracy: 0.9484732824427481\n",
            "Epoch 4/5, Batch Loss: 0.16631734371185303, Average Training Loss: 0.17311306675952493, Training Accuracy: 0.9483901515151515\n",
            "Epoch 4/5, Batch Loss: 0.9723773002624512, Average Training Loss: 0.18030881447507846, Training Accuracy: 0.9479659413434248\n",
            "Epoch 4/5, Average Training Loss: 0.17912257227458453, Training Accuracy: 0.9479659413434248\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.95      0.96      0.95       427\n",
            "                Educational Opportunity       0.89      0.92      0.91       451\n",
            "                         Family Support       0.98      0.99      0.99       396\n",
            "                      Financial Support       0.96      0.96      0.96       404\n",
            "                 Program Implementation       0.96      0.92      0.94       436\n",
            "\n",
            "                               accuracy                           0.95      2114\n",
            "                              macro avg       0.95      0.95      0.95      2114\n",
            "                           weighted avg       0.95      0.95      0.95      2114\n",
            "\n",
            "Epoch 4/5, Validation Loss: 33.21423905715346, Validation Accuracy: 0.7088846880907372\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.64      0.64       113\n",
            "                Educational Opportunity       0.49      0.51      0.50       100\n",
            "                         Family Support       0.91      0.93      0.92       105\n",
            "                      Financial Support       0.71      0.77      0.74        97\n",
            "                 Program Implementation       0.80      0.69      0.74       114\n",
            "\n",
            "                               accuracy                           0.71       529\n",
            "                              macro avg       0.71      0.71      0.71       529\n",
            "                           weighted avg       0.71      0.71      0.71       529\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.056890279054641724, Average Training Loss: 0.056890279054641724, Training Accuracy: 1.0\n",
            "Epoch 5/5, Batch Loss: 0.21517474949359894, Average Training Loss: 0.13603251427412033, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.0900893434882164, Average Training Loss: 0.12071812401215236, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/5, Batch Loss: 0.027935337275266647, Average Training Loss: 0.09752242732793093, Training Accuracy: 0.984375\n",
            "Epoch 5/5, Batch Loss: 0.06198102608323097, Average Training Loss: 0.09041414707899094, Training Accuracy: 0.9875\n",
            "Epoch 5/5, Batch Loss: 0.03868969902396202, Average Training Loss: 0.08179340573648612, Training Accuracy: 0.9895833333333334\n",
            "Epoch 5/5, Batch Loss: 0.19853907823562622, Average Training Loss: 0.09847135895064899, Training Accuracy: 0.9732142857142857\n",
            "Epoch 5/5, Batch Loss: 0.08873168379068375, Average Training Loss: 0.09725389955565333, Training Accuracy: 0.9765625\n",
            "Epoch 5/5, Batch Loss: 0.02306094951927662, Average Training Loss: 0.08901023844050036, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/5, Batch Loss: 0.14920452237129211, Average Training Loss: 0.09502966683357954, Training Accuracy: 0.98125\n",
            "Epoch 5/5, Batch Loss: 0.16328422725200653, Average Training Loss: 0.10123462687161836, Training Accuracy: 0.9772727272727273\n",
            "Epoch 5/5, Batch Loss: 0.501389741897583, Average Training Loss: 0.1345808864571154, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.07179005444049835, Average Training Loss: 0.1297508224558372, Training Accuracy: 0.9711538461538461\n",
            "Epoch 5/5, Batch Loss: 0.09838323295116425, Average Training Loss: 0.12751028034836054, Training Accuracy: 0.9732142857142857\n",
            "Epoch 5/5, Batch Loss: 0.10227683186531067, Average Training Loss: 0.12582805044949055, Training Accuracy: 0.9708333333333333\n",
            "Epoch 5/5, Batch Loss: 0.35864052176475525, Average Training Loss: 0.1403788299066946, Training Accuracy: 0.96484375\n",
            "Epoch 5/5, Batch Loss: 0.044776905328035355, Average Training Loss: 0.1347551872844205, Training Accuracy: 0.9669117647058824\n",
            "Epoch 5/5, Batch Loss: 0.0748308077454567, Average Training Loss: 0.1314260550878114, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.03924538567662239, Average Training Loss: 0.12657444090827516, Training Accuracy: 0.9703947368421053\n",
            "Epoch 5/5, Batch Loss: 0.09517470002174377, Average Training Loss: 0.1250044538639486, Training Accuracy: 0.971875\n",
            "Epoch 5/5, Batch Loss: 0.1576090008020401, Average Training Loss: 0.12655705133719103, Training Accuracy: 0.9702380952380952\n",
            "Epoch 5/5, Batch Loss: 0.055487774312496185, Average Training Loss: 0.12332662965425036, Training Accuracy: 0.9715909090909091\n",
            "Epoch 5/5, Batch Loss: 0.0611792616546154, Average Training Loss: 0.12062457017600536, Training Accuracy: 0.9728260869565217\n",
            "Epoch 5/5, Batch Loss: 0.3163220286369324, Average Training Loss: 0.12877863094521066, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.046506986021995544, Average Training Loss: 0.12548776514828205, Training Accuracy: 0.97\n",
            "Epoch 5/5, Batch Loss: 0.1241336315870285, Average Training Loss: 0.12543568308823383, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.1517823338508606, Average Training Loss: 0.12641148496833113, Training Accuracy: 0.9675925925925926\n",
            "Epoch 5/5, Batch Loss: 0.06987553089857101, Average Training Loss: 0.12439234375155397, Training Accuracy: 0.96875\n",
            "Epoch 5/5, Batch Loss: 0.025528419762849808, Average Training Loss: 0.12098324292435728, Training Accuracy: 0.9698275862068966\n",
            "Epoch 5/5, Batch Loss: 0.102786123752594, Average Training Loss: 0.12037667228529851, Training Accuracy: 0.9708333333333333\n",
            "Epoch 5/5, Batch Loss: 0.05240222066640854, Average Training Loss: 0.11818394803952786, Training Accuracy: 0.9717741935483871\n",
            "Epoch 5/5, Batch Loss: 0.06422007083892822, Average Training Loss: 0.11649757687700912, Training Accuracy: 0.97265625\n",
            "Epoch 5/5, Batch Loss: 0.23520810902118683, Average Training Loss: 0.120094865729863, Training Accuracy: 0.9696969696969697\n",
            "Epoch 5/5, Batch Loss: 0.021024953573942184, Average Training Loss: 0.11718104478410062, Training Accuracy: 0.9705882352941176\n",
            "Epoch 5/5, Batch Loss: 0.039381787180900574, Average Training Loss: 0.11495820885258061, Training Accuracy: 0.9714285714285714\n",
            "Epoch 5/5, Batch Loss: 0.059117499738931656, Average Training Loss: 0.11340707804386814, Training Accuracy: 0.9722222222222222\n",
            "Epoch 5/5, Batch Loss: 0.04810034856200218, Average Training Loss: 0.11164203130111501, Training Accuracy: 0.972972972972973\n",
            "Epoch 5/5, Batch Loss: 0.022673528641462326, Average Training Loss: 0.10930075491533468, Training Accuracy: 0.9736842105263158\n",
            "Epoch 5/5, Batch Loss: 0.08830051869153976, Average Training Loss: 0.10876228731985275, Training Accuracy: 0.9727564102564102\n",
            "Epoch 5/5, Batch Loss: 0.05702097713947296, Average Training Loss: 0.10746875456534326, Training Accuracy: 0.9734375\n",
            "Epoch 5/5, Batch Loss: 0.046519722789525986, Average Training Loss: 0.10598219281471358, Training Accuracy: 0.9740853658536586\n",
            "Epoch 5/5, Batch Loss: 0.38077375292778015, Average Training Loss: 0.11252484900788182, Training Accuracy: 0.9717261904761905\n",
            "Epoch 5/5, Batch Loss: 0.03344053402543068, Average Training Loss: 0.11068567889201086, Training Accuracy: 0.9723837209302325\n",
            "Epoch 5/5, Batch Loss: 0.06440795958042145, Average Training Loss: 0.1096339125440202, Training Accuracy: 0.9730113636363636\n",
            "Epoch 5/5, Batch Loss: 0.10014015436172485, Average Training Loss: 0.10942294013996919, Training Accuracy: 0.9722222222222222\n",
            "Epoch 5/5, Batch Loss: 0.04851708188652992, Average Training Loss: 0.1080988997431553, Training Accuracy: 0.9728260869565217\n",
            "Epoch 5/5, Batch Loss: 0.023442592471837997, Average Training Loss: 0.10629770171610599, Training Accuracy: 0.973404255319149\n",
            "Epoch 5/5, Batch Loss: 0.023752175271511078, Average Training Loss: 0.10457800324851026, Training Accuracy: 0.9739583333333334\n",
            "Epoch 5/5, Batch Loss: 0.04492935910820961, Average Training Loss: 0.10336068398034086, Training Accuracy: 0.9744897959183674\n",
            "Epoch 5/5, Batch Loss: 0.03588666021823883, Average Training Loss: 0.10201120350509882, Training Accuracy: 0.975\n",
            "Epoch 5/5, Batch Loss: 0.13348335027694702, Average Training Loss: 0.10262830442219388, Training Accuracy: 0.9754901960784313\n",
            "Epoch 5/5, Batch Loss: 0.13748516142368317, Average Training Loss: 0.10329862859529945, Training Accuracy: 0.9759615384615384\n",
            "Epoch 5/5, Batch Loss: 0.03606368973851204, Average Training Loss: 0.1020300448432846, Training Accuracy: 0.9764150943396226\n",
            "Epoch 5/5, Batch Loss: 0.03274991735816002, Average Training Loss: 0.10074707951948599, Training Accuracy: 0.9768518518518519\n",
            "Epoch 5/5, Batch Loss: 0.03178001195192337, Average Training Loss: 0.09949313283643939, Training Accuracy: 0.9772727272727273\n",
            "Epoch 5/5, Batch Loss: 0.030306026339530945, Average Training Loss: 0.09825764879185174, Training Accuracy: 0.9776785714285714\n",
            "Epoch 5/5, Batch Loss: 0.05274178087711334, Average Training Loss: 0.09745912479334756, Training Accuracy: 0.9780701754385965\n",
            "Epoch 5/5, Batch Loss: 0.09059619903564453, Average Training Loss: 0.09734079848718026, Training Accuracy: 0.978448275862069\n",
            "Epoch 5/5, Batch Loss: 0.041776470839977264, Average Training Loss: 0.09639903022197344, Training Accuracy: 0.9788135593220338\n",
            "Epoch 5/5, Batch Loss: 0.042929813265800476, Average Training Loss: 0.09550787660603723, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/5, Batch Loss: 0.18717291951179504, Average Training Loss: 0.09701058222744309, Training Accuracy: 0.9774590163934426\n",
            "Epoch 5/5, Batch Loss: 0.06367833912372589, Average Training Loss: 0.09647296540318959, Training Accuracy: 0.9778225806451613\n",
            "Epoch 5/5, Batch Loss: 0.10037356615066528, Average Training Loss: 0.09653487970076856, Training Accuracy: 0.9771825396825397\n",
            "Epoch 5/5, Batch Loss: 0.2519572377204895, Average Training Loss: 0.0989633540448267, Training Accuracy: 0.9755859375\n",
            "Epoch 5/5, Batch Loss: 0.023049764335155487, Average Training Loss: 0.09779545266467791, Training Accuracy: 0.9759615384615384\n",
            "Epoch 5/5, Batch Loss: 0.03721769526600838, Average Training Loss: 0.09687760785560716, Training Accuracy: 0.9763257575757576\n",
            "Epoch 5/5, Batch Loss: 0.05855977535247803, Average Training Loss: 0.09630569990779926, Training Accuracy: 0.976679104477612\n",
            "Epoch 5/5, Batch Loss: 0.10765737295150757, Average Training Loss: 0.0964726362760891, Training Accuracy: 0.9770220588235294\n",
            "Epoch 5/5, Batch Loss: 0.031142547726631165, Average Training Loss: 0.09552582339856072, Training Accuracy: 0.9773550724637681\n",
            "Epoch 5/5, Batch Loss: 0.05798906460404396, Average Training Loss: 0.09498958398721048, Training Accuracy: 0.9776785714285714\n",
            "Epoch 5/5, Batch Loss: 0.035749636590480804, Average Training Loss: 0.09415521853091852, Training Accuracy: 0.9779929577464789\n",
            "Epoch 5/5, Batch Loss: 0.04095873609185219, Average Training Loss: 0.0934163784970426, Training Accuracy: 0.9782986111111112\n",
            "Epoch 5/5, Batch Loss: 0.11597327888011932, Average Training Loss: 0.0937253771324272, Training Accuracy: 0.9777397260273972\n",
            "Epoch 5/5, Batch Loss: 0.03557802736759186, Average Training Loss: 0.0929396021356051, Training Accuracy: 0.9780405405405406\n",
            "Epoch 5/5, Batch Loss: 0.08446694165468216, Average Training Loss: 0.0928266333291928, Training Accuracy: 0.9783333333333334\n",
            "Epoch 5/5, Batch Loss: 0.036667101085186005, Average Training Loss: 0.09208769211545587, Training Accuracy: 0.9786184210526315\n",
            "Epoch 5/5, Batch Loss: 0.12484300881624222, Average Training Loss: 0.0925130858388427, Training Accuracy: 0.9780844155844156\n",
            "Epoch 5/5, Batch Loss: 0.11211475729942322, Average Training Loss: 0.09276438931910655, Training Accuracy: 0.9775641025641025\n",
            "Epoch 5/5, Batch Loss: 0.01968938671052456, Average Training Loss: 0.09183938928608652, Training Accuracy: 0.9778481012658228\n",
            "Epoch 5/5, Batch Loss: 0.040118180215358734, Average Training Loss: 0.09119287417270243, Training Accuracy: 0.978125\n",
            "Epoch 5/5, Batch Loss: 0.05980640649795532, Average Training Loss: 0.09080538691745864, Training Accuracy: 0.9783950617283951\n",
            "Epoch 5/5, Batch Loss: 0.05096764862537384, Average Training Loss: 0.0903195608407259, Training Accuracy: 0.9786585365853658\n",
            "Epoch 5/5, Batch Loss: 0.2742552161216736, Average Training Loss: 0.09253565307302647, Training Accuracy: 0.9781626506024096\n",
            "Epoch 5/5, Batch Loss: 0.07565096020698547, Average Training Loss: 0.09233464482462123, Training Accuracy: 0.9784226190476191\n",
            "Epoch 5/5, Batch Loss: 0.09385942667722702, Average Training Loss: 0.09235258343465189, Training Accuracy: 0.9786764705882353\n",
            "Epoch 5/5, Batch Loss: 0.21943478286266327, Average Training Loss: 0.09383028342800084, Training Accuracy: 0.9774709302325582\n",
            "Epoch 5/5, Batch Loss: 0.14113971590995789, Average Training Loss: 0.09437407000825324, Training Accuracy: 0.9770114942528736\n",
            "Epoch 5/5, Batch Loss: 0.025721007958054543, Average Training Loss: 0.0935939215758646, Training Accuracy: 0.9772727272727273\n",
            "Epoch 5/5, Batch Loss: 0.062467142939567566, Average Training Loss: 0.09324418249006351, Training Accuracy: 0.9775280898876404\n",
            "Epoch 5/5, Batch Loss: 0.034803833812475204, Average Training Loss: 0.09259484528253475, Training Accuracy: 0.9777777777777777\n",
            "Epoch 5/5, Batch Loss: 0.12375418841838837, Average Training Loss: 0.09293725564666502, Training Accuracy: 0.9773351648351648\n",
            "Epoch 5/5, Batch Loss: 0.0380401648581028, Average Training Loss: 0.09234054813809368, Training Accuracy: 0.9775815217391305\n",
            "Epoch 5/5, Batch Loss: 0.09694568812847137, Average Training Loss: 0.09239006577239882, Training Accuracy: 0.9778225806451613\n",
            "Epoch 5/5, Batch Loss: 0.03449399396777153, Average Training Loss: 0.0917741501149028, Training Accuracy: 0.9780585106382979\n",
            "Epoch 5/5, Batch Loss: 0.05905044078826904, Average Training Loss: 0.0914296900167277, Training Accuracy: 0.9782894736842105\n",
            "Epoch 5/5, Batch Loss: 0.10040152072906494, Average Training Loss: 0.09152314658664788, Training Accuracy: 0.978515625\n",
            "Epoch 5/5, Batch Loss: 0.04616883024573326, Average Training Loss: 0.09105557631509206, Training Accuracy: 0.9787371134020618\n",
            "Epoch 5/5, Batch Loss: 0.03375693038105965, Average Training Loss: 0.0904708962545407, Training Accuracy: 0.9789540816326531\n",
            "Epoch 5/5, Batch Loss: 0.1400337517261505, Average Training Loss: 0.09097153115829434, Training Accuracy: 0.9785353535353535\n",
            "Epoch 5/5, Batch Loss: 0.1270093470811844, Average Training Loss: 0.09133190931752325, Training Accuracy: 0.978125\n",
            "Epoch 5/5, Batch Loss: 0.11321261525154114, Average Training Loss: 0.0915485499703353, Training Accuracy: 0.9777227722772277\n",
            "Epoch 5/5, Batch Loss: 0.047486476600170135, Average Training Loss: 0.09111656885886309, Training Accuracy: 0.9779411764705882\n",
            "Epoch 5/5, Batch Loss: 0.05236882343888283, Average Training Loss: 0.09074037715575649, Training Accuracy: 0.9781553398058253\n",
            "Epoch 5/5, Batch Loss: 0.06497510522603989, Average Training Loss: 0.09049263415643229, Training Accuracy: 0.9783653846153846\n",
            "Epoch 5/5, Batch Loss: 0.022495504468679428, Average Training Loss: 0.08984504244512036, Training Accuracy: 0.9785714285714285\n",
            "Epoch 5/5, Batch Loss: 0.06957953423261642, Average Training Loss: 0.08965385840537976, Training Accuracy: 0.9787735849056604\n",
            "Epoch 5/5, Batch Loss: 0.031163305044174194, Average Training Loss: 0.08910721771976102, Training Accuracy: 0.9789719626168224\n",
            "Epoch 5/5, Batch Loss: 0.0674976110458374, Average Training Loss: 0.08890712876907653, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/5, Batch Loss: 0.40592795610427856, Average Training Loss: 0.09181557672628023, Training Accuracy: 0.9782110091743119\n",
            "Epoch 5/5, Batch Loss: 0.028279773890972137, Average Training Loss: 0.09123797851868651, Training Accuracy: 0.9784090909090909\n",
            "Epoch 5/5, Batch Loss: 0.08013343065977097, Average Training Loss: 0.09113793754698457, Training Accuracy: 0.9780405405405406\n",
            "Epoch 5/5, Batch Loss: 0.047265246510505676, Average Training Loss: 0.09074621709130172, Training Accuracy: 0.9782366071428571\n",
            "Epoch 5/5, Batch Loss: 0.029255220666527748, Average Training Loss: 0.09020204898134797, Training Accuracy: 0.978429203539823\n",
            "Epoch 5/5, Batch Loss: 0.2926247715950012, Average Training Loss: 0.09197768689901159, Training Accuracy: 0.9780701754385965\n",
            "Epoch 5/5, Batch Loss: 0.2820815443992615, Average Training Loss: 0.0936307639207529, Training Accuracy: 0.9777173913043479\n",
            "Epoch 5/5, Batch Loss: 0.07048450410366058, Average Training Loss: 0.09343122719819176, Training Accuracy: 0.9773706896551724\n",
            "Epoch 5/5, Batch Loss: 0.04940943792462349, Average Training Loss: 0.09305497258901596, Training Accuracy: 0.9775641025641025\n",
            "Epoch 5/5, Batch Loss: 0.05734855309128761, Average Training Loss: 0.09275237581361148, Training Accuracy: 0.9777542372881356\n",
            "Epoch 5/5, Batch Loss: 0.051028504967689514, Average Training Loss: 0.09240175505020037, Training Accuracy: 0.9779411764705882\n",
            "Epoch 5/5, Batch Loss: 0.43756020069122314, Average Training Loss: 0.09527807543054223, Training Accuracy: 0.9770833333333333\n",
            "Epoch 5/5, Batch Loss: 0.030851738527417183, Average Training Loss: 0.09474562636522715, Training Accuracy: 0.9772727272727273\n",
            "Epoch 5/5, Batch Loss: 0.025465121492743492, Average Training Loss: 0.09417775337446908, Training Accuracy: 0.9774590163934426\n",
            "Epoch 5/5, Batch Loss: 0.3553782105445862, Average Training Loss: 0.09630133432707166, Training Accuracy: 0.9766260162601627\n",
            "Epoch 5/5, Batch Loss: 0.3403196334838867, Average Training Loss: 0.09826922383640081, Training Accuracy: 0.9758064516129032\n",
            "Epoch 5/5, Batch Loss: 0.04251110926270485, Average Training Loss: 0.09782315891981125, Training Accuracy: 0.976\n",
            "Epoch 5/5, Batch Loss: 0.0807996317744255, Average Training Loss: 0.09768805156151454, Training Accuracy: 0.9756944444444444\n",
            "Epoch 5/5, Batch Loss: 0.03413432836532593, Average Training Loss: 0.09718762854422171, Training Accuracy: 0.9758858267716536\n",
            "Epoch 5/5, Batch Loss: 0.07673102617263794, Average Training Loss: 0.09702781133819371, Training Accuracy: 0.97607421875\n",
            "Epoch 5/5, Batch Loss: 0.04249878227710724, Average Training Loss: 0.09660510568655739, Training Accuracy: 0.9762596899224806\n",
            "Epoch 5/5, Batch Loss: 0.03992626816034317, Average Training Loss: 0.09616911462866343, Training Accuracy: 0.9764423076923077\n",
            "Epoch 5/5, Batch Loss: 0.04944920912384987, Average Training Loss: 0.09581247412862669, Training Accuracy: 0.9766221374045801\n",
            "Epoch 5/5, Batch Loss: 0.04775065928697586, Average Training Loss: 0.09544836947073539, Training Accuracy: 0.9767992424242424\n",
            "Epoch 5/5, Batch Loss: 0.020931757986545563, Average Training Loss: 0.09551649217122889, Training Accuracy: 0.9768211920529801\n",
            "Epoch 5/5, Average Training Loss: 0.09488809419641818, Training Accuracy: 0.9768211920529801\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.98      0.99      0.99       427\n",
            "                Educational Opportunity       0.95      0.96      0.96       451\n",
            "                         Family Support       0.99      1.00      0.99       396\n",
            "                      Financial Support       0.99      0.99      0.99       404\n",
            "                 Program Implementation       0.97      0.95      0.96       436\n",
            "\n",
            "                               accuracy                           0.98      2114\n",
            "                              macro avg       0.98      0.98      0.98      2114\n",
            "                           weighted avg       0.98      0.98      0.98      2114\n",
            "\n",
            "Epoch 5/5, Validation Loss: 33.60371542349458, Validation Accuracy: 0.7032136105860114\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.62      0.66      0.64       113\n",
            "                Educational Opportunity       0.45      0.53      0.49       100\n",
            "                         Family Support       0.90      0.91      0.91       105\n",
            "                      Financial Support       0.76      0.73      0.74        97\n",
            "                 Program Implementation       0.85      0.68      0.75       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.72      0.70      0.71       529\n",
            "                           weighted avg       0.72      0.70      0.71       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Testing-Dataset-Experience.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted Labels'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_labels = label_encoder.transform(test_df['True Labels'])\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Display test accuracy\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Calculate other metrics (precision, recall, F1 score, confusion matrix)\n",
        "test_classification_report = classification_report(test_labels, test_predictions, target_names=label_encoder.classes_)\n",
        "test_confusion_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Display other metrics\n",
        "print('Test Classification Report:')\n",
        "print(test_classification_report)\n",
        "print('Test Confusion Matrix:')\n",
        "print(test_confusion_matrix)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPOATjjSDheO",
        "outputId": "809c3325-0f0a-4101-eaa7-48f07aed0099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-0f7a71b74230>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.693034238488784\n",
            "Test Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.78      0.70       178\n",
            "                Educational Opportunity       0.53      0.59      0.56       188\n",
            "                         Family Support       0.90      0.94      0.92       100\n",
            "                      Financial Support       0.71      0.77      0.74       150\n",
            "                 Program Implementation       0.83      0.56      0.67       231\n",
            "\n",
            "                               accuracy                           0.69       847\n",
            "                              macro avg       0.72      0.73      0.72       847\n",
            "                           weighted avg       0.71      0.69      0.69       847\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[139  23   2   6   8]\n",
            " [ 39 110   5  20  14]\n",
            " [  1   2  94   3   0]\n",
            " [ 12  17   2 115   4]\n",
            " [ 27  56   1  18 129]]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Testing-Dataset-Experience.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted Labels'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_labels = label_encoder.transform(test_df['True Labels'])\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Display test accuracy\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Calculate other metrics (precision, recall, F1 score, confusion matrix)\n",
        "test_classification_report = classification_report(test_labels, test_predictions, target_names=label_encoder.classes_)\n",
        "test_confusion_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Display other metrics\n",
        "print('Test Classification Report:')\n",
        "print(test_classification_report)\n",
        "print('Test Confusion Matrix:')\n",
        "print(test_confusion_matrix)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFIUr-ad3Cpf",
        "outputId": "7b09f0e7-063c-4c9c-ad8e-51175e4e5022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-43c2a672f237>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6883116883116883\n",
            "Test Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.78      0.70       178\n",
            "                Educational Opportunity       0.53      0.58      0.55       188\n",
            "                         Family Support       0.90      0.94      0.92       100\n",
            "                      Financial Support       0.74      0.70      0.72       150\n",
            "                 Program Implementation       0.77      0.59      0.67       231\n",
            "\n",
            "                               accuracy                           0.69       847\n",
            "                              macro avg       0.72      0.72      0.71       847\n",
            "                           weighted avg       0.70      0.69      0.69       847\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[138  23   2   4  11]\n",
            " [ 40 109   5  15  19]\n",
            " [  1   2  94   3   0]\n",
            " [ 14  19   2 105  10]\n",
            " [ 24  54   2  14 137]]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Handle NaN values in the 'Label' column\n",
        "df['Label'].fillna('default_label', inplace=True)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and validation data\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIUQZmmVUMTx",
        "outputId": "05e48a24-f3a3-4ded-8638-85f4781f837d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-37-37758020bac2>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.6358721256256104, Average Training Loss: 1.6358721256256104, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.8207361698150635, Average Training Loss: 1.728304147720337, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.5434253215789795, Average Training Loss: 1.6666778723398845, Training Accuracy: 0.1875\n",
            "Epoch 1/5, Batch Loss: 1.8463597297668457, Average Training Loss: 1.7115983366966248, Training Accuracy: 0.15625\n",
            "Epoch 1/5, Batch Loss: 1.776472568511963, Average Training Loss: 1.7245731830596924, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.559312343597412, Average Training Loss: 1.697029709815979, Training Accuracy: 0.13541666666666666\n",
            "Epoch 1/5, Batch Loss: 1.5095734596252441, Average Training Loss: 1.6702502455030168, Training Accuracy: 0.15178571428571427\n",
            "Epoch 1/5, Batch Loss: 1.7437807321548462, Average Training Loss: 1.6794415563344955, Training Accuracy: 0.15625\n",
            "Epoch 1/5, Batch Loss: 1.626349687576294, Average Training Loss: 1.6735424598058064, Training Accuracy: 0.14583333333333334\n",
            "Epoch 1/5, Batch Loss: 1.6626291275024414, Average Training Loss: 1.67245112657547, Training Accuracy: 0.15625\n",
            "Epoch 1/5, Batch Loss: 1.6358721256256104, Average Training Loss: 1.6691257628527554, Training Accuracy: 0.14772727272727273\n",
            "Epoch 1/5, Batch Loss: 1.589127540588379, Average Training Loss: 1.662459244330724, Training Accuracy: 0.15104166666666666\n",
            "Epoch 1/5, Batch Loss: 1.6126420497894287, Average Training Loss: 1.6586271524429321, Training Accuracy: 0.15384615384615385\n",
            "Epoch 1/5, Batch Loss: 1.654939889907837, Average Training Loss: 1.6583637765475683, Training Accuracy: 0.16071428571428573\n",
            "Epoch 1/5, Batch Loss: 1.609538197517395, Average Training Loss: 1.6551087379455567, Training Accuracy: 0.1625\n",
            "Epoch 1/5, Batch Loss: 1.537485957145691, Average Training Loss: 1.647757314145565, Training Accuracy: 0.1640625\n",
            "Epoch 1/5, Batch Loss: 1.5296766757965088, Average Training Loss: 1.6408113942426794, Training Accuracy: 0.1875\n",
            "Epoch 1/5, Batch Loss: 1.5554561614990234, Average Training Loss: 1.6360694368680317, Training Accuracy: 0.1909722222222222\n",
            "Epoch 1/5, Batch Loss: 1.5832626819610596, Average Training Loss: 1.6332901339781911, Training Accuracy: 0.19736842105263158\n",
            "Epoch 1/5, Batch Loss: 1.616876244544983, Average Training Loss: 1.6324694395065307, Training Accuracy: 0.2\n",
            "Epoch 1/5, Batch Loss: 1.5948147773742676, Average Training Loss: 1.6306763603573753, Training Accuracy: 0.19940476190476192\n",
            "Epoch 1/5, Batch Loss: 1.6415098905563354, Average Training Loss: 1.6311687935482373, Training Accuracy: 0.19318181818181818\n",
            "Epoch 1/5, Batch Loss: 1.5807411670684814, Average Training Loss: 1.6289762880491174, Training Accuracy: 0.19021739130434784\n",
            "Epoch 1/5, Batch Loss: 1.5264931917190552, Average Training Loss: 1.6247061590353649, Training Accuracy: 0.20052083333333334\n",
            "Epoch 1/5, Batch Loss: 1.6400866508483887, Average Training Loss: 1.6253213787078857, Training Accuracy: 0.2\n",
            "Epoch 1/5, Batch Loss: 1.532403588294983, Average Training Loss: 1.6217476175381587, Training Accuracy: 0.2091346153846154\n",
            "Epoch 1/5, Batch Loss: 1.5283182859420776, Average Training Loss: 1.618287271923489, Training Accuracy: 0.21296296296296297\n",
            "Epoch 1/5, Batch Loss: 1.6417806148529053, Average Training Loss: 1.619126319885254, Training Accuracy: 0.21651785714285715\n",
            "Epoch 1/5, Batch Loss: 1.5945284366607666, Average Training Loss: 1.618278117015444, Training Accuracy: 0.21982758620689655\n",
            "Epoch 1/5, Batch Loss: 1.5507688522338867, Average Training Loss: 1.6160278081893922, Training Accuracy: 0.225\n",
            "Epoch 1/5, Batch Loss: 1.5893231630325317, Average Training Loss: 1.6151663680230417, Training Accuracy: 0.22782258064516128\n",
            "Epoch 1/5, Batch Loss: 1.532884955406189, Average Training Loss: 1.612595073878765, Training Accuracy: 0.234375\n",
            "Epoch 1/5, Batch Loss: 1.496142029762268, Average Training Loss: 1.6090661937540227, Training Accuracy: 0.23863636363636365\n",
            "Epoch 1/5, Batch Loss: 1.431443214416504, Average Training Loss: 1.60384198847939, Training Accuracy: 0.24816176470588236\n",
            "Epoch 1/5, Batch Loss: 1.5935707092285156, Average Training Loss: 1.6035485233579363, Training Accuracy: 0.2517857142857143\n",
            "Epoch 1/5, Batch Loss: 1.5060851573944092, Average Training Loss: 1.6008412076367273, Training Accuracy: 0.2534722222222222\n",
            "Epoch 1/5, Batch Loss: 1.5630578994750977, Average Training Loss: 1.5998200371458724, Training Accuracy: 0.25506756756756754\n",
            "Epoch 1/5, Batch Loss: 1.453751564025879, Average Training Loss: 1.595976129958504, Training Accuracy: 0.2565789473684211\n",
            "Epoch 1/5, Batch Loss: 1.5317596197128296, Average Training Loss: 1.5943295527727177, Training Accuracy: 0.2548076923076923\n",
            "Epoch 1/5, Batch Loss: 1.492632269859314, Average Training Loss: 1.5917871206998826, Training Accuracy: 0.2578125\n",
            "Epoch 1/5, Batch Loss: 1.4753022193908691, Average Training Loss: 1.5889460255460042, Training Accuracy: 0.2606707317073171\n",
            "Epoch 1/5, Batch Loss: 1.5319586992263794, Average Training Loss: 1.587589184443156, Training Accuracy: 0.2619047619047619\n",
            "Epoch 1/5, Batch Loss: 1.6510016918182373, Average Training Loss: 1.589063893916995, Training Accuracy: 0.2601744186046512\n",
            "Epoch 1/5, Batch Loss: 1.5130643844604492, Average Training Loss: 1.5873366323384372, Training Accuracy: 0.2627840909090909\n",
            "Epoch 1/5, Batch Loss: 1.643648386001587, Average Training Loss: 1.5885880046420626, Training Accuracy: 0.25972222222222224\n",
            "Epoch 1/5, Batch Loss: 1.3346666097640991, Average Training Loss: 1.5830679743186287, Training Accuracy: 0.266304347826087\n",
            "Epoch 1/5, Batch Loss: 1.436827301979065, Average Training Loss: 1.5799564706518294, Training Accuracy: 0.26728723404255317\n",
            "Epoch 1/5, Batch Loss: 1.4176948070526123, Average Training Loss: 1.5765760193268459, Training Accuracy: 0.2708333333333333\n",
            "Epoch 1/5, Batch Loss: 1.4352214336395264, Average Training Loss: 1.5736912318638392, Training Accuracy: 0.27168367346938777\n",
            "Epoch 1/5, Batch Loss: 1.4259366989135742, Average Training Loss: 1.570736141204834, Training Accuracy: 0.27625\n",
            "Epoch 1/5, Batch Loss: 1.571099877357483, Average Training Loss: 1.5707432732862585, Training Accuracy: 0.27818627450980393\n",
            "Epoch 1/5, Batch Loss: 1.5136513710021973, Average Training Loss: 1.569645352088488, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.5113316774368286, Average Training Loss: 1.5685450940761927, Training Accuracy: 0.2818396226415094\n",
            "Epoch 1/5, Batch Loss: 1.4647198915481567, Average Training Loss: 1.5666224051404882, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.4324896335601807, Average Training Loss: 1.5641836274753917, Training Accuracy: 0.2852272727272727\n",
            "Epoch 1/5, Batch Loss: 1.4308770895004272, Average Training Loss: 1.5618031535829817, Training Accuracy: 0.28794642857142855\n",
            "Epoch 1/5, Batch Loss: 1.587586760520935, Average Training Loss: 1.5622554975643492, Training Accuracy: 0.28728070175438597\n",
            "Epoch 1/5, Batch Loss: 1.4236161708831787, Average Training Loss: 1.5598651643457084, Training Accuracy: 0.28987068965517243\n",
            "Epoch 1/5, Batch Loss: 1.5508575439453125, Average Training Loss: 1.5597124928134982, Training Accuracy: 0.2891949152542373\n",
            "Epoch 1/5, Batch Loss: 1.4583923816680908, Average Training Loss: 1.5580238242944082, Training Accuracy: 0.28958333333333336\n",
            "Epoch 1/5, Batch Loss: 1.4302830696105957, Average Training Loss: 1.5559297135618866, Training Accuracy: 0.29098360655737704\n",
            "Epoch 1/5, Batch Loss: 1.4991600513458252, Average Training Loss: 1.5550140738487244, Training Accuracy: 0.2923387096774194\n",
            "Epoch 1/5, Batch Loss: 1.5039458274841309, Average Training Loss: 1.554203466763572, Training Accuracy: 0.29464285714285715\n",
            "Epoch 1/5, Batch Loss: 1.3599647283554077, Average Training Loss: 1.5511684864759445, Training Accuracy: 0.2978515625\n",
            "Epoch 1/5, Batch Loss: 1.378525733947754, Average Training Loss: 1.548512444129357, Training Accuracy: 0.3019230769230769\n",
            "Epoch 1/5, Batch Loss: 1.4135043621063232, Average Training Loss: 1.546466867129008, Training Accuracy: 0.3039772727272727\n",
            "Epoch 1/5, Batch Loss: 1.4707975387573242, Average Training Loss: 1.5453374741682366, Training Accuracy: 0.3041044776119403\n",
            "Epoch 1/5, Batch Loss: 1.3467299938201904, Average Training Loss: 1.5424167759278242, Training Accuracy: 0.3069852941176471\n",
            "Epoch 1/5, Batch Loss: 1.2936162948608398, Average Training Loss: 1.5388109718543896, Training Accuracy: 0.30978260869565216\n",
            "Epoch 1/5, Batch Loss: 1.3640446662902832, Average Training Loss: 1.5363143103463308, Training Accuracy: 0.31339285714285714\n",
            "Epoch 1/5, Batch Loss: 1.430678367614746, Average Training Loss: 1.5348264801670128, Training Accuracy: 0.31514084507042256\n",
            "Epoch 1/5, Batch Loss: 1.532859206199646, Average Training Loss: 1.5347991569174662, Training Accuracy: 0.3159722222222222\n",
            "Epoch 1/5, Batch Loss: 1.3853968381881714, Average Training Loss: 1.5327525498115853, Training Accuracy: 0.3184931506849315\n",
            "Epoch 1/5, Batch Loss: 1.335032343864441, Average Training Loss: 1.530080655136624, Training Accuracy: 0.32094594594594594\n",
            "Epoch 1/5, Batch Loss: 1.328770637512207, Average Training Loss: 1.5273965215682983, Training Accuracy: 0.325\n",
            "Epoch 1/5, Batch Loss: 1.5135036706924438, Average Training Loss: 1.5272137208988792, Training Accuracy: 0.32401315789473684\n",
            "Epoch 1/5, Batch Loss: 1.319326639175415, Average Training Loss: 1.5245138886687044, Training Accuracy: 0.3246753246753247\n",
            "Epoch 1/5, Batch Loss: 1.3387144804000854, Average Training Loss: 1.5221318449729528, Training Accuracy: 0.3261217948717949\n",
            "Epoch 1/5, Batch Loss: 1.30405592918396, Average Training Loss: 1.5193713903427124, Training Accuracy: 0.3275316455696203\n",
            "Epoch 1/5, Batch Loss: 1.4439481496810913, Average Training Loss: 1.5184285998344422, Training Accuracy: 0.328125\n",
            "Epoch 1/5, Batch Loss: 1.2226574420928955, Average Training Loss: 1.5147771040598552, Training Accuracy: 0.3317901234567901\n",
            "Epoch 1/5, Batch Loss: 1.1503112316131592, Average Training Loss: 1.5103323982983101, Training Accuracy: 0.3361280487804878\n",
            "Epoch 1/5, Batch Loss: 1.3100210428237915, Average Training Loss: 1.5079190084733158, Training Accuracy: 0.3381024096385542\n",
            "Epoch 1/5, Batch Loss: 1.3057160377502441, Average Training Loss: 1.5055118302504222, Training Accuracy: 0.34077380952380953\n",
            "Epoch 1/5, Batch Loss: 1.5745558738708496, Average Training Loss: 1.5063241131165448, Training Accuracy: 0.3411764705882353\n",
            "Epoch 1/5, Batch Loss: 1.3372517824172974, Average Training Loss: 1.5043581557828327, Training Accuracy: 0.34375\n",
            "Epoch 1/5, Batch Loss: 1.3001419305801392, Average Training Loss: 1.5020108428494683, Training Accuracy: 0.34626436781609193\n",
            "Epoch 1/5, Batch Loss: 1.2308971881866455, Average Training Loss: 1.4989300058646635, Training Accuracy: 0.3465909090909091\n",
            "Epoch 1/5, Batch Loss: 1.474623680114746, Average Training Loss: 1.4986569010809567, Training Accuracy: 0.3455056179775281\n",
            "Epoch 1/5, Batch Loss: 1.4700919389724731, Average Training Loss: 1.4983395126130845, Training Accuracy: 0.34375\n",
            "Epoch 1/5, Batch Loss: 1.3022273778915405, Average Training Loss: 1.4961844342095512, Training Accuracy: 0.3447802197802198\n",
            "Epoch 1/5, Batch Loss: 1.1054779291152954, Average Training Loss: 1.49193762437157, Training Accuracy: 0.34782608695652173\n",
            "Epoch 1/5, Batch Loss: 1.49860680103302, Average Training Loss: 1.4920093359485749, Training Accuracy: 0.3474462365591398\n",
            "Epoch 1/5, Batch Loss: 1.2440626621246338, Average Training Loss: 1.4893716053759798, Training Accuracy: 0.3490691489361702\n",
            "Epoch 1/5, Batch Loss: 1.397348403930664, Average Training Loss: 1.488402940097608, Training Accuracy: 0.3480263157894737\n",
            "Epoch 1/5, Batch Loss: 1.060308814048767, Average Training Loss: 1.4839436262845993, Training Accuracy: 0.3515625\n",
            "Epoch 1/5, Batch Loss: 1.293623685836792, Average Training Loss: 1.4819815650428694, Training Accuracy: 0.35309278350515466\n",
            "Epoch 1/5, Batch Loss: 1.4081143140792847, Average Training Loss: 1.4812278175840572, Training Accuracy: 0.35459183673469385\n",
            "Epoch 1/5, Batch Loss: 0.9784757494926453, Average Training Loss: 1.4761495138659622, Training Accuracy: 0.35795454545454547\n",
            "Epoch 1/5, Batch Loss: 1.3603756427764893, Average Training Loss: 1.4749917751550674, Training Accuracy: 0.35875\n",
            "Epoch 1/5, Batch Loss: 1.0139209032058716, Average Training Loss: 1.4704267170169565, Training Accuracy: 0.36076732673267325\n",
            "Epoch 1/5, Batch Loss: 1.0255110263824463, Average Training Loss: 1.4660647984813242, Training Accuracy: 0.3633578431372549\n",
            "Epoch 1/5, Batch Loss: 1.1036278009414673, Average Training Loss: 1.4625459926799662, Training Accuracy: 0.36468446601941745\n",
            "Epoch 1/5, Batch Loss: 1.278066873550415, Average Training Loss: 1.4607721549960284, Training Accuracy: 0.36478365384615385\n",
            "Epoch 1/5, Batch Loss: 1.160834550857544, Average Training Loss: 1.4579156063851857, Training Accuracy: 0.36666666666666664\n",
            "Epoch 1/5, Batch Loss: 1.1359431743621826, Average Training Loss: 1.4548781306113836, Training Accuracy: 0.36792452830188677\n",
            "Epoch 1/5, Batch Loss: 1.3019222021102905, Average Training Loss: 1.453448635952495, Training Accuracy: 0.3691588785046729\n",
            "Epoch 1/5, Batch Loss: 1.0943697690963745, Average Training Loss: 1.4501238316297531, Training Accuracy: 0.3726851851851852\n",
            "Epoch 1/5, Batch Loss: 1.3587403297424316, Average Training Loss: 1.4492854508784934, Training Accuracy: 0.37155963302752293\n",
            "Epoch 1/5, Batch Loss: 1.103603482246399, Average Training Loss: 1.4461428875272924, Training Accuracy: 0.37329545454545454\n",
            "Epoch 1/5, Batch Loss: 1.1236051321029663, Average Training Loss: 1.443237141982929, Training Accuracy: 0.3755630630630631\n",
            "Epoch 1/5, Batch Loss: 0.9391453266143799, Average Training Loss: 1.4387363222028529, Training Accuracy: 0.37779017857142855\n",
            "Epoch 1/5, Batch Loss: 1.1315100193023682, Average Training Loss: 1.4360175053630255, Training Accuracy: 0.3788716814159292\n",
            "Epoch 1/5, Batch Loss: 1.168915867805481, Average Training Loss: 1.4336745085423452, Training Accuracy: 0.37993421052631576\n",
            "Epoch 1/5, Batch Loss: 0.9708482623100281, Average Training Loss: 1.4296499324881513, Training Accuracy: 0.3826086956521739\n",
            "Epoch 1/5, Batch Loss: 1.139125943183899, Average Training Loss: 1.4271454153389767, Training Accuracy: 0.38362068965517243\n",
            "Epoch 1/5, Average Training Loss: 1.4271454153389767, Training Accuracy: 0.38362068965517243\n",
            "Epoch 1/5, Validation Loss: 31.74251115322113, Validation Accuracy: 0.6077586206896551\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.50      0.71      0.59        99\n",
            "                Educational Opportunity       0.50      0.09      0.16        87\n",
            "                         Family Support       0.65      0.99      0.79        93\n",
            "                      Financial Support       0.61      0.70      0.65        89\n",
            "                 Program Implementation       0.76      0.52      0.62        96\n",
            "\n",
            "                               accuracy                           0.61       464\n",
            "                              macro avg       0.60      0.60      0.56       464\n",
            "                           weighted avg       0.61      0.61      0.56       464\n",
            "\n",
            "Epoch 2/5, Batch Loss: 1.0803349018096924, Average Training Loss: 1.0803349018096924, Training Accuracy: 0.625\n",
            "Epoch 2/5, Batch Loss: 0.9868111610412598, Average Training Loss: 1.033573031425476, Training Accuracy: 0.65625\n",
            "Epoch 2/5, Batch Loss: 0.8382147550582886, Average Training Loss: 0.968453605969747, Training Accuracy: 0.6666666666666666\n",
            "Epoch 2/5, Batch Loss: 1.0705783367156982, Average Training Loss: 0.9939847886562347, Training Accuracy: 0.65625\n",
            "Epoch 2/5, Batch Loss: 1.3884963989257812, Average Training Loss: 1.072887110710144, Training Accuracy: 0.6\n",
            "Epoch 2/5, Batch Loss: 1.0385884046554565, Average Training Loss: 1.0671706597010295, Training Accuracy: 0.6041666666666666\n",
            "Epoch 2/5, Batch Loss: 1.0079470872879028, Average Training Loss: 1.0587101493562971, Training Accuracy: 0.6160714285714286\n",
            "Epoch 2/5, Batch Loss: 1.031227946281433, Average Training Loss: 1.055274873971939, Training Accuracy: 0.59375\n",
            "Epoch 2/5, Batch Loss: 1.2825675010681152, Average Training Loss: 1.0805296103159587, Training Accuracy: 0.5902777777777778\n",
            "Epoch 2/5, Batch Loss: 0.879305362701416, Average Training Loss: 1.0604071855545043, Training Accuracy: 0.6\n",
            "Epoch 2/5, Batch Loss: 1.1007903814315796, Average Training Loss: 1.064078385179693, Training Accuracy: 0.5965909090909091\n",
            "Epoch 2/5, Batch Loss: 0.976006269454956, Average Training Loss: 1.0567390422026317, Training Accuracy: 0.5885416666666666\n",
            "Epoch 2/5, Batch Loss: 1.430321455001831, Average Training Loss: 1.0854761508794932, Training Accuracy: 0.5625\n",
            "Epoch 2/5, Batch Loss: 1.2216893434524536, Average Training Loss: 1.0952056646347046, Training Accuracy: 0.5669642857142857\n",
            "Epoch 2/5, Batch Loss: 1.0303659439086914, Average Training Loss: 1.0908830165863037, Training Accuracy: 0.5625\n",
            "Epoch 2/5, Batch Loss: 0.908062219619751, Average Training Loss: 1.0794567167758942, Training Accuracy: 0.578125\n",
            "Epoch 2/5, Batch Loss: 0.9699174761772156, Average Training Loss: 1.0730132320347954, Training Accuracy: 0.5882352941176471\n",
            "Epoch 2/5, Batch Loss: 1.1423301696777344, Average Training Loss: 1.0768641730149586, Training Accuracy: 0.5833333333333334\n",
            "Epoch 2/5, Batch Loss: 0.7981026768684387, Average Training Loss: 1.0621925153230365, Training Accuracy: 0.5921052631578947\n",
            "Epoch 2/5, Batch Loss: 1.1728465557098389, Average Training Loss: 1.0677252173423768, Training Accuracy: 0.59375\n",
            "Epoch 2/5, Batch Loss: 1.1321942806243896, Average Training Loss: 1.0707951727367582, Training Accuracy: 0.5892857142857143\n",
            "Epoch 2/5, Batch Loss: 0.983551025390625, Average Training Loss: 1.0668295296755703, Training Accuracy: 0.59375\n",
            "Epoch 2/5, Batch Loss: 1.0778164863586426, Average Training Loss: 1.0673072234443997, Training Accuracy: 0.592391304347826\n",
            "Epoch 2/5, Batch Loss: 1.167615532875061, Average Training Loss: 1.071486736337344, Training Accuracy: 0.5911458333333334\n",
            "Epoch 2/5, Batch Loss: 1.2967040538787842, Average Training Loss: 1.0804954290390014, Training Accuracy: 0.59\n",
            "Epoch 2/5, Batch Loss: 1.180180311203003, Average Training Loss: 1.0843294629683862, Training Accuracy: 0.5841346153846154\n",
            "Epoch 2/5, Batch Loss: 1.2241047620773315, Average Training Loss: 1.089506325898347, Training Accuracy: 0.5810185185185185\n",
            "Epoch 2/5, Batch Loss: 1.1260497570037842, Average Training Loss: 1.090811448437827, Training Accuracy: 0.5803571428571429\n",
            "Epoch 2/5, Batch Loss: 0.8293742537498474, Average Training Loss: 1.081796372758931, Training Accuracy: 0.5905172413793104\n",
            "Epoch 2/5, Batch Loss: 1.0884714126586914, Average Training Loss: 1.0820188740889232, Training Accuracy: 0.59375\n",
            "Epoch 2/5, Batch Loss: 1.078129529953003, Average Training Loss: 1.0818934113748613, Training Accuracy: 0.594758064516129\n",
            "Epoch 2/5, Batch Loss: 1.2256778478622437, Average Training Loss: 1.086386675015092, Training Accuracy: 0.591796875\n",
            "Epoch 2/5, Batch Loss: 0.7421028017997742, Average Training Loss: 1.0759538303722034, Training Accuracy: 0.5984848484848485\n",
            "Epoch 2/5, Batch Loss: 1.1182409524917603, Average Training Loss: 1.0771975692580729, Training Accuracy: 0.5974264705882353\n",
            "Epoch 2/5, Batch Loss: 0.9565542340278625, Average Training Loss: 1.0737506168229238, Training Accuracy: 0.5982142857142857\n",
            "Epoch 2/5, Batch Loss: 1.1210551261901855, Average Training Loss: 1.0750646309720144, Training Accuracy: 0.5972222222222222\n",
            "Epoch 2/5, Batch Loss: 0.7431634664535522, Average Training Loss: 1.0660943292282723, Training Accuracy: 0.6030405405405406\n",
            "Epoch 2/5, Batch Loss: 0.7919411063194275, Average Training Loss: 1.0588797707306712, Training Accuracy: 0.6118421052631579\n",
            "Epoch 2/5, Batch Loss: 0.868353009223938, Average Training Loss: 1.0539944691535754, Training Accuracy: 0.6137820512820513\n",
            "Epoch 2/5, Batch Loss: 1.075365424156189, Average Training Loss: 1.0545287430286407, Training Accuracy: 0.6140625\n",
            "Epoch 2/5, Batch Loss: 1.0127592086791992, Average Training Loss: 1.0535099738981666, Training Accuracy: 0.6158536585365854\n",
            "Epoch 2/5, Batch Loss: 1.3816272020339966, Average Training Loss: 1.0613222888537817, Training Accuracy: 0.6101190476190477\n",
            "Epoch 2/5, Batch Loss: 1.2326083183288574, Average Training Loss: 1.0653056848880857, Training Accuracy: 0.6075581395348837\n",
            "Epoch 2/5, Batch Loss: 0.7366434335708618, Average Training Loss: 1.0578360882672397, Training Accuracy: 0.6122159090909091\n",
            "Epoch 2/5, Batch Loss: 1.0982214212417603, Average Training Loss: 1.058733540111118, Training Accuracy: 0.6138888888888889\n",
            "Epoch 2/5, Batch Loss: 1.384414792060852, Average Training Loss: 1.0658135673274165, Training Accuracy: 0.6100543478260869\n",
            "Epoch 2/5, Batch Loss: 0.7989317774772644, Average Training Loss: 1.060135231373158, Training Accuracy: 0.6117021276595744\n",
            "Epoch 2/5, Batch Loss: 0.9290392398834229, Average Training Loss: 1.0574040648837884, Training Accuracy: 0.6145833333333334\n",
            "Epoch 2/5, Batch Loss: 0.8117319345474243, Average Training Loss: 1.0523903479381485, Training Accuracy: 0.6186224489795918\n",
            "Epoch 2/5, Batch Loss: 0.9940823912620544, Average Training Loss: 1.0512241888046265, Training Accuracy: 0.61875\n",
            "Epoch 2/5, Batch Loss: 0.938262403011322, Average Training Loss: 1.0490092518282872, Training Accuracy: 0.616421568627451\n",
            "Epoch 2/5, Batch Loss: 0.8157933950424194, Average Training Loss: 1.044524331505482, Training Accuracy: 0.6177884615384616\n",
            "Epoch 2/5, Batch Loss: 0.9351128935813904, Average Training Loss: 1.0424599647521973, Training Accuracy: 0.6167452830188679\n",
            "Epoch 2/5, Batch Loss: 1.171338438987732, Average Training Loss: 1.0448466031639665, Training Accuracy: 0.6145833333333334\n",
            "Epoch 2/5, Batch Loss: 0.9219475984573364, Average Training Loss: 1.042612075805664, Training Accuracy: 0.6136363636363636\n",
            "Epoch 2/5, Batch Loss: 0.7778729796409607, Average Training Loss: 1.0378845919455801, Training Accuracy: 0.6160714285714286\n",
            "Epoch 2/5, Batch Loss: 1.1875345706939697, Average Training Loss: 1.040510030169236, Training Accuracy: 0.6151315789473685\n",
            "Epoch 2/5, Batch Loss: 0.747853696346283, Average Training Loss: 1.0354642313102196, Training Accuracy: 0.6174568965517241\n",
            "Epoch 2/5, Batch Loss: 0.7289600372314453, Average Training Loss: 1.0302692449699014, Training Accuracy: 0.6207627118644068\n",
            "Epoch 2/5, Batch Loss: 0.9557557106018066, Average Training Loss: 1.0290273527304332, Training Accuracy: 0.6208333333333333\n",
            "Epoch 2/5, Batch Loss: 1.0780941247940063, Average Training Loss: 1.0298317260429508, Training Accuracy: 0.6209016393442623\n",
            "Epoch 2/5, Batch Loss: 1.1219614744186401, Average Training Loss: 1.0313176897264296, Training Accuracy: 0.6209677419354839\n",
            "Epoch 2/5, Batch Loss: 1.055119514465332, Average Training Loss: 1.031695496468317, Training Accuracy: 0.621031746031746\n",
            "Epoch 2/5, Batch Loss: 1.0866655111312866, Average Training Loss: 1.0325544029474258, Training Accuracy: 0.6201171875\n",
            "Epoch 2/5, Batch Loss: 1.0277724266052246, Average Training Loss: 1.0324808340806229, Training Accuracy: 0.6192307692307693\n",
            "Epoch 2/5, Batch Loss: 1.084948182106018, Average Training Loss: 1.0332757938991894, Training Accuracy: 0.6193181818181818\n",
            "Epoch 2/5, Batch Loss: 1.2278491258621216, Average Training Loss: 1.0361798734807257, Training Accuracy: 0.6184701492537313\n",
            "Epoch 2/5, Batch Loss: 1.1825149059295654, Average Training Loss: 1.038331859252032, Training Accuracy: 0.6176470588235294\n",
            "Epoch 2/5, Batch Loss: 0.7817834615707397, Average Training Loss: 1.0346137665320134, Training Accuracy: 0.6186594202898551\n",
            "Epoch 2/5, Batch Loss: 0.9059409499168396, Average Training Loss: 1.032775583437511, Training Accuracy: 0.6205357142857143\n",
            "Epoch 2/5, Batch Loss: 0.7687453031539917, Average Training Loss: 1.0290568470954895, Training Accuracy: 0.6214788732394366\n",
            "Epoch 2/5, Batch Loss: 1.1819435358047485, Average Training Loss: 1.0311802733275626, Training Accuracy: 0.6180555555555556\n",
            "Epoch 2/5, Batch Loss: 1.0453159809112549, Average Training Loss: 1.0313739131574762, Training Accuracy: 0.6190068493150684\n",
            "Epoch 2/5, Batch Loss: 0.8221780061721802, Average Training Loss: 1.0285469414414585, Training Accuracy: 0.6216216216216216\n",
            "Epoch 2/5, Batch Loss: 0.6151136755943298, Average Training Loss: 1.0230344978968302, Training Accuracy: 0.6233333333333333\n",
            "Epoch 2/5, Batch Loss: 0.8039129376411438, Average Training Loss: 1.0201513194724132, Training Accuracy: 0.625\n",
            "Epoch 2/5, Batch Loss: 0.6795753836631775, Average Training Loss: 1.0157282553709948, Training Accuracy: 0.6266233766233766\n",
            "Epoch 2/5, Batch Loss: 0.9871392250061035, Average Training Loss: 1.0153617293406756, Training Accuracy: 0.6266025641025641\n",
            "Epoch 2/5, Batch Loss: 0.5469268560409546, Average Training Loss: 1.0094321739824512, Training Accuracy: 0.629746835443038\n",
            "Epoch 2/5, Batch Loss: 0.547448992729187, Average Training Loss: 1.0036573842167855, Training Accuracy: 0.6328125\n",
            "Epoch 2/5, Batch Loss: 1.0988669395446777, Average Training Loss: 1.0048328108257718, Training Accuracy: 0.6334876543209876\n",
            "Epoch 2/5, Batch Loss: 1.3387329578399658, Average Training Loss: 1.0089047638381399, Training Accuracy: 0.6310975609756098\n",
            "Epoch 2/5, Batch Loss: 0.7478669285774231, Average Training Loss: 1.0057597296783722, Training Accuracy: 0.6317771084337349\n",
            "Epoch 2/5, Batch Loss: 0.6942168474197388, Average Training Loss: 1.00205088584196, Training Accuracy: 0.6331845238095238\n",
            "Epoch 2/5, Batch Loss: 0.9762925505638123, Average Training Loss: 1.0017478466033936, Training Accuracy: 0.6330882352941176\n",
            "Epoch 2/5, Batch Loss: 0.7677688598632812, Average Training Loss: 0.9990271607110667, Training Accuracy: 0.6337209302325582\n",
            "Epoch 2/5, Batch Loss: 0.5890134572982788, Average Training Loss: 0.994314359522414, Training Accuracy: 0.6350574712643678\n",
            "Epoch 2/5, Batch Loss: 0.5487292408943176, Average Training Loss: 0.9892508922652765, Training Accuracy: 0.6370738636363636\n",
            "Epoch 2/5, Batch Loss: 0.8541032671928406, Average Training Loss: 0.9877323796240132, Training Accuracy: 0.6376404494382022\n",
            "Epoch 2/5, Batch Loss: 0.9028974771499634, Average Training Loss: 0.9867897695965238, Training Accuracy: 0.6381944444444444\n",
            "Epoch 2/5, Batch Loss: 0.617337703704834, Average Training Loss: 0.9827298567845271, Training Accuracy: 0.6387362637362637\n",
            "Epoch 2/5, Batch Loss: 0.9855127334594727, Average Training Loss: 0.9827601054440374, Training Accuracy: 0.6385869565217391\n",
            "Epoch 2/5, Batch Loss: 1.1170510053634644, Average Training Loss: 0.984204093615214, Training Accuracy: 0.6370967741935484\n",
            "Epoch 2/5, Batch Loss: 0.5686932802200317, Average Training Loss: 0.9797837658131376, Training Accuracy: 0.6389627659574468\n",
            "Epoch 2/5, Batch Loss: 0.9031503200531006, Average Training Loss: 0.978977097963032, Training Accuracy: 0.6394736842105263\n",
            "Epoch 2/5, Batch Loss: 0.956706702709198, Average Training Loss: 0.9787451146791378, Training Accuracy: 0.638671875\n",
            "Epoch 2/5, Batch Loss: 1.139430284500122, Average Training Loss: 0.9804016628216222, Training Accuracy: 0.6385309278350515\n",
            "Epoch 2/5, Batch Loss: 0.6717366576194763, Average Training Loss: 0.9772520199113962, Training Accuracy: 0.6396683673469388\n",
            "Epoch 2/5, Batch Loss: 1.013052225112915, Average Training Loss: 0.9776136381457551, Training Accuracy: 0.6382575757575758\n",
            "Epoch 2/5, Batch Loss: 0.9526299834251404, Average Training Loss: 0.9773638015985489, Training Accuracy: 0.63875\n",
            "Epoch 2/5, Batch Loss: 0.650822639465332, Average Training Loss: 0.9741307207853487, Training Accuracy: 0.6404702970297029\n",
            "Epoch 2/5, Batch Loss: 1.1743643283843994, Average Training Loss: 0.9760937953696531, Training Accuracy: 0.6390931372549019\n",
            "Epoch 2/5, Batch Loss: 1.0242153406143188, Average Training Loss: 0.9765609948380479, Training Accuracy: 0.6371359223300971\n",
            "Epoch 2/5, Batch Loss: 1.0049104690551758, Average Training Loss: 0.9768335859362896, Training Accuracy: 0.6382211538461539\n",
            "Epoch 2/5, Batch Loss: 1.0974819660186768, Average Training Loss: 0.9779826181275504, Training Accuracy: 0.6386904761904761\n",
            "Epoch 2/5, Batch Loss: 0.7867521643638611, Average Training Loss: 0.9761785572429873, Training Accuracy: 0.6391509433962265\n",
            "Epoch 2/5, Batch Loss: 0.8416087627410889, Average Training Loss: 0.9749208956121285, Training Accuracy: 0.6396028037383178\n",
            "Epoch 2/5, Batch Loss: 1.199499249458313, Average Training Loss: 0.9770003248144079, Training Accuracy: 0.6388888888888888\n",
            "Epoch 2/5, Batch Loss: 1.1738953590393066, Average Training Loss: 0.9788067012751868, Training Accuracy: 0.6387614678899083\n",
            "Epoch 2/5, Batch Loss: 1.0140835046768188, Average Training Loss: 0.9791273994879289, Training Accuracy: 0.6386363636363637\n",
            "Epoch 2/5, Batch Loss: 0.7595936059951782, Average Training Loss: 0.9771496175645707, Training Accuracy: 0.6402027027027027\n",
            "Epoch 2/5, Batch Loss: 1.256898283958435, Average Training Loss: 0.979647373514516, Training Accuracy: 0.6389508928571429\n",
            "Epoch 2/5, Batch Loss: 0.7528120279312134, Average Training Loss: 0.9776399810757257, Training Accuracy: 0.6393805309734514\n",
            "Epoch 2/5, Batch Loss: 0.8857892155647278, Average Training Loss: 0.976834272606331, Training Accuracy: 0.6387061403508771\n",
            "Epoch 2/5, Batch Loss: 0.665475070476532, Average Training Loss: 0.9741268012834632, Training Accuracy: 0.6396739130434783\n",
            "Epoch 2/5, Batch Loss: 0.8334835767745972, Average Training Loss: 0.9729143596928695, Training Accuracy: 0.640625\n",
            "Epoch 2/5, Average Training Loss: 0.9729143596928695, Training Accuracy: 0.640625\n",
            "Epoch 2/5, Validation Loss: 26.499300837516785, Validation Accuracy: 0.6637931034482759\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.60      0.64        99\n",
            "                Educational Opportunity       0.46      0.54      0.50        87\n",
            "                         Family Support       0.74      0.99      0.84        93\n",
            "                      Financial Support       0.71      0.65      0.68        89\n",
            "                 Program Implementation       0.74      0.54      0.63        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.67      0.66      0.66       464\n",
            "                           weighted avg       0.67      0.66      0.66       464\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.4777059853076935, Average Training Loss: 0.4777059853076935, Training Accuracy: 0.8125\n",
            "Epoch 3/5, Batch Loss: 0.6566557288169861, Average Training Loss: 0.5671808570623398, Training Accuracy: 0.78125\n",
            "Epoch 3/5, Batch Loss: 0.7567795515060425, Average Training Loss: 0.6303804218769073, Training Accuracy: 0.7708333333333334\n",
            "Epoch 3/5, Batch Loss: 1.1196918487548828, Average Training Loss: 0.7527082785964012, Training Accuracy: 0.71875\n",
            "Epoch 3/5, Batch Loss: 0.9478602409362793, Average Training Loss: 0.7917386710643768, Training Accuracy: 0.6875\n",
            "Epoch 3/5, Batch Loss: 0.6404656767845154, Average Training Loss: 0.7665265053510666, Training Accuracy: 0.7083333333333334\n",
            "Epoch 3/5, Batch Loss: 0.8001562356948853, Average Training Loss: 0.7713307525430407, Training Accuracy: 0.7053571428571429\n",
            "Epoch 3/5, Batch Loss: 0.6571131348609924, Average Training Loss: 0.7570535503327847, Training Accuracy: 0.7109375\n",
            "Epoch 3/5, Batch Loss: 0.8429805040359497, Average Training Loss: 0.7666009896331363, Training Accuracy: 0.7083333333333334\n",
            "Epoch 3/5, Batch Loss: 0.9459094405174255, Average Training Loss: 0.7845318347215653, Training Accuracy: 0.6875\n",
            "Epoch 3/5, Batch Loss: 0.746137261390686, Average Training Loss: 0.7810414189642126, Training Accuracy: 0.6931818181818182\n",
            "Epoch 3/5, Batch Loss: 1.1250914335250854, Average Training Loss: 0.809712253510952, Training Accuracy: 0.6875\n",
            "Epoch 3/5, Batch Loss: 0.5686554908752441, Average Training Loss: 0.7911694256158975, Training Accuracy: 0.7019230769230769\n",
            "Epoch 3/5, Batch Loss: 0.5910857319831848, Average Training Loss: 0.7768777332135609, Training Accuracy: 0.7142857142857143\n",
            "Epoch 3/5, Batch Loss: 0.8655335903167725, Average Training Loss: 0.7827881236871084, Training Accuracy: 0.7083333333333334\n",
            "Epoch 3/5, Batch Loss: 0.49506160616874695, Average Training Loss: 0.7648052163422108, Training Accuracy: 0.71484375\n",
            "Epoch 3/5, Batch Loss: 0.7008412480354309, Average Training Loss: 0.7610426299712237, Training Accuracy: 0.7242647058823529\n",
            "Epoch 3/5, Batch Loss: 1.0001190900802612, Average Training Loss: 0.7743246555328369, Training Accuracy: 0.71875\n",
            "Epoch 3/5, Batch Loss: 0.9300458431243896, Average Training Loss: 0.7825205075113397, Training Accuracy: 0.7105263157894737\n",
            "Epoch 3/5, Batch Loss: 0.9397967457771301, Average Training Loss: 0.7903843194246292, Training Accuracy: 0.70625\n",
            "Epoch 3/5, Batch Loss: 0.7035104036331177, Average Training Loss: 0.7862474662917001, Training Accuracy: 0.7053571428571429\n",
            "Epoch 3/5, Batch Loss: 0.4707591235637665, Average Training Loss: 0.771907087076794, Training Accuracy: 0.7130681818181818\n",
            "Epoch 3/5, Batch Loss: 0.8037159442901611, Average Training Loss: 0.7732900808686796, Training Accuracy: 0.717391304347826\n",
            "Epoch 3/5, Batch Loss: 0.9849390387535095, Average Training Loss: 0.7821087874472141, Training Accuracy: 0.7135416666666666\n",
            "Epoch 3/5, Batch Loss: 0.6343657374382019, Average Training Loss: 0.7761990654468537, Training Accuracy: 0.7125\n",
            "Epoch 3/5, Batch Loss: 0.7742457389831543, Average Training Loss: 0.7761239375059421, Training Accuracy: 0.7139423076923077\n",
            "Epoch 3/5, Batch Loss: 0.8978466987609863, Average Training Loss: 0.7806321879227957, Training Accuracy: 0.7106481481481481\n",
            "Epoch 3/5, Batch Loss: 0.6342822909355164, Average Training Loss: 0.7754054058875356, Training Accuracy: 0.7120535714285714\n",
            "Epoch 3/5, Batch Loss: 0.6074328422546387, Average Training Loss: 0.769613248520884, Training Accuracy: 0.7155172413793104\n",
            "Epoch 3/5, Batch Loss: 0.9662538170814514, Average Training Loss: 0.7761679341395696, Training Accuracy: 0.7125\n",
            "Epoch 3/5, Batch Loss: 0.6657213568687439, Average Training Loss: 0.7726051413243816, Training Accuracy: 0.7116935483870968\n",
            "Epoch 3/5, Batch Loss: 0.8928210735321045, Average Training Loss: 0.776361889205873, Training Accuracy: 0.712890625\n",
            "Epoch 3/5, Batch Loss: 0.682056725025177, Average Training Loss: 0.7735041569579731, Training Accuracy: 0.7121212121212122\n",
            "Epoch 3/5, Batch Loss: 0.7723466157913208, Average Training Loss: 0.7734701116295422, Training Accuracy: 0.7132352941176471\n",
            "Epoch 3/5, Batch Loss: 0.7360450029373169, Average Training Loss: 0.7724008228097643, Training Accuracy: 0.7142857142857143\n",
            "Epoch 3/5, Batch Loss: 0.8101395964622498, Average Training Loss: 0.773449122077889, Training Accuracy: 0.7135416666666666\n",
            "Epoch 3/5, Batch Loss: 0.5041497945785522, Average Training Loss: 0.7661707618752042, Training Accuracy: 0.7162162162162162\n",
            "Epoch 3/5, Batch Loss: 0.5777531266212463, Average Training Loss: 0.7612124030527315, Training Accuracy: 0.7203947368421053\n",
            "Epoch 3/5, Batch Loss: 0.46548399329185486, Average Training Loss: 0.7536296233152732, Training Accuracy: 0.7243589743589743\n",
            "Epoch 3/5, Batch Loss: 0.8688714504241943, Average Training Loss: 0.7565106689929962, Training Accuracy: 0.7265625\n",
            "Epoch 3/5, Batch Loss: 0.9836583733558655, Average Training Loss: 0.7620508569042858, Training Accuracy: 0.7240853658536586\n",
            "Epoch 3/5, Batch Loss: 0.7974420785903931, Average Training Loss: 0.7628935050396692, Training Accuracy: 0.7247023809523809\n",
            "Epoch 3/5, Batch Loss: 0.7033998370170593, Average Training Loss: 0.7615099313647248, Training Accuracy: 0.7267441860465116\n",
            "Epoch 3/5, Batch Loss: 0.4312140643596649, Average Training Loss: 0.7540032071146098, Training Accuracy: 0.7315340909090909\n",
            "Epoch 3/5, Batch Loss: 0.4776318371295929, Average Training Loss: 0.7478616211149428, Training Accuracy: 0.7347222222222223\n",
            "Epoch 3/5, Batch Loss: 0.7862020134925842, Average Training Loss: 0.7486951079057611, Training Accuracy: 0.7336956521739131\n",
            "Epoch 3/5, Batch Loss: 1.0006426572799683, Average Training Loss: 0.754055694062659, Training Accuracy: 0.7287234042553191\n",
            "Epoch 3/5, Batch Loss: 0.7172126770019531, Average Training Loss: 0.7532881312072277, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/5, Batch Loss: 0.694327175617218, Average Training Loss: 0.7520848463992683, Training Accuracy: 0.7295918367346939\n",
            "Epoch 3/5, Batch Loss: 0.5262459516525269, Average Training Loss: 0.7475680685043335, Training Accuracy: 0.7325\n",
            "Epoch 3/5, Batch Loss: 0.7172955870628357, Average Training Loss: 0.7469744904368532, Training Accuracy: 0.7328431372549019\n",
            "Epoch 3/5, Batch Loss: 0.896880030632019, Average Training Loss: 0.7498572892867602, Training Accuracy: 0.7295673076923077\n",
            "Epoch 3/5, Batch Loss: 0.9218945503234863, Average Training Loss: 0.7531032753440569, Training Accuracy: 0.7287735849056604\n",
            "Epoch 3/5, Batch Loss: 0.7407472729682922, Average Training Loss: 0.7528744604852464, Training Accuracy: 0.7280092592592593\n",
            "Epoch 3/5, Batch Loss: 0.9512272477149963, Average Training Loss: 0.7564808747985147, Training Accuracy: 0.725\n",
            "Epoch 3/5, Batch Loss: 0.8011281490325928, Average Training Loss: 0.7572781475526946, Training Accuracy: 0.7254464285714286\n",
            "Epoch 3/5, Batch Loss: 0.5426701307296753, Average Training Loss: 0.7535130946259749, Training Accuracy: 0.7280701754385965\n",
            "Epoch 3/5, Batch Loss: 0.8967067003250122, Average Training Loss: 0.755981949896648, Training Accuracy: 0.7262931034482759\n",
            "Epoch 3/5, Batch Loss: 0.9439417123794556, Average Training Loss: 0.7591677085827973, Training Accuracy: 0.725635593220339\n",
            "Epoch 3/5, Batch Loss: 0.7186891436576843, Average Training Loss: 0.7584930658340454, Training Accuracy: 0.7260416666666667\n",
            "Epoch 3/5, Batch Loss: 0.34034472703933716, Average Training Loss: 0.7516381750341321, Training Accuracy: 0.7284836065573771\n",
            "Epoch 3/5, Batch Loss: 0.9980638027191162, Average Training Loss: 0.7556127819322771, Training Accuracy: 0.7288306451612904\n",
            "Epoch 3/5, Batch Loss: 0.4350055158138275, Average Training Loss: 0.7505237777081747, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/5, Batch Loss: 0.5383836030960083, Average Training Loss: 0.7472090874798596, Training Accuracy: 0.7333984375\n",
            "Epoch 3/5, Batch Loss: 0.5075487494468689, Average Training Loss: 0.7435220053562751, Training Accuracy: 0.7346153846153847\n",
            "Epoch 3/5, Batch Loss: 0.6663225293159485, Average Training Loss: 0.742352316325361, Training Accuracy: 0.7348484848484849\n",
            "Epoch 3/5, Batch Loss: 0.9050535559654236, Average Training Loss: 0.7447806930364068, Training Accuracy: 0.7350746268656716\n",
            "Epoch 3/5, Batch Loss: 0.9794019460678101, Average Training Loss: 0.7482310055809862, Training Accuracy: 0.7334558823529411\n",
            "Epoch 3/5, Batch Loss: 0.9196175336837769, Average Training Loss: 0.7507148683071136, Training Accuracy: 0.7318840579710145\n",
            "Epoch 3/5, Batch Loss: 1.192630648612976, Average Training Loss: 0.7570279508829116, Training Accuracy: 0.7285714285714285\n",
            "Epoch 3/5, Batch Loss: 0.7358881235122681, Average Training Loss: 0.7567302068354378, Training Accuracy: 0.7279929577464789\n",
            "Epoch 3/5, Batch Loss: 0.9628775119781494, Average Training Loss: 0.7595933638513088, Training Accuracy: 0.7265625\n",
            "Epoch 3/5, Batch Loss: 0.8469049334526062, Average Training Loss: 0.7607894127499567, Training Accuracy: 0.726027397260274\n",
            "Epoch 3/5, Batch Loss: 0.5564109683036804, Average Training Loss: 0.7580275418790611, Training Accuracy: 0.7263513513513513\n",
            "Epoch 3/5, Batch Loss: 0.7585229277610779, Average Training Loss: 0.7580341470241546, Training Accuracy: 0.7275\n",
            "Epoch 3/5, Batch Loss: 0.9927748441696167, Average Training Loss: 0.7611228404076475, Training Accuracy: 0.7269736842105263\n",
            "Epoch 3/5, Batch Loss: 0.7210580706596375, Average Training Loss: 0.7606025187226085, Training Accuracy: 0.726461038961039\n",
            "Epoch 3/5, Batch Loss: 0.7059109807014465, Average Training Loss: 0.7599013451582346, Training Accuracy: 0.7267628205128205\n",
            "Epoch 3/5, Batch Loss: 0.8553968667984009, Average Training Loss: 0.7611101492296292, Training Accuracy: 0.7278481012658228\n",
            "Epoch 3/5, Batch Loss: 0.7192686200141907, Average Training Loss: 0.7605871301144361, Training Accuracy: 0.728125\n",
            "Epoch 3/5, Batch Loss: 0.7204355597496033, Average Training Loss: 0.7600914317148703, Training Accuracy: 0.7283950617283951\n",
            "Epoch 3/5, Batch Loss: 0.3318159282207489, Average Training Loss: 0.7548685597210396, Training Accuracy: 0.7317073170731707\n",
            "Epoch 3/5, Batch Loss: 1.1160218715667725, Average Training Loss: 0.7592198044420725, Training Accuracy: 0.7289156626506024\n",
            "Epoch 3/5, Batch Loss: 1.0294685363769531, Average Training Loss: 0.7624370512508211, Training Accuracy: 0.7276785714285714\n",
            "Epoch 3/5, Batch Loss: 0.6831793785095215, Average Training Loss: 0.7615046080420999, Training Accuracy: 0.7279411764705882\n",
            "Epoch 3/5, Batch Loss: 0.5000073909759521, Average Training Loss: 0.7584639427273773, Training Accuracy: 0.7296511627906976\n",
            "Epoch 3/5, Batch Loss: 0.6465569138526917, Average Training Loss: 0.7571776550391625, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/5, Batch Loss: 0.61397385597229, Average Training Loss: 0.7555503391406753, Training Accuracy: 0.7301136363636364\n",
            "Epoch 3/5, Batch Loss: 0.8050033450126648, Average Training Loss: 0.756105990892046, Training Accuracy: 0.7310393258426966\n",
            "Epoch 3/5, Batch Loss: 0.8396227359771729, Average Training Loss: 0.7570339547263252, Training Accuracy: 0.7319444444444444\n",
            "Epoch 3/5, Batch Loss: 0.4572910964488983, Average Training Loss: 0.753740077162837, Training Accuracy: 0.7335164835164835\n",
            "Epoch 3/5, Batch Loss: 0.714504599571228, Average Training Loss: 0.7533136045803195, Training Accuracy: 0.734375\n",
            "Epoch 3/5, Batch Loss: 0.8624316453933716, Average Training Loss: 0.7544869168471264, Training Accuracy: 0.7325268817204301\n",
            "Epoch 3/5, Batch Loss: 0.4476049840450287, Average Training Loss: 0.7512222154343382, Training Accuracy: 0.7333776595744681\n",
            "Epoch 3/5, Batch Loss: 0.5303413271903992, Average Training Loss: 0.748897153452823, Training Accuracy: 0.7342105263157894\n",
            "Epoch 3/5, Batch Loss: 0.5127577781677246, Average Training Loss: 0.7464373682936033, Training Accuracy: 0.734375\n",
            "Epoch 3/5, Batch Loss: 0.8451136350631714, Average Training Loss: 0.7474546493943205, Training Accuracy: 0.7332474226804123\n",
            "Epoch 3/5, Batch Loss: 0.6541358232498169, Average Training Loss: 0.7465024164744786, Training Accuracy: 0.732780612244898\n",
            "Epoch 3/5, Batch Loss: 0.4799487888813019, Average Training Loss: 0.743809955589699, Training Accuracy: 0.7329545454545454\n",
            "Epoch 3/5, Batch Loss: 0.5753216743469238, Average Training Loss: 0.7421250727772712, Training Accuracy: 0.73375\n",
            "Epoch 3/5, Batch Loss: 0.6765387654304504, Average Training Loss: 0.7414757033975998, Training Accuracy: 0.7345297029702971\n",
            "Epoch 3/5, Batch Loss: 1.0696951150894165, Average Training Loss: 0.7446935407671273, Training Accuracy: 0.7328431372549019\n",
            "Epoch 3/5, Batch Loss: 1.1705676317214966, Average Training Loss: 0.7488282406793058, Training Accuracy: 0.7305825242718447\n",
            "Epoch 3/5, Batch Loss: 0.5259533524513245, Average Training Loss: 0.7466852129078828, Training Accuracy: 0.7313701923076923\n",
            "Epoch 3/5, Batch Loss: 0.8547620177268982, Average Training Loss: 0.7477145158109211, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/5, Batch Loss: 0.872290313243866, Average Training Loss: 0.74888975918293, Training Accuracy: 0.7317216981132075\n",
            "Epoch 3/5, Batch Loss: 0.4829240143299103, Average Training Loss: 0.7464040980160793, Training Accuracy: 0.7324766355140186\n",
            "Epoch 3/5, Batch Loss: 0.7381715774536133, Average Training Loss: 0.7463278709738342, Training Accuracy: 0.7332175925925926\n",
            "Epoch 3/5, Batch Loss: 0.9935300946235657, Average Training Loss: 0.7485957812825474, Training Accuracy: 0.7322247706422018\n",
            "Epoch 3/5, Batch Loss: 1.1691166162490845, Average Training Loss: 0.7524186979640614, Training Accuracy: 0.7301136363636364\n",
            "Epoch 3/5, Batch Loss: 1.0085045099258423, Average Training Loss: 0.7547257773511045, Training Accuracy: 0.7286036036036037\n",
            "Epoch 3/5, Batch Loss: 1.2088011503219604, Average Training Loss: 0.7587800217526299, Training Accuracy: 0.7260044642857143\n",
            "Epoch 3/5, Batch Loss: 0.5433899760246277, Average Training Loss: 0.7568739151532671, Training Accuracy: 0.7278761061946902\n",
            "Epoch 3/5, Batch Loss: 0.7243394255638123, Average Training Loss: 0.7565885248937105, Training Accuracy: 0.7286184210526315\n",
            "Epoch 3/5, Batch Loss: 1.0112401247024536, Average Training Loss: 0.7588028866311778, Training Accuracy: 0.7282608695652174\n",
            "Epoch 3/5, Batch Loss: 0.5915183424949646, Average Training Loss: 0.7573607784920725, Training Accuracy: 0.7300646551724138\n",
            "Epoch 3/5, Average Training Loss: 0.7573607784920725, Training Accuracy: 0.7300646551724138\n",
            "Epoch 3/5, Validation Loss: 25.01983630657196, Validation Accuracy: 0.6767241379310345\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.74      0.71        99\n",
            "                Educational Opportunity       0.48      0.46      0.47        87\n",
            "                         Family Support       0.80      0.92      0.86        93\n",
            "                      Financial Support       0.67      0.70      0.68        89\n",
            "                 Program Implementation       0.73      0.55      0.63        96\n",
            "\n",
            "                               accuracy                           0.68       464\n",
            "                              macro avg       0.67      0.67      0.67       464\n",
            "                           weighted avg       0.67      0.68      0.67       464\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.8214346766471863, Average Training Loss: 0.8214346766471863, Training Accuracy: 0.75\n",
            "Epoch 4/5, Batch Loss: 0.5298636555671692, Average Training Loss: 0.6756491661071777, Training Accuracy: 0.75\n",
            "Epoch 4/5, Batch Loss: 0.8917749524116516, Average Training Loss: 0.7476910948753357, Training Accuracy: 0.75\n",
            "Epoch 4/5, Batch Loss: 0.48405134677886963, Average Training Loss: 0.6817811578512192, Training Accuracy: 0.796875\n",
            "Epoch 4/5, Batch Loss: 0.6756749749183655, Average Training Loss: 0.6805599212646485, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.45353204011917114, Average Training Loss: 0.6427219410737356, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.3988836407661438, Average Training Loss: 0.607887898172651, Training Accuracy: 0.8392857142857143\n",
            "Epoch 4/5, Batch Loss: 0.3696449398994446, Average Training Loss: 0.5781075283885002, Training Accuracy: 0.84375\n",
            "Epoch 4/5, Batch Loss: 0.25194957852363586, Average Training Loss: 0.541867756181293, Training Accuracy: 0.8611111111111112\n",
            "Epoch 4/5, Batch Loss: 0.6503827571868896, Average Training Loss: 0.5527192562818527, Training Accuracy: 0.84375\n",
            "Epoch 4/5, Batch Loss: 0.8809778094291687, Average Training Loss: 0.5825609429316088, Training Accuracy: 0.8295454545454546\n",
            "Epoch 4/5, Batch Loss: 0.41797250509262085, Average Training Loss: 0.5688452397783598, Training Accuracy: 0.8333333333333334\n",
            "Epoch 4/5, Batch Loss: 0.5336768627166748, Average Training Loss: 0.5661399800043839, Training Accuracy: 0.8365384615384616\n",
            "Epoch 4/5, Batch Loss: 0.5185642838478088, Average Training Loss: 0.5627417159932, Training Accuracy: 0.8392857142857143\n",
            "Epoch 4/5, Batch Loss: 0.6576485633850098, Average Training Loss: 0.569068839152654, Training Accuracy: 0.8333333333333334\n",
            "Epoch 4/5, Batch Loss: 0.3777233958244324, Average Training Loss: 0.5571097489446402, Training Accuracy: 0.83984375\n",
            "Epoch 4/5, Batch Loss: 0.6225038170814514, Average Training Loss: 0.5609564588350409, Training Accuracy: 0.8308823529411765\n",
            "Epoch 4/5, Batch Loss: 0.7765719890594482, Average Training Loss: 0.5729350994030634, Training Accuracy: 0.8298611111111112\n",
            "Epoch 4/5, Batch Loss: 0.42229318618774414, Average Training Loss: 0.5650065776548887, Training Accuracy: 0.8355263157894737\n",
            "Epoch 4/5, Batch Loss: 0.855940580368042, Average Training Loss: 0.5795532777905464, Training Accuracy: 0.828125\n",
            "Epoch 4/5, Batch Loss: 0.33104071021080017, Average Training Loss: 0.5677193460010347, Training Accuracy: 0.8273809523809523\n",
            "Epoch 4/5, Batch Loss: 0.4651344418525696, Average Training Loss: 0.5630563958124681, Training Accuracy: 0.8267045454545454\n",
            "Epoch 4/5, Batch Loss: 0.729198694229126, Average Training Loss: 0.5702799740044967, Training Accuracy: 0.8233695652173914\n",
            "Epoch 4/5, Batch Loss: 0.5202741026878357, Average Training Loss: 0.5681963960329691, Training Accuracy: 0.8229166666666666\n",
            "Epoch 4/5, Batch Loss: 0.6870407462120056, Average Training Loss: 0.5729501700401306, Training Accuracy: 0.8175\n",
            "Epoch 4/5, Batch Loss: 0.6384364366531372, Average Training Loss: 0.5754688726021693, Training Accuracy: 0.8149038461538461\n",
            "Epoch 4/5, Batch Loss: 0.41846662759780884, Average Training Loss: 0.5696539746390449, Training Accuracy: 0.8148148148148148\n",
            "Epoch 4/5, Batch Loss: 0.681566596031189, Average Training Loss: 0.5736508539744786, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.47036653757095337, Average Training Loss: 0.5700893258226329, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.6802555918693542, Average Training Loss: 0.5737615346908569, Training Accuracy: 0.8104166666666667\n",
            "Epoch 4/5, Batch Loss: 0.49254751205444336, Average Training Loss: 0.5711417275090371, Training Accuracy: 0.8084677419354839\n",
            "Epoch 4/5, Batch Loss: 0.8514164090156555, Average Training Loss: 0.579900311306119, Training Accuracy: 0.806640625\n",
            "Epoch 4/5, Batch Loss: 0.5990012884140015, Average Training Loss: 0.5804791287942366, Training Accuracy: 0.803030303030303\n",
            "Epoch 4/5, Batch Loss: 0.5461845397949219, Average Training Loss: 0.5794704644119039, Training Accuracy: 0.8033088235294118\n",
            "Epoch 4/5, Batch Loss: 0.5589895844459534, Average Training Loss: 0.5788852964128767, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.40071672201156616, Average Training Loss: 0.5739361693461736, Training Accuracy: 0.8020833333333334\n",
            "Epoch 4/5, Batch Loss: 0.5221080183982849, Average Training Loss: 0.5725354085097442, Training Accuracy: 0.8040540540540541\n",
            "Epoch 4/5, Batch Loss: 0.8579984307289124, Average Training Loss: 0.5800475933049855, Training Accuracy: 0.8026315789473685\n",
            "Epoch 4/5, Batch Loss: 0.5083117485046387, Average Training Loss: 0.5782082126690791, Training Accuracy: 0.8044871794871795\n",
            "Epoch 4/5, Batch Loss: 0.5680872797966003, Average Training Loss: 0.5779551893472672, Training Accuracy: 0.8046875\n",
            "Epoch 4/5, Batch Loss: 0.5371196866035461, Average Training Loss: 0.5769592014754691, Training Accuracy: 0.8048780487804879\n",
            "Epoch 4/5, Batch Loss: 0.7139431834220886, Average Training Loss: 0.5802207248551505, Training Accuracy: 0.8050595238095238\n",
            "Epoch 4/5, Batch Loss: 0.6498651504516602, Average Training Loss: 0.5818403626597205, Training Accuracy: 0.8023255813953488\n",
            "Epoch 4/5, Batch Loss: 0.8235517740249634, Average Training Loss: 0.5873338038271124, Training Accuracy: 0.8025568181818182\n",
            "Epoch 4/5, Batch Loss: 0.5155336260795593, Average Training Loss: 0.5857382443216111, Training Accuracy: 0.8027777777777778\n",
            "Epoch 4/5, Batch Loss: 0.836938738822937, Average Training Loss: 0.5911991246368574, Training Accuracy: 0.7989130434782609\n",
            "Epoch 4/5, Batch Loss: 0.3169897496700287, Average Training Loss: 0.5853648826162866, Training Accuracy: 0.8018617021276596\n",
            "Epoch 4/5, Batch Loss: 0.45874130725860596, Average Training Loss: 0.5827268914630016, Training Accuracy: 0.8020833333333334\n",
            "Epoch 4/5, Batch Loss: 0.7392749190330505, Average Training Loss: 0.5859217491685128, Training Accuracy: 0.8010204081632653\n",
            "Epoch 4/5, Batch Loss: 0.39456021785736084, Average Training Loss: 0.5820945185422898, Training Accuracy: 0.8025\n",
            "Epoch 4/5, Batch Loss: 0.6377255320549011, Average Training Loss: 0.5831853227288115, Training Accuracy: 0.8014705882352942\n",
            "Epoch 4/5, Batch Loss: 0.4738287925720215, Average Training Loss: 0.5810823125334886, Training Accuracy: 0.8004807692307693\n",
            "Epoch 4/5, Batch Loss: 0.5665124654769897, Average Training Loss: 0.5808074097588377, Training Accuracy: 0.7995283018867925\n",
            "Epoch 4/5, Batch Loss: 0.5103957653045654, Average Training Loss: 0.5795034904170919, Training Accuracy: 0.7997685185185185\n",
            "Epoch 4/5, Batch Loss: 0.42681175470352173, Average Training Loss: 0.5767272770404815, Training Accuracy: 0.8022727272727272\n",
            "Epoch 4/5, Batch Loss: 0.6423340439796448, Average Training Loss: 0.5778988264501095, Training Accuracy: 0.8013392857142857\n",
            "Epoch 4/5, Batch Loss: 0.4090915322303772, Average Training Loss: 0.5749372949725703, Training Accuracy: 0.8026315789473685\n",
            "Epoch 4/5, Batch Loss: 0.4642998278141022, Average Training Loss: 0.5730297524353554, Training Accuracy: 0.802801724137931\n",
            "Epoch 4/5, Batch Loss: 0.44420623779296875, Average Training Loss: 0.5708463030346369, Training Accuracy: 0.8040254237288136\n",
            "Epoch 4/5, Batch Loss: 0.37436237931251526, Average Training Loss: 0.5675715709726016, Training Accuracy: 0.8052083333333333\n",
            "Epoch 4/5, Batch Loss: 0.5624822974205017, Average Training Loss: 0.5674881402586327, Training Accuracy: 0.8032786885245902\n",
            "Epoch 4/5, Batch Loss: 0.5529804229736328, Average Training Loss: 0.5672541448185521, Training Accuracy: 0.8024193548387096\n",
            "Epoch 4/5, Batch Loss: 0.5618387460708618, Average Training Loss: 0.5671681861082712, Training Accuracy: 0.8015873015873016\n",
            "Epoch 4/5, Batch Loss: 0.5692228674888611, Average Training Loss: 0.567200290504843, Training Accuracy: 0.802734375\n",
            "Epoch 4/5, Batch Loss: 0.6662801504135132, Average Training Loss: 0.5687245960418995, Training Accuracy: 0.8009615384615385\n",
            "Epoch 4/5, Batch Loss: 0.7249640226364136, Average Training Loss: 0.5710918600812103, Training Accuracy: 0.8001893939393939\n",
            "Epoch 4/5, Batch Loss: 0.5005489587783813, Average Training Loss: 0.5700389809572874, Training Accuracy: 0.8003731343283582\n",
            "Epoch 4/5, Batch Loss: 0.8569349646568298, Average Training Loss: 0.5742580395411042, Training Accuracy: 0.7996323529411765\n",
            "Epoch 4/5, Batch Loss: 0.5296517014503479, Average Training Loss: 0.5736115708731223, Training Accuracy: 0.7989130434782609\n",
            "Epoch 4/5, Batch Loss: 0.352493554353714, Average Training Loss: 0.5704527420657022, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.5526449084281921, Average Training Loss: 0.5702019275074274, Training Accuracy: 0.801056338028169\n",
            "Epoch 4/5, Batch Loss: 0.6114723682403564, Average Training Loss: 0.5707751280731626, Training Accuracy: 0.8012152777777778\n",
            "Epoch 4/5, Batch Loss: 0.6237090229988098, Average Training Loss: 0.5715002499214591, Training Accuracy: 0.8022260273972602\n",
            "Epoch 4/5, Batch Loss: 0.4954372048377991, Average Training Loss: 0.5704723709338421, Training Accuracy: 0.8023648648648649\n",
            "Epoch 4/5, Batch Loss: 0.644803524017334, Average Training Loss: 0.5714634529749553, Training Accuracy: 0.8016666666666666\n",
            "Epoch 4/5, Batch Loss: 0.5553243160247803, Average Training Loss: 0.5712510959098214, Training Accuracy: 0.8018092105263158\n",
            "Epoch 4/5, Batch Loss: 0.959393322467804, Average Training Loss: 0.576291904046938, Training Accuracy: 0.799512987012987\n",
            "Epoch 4/5, Batch Loss: 0.346310019493103, Average Training Loss: 0.5733434183475299, Training Accuracy: 0.8020833333333334\n",
            "Epoch 4/5, Batch Loss: 0.8589705228805542, Average Training Loss: 0.5769589513163024, Training Accuracy: 0.8006329113924051\n",
            "Epoch 4/5, Batch Loss: 0.7876479029655457, Average Training Loss: 0.5795925632119179, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.5608386993408203, Average Training Loss: 0.5793610340283241, Training Accuracy: 0.7993827160493827\n",
            "Epoch 4/5, Batch Loss: 0.5037349462509155, Average Training Loss: 0.578438764665185, Training Accuracy: 0.7995426829268293\n",
            "Epoch 4/5, Batch Loss: 0.7359855771064758, Average Training Loss: 0.5803369190319475, Training Accuracy: 0.7989457831325302\n",
            "Epoch 4/5, Batch Loss: 0.6692812442779541, Average Training Loss: 0.5813957800467809, Training Accuracy: 0.7976190476190477\n",
            "Epoch 4/5, Batch Loss: 0.4243532717227936, Average Training Loss: 0.5795482211253222, Training Accuracy: 0.7985294117647059\n",
            "Epoch 4/5, Batch Loss: 0.5362300872802734, Average Training Loss: 0.5790445218945659, Training Accuracy: 0.7986918604651163\n",
            "Epoch 4/5, Batch Loss: 0.8920596837997437, Average Training Loss: 0.5826423973187633, Training Accuracy: 0.7966954022988506\n",
            "Epoch 4/5, Batch Loss: 0.7399191856384277, Average Training Loss: 0.5844296335496686, Training Accuracy: 0.7975852272727273\n",
            "Epoch 4/5, Batch Loss: 0.740820586681366, Average Training Loss: 0.5861868352702494, Training Accuracy: 0.7956460674157303\n",
            "Epoch 4/5, Batch Loss: 0.7953898906707764, Average Training Loss: 0.5885113136635887, Training Accuracy: 0.7944444444444444\n",
            "Epoch 4/5, Batch Loss: 0.5764065980911255, Average Training Loss: 0.588378294811144, Training Accuracy: 0.7953296703296703\n",
            "Epoch 4/5, Batch Loss: 0.5899094343185425, Average Training Loss: 0.5883949376318766, Training Accuracy: 0.7948369565217391\n",
            "Epoch 4/5, Batch Loss: 0.4409756064414978, Average Training Loss: 0.5868097835330552, Training Accuracy: 0.7950268817204301\n",
            "Epoch 4/5, Batch Loss: 0.5675910115242004, Average Training Loss: 0.5866053285116845, Training Accuracy: 0.7945478723404256\n",
            "Epoch 4/5, Batch Loss: 0.5848339200019836, Average Training Loss: 0.5865866821063193, Training Accuracy: 0.7947368421052632\n",
            "Epoch 4/5, Batch Loss: 0.37455490231513977, Average Training Loss: 0.5843780177334944, Training Accuracy: 0.7955729166666666\n",
            "Epoch 4/5, Batch Loss: 0.3353644907474518, Average Training Loss: 0.5818108679707518, Training Accuracy: 0.7970360824742269\n",
            "Epoch 4/5, Batch Loss: 0.8677573204040527, Average Training Loss: 0.5847286889139487, Training Accuracy: 0.7946428571428571\n",
            "Epoch 4/5, Batch Loss: 0.742935299873352, Average Training Loss: 0.5863267354892961, Training Accuracy: 0.7935606060606061\n",
            "Epoch 4/5, Batch Loss: 0.7752448916435242, Average Training Loss: 0.5882159170508384, Training Accuracy: 0.793125\n",
            "Epoch 4/5, Batch Loss: 0.6420577168464661, Average Training Loss: 0.5887490041775278, Training Accuracy: 0.7933168316831684\n",
            "Epoch 4/5, Batch Loss: 0.5235424041748047, Average Training Loss: 0.5881097237853443, Training Accuracy: 0.7941176470588235\n",
            "Epoch 4/5, Batch Loss: 0.7028818726539612, Average Training Loss: 0.5892240164928066, Training Accuracy: 0.7924757281553398\n",
            "Epoch 4/5, Batch Loss: 0.7052427530288696, Average Training Loss: 0.5903395812671918, Training Accuracy: 0.7920673076923077\n",
            "Epoch 4/5, Batch Loss: 0.6720448136329651, Average Training Loss: 0.591117726337342, Training Accuracy: 0.7922619047619047\n",
            "Epoch 4/5, Batch Loss: 0.9138815402984619, Average Training Loss: 0.5941626679784847, Training Accuracy: 0.7912735849056604\n",
            "Epoch 4/5, Batch Loss: 0.7304183840751648, Average Training Loss: 0.5954360858859303, Training Accuracy: 0.7914719626168224\n",
            "Epoch 4/5, Batch Loss: 1.1901659965515137, Average Training Loss: 0.600942844318019, Training Accuracy: 0.7893518518518519\n",
            "Epoch 4/5, Batch Loss: 0.27737030386924744, Average Training Loss: 0.5979742889010579, Training Accuracy: 0.7901376146788991\n",
            "Epoch 4/5, Batch Loss: 0.5182708501815796, Average Training Loss: 0.5972497121854262, Training Accuracy: 0.7909090909090909\n",
            "Epoch 4/5, Batch Loss: 0.6748286485671997, Average Training Loss: 0.597948621522199, Training Accuracy: 0.7911036036036037\n",
            "Epoch 4/5, Batch Loss: 0.6355850100517273, Average Training Loss: 0.5982846607054982, Training Accuracy: 0.7912946428571429\n",
            "Epoch 4/5, Batch Loss: 0.32538706064224243, Average Training Loss: 0.5958696376960889, Training Accuracy: 0.7914823008849557\n",
            "Epoch 4/5, Batch Loss: 0.8363012671470642, Average Training Loss: 0.5979786870772379, Training Accuracy: 0.7905701754385965\n",
            "Epoch 4/5, Batch Loss: 0.8561422228813171, Average Training Loss: 0.6002235873885776, Training Accuracy: 0.7891304347826087\n",
            "Epoch 4/5, Batch Loss: 0.571006715297699, Average Training Loss: 0.5999717178015873, Training Accuracy: 0.7898706896551724\n",
            "Epoch 4/5, Average Training Loss: 0.5999717178015873, Training Accuracy: 0.7898706896551724\n",
            "Epoch 4/5, Validation Loss: 25.257644206285477, Validation Accuracy: 0.6831896551724138\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.74      0.73        99\n",
            "                Educational Opportunity       0.50      0.51      0.50        87\n",
            "                         Family Support       0.81      0.89      0.85        93\n",
            "                      Financial Support       0.67      0.67      0.67        89\n",
            "                 Program Implementation       0.70      0.59      0.64        96\n",
            "\n",
            "                               accuracy                           0.68       464\n",
            "                              macro avg       0.68      0.68      0.68       464\n",
            "                           weighted avg       0.68      0.68      0.68       464\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.6267237663269043, Average Training Loss: 0.6267237663269043, Training Accuracy: 0.8125\n",
            "Epoch 5/5, Batch Loss: 0.2802903652191162, Average Training Loss: 0.45350706577301025, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.7980329394340515, Average Training Loss: 0.568349023660024, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/5, Batch Loss: 0.7174807190895081, Average Training Loss: 0.605631947517395, Training Accuracy: 0.765625\n",
            "Epoch 5/5, Batch Loss: 0.44772329926490784, Average Training Loss: 0.5740502178668976, Training Accuracy: 0.7875\n",
            "Epoch 5/5, Batch Loss: 0.681469738483429, Average Training Loss: 0.5919534713029861, Training Accuracy: 0.7916666666666666\n",
            "Epoch 5/5, Batch Loss: 0.43249207735061646, Average Training Loss: 0.5691732721669334, Training Accuracy: 0.8035714285714286\n",
            "Epoch 5/5, Batch Loss: 0.34145587682724, Average Training Loss: 0.5407085977494717, Training Accuracy: 0.8203125\n",
            "Epoch 5/5, Batch Loss: 0.5186375975608826, Average Training Loss: 0.538256264395184, Training Accuracy: 0.8125\n",
            "Epoch 5/5, Batch Loss: 0.5146133303642273, Average Training Loss: 0.5358919709920883, Training Accuracy: 0.81875\n",
            "Epoch 5/5, Batch Loss: 0.5515208840370178, Average Training Loss: 0.5373127812689001, Training Accuracy: 0.8181818181818182\n",
            "Epoch 5/5, Batch Loss: 0.6573114991188049, Average Training Loss: 0.5473126744230589, Training Accuracy: 0.8125\n",
            "Epoch 5/5, Batch Loss: 0.8549978137016296, Average Training Loss: 0.5709807620598719, Training Accuracy: 0.8076923076923077\n",
            "Epoch 5/5, Batch Loss: 0.41883012652397156, Average Training Loss: 0.5601128595215934, Training Accuracy: 0.8125\n",
            "Epoch 5/5, Batch Loss: 0.460125207901001, Average Training Loss: 0.5534470160802205, Training Accuracy: 0.8166666666666667\n",
            "Epoch 5/5, Batch Loss: 0.33823496103286743, Average Training Loss: 0.539996262639761, Training Accuracy: 0.8203125\n",
            "Epoch 5/5, Batch Loss: 0.36313992738723755, Average Training Loss: 0.5295929488013772, Training Accuracy: 0.8308823529411765\n",
            "Epoch 5/5, Batch Loss: 0.7308262586593628, Average Training Loss: 0.5407725771268209, Training Accuracy: 0.8229166666666666\n",
            "Epoch 5/5, Batch Loss: 0.674300491809845, Average Training Loss: 0.5478003621101379, Training Accuracy: 0.819078947368421\n",
            "Epoch 5/5, Batch Loss: 0.469873309135437, Average Training Loss: 0.5439040094614029, Training Accuracy: 0.821875\n",
            "Epoch 5/5, Batch Loss: 0.4932762384414673, Average Training Loss: 0.5414931632223583, Training Accuracy: 0.8214285714285714\n",
            "Epoch 5/5, Batch Loss: 0.5765931606292725, Average Training Loss: 0.5430886176499453, Training Accuracy: 0.8210227272727273\n",
            "Epoch 5/5, Batch Loss: 0.7607200145721436, Average Training Loss: 0.5525508522987366, Training Accuracy: 0.8179347826086957\n",
            "Epoch 5/5, Batch Loss: 0.3945656418800354, Average Training Loss: 0.5459681351979574, Training Accuracy: 0.8203125\n",
            "Epoch 5/5, Batch Loss: 0.6138489246368408, Average Training Loss: 0.5486833667755127, Training Accuracy: 0.8125\n",
            "Epoch 5/5, Batch Loss: 0.27812230587005615, Average Training Loss: 0.5382771721253028, Training Accuracy: 0.8173076923076923\n",
            "Epoch 5/5, Batch Loss: 0.31574660539627075, Average Training Loss: 0.5300352992834868, Training Accuracy: 0.8217592592592593\n",
            "Epoch 5/5, Batch Loss: 0.7650623917579651, Average Training Loss: 0.5384291240147182, Training Accuracy: 0.8191964285714286\n",
            "Epoch 5/5, Batch Loss: 0.45746544003486633, Average Training Loss: 0.5356372728429991, Training Accuracy: 0.8232758620689655\n",
            "Epoch 5/5, Batch Loss: 0.6709936857223511, Average Training Loss: 0.540149153272311, Training Accuracy: 0.8208333333333333\n",
            "Epoch 5/5, Batch Loss: 0.4075404107570648, Average Training Loss: 0.5358714519008514, Training Accuracy: 0.8245967741935484\n",
            "Epoch 5/5, Batch Loss: 0.25590384006500244, Average Training Loss: 0.5271224640309811, Training Accuracy: 0.828125\n",
            "Epoch 5/5, Batch Loss: 0.6091409921646118, Average Training Loss: 0.5296078739744244, Training Accuracy: 0.8295454545454546\n",
            "Epoch 5/5, Batch Loss: 0.4012967646121979, Average Training Loss: 0.5258340178167119, Training Accuracy: 0.8308823529411765\n",
            "Epoch 5/5, Batch Loss: 0.6288849711418152, Average Training Loss: 0.5287783307688577, Training Accuracy: 0.8303571428571429\n",
            "Epoch 5/5, Batch Loss: 0.2932215631008148, Average Training Loss: 0.5222350872225232, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/5, Batch Loss: 0.4712086617946625, Average Training Loss: 0.5208559946433918, Training Accuracy: 0.8344594594594594\n",
            "Epoch 5/5, Batch Loss: 0.608354926109314, Average Training Loss: 0.5231585981030213, Training Accuracy: 0.8322368421052632\n",
            "Epoch 5/5, Batch Loss: 0.3982027471065521, Average Training Loss: 0.5199546019236246, Training Accuracy: 0.8349358974358975\n",
            "Epoch 5/5, Batch Loss: 0.3950638473033905, Average Training Loss: 0.5168323330581188, Training Accuracy: 0.8359375\n",
            "Epoch 5/5, Batch Loss: 0.41132888197898865, Average Training Loss: 0.5142590781537498, Training Accuracy: 0.8384146341463414\n",
            "Epoch 5/5, Batch Loss: 0.27876153588294983, Average Training Loss: 0.5086519938139689, Training Accuracy: 0.8407738095238095\n",
            "Epoch 5/5, Batch Loss: 0.39280402660369873, Average Training Loss: 0.5059578550416369, Training Accuracy: 0.8430232558139535\n",
            "Epoch 5/5, Batch Loss: 0.36770838499069214, Average Training Loss: 0.5028158216313883, Training Accuracy: 0.84375\n",
            "Epoch 5/5, Batch Loss: 0.3505477011203766, Average Training Loss: 0.49943208562003244, Training Accuracy: 0.8444444444444444\n",
            "Epoch 5/5, Batch Loss: 0.8103216886520386, Average Training Loss: 0.506190555251163, Training Accuracy: 0.8410326086956522\n",
            "Epoch 5/5, Batch Loss: 0.7579723596572876, Average Training Loss: 0.5115476149193784, Training Accuracy: 0.839095744680851\n",
            "Epoch 5/5, Batch Loss: 0.5929099917411804, Average Training Loss: 0.5132426644364992, Training Accuracy: 0.8385416666666666\n",
            "Epoch 5/5, Batch Loss: 0.5706807971000671, Average Training Loss: 0.5144148712255516, Training Accuracy: 0.8367346938775511\n",
            "Epoch 5/5, Batch Loss: 0.5107789039611816, Average Training Loss: 0.5143421518802643, Training Accuracy: 0.835\n",
            "Epoch 5/5, Batch Loss: 0.5701103806495667, Average Training Loss: 0.5154356465620153, Training Accuracy: 0.8357843137254902\n",
            "Epoch 5/5, Batch Loss: 0.5019308924674988, Average Training Loss: 0.5151759397525054, Training Accuracy: 0.8353365384615384\n",
            "Epoch 5/5, Batch Loss: 0.328391969203949, Average Training Loss: 0.5116517138930986, Training Accuracy: 0.8372641509433962\n",
            "Epoch 5/5, Batch Loss: 0.5245780944824219, Average Training Loss: 0.5118910913114194, Training Accuracy: 0.8368055555555556\n",
            "Epoch 5/5, Batch Loss: 0.7753645777702332, Average Training Loss: 0.5166815183379433, Training Accuracy: 0.8340909090909091\n",
            "Epoch 5/5, Batch Loss: 0.2813067138195038, Average Training Loss: 0.5124783968286855, Training Accuracy: 0.8370535714285714\n",
            "Epoch 5/5, Batch Loss: 0.378717303276062, Average Training Loss: 0.510131710976885, Training Accuracy: 0.8377192982456141\n",
            "Epoch 5/5, Batch Loss: 0.27312442660331726, Average Training Loss: 0.5060453784876856, Training Accuracy: 0.8394396551724138\n",
            "Epoch 5/5, Batch Loss: 0.3143369257450104, Average Training Loss: 0.5027960826784877, Training Accuracy: 0.8411016949152542\n",
            "Epoch 5/5, Batch Loss: 0.27083122730255127, Average Training Loss: 0.49893000175555546, Training Accuracy: 0.8427083333333333\n",
            "Epoch 5/5, Batch Loss: 0.2610258162021637, Average Training Loss: 0.4950299331399261, Training Accuracy: 0.8452868852459017\n",
            "Epoch 5/5, Batch Loss: 0.37204769253730774, Average Training Loss: 0.4930463486140774, Training Accuracy: 0.8467741935483871\n",
            "Epoch 5/5, Batch Loss: 0.31088098883628845, Average Training Loss: 0.49015483496681095, Training Accuracy: 0.8492063492063492\n",
            "Epoch 5/5, Batch Loss: 0.3996875584125519, Average Training Loss: 0.4887412837706506, Training Accuracy: 0.8486328125\n",
            "Epoch 5/5, Batch Loss: 0.36400556564331055, Average Training Loss: 0.4868222727225377, Training Accuracy: 0.8490384615384615\n",
            "Epoch 5/5, Batch Loss: 0.358109712600708, Average Training Loss: 0.4848720824176615, Training Accuracy: 0.8484848484848485\n",
            "Epoch 5/5, Batch Loss: 0.5064873695373535, Average Training Loss: 0.48519469864332854, Training Accuracy: 0.8479477611940298\n",
            "Epoch 5/5, Batch Loss: 0.38932153582572937, Average Training Loss: 0.48378479919012857, Training Accuracy: 0.8474264705882353\n",
            "Epoch 5/5, Batch Loss: 0.40645352005958557, Average Training Loss: 0.4826640560143236, Training Accuracy: 0.8478260869565217\n",
            "Epoch 5/5, Batch Loss: 0.3926815688610077, Average Training Loss: 0.48137859191213334, Training Accuracy: 0.8464285714285714\n",
            "Epoch 5/5, Batch Loss: 0.53962242603302, Average Training Loss: 0.4821989276039768, Training Accuracy: 0.8459507042253521\n",
            "Epoch 5/5, Batch Loss: 0.5692289471626282, Average Training Loss: 0.4834076778756248, Training Accuracy: 0.8454861111111112\n",
            "Epoch 5/5, Batch Loss: 0.36959731578826904, Average Training Loss: 0.4818486318196336, Training Accuracy: 0.8450342465753424\n",
            "Epoch 5/5, Batch Loss: 0.5065802335739136, Average Training Loss: 0.4821828426541509, Training Accuracy: 0.84375\n",
            "Epoch 5/5, Batch Loss: 0.4459521770477295, Average Training Loss: 0.48169976711273194, Training Accuracy: 0.8441666666666666\n",
            "Epoch 5/5, Batch Loss: 0.2987557351589203, Average Training Loss: 0.4792926087975502, Training Accuracy: 0.8453947368421053\n",
            "Epoch 5/5, Batch Loss: 0.4837952256202698, Average Training Loss: 0.4793510843407024, Training Accuracy: 0.8457792207792207\n",
            "Epoch 5/5, Batch Loss: 0.40760982036590576, Average Training Loss: 0.4784313245461537, Training Accuracy: 0.8461538461538461\n",
            "Epoch 5/5, Batch Loss: 0.20226217806339264, Average Training Loss: 0.47493551256535926, Training Accuracy: 0.8481012658227848\n",
            "Epoch 5/5, Batch Loss: 0.34578457474708557, Average Training Loss: 0.47332112584263086, Training Accuracy: 0.8484375\n",
            "Epoch 5/5, Batch Loss: 0.685804009437561, Average Training Loss: 0.4759443713191115, Training Accuracy: 0.8479938271604939\n",
            "Epoch 5/5, Batch Loss: 0.385315477848053, Average Training Loss: 0.4748391409109278, Training Accuracy: 0.8483231707317073\n",
            "Epoch 5/5, Batch Loss: 0.3272455930709839, Average Training Loss: 0.47306090539478396, Training Accuracy: 0.8493975903614458\n",
            "Epoch 5/5, Batch Loss: 0.42583945393562317, Average Training Loss: 0.4724987452583654, Training Accuracy: 0.8504464285714286\n",
            "Epoch 5/5, Batch Loss: 0.4222872257232666, Average Training Loss: 0.4719080214991289, Training Accuracy: 0.8514705882352941\n",
            "Epoch 5/5, Batch Loss: 0.5124461054801941, Average Training Loss: 0.47237939456867617, Training Accuracy: 0.8517441860465116\n",
            "Epoch 5/5, Batch Loss: 0.3593170940876007, Average Training Loss: 0.4710798278964799, Training Accuracy: 0.8520114942528736\n",
            "Epoch 5/5, Batch Loss: 0.46128353476524353, Average Training Loss: 0.4709685063836249, Training Accuracy: 0.8515625\n",
            "Epoch 5/5, Batch Loss: 0.7046195268630981, Average Training Loss: 0.47359379874856283, Training Accuracy: 0.8504213483146067\n",
            "Epoch 5/5, Batch Loss: 0.6509842276573181, Average Training Loss: 0.4755648035142157, Training Accuracy: 0.8493055555555555\n",
            "Epoch 5/5, Batch Loss: 0.6887588500976562, Average Training Loss: 0.47790759523491283, Training Accuracy: 0.8468406593406593\n",
            "Epoch 5/5, Batch Loss: 0.5757959485054016, Average Training Loss: 0.47897159907480946, Training Accuracy: 0.8457880434782609\n",
            "Epoch 5/5, Batch Loss: 0.4300406873226166, Average Training Loss: 0.4784454602387644, Training Accuracy: 0.8454301075268817\n",
            "Epoch 5/5, Batch Loss: 0.729147732257843, Average Training Loss: 0.48111250568577585, Training Accuracy: 0.8444148936170213\n",
            "Epoch 5/5, Batch Loss: 0.6624855995178223, Average Training Loss: 0.4830216961471658, Training Accuracy: 0.843421052631579\n",
            "Epoch 5/5, Batch Loss: 0.7772730588912964, Average Training Loss: 0.4860868145090838, Training Accuracy: 0.8411458333333334\n",
            "Epoch 5/5, Batch Loss: 0.36056074500083923, Average Training Loss: 0.48479273131827716, Training Accuracy: 0.8414948453608248\n",
            "Epoch 5/5, Batch Loss: 0.4552302360534668, Average Training Loss: 0.4844910732033301, Training Accuracy: 0.8411989795918368\n",
            "Epoch 5/5, Batch Loss: 0.42695364356040955, Average Training Loss: 0.48390988704532084, Training Accuracy: 0.8415404040404041\n",
            "Epoch 5/5, Batch Loss: 0.7940258979797363, Average Training Loss: 0.487011047154665, Training Accuracy: 0.839375\n",
            "Epoch 5/5, Batch Loss: 0.6717979907989502, Average Training Loss: 0.48884062085411334, Training Accuracy: 0.838490099009901\n",
            "Epoch 5/5, Batch Loss: 0.6375049352645874, Average Training Loss: 0.4902981141326474, Training Accuracy: 0.8376225490196079\n",
            "Epoch 5/5, Batch Loss: 0.5395516753196716, Average Training Loss: 0.49077630404708456, Training Accuracy: 0.8367718446601942\n",
            "Epoch 5/5, Batch Loss: 0.46202898025512695, Average Training Loss: 0.4904998874721619, Training Accuracy: 0.8371394230769231\n",
            "Epoch 5/5, Batch Loss: 0.3515998423099518, Average Training Loss: 0.48917702989918843, Training Accuracy: 0.8375\n",
            "Epoch 5/5, Batch Loss: 0.3387937843799591, Average Training Loss: 0.4877583200357995, Training Accuracy: 0.8384433962264151\n",
            "Epoch 5/5, Batch Loss: 0.20793995261192322, Average Training Loss: 0.48514319510660436, Training Accuracy: 0.8393691588785047\n",
            "Epoch 5/5, Batch Loss: 0.5137690305709839, Average Training Loss: 0.48540824913868197, Training Accuracy: 0.8385416666666666\n",
            "Epoch 5/5, Batch Loss: 0.5980614423751831, Average Training Loss: 0.4864417646729618, Training Accuracy: 0.8377293577981652\n",
            "Epoch 5/5, Batch Loss: 0.5822843909263611, Average Training Loss: 0.4873130612752654, Training Accuracy: 0.8380681818181818\n",
            "Epoch 5/5, Batch Loss: 0.34725695848464966, Average Training Loss: 0.4860512945834581, Training Accuracy: 0.8378378378378378\n",
            "Epoch 5/5, Batch Loss: 0.31212982535362244, Average Training Loss: 0.4844984243224774, Training Accuracy: 0.8381696428571429\n",
            "Epoch 5/5, Batch Loss: 0.48756057024002075, Average Training Loss: 0.4845255229589158, Training Accuracy: 0.8379424778761062\n",
            "Epoch 5/5, Batch Loss: 0.7595970630645752, Average Training Loss: 0.4869384312054567, Training Accuracy: 0.837171052631579\n",
            "Epoch 5/5, Batch Loss: 0.46316105127334595, Average Training Loss: 0.4867316713799601, Training Accuracy: 0.8369565217391305\n",
            "Epoch 5/5, Batch Loss: 0.5715181827545166, Average Training Loss: 0.4874625895814649, Training Accuracy: 0.8367456896551724\n",
            "Epoch 5/5, Average Training Loss: 0.4874625895814649, Training Accuracy: 0.8367456896551724\n",
            "Epoch 5/5, Validation Loss: 26.05522894859314, Validation Accuracy: 0.6875\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.76      0.66      0.71        99\n",
            "                Educational Opportunity       0.51      0.48      0.49        87\n",
            "                         Family Support       0.79      0.94      0.86        93\n",
            "                      Financial Support       0.66      0.74      0.70        89\n",
            "                 Program Implementation       0.69      0.61      0.65        96\n",
            "\n",
            "                               accuracy                           0.69       464\n",
            "                              macro avg       0.68      0.69      0.68       464\n",
            "                           weighted avg       0.69      0.69      0.68       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Handle NaN values in the 'Label' column\n",
        "df['Label'].fillna('default_label', inplace=True)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and validation data\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 15\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4HFfNu1E5J6",
        "outputId": "a7d17841-401e-42c2-db69-793a2a9fdfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-43-b2e81f2ef97b>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Batch Loss: 1.748457908630371, Average Training Loss: 1.748457908630371, Training Accuracy: 0.109375\n",
            "Epoch 1/15, Batch Loss: 1.596543788909912, Average Training Loss: 1.6725008487701416, Training Accuracy: 0.2109375\n",
            "Epoch 1/15, Batch Loss: 1.6306307315826416, Average Training Loss: 1.6585441430409749, Training Accuracy: 0.19791666666666666\n",
            "Epoch 1/15, Batch Loss: 1.6481775045394897, Average Training Loss: 1.6559524834156036, Training Accuracy: 0.1875\n",
            "Epoch 1/15, Batch Loss: 1.610304594039917, Average Training Loss: 1.6468229055404664, Training Accuracy: 0.203125\n",
            "Epoch 1/15, Batch Loss: 1.5896228551864624, Average Training Loss: 1.637289563814799, Training Accuracy: 0.21354166666666666\n",
            "Epoch 1/15, Batch Loss: 1.6083388328552246, Average Training Loss: 1.6331537451062883, Training Accuracy: 0.22098214285714285\n",
            "Epoch 1/15, Batch Loss: 1.5885634422302246, Average Training Loss: 1.6275799572467804, Training Accuracy: 0.22265625\n",
            "Epoch 1/15, Batch Loss: 1.6194385290145874, Average Training Loss: 1.62667535410987, Training Accuracy: 0.2204861111111111\n",
            "Epoch 1/15, Batch Loss: 1.6154905557632446, Average Training Loss: 1.6255568742752076, Training Accuracy: 0.215625\n",
            "Epoch 1/15, Batch Loss: 1.5923619270324707, Average Training Loss: 1.622539151798595, Training Accuracy: 0.21732954545454544\n",
            "Epoch 1/15, Batch Loss: 1.5787394046783447, Average Training Loss: 1.6188891728719075, Training Accuracy: 0.22135416666666666\n",
            "Epoch 1/15, Batch Loss: 1.5999945402145386, Average Training Loss: 1.6174357395905714, Training Accuracy: 0.21995192307692307\n",
            "Epoch 1/15, Batch Loss: 1.5759998559951782, Average Training Loss: 1.614476033619472, Training Accuracy: 0.22767857142857142\n",
            "Epoch 1/15, Batch Loss: 1.5272765159606934, Average Training Loss: 1.60866273244222, Training Accuracy: 0.23541666666666666\n",
            "Epoch 1/15, Batch Loss: 1.5732502937316895, Average Training Loss: 1.606449455022812, Training Accuracy: 0.2392578125\n",
            "Epoch 1/15, Batch Loss: 1.5233972072601318, Average Training Loss: 1.6015640286838306, Training Accuracy: 0.24540441176470587\n",
            "Epoch 1/15, Batch Loss: 1.5758901834487915, Average Training Loss: 1.6001377039485507, Training Accuracy: 0.24479166666666666\n",
            "Epoch 1/15, Batch Loss: 1.5053937435150146, Average Training Loss: 1.5951511797152067, Training Accuracy: 0.25082236842105265\n",
            "Epoch 1/15, Batch Loss: 1.4996638298034668, Average Training Loss: 1.5903768122196198, Training Accuracy: 0.25859375\n",
            "Epoch 1/15, Batch Loss: 1.5125905275344849, Average Training Loss: 1.5866727034250896, Training Accuracy: 0.26264880952380953\n",
            "Epoch 1/15, Batch Loss: 1.5320698022842407, Average Training Loss: 1.5841907533732327, Training Accuracy: 0.2634943181818182\n",
            "Epoch 1/15, Batch Loss: 1.4753024578094482, Average Training Loss: 1.5794564796530681, Training Accuracy: 0.26766304347826086\n",
            "Epoch 1/15, Batch Loss: 1.5778403282165527, Average Training Loss: 1.57938914000988, Training Accuracy: 0.2669270833333333\n",
            "Epoch 1/15, Batch Loss: 1.4614185094833374, Average Training Loss: 1.5746703147888184, Training Accuracy: 0.27625\n",
            "Epoch 1/15, Batch Loss: 1.4763548374176025, Average Training Loss: 1.570888950274541, Training Accuracy: 0.28125\n",
            "Epoch 1/15, Batch Loss: 1.4493683576583862, Average Training Loss: 1.5663881875850536, Training Accuracy: 0.28587962962962965\n",
            "Epoch 1/15, Batch Loss: 1.447570562362671, Average Training Loss: 1.5621447009699685, Training Accuracy: 0.29073660714285715\n",
            "Epoch 1/15, Batch Loss: 1.401685118675232, Average Training Loss: 1.5566116119253224, Training Accuracy: 0.2984913793103448\n",
            "Epoch 1/15, Average Training Loss: 1.5566116119253224, Training Accuracy: 0.2984913793103448\n",
            "Epoch 1/15, Validation Loss: 11.055947065353394, Validation Accuracy: 0.5301724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.35      0.47        99\n",
            "                Educational Opportunity       0.41      0.49      0.45        87\n",
            "                         Family Support       0.52      0.71      0.60        93\n",
            "                      Financial Support       0.47      0.66      0.55        89\n",
            "                 Program Implementation       0.74      0.45      0.56        96\n",
            "\n",
            "                               accuracy                           0.53       464\n",
            "                              macro avg       0.57      0.53      0.53       464\n",
            "                           weighted avg       0.57      0.53      0.53       464\n",
            "\n",
            "Epoch 2/15, Batch Loss: 1.3819708824157715, Average Training Loss: 1.3819708824157715, Training Accuracy: 0.5\n",
            "Epoch 2/15, Batch Loss: 1.4180734157562256, Average Training Loss: 1.4000221490859985, Training Accuracy: 0.5\n",
            "Epoch 2/15, Batch Loss: 1.359025239944458, Average Training Loss: 1.386356512705485, Training Accuracy: 0.484375\n",
            "Epoch 2/15, Batch Loss: 1.2383301258087158, Average Training Loss: 1.3493499159812927, Training Accuracy: 0.515625\n",
            "Epoch 2/15, Batch Loss: 1.4193947315216064, Average Training Loss: 1.3633588790893554, Training Accuracy: 0.49375\n",
            "Epoch 2/15, Batch Loss: 1.3397549390792847, Average Training Loss: 1.359424889087677, Training Accuracy: 0.4869791666666667\n",
            "Epoch 2/15, Batch Loss: 1.3220250606536865, Average Training Loss: 1.3540820564542497, Training Accuracy: 0.48214285714285715\n",
            "Epoch 2/15, Batch Loss: 1.2675201892852783, Average Training Loss: 1.3432618230581284, Training Accuracy: 0.5\n",
            "Epoch 2/15, Batch Loss: 1.3426858186721802, Average Training Loss: 1.3431978225708008, Training Accuracy: 0.5\n",
            "Epoch 2/15, Batch Loss: 1.3060888051986694, Average Training Loss: 1.3394869208335876, Training Accuracy: 0.509375\n",
            "Epoch 2/15, Batch Loss: 1.251579761505127, Average Training Loss: 1.3314953608946367, Training Accuracy: 0.5170454545454546\n",
            "Epoch 2/15, Batch Loss: 1.1898201704025269, Average Training Loss: 1.3196890950202942, Training Accuracy: 0.5260416666666666\n",
            "Epoch 2/15, Batch Loss: 1.10865318775177, Average Training Loss: 1.3034555636919463, Training Accuracy: 0.5384615384615384\n",
            "Epoch 2/15, Batch Loss: 1.2368208169937134, Average Training Loss: 1.2986959389277868, Training Accuracy: 0.5323660714285714\n",
            "Epoch 2/15, Batch Loss: 1.2525854110717773, Average Training Loss: 1.2956219037373862, Training Accuracy: 0.5364583333333334\n",
            "Epoch 2/15, Batch Loss: 1.2513352632522583, Average Training Loss: 1.2928539887070656, Training Accuracy: 0.537109375\n",
            "Epoch 2/15, Batch Loss: 1.1733253002166748, Average Training Loss: 1.2858228893841015, Training Accuracy: 0.5376838235294118\n",
            "Epoch 2/15, Batch Loss: 1.1934947967529297, Average Training Loss: 1.2806935509045918, Training Accuracy: 0.5425347222222222\n",
            "Epoch 2/15, Batch Loss: 1.1874796152114868, Average Training Loss: 1.2757875542891652, Training Accuracy: 0.5452302631578947\n",
            "Epoch 2/15, Batch Loss: 1.2177239656448364, Average Training Loss: 1.272884374856949, Training Accuracy: 0.546875\n",
            "Epoch 2/15, Batch Loss: 1.1153788566589355, Average Training Loss: 1.2653841120856149, Training Accuracy: 0.5498511904761905\n",
            "Epoch 2/15, Batch Loss: 1.1489591598510742, Average Training Loss: 1.2600920688022266, Training Accuracy: 0.5518465909090909\n",
            "Epoch 2/15, Batch Loss: 1.1634758710861206, Average Training Loss: 1.2558913645537004, Training Accuracy: 0.5523097826086957\n",
            "Epoch 2/15, Batch Loss: 1.1765837669372559, Average Training Loss: 1.2525868813196819, Training Accuracy: 0.5559895833333334\n",
            "Epoch 2/15, Batch Loss: 1.100005030632019, Average Training Loss: 1.2464836072921752, Training Accuracy: 0.558125\n",
            "Epoch 2/15, Batch Loss: 1.118868112564087, Average Training Loss: 1.2415753190334027, Training Accuracy: 0.5600961538461539\n",
            "Epoch 2/15, Batch Loss: 1.0799933671951294, Average Training Loss: 1.2355908022986517, Training Accuracy: 0.5636574074074074\n",
            "Epoch 2/15, Batch Loss: 1.136531114578247, Average Training Loss: 1.2320529563086373, Training Accuracy: 0.5658482142857143\n",
            "Epoch 2/15, Batch Loss: 1.0704001188278198, Average Training Loss: 1.2264787205334367, Training Accuracy: 0.568426724137931\n",
            "Epoch 2/15, Average Training Loss: 1.2264787205334367, Training Accuracy: 0.568426724137931\n",
            "Epoch 2/15, Validation Loss: 8.192364692687988, Validation Accuracy: 0.625\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.46      0.55        99\n",
            "                Educational Opportunity       0.39      0.46      0.42        87\n",
            "                         Family Support       0.71      0.99      0.83        93\n",
            "                      Financial Support       0.67      0.71      0.69        89\n",
            "                 Program Implementation       0.71      0.51      0.59        96\n",
            "\n",
            "                               accuracy                           0.62       464\n",
            "                              macro avg       0.63      0.63      0.62       464\n",
            "                           weighted avg       0.63      0.62      0.62       464\n",
            "\n",
            "Epoch 3/15, Batch Loss: 0.9472957849502563, Average Training Loss: 0.9472957849502563, Training Accuracy: 0.71875\n",
            "Epoch 3/15, Batch Loss: 1.1168019771575928, Average Training Loss: 1.0320488810539246, Training Accuracy: 0.640625\n",
            "Epoch 3/15, Batch Loss: 0.993701159954071, Average Training Loss: 1.0192663073539734, Training Accuracy: 0.65625\n",
            "Epoch 3/15, Batch Loss: 0.9075160622596741, Average Training Loss: 0.9913287460803986, Training Accuracy: 0.67578125\n",
            "Epoch 3/15, Batch Loss: 1.012863278388977, Average Training Loss: 0.9956356525421143, Training Accuracy: 0.66875\n",
            "Epoch 3/15, Batch Loss: 0.8173890709877014, Average Training Loss: 0.9659278889497122, Training Accuracy: 0.6875\n",
            "Epoch 3/15, Batch Loss: 1.0361016988754272, Average Training Loss: 0.9759527189391, Training Accuracy: 0.6785714285714286\n",
            "Epoch 3/15, Batch Loss: 0.8646907806396484, Average Training Loss: 0.9620449766516685, Training Accuracy: 0.68359375\n",
            "Epoch 3/15, Batch Loss: 0.9111738801002502, Average Training Loss: 0.9563926325903999, Training Accuracy: 0.6857638888888888\n",
            "Epoch 3/15, Batch Loss: 1.1007782220840454, Average Training Loss: 0.9708311915397644, Training Accuracy: 0.671875\n",
            "Epoch 3/15, Batch Loss: 0.8982179164886475, Average Training Loss: 0.9642299847169356, Training Accuracy: 0.6775568181818182\n",
            "Epoch 3/15, Batch Loss: 0.9248300194740295, Average Training Loss: 0.9609466542800268, Training Accuracy: 0.6809895833333334\n",
            "Epoch 3/15, Batch Loss: 0.9377235174179077, Average Training Loss: 0.9591602591367868, Training Accuracy: 0.6766826923076923\n",
            "Epoch 3/15, Batch Loss: 0.9278548359870911, Average Training Loss: 0.9569241574832371, Training Accuracy: 0.6763392857142857\n",
            "Epoch 3/15, Batch Loss: 0.9423386454582214, Average Training Loss: 0.9559517900149027, Training Accuracy: 0.675\n",
            "Epoch 3/15, Batch Loss: 0.8081885576248169, Average Training Loss: 0.9467165879905224, Training Accuracy: 0.6767578125\n",
            "Epoch 3/15, Batch Loss: 0.792506217956543, Average Training Loss: 0.9376453897532295, Training Accuracy: 0.6829044117647058\n",
            "Epoch 3/15, Batch Loss: 0.9283854365348816, Average Training Loss: 0.9371309479077657, Training Accuracy: 0.6822916666666666\n",
            "Epoch 3/15, Batch Loss: 0.8376458883285522, Average Training Loss: 0.9318948921404386, Training Accuracy: 0.6825657894736842\n",
            "Epoch 3/15, Batch Loss: 0.9496189951896667, Average Training Loss: 0.9327810972929, Training Accuracy: 0.6796875\n",
            "Epoch 3/15, Batch Loss: 1.089045524597168, Average Training Loss: 0.9402222604978652, Training Accuracy: 0.6733630952380952\n",
            "Epoch 3/15, Batch Loss: 1.0273196697235107, Average Training Loss: 0.9441812336444855, Training Accuracy: 0.6711647727272727\n",
            "Epoch 3/15, Batch Loss: 1.167336106300354, Average Training Loss: 0.953883619412132, Training Accuracy: 0.6637228260869565\n",
            "Epoch 3/15, Batch Loss: 0.8966960310935974, Average Training Loss: 0.951500803232193, Training Accuracy: 0.6653645833333334\n",
            "Epoch 3/15, Batch Loss: 0.9694160223007202, Average Training Loss: 0.952217411994934, Training Accuracy: 0.665625\n",
            "Epoch 3/15, Batch Loss: 0.8967705368995667, Average Training Loss: 0.9500848398758814, Training Accuracy: 0.6646634615384616\n",
            "Epoch 3/15, Batch Loss: 0.8854788541793823, Average Training Loss: 0.947692025590826, Training Accuracy: 0.6626157407407407\n",
            "Epoch 3/15, Batch Loss: 0.9253051280975342, Average Training Loss: 0.9468924935374942, Training Accuracy: 0.6640625\n",
            "Epoch 3/15, Batch Loss: 0.9738598465919495, Average Training Loss: 0.9478224022635098, Training Accuracy: 0.662176724137931\n",
            "Epoch 3/15, Average Training Loss: 0.9478224022635098, Training Accuracy: 0.662176724137931\n",
            "Epoch 3/15, Validation Loss: 7.045260667800903, Validation Accuracy: 0.6573275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.66      0.67        99\n",
            "                Educational Opportunity       0.43      0.46      0.45        87\n",
            "                         Family Support       0.76      0.97      0.85        93\n",
            "                      Financial Support       0.69      0.67      0.68        89\n",
            "                 Program Implementation       0.71      0.52      0.60        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 4/15, Batch Loss: 0.6361142992973328, Average Training Loss: 0.6361142992973328, Training Accuracy: 0.8125\n",
            "Epoch 4/15, Batch Loss: 0.880319356918335, Average Training Loss: 0.7582168281078339, Training Accuracy: 0.7265625\n",
            "Epoch 4/15, Batch Loss: 0.8194445967674255, Average Training Loss: 0.7786260843276978, Training Accuracy: 0.7083333333333334\n",
            "Epoch 4/15, Batch Loss: 0.8641724586486816, Average Training Loss: 0.8000126779079437, Training Accuracy: 0.7109375\n",
            "Epoch 4/15, Batch Loss: 0.6612216830253601, Average Training Loss: 0.772254478931427, Training Accuracy: 0.71875\n",
            "Epoch 4/15, Batch Loss: 0.8296955823898315, Average Training Loss: 0.7818279961744944, Training Accuracy: 0.7161458333333334\n",
            "Epoch 4/15, Batch Loss: 0.7909215688705444, Average Training Loss: 0.7831270779882159, Training Accuracy: 0.7209821428571429\n",
            "Epoch 4/15, Batch Loss: 0.7130081653594971, Average Training Loss: 0.774362213909626, Training Accuracy: 0.724609375\n",
            "Epoch 4/15, Batch Loss: 0.8792975544929504, Average Training Loss: 0.7860216961966621, Training Accuracy: 0.7170138888888888\n",
            "Epoch 4/15, Batch Loss: 0.7070503830909729, Average Training Loss: 0.7781245648860932, Training Accuracy: 0.7265625\n",
            "Epoch 4/15, Batch Loss: 0.7893949151039124, Average Training Loss: 0.7791491421786222, Training Accuracy: 0.7272727272727273\n",
            "Epoch 4/15, Batch Loss: 0.8090835213661194, Average Training Loss: 0.7816436737775803, Training Accuracy: 0.7252604166666666\n",
            "Epoch 4/15, Batch Loss: 0.7146176099777222, Average Training Loss: 0.7764878227160528, Training Accuracy: 0.7283653846153846\n",
            "Epoch 4/15, Batch Loss: 0.7497172951698303, Average Training Loss: 0.7745756421770368, Training Accuracy: 0.7276785714285714\n",
            "Epoch 4/15, Batch Loss: 0.8319756984710693, Average Training Loss: 0.778402312596639, Training Accuracy: 0.728125\n",
            "Epoch 4/15, Batch Loss: 0.8263727426528931, Average Training Loss: 0.7814004644751549, Training Accuracy: 0.7265625\n",
            "Epoch 4/15, Batch Loss: 0.9258000254631042, Average Training Loss: 0.7898945562979754, Training Accuracy: 0.7224264705882353\n",
            "Epoch 4/15, Batch Loss: 0.7241572141647339, Average Training Loss: 0.7862424817350175, Training Accuracy: 0.7222222222222222\n",
            "Epoch 4/15, Batch Loss: 0.7871758937835693, Average Training Loss: 0.7862916086849413, Training Accuracy: 0.7236842105263158\n",
            "Epoch 4/15, Batch Loss: 0.7419131398200989, Average Training Loss: 0.7840726852416993, Training Accuracy: 0.7265625\n",
            "Epoch 4/15, Batch Loss: 0.7805711030960083, Average Training Loss: 0.7839059432347616, Training Accuracy: 0.7254464285714286\n",
            "Epoch 4/15, Batch Loss: 0.7159185409545898, Average Training Loss: 0.7808156067674811, Training Accuracy: 0.7279829545454546\n",
            "Epoch 4/15, Batch Loss: 0.7873020172119141, Average Training Loss: 0.7810976246128911, Training Accuracy: 0.7269021739130435\n",
            "Epoch 4/15, Batch Loss: 0.6838452219963074, Average Training Loss: 0.7770454411705335, Training Accuracy: 0.73046875\n",
            "Epoch 4/15, Batch Loss: 0.7610307931900024, Average Training Loss: 0.7764048552513123, Training Accuracy: 0.73125\n",
            "Epoch 4/15, Batch Loss: 0.6605046391487122, Average Training Loss: 0.7719471546319815, Training Accuracy: 0.7319711538461539\n",
            "Epoch 4/15, Batch Loss: 0.7574993968009949, Average Training Loss: 0.771412052490093, Training Accuracy: 0.7314814814814815\n",
            "Epoch 4/15, Batch Loss: 0.8520826697349548, Average Training Loss: 0.7742931459631238, Training Accuracy: 0.7315848214285714\n",
            "Epoch 4/15, Batch Loss: 0.6531143188476562, Average Training Loss: 0.7701145657177629, Training Accuracy: 0.7338362068965517\n",
            "Epoch 4/15, Average Training Loss: 0.7701145657177629, Training Accuracy: 0.7338362068965517\n",
            "Epoch 4/15, Validation Loss: 7.054534018039703, Validation Accuracy: 0.6637931034482759\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.70      0.69        99\n",
            "                Educational Opportunity       0.44      0.47      0.46        87\n",
            "                         Family Support       0.75      0.96      0.84        93\n",
            "                      Financial Support       0.69      0.69      0.69        89\n",
            "                 Program Implementation       0.75      0.50      0.60        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.67      0.66      0.66       464\n",
            "\n",
            "Epoch 5/15, Batch Loss: 0.6002843379974365, Average Training Loss: 0.6002843379974365, Training Accuracy: 0.84375\n",
            "Epoch 5/15, Batch Loss: 0.7125524282455444, Average Training Loss: 0.6564183831214905, Training Accuracy: 0.8125\n",
            "Epoch 5/15, Batch Loss: 0.6250454187393188, Average Training Loss: 0.6459607283274332, Training Accuracy: 0.7864583333333334\n",
            "Epoch 5/15, Batch Loss: 0.6547279357910156, Average Training Loss: 0.6481525301933289, Training Accuracy: 0.78125\n",
            "Epoch 5/15, Batch Loss: 0.6848254799842834, Average Training Loss: 0.6554871201515198, Training Accuracy: 0.7875\n",
            "Epoch 5/15, Batch Loss: 0.6785421967506409, Average Training Loss: 0.6593296329180399, Training Accuracy: 0.7890625\n",
            "Epoch 5/15, Batch Loss: 0.5175560712814331, Average Training Loss: 0.6390762669699532, Training Accuracy: 0.8013392857142857\n",
            "Epoch 5/15, Batch Loss: 0.7404983639717102, Average Training Loss: 0.6517540290951729, Training Accuracy: 0.791015625\n",
            "Epoch 5/15, Batch Loss: 0.6696127653121948, Average Training Loss: 0.6537383331192864, Training Accuracy: 0.7881944444444444\n",
            "Epoch 5/15, Batch Loss: 0.5706590414047241, Average Training Loss: 0.6454304039478302, Training Accuracy: 0.7859375\n",
            "Epoch 5/15, Batch Loss: 0.8865490555763245, Average Training Loss: 0.6673502813686024, Training Accuracy: 0.7755681818181818\n",
            "Epoch 5/15, Batch Loss: 0.5528031587600708, Average Training Loss: 0.6578046878178915, Training Accuracy: 0.7760416666666666\n",
            "Epoch 5/15, Batch Loss: 0.6628962159156799, Average Training Loss: 0.6581963438254136, Training Accuracy: 0.7728365384615384\n",
            "Epoch 5/15, Batch Loss: 0.5328996181488037, Average Training Loss: 0.6492465777056557, Training Accuracy: 0.7756696428571429\n",
            "Epoch 5/15, Batch Loss: 0.6103998422622681, Average Training Loss: 0.6466567953427632, Training Accuracy: 0.7791666666666667\n",
            "Epoch 5/15, Batch Loss: 0.6116087436676025, Average Training Loss: 0.6444662921130657, Training Accuracy: 0.7861328125\n",
            "Epoch 5/15, Batch Loss: 0.7884265184402466, Average Training Loss: 0.6529345407205469, Training Accuracy: 0.7821691176470589\n",
            "Epoch 5/15, Batch Loss: 0.6505898237228394, Average Training Loss: 0.6528042786651187, Training Accuracy: 0.7803819444444444\n",
            "Epoch 5/15, Batch Loss: 0.6041173338890076, Average Training Loss: 0.6502418078874287, Training Accuracy: 0.7804276315789473\n",
            "Epoch 5/15, Batch Loss: 0.743679940700531, Average Training Loss: 0.6549137145280838, Training Accuracy: 0.78046875\n",
            "Epoch 5/15, Batch Loss: 0.6815348863601685, Average Training Loss: 0.6561813893772307, Training Accuracy: 0.7790178571428571\n",
            "Epoch 5/15, Batch Loss: 0.6897965669631958, Average Training Loss: 0.6577093519947745, Training Accuracy: 0.7798295454545454\n",
            "Epoch 5/15, Batch Loss: 0.5654555559158325, Average Training Loss: 0.6536983173826466, Training Accuracy: 0.7819293478260869\n",
            "Epoch 5/15, Batch Loss: 0.67877197265625, Average Training Loss: 0.6547430530190468, Training Accuracy: 0.78125\n",
            "Epoch 5/15, Batch Loss: 0.5215146541595459, Average Training Loss: 0.6494139170646668, Training Accuracy: 0.7825\n",
            "Epoch 5/15, Batch Loss: 0.6557775139808655, Average Training Loss: 0.6496586707922128, Training Accuracy: 0.7824519230769231\n",
            "Epoch 5/15, Batch Loss: 0.596190869808197, Average Training Loss: 0.647678381866879, Training Accuracy: 0.7829861111111112\n",
            "Epoch 5/15, Batch Loss: 0.6646472811698914, Average Training Loss: 0.6482844139848437, Training Accuracy: 0.7840401785714286\n",
            "Epoch 5/15, Batch Loss: 0.6714569330215454, Average Training Loss: 0.6490834663654196, Training Accuracy: 0.7817887931034483\n",
            "Epoch 5/15, Average Training Loss: 0.6490834663654196, Training Accuracy: 0.7817887931034483\n",
            "Epoch 5/15, Validation Loss: 6.915535807609558, Validation Accuracy: 0.6681034482758621\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.65      0.67        99\n",
            "                Educational Opportunity       0.45      0.51      0.48        87\n",
            "                         Family Support       0.80      0.91      0.85        93\n",
            "                      Financial Support       0.66      0.70      0.68        89\n",
            "                 Program Implementation       0.75      0.57      0.65        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.67      0.67      0.67       464\n",
            "                           weighted avg       0.67      0.67      0.67       464\n",
            "\n",
            "Epoch 6/15, Batch Loss: 0.6304668188095093, Average Training Loss: 0.6304668188095093, Training Accuracy: 0.78125\n",
            "Epoch 6/15, Batch Loss: 0.545193076133728, Average Training Loss: 0.5878299474716187, Training Accuracy: 0.8046875\n",
            "Epoch 6/15, Batch Loss: 0.42840147018432617, Average Training Loss: 0.5346871217091879, Training Accuracy: 0.8385416666666666\n",
            "Epoch 6/15, Batch Loss: 0.4686453938484192, Average Training Loss: 0.5181766897439957, Training Accuracy: 0.8515625\n",
            "Epoch 6/15, Batch Loss: 0.5371877551078796, Average Training Loss: 0.5219789028167725, Training Accuracy: 0.8375\n",
            "Epoch 6/15, Batch Loss: 0.4336373209953308, Average Training Loss: 0.5072553058465322, Training Accuracy: 0.84375\n",
            "Epoch 6/15, Batch Loss: 0.6355010867118835, Average Training Loss: 0.5255761316844395, Training Accuracy: 0.8370535714285714\n",
            "Epoch 6/15, Batch Loss: 0.5842790007591248, Average Training Loss: 0.5329139903187752, Training Accuracy: 0.828125\n",
            "Epoch 6/15, Batch Loss: 0.4374322295188904, Average Training Loss: 0.5223049057854546, Training Accuracy: 0.8315972222222222\n",
            "Epoch 6/15, Batch Loss: 0.6284680366516113, Average Training Loss: 0.5329212188720703, Training Accuracy: 0.8296875\n",
            "Epoch 6/15, Batch Loss: 0.534946084022522, Average Training Loss: 0.5331052975221113, Training Accuracy: 0.8295454545454546\n",
            "Epoch 6/15, Batch Loss: 0.4543193280696869, Average Training Loss: 0.5265398000677427, Training Accuracy: 0.83203125\n",
            "Epoch 6/15, Batch Loss: 0.47753027081489563, Average Training Loss: 0.5227698362790622, Training Accuracy: 0.8317307692307693\n",
            "Epoch 6/15, Batch Loss: 0.7064087986946106, Average Training Loss: 0.5358869050230298, Training Accuracy: 0.8292410714285714\n",
            "Epoch 6/15, Batch Loss: 0.5163516402244568, Average Training Loss: 0.5345845540364583, Training Accuracy: 0.83125\n",
            "Epoch 6/15, Batch Loss: 0.5416419506072998, Average Training Loss: 0.5350256413221359, Training Accuracy: 0.8330078125\n",
            "Epoch 6/15, Batch Loss: 0.5769845843315125, Average Training Loss: 0.5374938144403345, Training Accuracy: 0.8354779411764706\n",
            "Epoch 6/15, Batch Loss: 0.6133647561073303, Average Training Loss: 0.5417088667551676, Training Accuracy: 0.8333333333333334\n",
            "Epoch 6/15, Batch Loss: 0.4510565996170044, Average Training Loss: 0.5369376948005274, Training Accuracy: 0.8363486842105263\n",
            "Epoch 6/15, Batch Loss: 0.6277216076850891, Average Training Loss: 0.5414768904447556, Training Accuracy: 0.8328125\n",
            "Epoch 6/15, Batch Loss: 0.4784643054008484, Average Training Loss: 0.5384762911569505, Training Accuracy: 0.8348214285714286\n",
            "Epoch 6/15, Batch Loss: 0.4689294099807739, Average Training Loss: 0.535315069285306, Training Accuracy: 0.8373579545454546\n",
            "Epoch 6/15, Batch Loss: 0.4512893855571747, Average Training Loss: 0.5316617786884308, Training Accuracy: 0.8396739130434783\n",
            "Epoch 6/15, Batch Loss: 0.4678296744823456, Average Training Loss: 0.5290021076798439, Training Accuracy: 0.8385416666666666\n",
            "Epoch 6/15, Batch Loss: 0.46100080013275146, Average Training Loss: 0.5262820553779602, Training Accuracy: 0.83875\n",
            "Epoch 6/15, Batch Loss: 0.36745965480804443, Average Training Loss: 0.5201735015098865, Training Accuracy: 0.8413461538461539\n",
            "Epoch 6/15, Batch Loss: 0.5164519548416138, Average Training Loss: 0.5200356664480986, Training Accuracy: 0.8414351851851852\n",
            "Epoch 6/15, Batch Loss: 0.47738492488861084, Average Training Loss: 0.518512425678117, Training Accuracy: 0.8426339285714286\n",
            "Epoch 6/15, Batch Loss: 0.595335841178894, Average Training Loss: 0.5211615089712471, Training Accuracy: 0.8405172413793104\n",
            "Epoch 6/15, Average Training Loss: 0.5211615089712471, Training Accuracy: 0.8405172413793104\n",
            "Epoch 6/15, Validation Loss: 7.148007869720459, Validation Accuracy: 0.6616379310344828\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.66      0.67        99\n",
            "                Educational Opportunity       0.46      0.46      0.46        87\n",
            "                         Family Support       0.80      0.89      0.84        93\n",
            "                      Financial Support       0.65      0.66      0.66        89\n",
            "                 Program Implementation       0.69      0.62      0.66        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.66      0.66      0.66       464\n",
            "\n",
            "Epoch 7/15, Batch Loss: 0.348404198884964, Average Training Loss: 0.348404198884964, Training Accuracy: 0.921875\n",
            "Epoch 7/15, Batch Loss: 0.4923667013645172, Average Training Loss: 0.4203854501247406, Training Accuracy: 0.890625\n",
            "Epoch 7/15, Batch Loss: 0.5637655258178711, Average Training Loss: 0.46817880868911743, Training Accuracy: 0.890625\n",
            "Epoch 7/15, Batch Loss: 0.32783156633377075, Average Training Loss: 0.43309199810028076, Training Accuracy: 0.90234375\n",
            "Epoch 7/15, Batch Loss: 0.3108501136302948, Average Training Loss: 0.40864362120628356, Training Accuracy: 0.909375\n",
            "Epoch 7/15, Batch Loss: 0.49027130007743835, Average Training Loss: 0.422248234351476, Training Accuracy: 0.9036458333333334\n",
            "Epoch 7/15, Batch Loss: 0.37996765971183777, Average Training Loss: 0.41620815226009916, Training Accuracy: 0.90625\n",
            "Epoch 7/15, Batch Loss: 0.4021693170070648, Average Training Loss: 0.41445329785346985, Training Accuracy: 0.8984375\n",
            "Epoch 7/15, Batch Loss: 0.32714876532554626, Average Training Loss: 0.40475279423925614, Training Accuracy: 0.9027777777777778\n",
            "Epoch 7/15, Batch Loss: 0.3876248002052307, Average Training Loss: 0.40303999483585357, Training Accuracy: 0.8984375\n",
            "Epoch 7/15, Batch Loss: 0.35941797494888306, Average Training Loss: 0.3990743566643108, Training Accuracy: 0.8991477272727273\n",
            "Epoch 7/15, Batch Loss: 0.35457226634025574, Average Training Loss: 0.3953658491373062, Training Accuracy: 0.8984375\n",
            "Epoch 7/15, Batch Loss: 0.3290664553642273, Average Training Loss: 0.3902658957701463, Training Accuracy: 0.8978365384615384\n",
            "Epoch 7/15, Batch Loss: 0.3756614327430725, Average Training Loss: 0.389222719839641, Training Accuracy: 0.8984375\n",
            "Epoch 7/15, Batch Loss: 0.521111249923706, Average Training Loss: 0.39801528851191204, Training Accuracy: 0.89375\n",
            "Epoch 7/15, Batch Loss: 0.5631569623947144, Average Training Loss: 0.4083366431295872, Training Accuracy: 0.8896484375\n",
            "Epoch 7/15, Batch Loss: 0.597318708896637, Average Training Loss: 0.4194532352335313, Training Accuracy: 0.8841911764705882\n",
            "Epoch 7/15, Batch Loss: 0.35835379362106323, Average Training Loss: 0.4160588218106164, Training Accuracy: 0.8854166666666666\n",
            "Epoch 7/15, Batch Loss: 0.42162686586380005, Average Training Loss: 0.41635187676078395, Training Accuracy: 0.8865131578947368\n",
            "Epoch 7/15, Batch Loss: 0.5186512470245361, Average Training Loss: 0.42146684527397155, Training Accuracy: 0.8828125\n",
            "Epoch 7/15, Batch Loss: 0.31622636318206787, Average Training Loss: 0.41645539374578566, Training Accuracy: 0.8854166666666666\n",
            "Epoch 7/15, Batch Loss: 0.5394735336303711, Average Training Loss: 0.4220471273769032, Training Accuracy: 0.8821022727272727\n",
            "Epoch 7/15, Batch Loss: 0.31519803404808044, Average Training Loss: 0.41740151462347613, Training Accuracy: 0.8831521739130435\n",
            "Epoch 7/15, Batch Loss: 0.379210501909256, Average Training Loss: 0.4158102224270503, Training Accuracy: 0.8834635416666666\n",
            "Epoch 7/15, Batch Loss: 0.48919135332107544, Average Training Loss: 0.4187454676628113, Training Accuracy: 0.880625\n",
            "Epoch 7/15, Batch Loss: 0.5105165243148804, Average Training Loss: 0.4222751236878909, Training Accuracy: 0.8780048076923077\n",
            "Epoch 7/15, Batch Loss: 0.3919880986213684, Average Training Loss: 0.4211533820187604, Training Accuracy: 0.8784722222222222\n",
            "Epoch 7/15, Batch Loss: 0.38011807203292847, Average Training Loss: 0.41968783523355213, Training Accuracy: 0.8794642857142857\n",
            "Epoch 7/15, Batch Loss: 0.5103988647460938, Average Training Loss: 0.42281580176846734, Training Accuracy: 0.8787715517241379\n",
            "Epoch 7/15, Average Training Loss: 0.42281580176846734, Training Accuracy: 0.8787715517241379\n",
            "Epoch 7/15, Validation Loss: 7.53688770532608, Validation Accuracy: 0.6551724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.61      0.66        99\n",
            "                Educational Opportunity       0.46      0.49      0.48        87\n",
            "                         Family Support       0.77      0.90      0.83        93\n",
            "                      Financial Support       0.63      0.70      0.66        89\n",
            "                 Program Implementation       0.69      0.57      0.62        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 8/15, Batch Loss: 0.3561001121997833, Average Training Loss: 0.3561001121997833, Training Accuracy: 0.90625\n",
            "Epoch 8/15, Batch Loss: 0.36126065254211426, Average Training Loss: 0.3586803823709488, Training Accuracy: 0.8828125\n",
            "Epoch 8/15, Batch Loss: 0.3747759461402893, Average Training Loss: 0.3640455702940623, Training Accuracy: 0.890625\n",
            "Epoch 8/15, Batch Loss: 0.3100374937057495, Average Training Loss: 0.3505435511469841, Training Accuracy: 0.90234375\n",
            "Epoch 8/15, Batch Loss: 0.2702236473560333, Average Training Loss: 0.33447957038879395, Training Accuracy: 0.909375\n",
            "Epoch 8/15, Batch Loss: 0.39699721336364746, Average Training Loss: 0.34489917755126953, Training Accuracy: 0.9036458333333334\n",
            "Epoch 8/15, Batch Loss: 0.24044229090213776, Average Training Loss: 0.32997676517282215, Training Accuracy: 0.9084821428571429\n",
            "Epoch 8/15, Batch Loss: 0.30164143443107605, Average Training Loss: 0.3264348488301039, Training Accuracy: 0.9140625\n",
            "Epoch 8/15, Batch Loss: 0.2526106536388397, Average Training Loss: 0.31823216047551894, Training Accuracy: 0.9149305555555556\n",
            "Epoch 8/15, Batch Loss: 0.40614715218544006, Average Training Loss: 0.3270236596465111, Training Accuracy: 0.9125\n",
            "Epoch 8/15, Batch Loss: 0.36402589082717896, Average Training Loss: 0.3303874988447536, Training Accuracy: 0.9105113636363636\n",
            "Epoch 8/15, Batch Loss: 0.43336087465286255, Average Training Loss: 0.33896861349542934, Training Accuracy: 0.9049479166666666\n",
            "Epoch 8/15, Batch Loss: 0.3813473880290985, Average Training Loss: 0.3422285192287885, Training Accuracy: 0.9014423076923077\n",
            "Epoch 8/15, Batch Loss: 0.4460117518901825, Average Training Loss: 0.34964160727603094, Training Accuracy: 0.8973214285714286\n",
            "Epoch 8/15, Batch Loss: 0.36049485206604004, Average Training Loss: 0.35036515692869824, Training Accuracy: 0.896875\n",
            "Epoch 8/15, Batch Loss: 0.3770986795425415, Average Training Loss: 0.3520360020920634, Training Accuracy: 0.8935546875\n",
            "Epoch 8/15, Batch Loss: 0.35266730189323425, Average Training Loss: 0.35207313737448526, Training Accuracy: 0.8933823529411765\n",
            "Epoch 8/15, Batch Loss: 0.4396257698535919, Average Training Loss: 0.3569371725122134, Training Accuracy: 0.890625\n",
            "Epoch 8/15, Batch Loss: 0.4682813286781311, Average Training Loss: 0.362797391257788, Training Accuracy: 0.8856907894736842\n",
            "Epoch 8/15, Batch Loss: 0.3154037594795227, Average Training Loss: 0.3604277096688747, Training Accuracy: 0.8875\n",
            "Epoch 8/15, Batch Loss: 0.42052772641181946, Average Training Loss: 0.3632896152280626, Training Accuracy: 0.8876488095238095\n",
            "Epoch 8/15, Batch Loss: 0.46906381845474243, Average Training Loss: 0.368097533556548, Training Accuracy: 0.8863636363636364\n",
            "Epoch 8/15, Batch Loss: 0.3177977204322815, Average Training Loss: 0.3659105851598408, Training Accuracy: 0.8879076086956522\n",
            "Epoch 8/15, Batch Loss: 0.3032064139842987, Average Training Loss: 0.36329791136085987, Training Accuracy: 0.8893229166666666\n",
            "Epoch 8/15, Batch Loss: 0.2464417964220047, Average Training Loss: 0.35862366676330565, Training Accuracy: 0.89125\n",
            "Epoch 8/15, Batch Loss: 0.4104121923446655, Average Training Loss: 0.3606155331318195, Training Accuracy: 0.890625\n",
            "Epoch 8/15, Batch Loss: 0.3629692494869232, Average Training Loss: 0.36070270781163816, Training Accuracy: 0.890625\n",
            "Epoch 8/15, Batch Loss: 0.22121647000312805, Average Training Loss: 0.35572105646133423, Training Accuracy: 0.8934151785714286\n",
            "Epoch 8/15, Batch Loss: 0.3857143223285675, Average Training Loss: 0.3567553070084802, Training Accuracy: 0.8927801724137931\n",
            "Epoch 8/15, Average Training Loss: 0.3567553070084802, Training Accuracy: 0.8927801724137931\n",
            "Epoch 8/15, Validation Loss: 7.679285705089569, Validation Accuracy: 0.6487068965517241\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.61      0.64        99\n",
            "                Educational Opportunity       0.48      0.36      0.41        87\n",
            "                         Family Support       0.77      0.91      0.83        93\n",
            "                      Financial Support       0.58      0.71      0.64        89\n",
            "                 Program Implementation       0.67      0.65      0.66        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.64      0.65      0.64       464\n",
            "                           weighted avg       0.64      0.65      0.64       464\n",
            "\n",
            "Epoch 9/15, Batch Loss: 0.363632470369339, Average Training Loss: 0.363632470369339, Training Accuracy: 0.875\n",
            "Epoch 9/15, Batch Loss: 0.3712877929210663, Average Training Loss: 0.36746013164520264, Training Accuracy: 0.875\n",
            "Epoch 9/15, Batch Loss: 0.4580278694629669, Average Training Loss: 0.3976493775844574, Training Accuracy: 0.8697916666666666\n",
            "Epoch 9/15, Batch Loss: 0.2980858385562897, Average Training Loss: 0.37275849282741547, Training Accuracy: 0.87890625\n",
            "Epoch 9/15, Batch Loss: 0.32882681488990784, Average Training Loss: 0.36397215723991394, Training Accuracy: 0.884375\n",
            "Epoch 9/15, Batch Loss: 0.3131919503211975, Average Training Loss: 0.35550878942012787, Training Accuracy: 0.890625\n",
            "Epoch 9/15, Batch Loss: 0.3560739755630493, Average Training Loss: 0.3555895302976881, Training Accuracy: 0.8883928571428571\n",
            "Epoch 9/15, Batch Loss: 0.3195698857307434, Average Training Loss: 0.35108707472682, Training Accuracy: 0.892578125\n",
            "Epoch 9/15, Batch Loss: 0.23873692750930786, Average Training Loss: 0.3386037250359853, Training Accuracy: 0.8975694444444444\n",
            "Epoch 9/15, Batch Loss: 0.4210054278373718, Average Training Loss: 0.346843895316124, Training Accuracy: 0.89375\n",
            "Epoch 9/15, Batch Loss: 0.2620828151702881, Average Training Loss: 0.33913834257559344, Training Accuracy: 0.8977272727272727\n",
            "Epoch 9/15, Batch Loss: 0.3228762745857239, Average Training Loss: 0.3377831702431043, Training Accuracy: 0.8997395833333334\n",
            "Epoch 9/15, Batch Loss: 0.33836013078689575, Average Training Loss: 0.33782755182339597, Training Accuracy: 0.9014423076923077\n",
            "Epoch 9/15, Batch Loss: 0.2367239147424698, Average Training Loss: 0.33060586346047266, Training Accuracy: 0.9040178571428571\n",
            "Epoch 9/15, Batch Loss: 0.334700345993042, Average Training Loss: 0.3308788289626439, Training Accuracy: 0.9041666666666667\n",
            "Epoch 9/15, Batch Loss: 0.23068244755268097, Average Training Loss: 0.32461655512452126, Training Accuracy: 0.90625\n",
            "Epoch 9/15, Batch Loss: 0.24489569664001465, Average Training Loss: 0.31992709286072674, Training Accuracy: 0.9090073529411765\n",
            "Epoch 9/15, Batch Loss: 0.21547245979309082, Average Training Loss: 0.31412405769030255, Training Accuracy: 0.9105902777777778\n",
            "Epoch 9/15, Batch Loss: 0.285823792219162, Average Training Loss: 0.3126345700339267, Training Accuracy: 0.9095394736842105\n",
            "Epoch 9/15, Batch Loss: 0.34143540263175964, Average Training Loss: 0.31407461166381834, Training Accuracy: 0.9078125\n",
            "Epoch 9/15, Batch Loss: 0.32398098707199097, Average Training Loss: 0.3145463438261123, Training Accuracy: 0.90625\n",
            "Epoch 9/15, Batch Loss: 0.23196956515312195, Average Training Loss: 0.3107928538864309, Training Accuracy: 0.9090909090909091\n",
            "Epoch 9/15, Batch Loss: 0.2497079223394394, Average Training Loss: 0.3081369872974313, Training Accuracy: 0.9103260869565217\n",
            "Epoch 9/15, Batch Loss: 0.33527761697769165, Average Training Loss: 0.30926784686744213, Training Accuracy: 0.9088541666666666\n",
            "Epoch 9/15, Batch Loss: 0.2613639831542969, Average Training Loss: 0.30735169231891635, Training Accuracy: 0.91\n",
            "Epoch 9/15, Batch Loss: 0.30231186747550964, Average Training Loss: 0.3071578529018622, Training Accuracy: 0.9110576923076923\n",
            "Epoch 9/15, Batch Loss: 0.2267179638147354, Average Training Loss: 0.30417859775048717, Training Accuracy: 0.9126157407407407\n",
            "Epoch 9/15, Batch Loss: 0.1566689908504486, Average Training Loss: 0.2989103975040572, Training Accuracy: 0.9151785714285714\n",
            "Epoch 9/15, Batch Loss: 0.2026035636663437, Average Training Loss: 0.2955894721993085, Training Accuracy: 0.9164870689655172\n",
            "Epoch 9/15, Average Training Loss: 0.2955894721993085, Training Accuracy: 0.9164870689655172\n",
            "Epoch 9/15, Validation Loss: 7.799053251743317, Validation Accuracy: 0.6616379310344828\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.71      0.68        99\n",
            "                Educational Opportunity       0.45      0.48      0.46        87\n",
            "                         Family Support       0.80      0.90      0.85        93\n",
            "                      Financial Support       0.66      0.64      0.65        89\n",
            "                 Program Implementation       0.74      0.56      0.64        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.67      0.66      0.66       464\n",
            "\n",
            "Epoch 10/15, Batch Loss: 0.27858811616897583, Average Training Loss: 0.27858811616897583, Training Accuracy: 0.90625\n",
            "Epoch 10/15, Batch Loss: 0.23305973410606384, Average Training Loss: 0.25582392513751984, Training Accuracy: 0.9296875\n",
            "Epoch 10/15, Batch Loss: 0.2429019659757614, Average Training Loss: 0.2515166054169337, Training Accuracy: 0.9322916666666666\n",
            "Epoch 10/15, Batch Loss: 0.32422563433647156, Average Training Loss: 0.26969386264681816, Training Accuracy: 0.92578125\n",
            "Epoch 10/15, Batch Loss: 0.22408507764339447, Average Training Loss: 0.2605721056461334, Training Accuracy: 0.928125\n",
            "Epoch 10/15, Batch Loss: 0.2617606222629547, Average Training Loss: 0.26077019174893695, Training Accuracy: 0.9296875\n",
            "Epoch 10/15, Batch Loss: 0.26868462562561035, Average Training Loss: 0.2619008251598903, Training Accuracy: 0.9308035714285714\n",
            "Epoch 10/15, Batch Loss: 0.2629699110984802, Average Training Loss: 0.26203446090221405, Training Accuracy: 0.93359375\n",
            "Epoch 10/15, Batch Loss: 0.3402520418167114, Average Training Loss: 0.2707253032260471, Training Accuracy: 0.9340277777777778\n",
            "Epoch 10/15, Batch Loss: 0.29754558205604553, Average Training Loss: 0.2734073311090469, Training Accuracy: 0.9296875\n",
            "Epoch 10/15, Batch Loss: 0.15295107662677765, Average Training Loss: 0.26245676251974975, Training Accuracy: 0.9332386363636364\n",
            "Epoch 10/15, Batch Loss: 0.1315142810344696, Average Training Loss: 0.25154488906264305, Training Accuracy: 0.9375\n",
            "Epoch 10/15, Batch Loss: 0.14945046603679657, Average Training Loss: 0.2436914719068087, Training Accuracy: 0.9411057692307693\n",
            "Epoch 10/15, Batch Loss: 0.2209182232618332, Average Training Loss: 0.24206481128931046, Training Accuracy: 0.9397321428571429\n",
            "Epoch 10/15, Batch Loss: 0.2471301257610321, Average Training Loss: 0.24240249892075857, Training Accuracy: 0.940625\n",
            "Epoch 10/15, Batch Loss: 0.18777017295360565, Average Training Loss: 0.2389879785478115, Training Accuracy: 0.939453125\n",
            "Epoch 10/15, Batch Loss: 0.14377865195274353, Average Training Loss: 0.2333874299245722, Training Accuracy: 0.9411764705882353\n",
            "Epoch 10/15, Batch Loss: 0.33350473642349243, Average Training Loss: 0.23894950250784555, Training Accuracy: 0.9401041666666666\n",
            "Epoch 10/15, Batch Loss: 0.22466129064559937, Average Training Loss: 0.23819749135720103, Training Accuracy: 0.9399671052631579\n",
            "Epoch 10/15, Batch Loss: 0.2767079174518585, Average Training Loss: 0.2401230126619339, Training Accuracy: 0.93984375\n",
            "Epoch 10/15, Batch Loss: 0.21478815376758575, Average Training Loss: 0.23891659080982208, Training Accuracy: 0.9397321428571429\n",
            "Epoch 10/15, Batch Loss: 0.1858617216348648, Average Training Loss: 0.23650500584732403, Training Accuracy: 0.9410511363636364\n",
            "Epoch 10/15, Batch Loss: 0.24260413646697998, Average Training Loss: 0.23677018543948297, Training Accuracy: 0.9415760869565217\n",
            "Epoch 10/15, Batch Loss: 0.23610417544841766, Average Training Loss: 0.2367424350231886, Training Accuracy: 0.9407552083333334\n",
            "Epoch 10/15, Batch Loss: 0.1518409550189972, Average Training Loss: 0.23334637582302092, Training Accuracy: 0.94125\n",
            "Epoch 10/15, Batch Loss: 0.2994743883609772, Average Training Loss: 0.23588976092063463, Training Accuracy: 0.9393028846153846\n",
            "Epoch 10/15, Batch Loss: 0.22348259389400482, Average Training Loss: 0.23543023621594464, Training Accuracy: 0.9398148148148148\n",
            "Epoch 10/15, Batch Loss: 0.38769400119781494, Average Training Loss: 0.24086822782244002, Training Accuracy: 0.9380580357142857\n",
            "Epoch 10/15, Batch Loss: 0.25559738278388977, Average Training Loss: 0.24137612971766242, Training Accuracy: 0.9369612068965517\n",
            "Epoch 10/15, Average Training Loss: 0.24137612971766242, Training Accuracy: 0.9369612068965517\n",
            "Epoch 10/15, Validation Loss: 8.094214677810669, Validation Accuracy: 0.6508620689655172\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.59      0.64        99\n",
            "                Educational Opportunity       0.45      0.45      0.45        87\n",
            "                         Family Support       0.78      0.90      0.84        93\n",
            "                      Financial Support       0.63      0.70      0.66        89\n",
            "                 Program Implementation       0.67      0.61      0.64        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.65      0.65      0.65       464\n",
            "\n",
            "Epoch 11/15, Batch Loss: 0.24078868329524994, Average Training Loss: 0.24078868329524994, Training Accuracy: 0.9375\n",
            "Epoch 11/15, Batch Loss: 0.19059902429580688, Average Training Loss: 0.2156938537955284, Training Accuracy: 0.9609375\n",
            "Epoch 11/15, Batch Loss: 0.12891599535942078, Average Training Loss: 0.18676790098349252, Training Accuracy: 0.96875\n",
            "Epoch 11/15, Batch Loss: 0.22677414119243622, Average Training Loss: 0.19676946103572845, Training Accuracy: 0.9609375\n",
            "Epoch 11/15, Batch Loss: 0.13180789351463318, Average Training Loss: 0.1837771475315094, Training Accuracy: 0.9625\n",
            "Epoch 11/15, Batch Loss: 0.18185807764530182, Average Training Loss: 0.1834573025504748, Training Accuracy: 0.9609375\n",
            "Epoch 11/15, Batch Loss: 0.1615363210439682, Average Training Loss: 0.18032573376383101, Training Accuracy: 0.9598214285714286\n",
            "Epoch 11/15, Batch Loss: 0.11386383324861526, Average Training Loss: 0.17201799619942904, Training Accuracy: 0.96484375\n",
            "Epoch 11/15, Batch Loss: 0.15713131427764893, Average Training Loss: 0.17036392043034235, Training Accuracy: 0.9652777777777778\n",
            "Epoch 11/15, Batch Loss: 0.1747724860906601, Average Training Loss: 0.17080477699637414, Training Accuracy: 0.965625\n",
            "Epoch 11/15, Batch Loss: 0.2708227038383484, Average Training Loss: 0.17989731580018997, Training Accuracy: 0.9616477272727273\n",
            "Epoch 11/15, Batch Loss: 0.13845135271549225, Average Training Loss: 0.17644348554313183, Training Accuracy: 0.9622395833333334\n",
            "Epoch 11/15, Batch Loss: 0.23797154426574707, Average Training Loss: 0.18117641313717917, Training Accuracy: 0.9603365384615384\n",
            "Epoch 11/15, Batch Loss: 0.1581658273935318, Average Training Loss: 0.17953279986977577, Training Accuracy: 0.9609375\n",
            "Epoch 11/15, Batch Loss: 0.25124379992485046, Average Training Loss: 0.18431353320678076, Training Accuracy: 0.95625\n",
            "Epoch 11/15, Batch Loss: 0.1888914555311203, Average Training Loss: 0.18459965335205197, Training Accuracy: 0.9560546875\n",
            "Epoch 11/15, Batch Loss: 0.2976531982421875, Average Training Loss: 0.19124986187500112, Training Accuracy: 0.9540441176470589\n",
            "Epoch 11/15, Batch Loss: 0.3281863331794739, Average Training Loss: 0.19885744361413848, Training Accuracy: 0.9496527777777778\n",
            "Epoch 11/15, Batch Loss: 0.184208482503891, Average Training Loss: 0.19808644566096759, Training Accuracy: 0.9490131578947368\n",
            "Epoch 11/15, Batch Loss: 0.3490772545337677, Average Training Loss: 0.2056359861046076, Training Accuracy: 0.9453125\n",
            "Epoch 11/15, Batch Loss: 0.20731998980045319, Average Training Loss: 0.20571617675679071, Training Accuracy: 0.9441964285714286\n",
            "Epoch 11/15, Batch Loss: 0.27774229645729065, Average Training Loss: 0.2089900912886316, Training Accuracy: 0.9431818181818182\n",
            "Epoch 11/15, Batch Loss: 0.23212796449661255, Average Training Loss: 0.20999608577593512, Training Accuracy: 0.9422554347826086\n",
            "Epoch 11/15, Batch Loss: 0.1755051165819168, Average Training Loss: 0.2085589620595177, Training Accuracy: 0.9440104166666666\n",
            "Epoch 11/15, Batch Loss: 0.22596806287765503, Average Training Loss: 0.2092553260922432, Training Accuracy: 0.943125\n",
            "Epoch 11/15, Batch Loss: 0.16383177042007446, Average Training Loss: 0.20750826625869825, Training Accuracy: 0.9447115384615384\n",
            "Epoch 11/15, Batch Loss: 0.24668250977993011, Average Training Loss: 0.208959164166892, Training Accuracy: 0.9450231481481481\n",
            "Epoch 11/15, Batch Loss: 0.23700715601444244, Average Training Loss: 0.2099608781614474, Training Accuracy: 0.9441964285714286\n",
            "Epoch 11/15, Batch Loss: 0.2544761300086975, Average Training Loss: 0.2114958868458353, Training Accuracy: 0.943426724137931\n",
            "Epoch 11/15, Average Training Loss: 0.2114958868458353, Training Accuracy: 0.943426724137931\n",
            "Epoch 11/15, Validation Loss: 8.186136841773987, Validation Accuracy: 0.6551724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.61      0.64        99\n",
            "                Educational Opportunity       0.46      0.47      0.47        87\n",
            "                         Family Support       0.76      0.91      0.83        93\n",
            "                      Financial Support       0.64      0.66      0.65        89\n",
            "                 Program Implementation       0.71      0.61      0.66        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.65      0.66      0.65       464\n",
            "\n",
            "Epoch 12/15, Batch Loss: 0.16409710049629211, Average Training Loss: 0.16409710049629211, Training Accuracy: 0.953125\n",
            "Epoch 12/15, Batch Loss: 0.1208667904138565, Average Training Loss: 0.1424819454550743, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.15001961588859558, Average Training Loss: 0.14499450226624808, Training Accuracy: 0.9635416666666666\n",
            "Epoch 12/15, Batch Loss: 0.16731911897659302, Average Training Loss: 0.1505756564438343, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.1567501425743103, Average Training Loss: 0.15181055366992952, Training Accuracy: 0.959375\n",
            "Epoch 12/15, Batch Loss: 0.1744806468486786, Average Training Loss: 0.15558890253305435, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.21957038342952728, Average Training Loss: 0.16472911408969335, Training Accuracy: 0.9620535714285714\n",
            "Epoch 12/15, Batch Loss: 0.13640233874320984, Average Training Loss: 0.1611882671713829, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.22648535668849945, Average Training Loss: 0.1684434993399514, Training Accuracy: 0.9565972222222222\n",
            "Epoch 12/15, Batch Loss: 0.09339135140180588, Average Training Loss: 0.16093828454613684, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.2537994384765625, Average Training Loss: 0.169380207630721, Training Accuracy: 0.9588068181818182\n",
            "Epoch 12/15, Batch Loss: 0.15029948949813843, Average Training Loss: 0.16779014778633913, Training Accuracy: 0.9596354166666666\n",
            "Epoch 12/15, Batch Loss: 0.20194105803966522, Average Training Loss: 0.1704171408827488, Training Accuracy: 0.9603365384615384\n",
            "Epoch 12/15, Batch Loss: 0.14814932644367218, Average Training Loss: 0.16882658270852907, Training Accuracy: 0.9609375\n",
            "Epoch 12/15, Batch Loss: 0.20158977806568146, Average Training Loss: 0.1710107957323392, Training Accuracy: 0.959375\n",
            "Epoch 12/15, Batch Loss: 0.3132302761077881, Average Training Loss: 0.17989951325580478, Training Accuracy: 0.9560546875\n",
            "Epoch 12/15, Batch Loss: 0.1599220633506775, Average Training Loss: 0.17872436914373846, Training Accuracy: 0.9577205882352942\n",
            "Epoch 12/15, Batch Loss: 0.2242865264415741, Average Training Loss: 0.18125560010472933, Training Accuracy: 0.9557291666666666\n",
            "Epoch 12/15, Batch Loss: 0.16060559451580048, Average Training Loss: 0.18016875770531202, Training Accuracy: 0.9572368421052632\n",
            "Epoch 12/15, Batch Loss: 0.2425893247127533, Average Training Loss: 0.18328978605568408, Training Accuracy: 0.9546875\n",
            "Epoch 12/15, Batch Loss: 0.18049979209899902, Average Training Loss: 0.18315692920060384, Training Accuracy: 0.9546130952380952\n",
            "Epoch 12/15, Batch Loss: 0.09397837519645691, Average Training Loss: 0.1791033585640517, Training Accuracy: 0.9566761363636364\n",
            "Epoch 12/15, Batch Loss: 0.16801780462265015, Average Training Loss: 0.1786213779579038, Training Accuracy: 0.9572010869565217\n",
            "Epoch 12/15, Batch Loss: 0.13726533949375153, Average Training Loss: 0.17689820968856415, Training Accuracy: 0.95703125\n",
            "Epoch 12/15, Batch Loss: 0.3303753137588501, Average Training Loss: 0.18303729385137557, Training Accuracy: 0.954375\n",
            "Epoch 12/15, Batch Loss: 0.19871880114078522, Average Training Loss: 0.1836404287471221, Training Accuracy: 0.9543269230769231\n",
            "Epoch 12/15, Batch Loss: 0.16191698610782623, Average Training Loss: 0.18283585679751854, Training Accuracy: 0.9548611111111112\n",
            "Epoch 12/15, Batch Loss: 0.19196383655071259, Average Training Loss: 0.18316185607441834, Training Accuracy: 0.9536830357142857\n",
            "Epoch 12/15, Batch Loss: 0.14746446907520294, Average Training Loss: 0.18193091169513506, Training Accuracy: 0.9542025862068966\n",
            "Epoch 12/15, Average Training Loss: 0.18193091169513506, Training Accuracy: 0.9542025862068966\n",
            "Epoch 12/15, Validation Loss: 8.18091630935669, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.71      0.68        99\n",
            "                Educational Opportunity       0.46      0.45      0.46        87\n",
            "                         Family Support       0.77      0.92      0.84        93\n",
            "                      Financial Support       0.69      0.64      0.66        89\n",
            "                 Program Implementation       0.72      0.59      0.65        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.66      0.67      0.66       464\n",
            "\n",
            "Epoch 13/15, Batch Loss: 0.1517399102449417, Average Training Loss: 0.1517399102449417, Training Accuracy: 0.984375\n",
            "Epoch 13/15, Batch Loss: 0.10403764992952347, Average Training Loss: 0.1278887800872326, Training Accuracy: 0.984375\n",
            "Epoch 13/15, Batch Loss: 0.10968292504549026, Average Training Loss: 0.12182016173998515, Training Accuracy: 0.9791666666666666\n",
            "Epoch 13/15, Batch Loss: 0.2832655906677246, Average Training Loss: 0.16218151897192, Training Accuracy: 0.95703125\n",
            "Epoch 13/15, Batch Loss: 0.11791425198316574, Average Training Loss: 0.15332806557416917, Training Accuracy: 0.9625\n",
            "Epoch 13/15, Batch Loss: 0.08909257501363754, Average Training Loss: 0.14262215048074722, Training Accuracy: 0.96875\n",
            "Epoch 13/15, Batch Loss: 0.23290351033210754, Average Training Loss: 0.15551948760237014, Training Accuracy: 0.9642857142857143\n",
            "Epoch 13/15, Batch Loss: 0.20462489128112793, Average Training Loss: 0.16165766306221485, Training Accuracy: 0.962890625\n",
            "Epoch 13/15, Batch Loss: 0.18038687109947205, Average Training Loss: 0.16373868617746565, Training Accuracy: 0.9618055555555556\n",
            "Epoch 13/15, Batch Loss: 0.22052153944969177, Average Training Loss: 0.16941697150468826, Training Accuracy: 0.9609375\n",
            "Epoch 13/15, Batch Loss: 0.1270170509815216, Average Training Loss: 0.16556243327530948, Training Accuracy: 0.9602272727272727\n",
            "Epoch 13/15, Batch Loss: 0.2241150289773941, Average Training Loss: 0.17044181625048319, Training Accuracy: 0.95703125\n",
            "Epoch 13/15, Batch Loss: 0.16386893391609192, Average Training Loss: 0.16993620991706848, Training Accuracy: 0.9567307692307693\n",
            "Epoch 13/15, Batch Loss: 0.15869803726673126, Average Training Loss: 0.16913348329918726, Training Accuracy: 0.9553571428571429\n",
            "Epoch 13/15, Batch Loss: 0.16509103775024414, Average Training Loss: 0.16886398692925772, Training Accuracy: 0.95625\n",
            "Epoch 13/15, Batch Loss: 0.17808809876441956, Average Training Loss: 0.16944049391895533, Training Accuracy: 0.95703125\n",
            "Epoch 13/15, Batch Loss: 0.20778349041938782, Average Training Loss: 0.17169596430133371, Training Accuracy: 0.9558823529411765\n",
            "Epoch 13/15, Batch Loss: 0.09617583453655243, Average Training Loss: 0.16750040153662363, Training Accuracy: 0.9574652777777778\n",
            "Epoch 13/15, Batch Loss: 0.10046885162591934, Average Training Loss: 0.16397242522553393, Training Accuracy: 0.959703947368421\n",
            "Epoch 13/15, Batch Loss: 0.1648024022579193, Average Training Loss: 0.1640139240771532, Training Accuracy: 0.96015625\n",
            "Epoch 13/15, Batch Loss: 0.1409413367509842, Average Training Loss: 0.16291522944257372, Training Accuracy: 0.9598214285714286\n",
            "Epoch 13/15, Batch Loss: 0.07086826115846634, Average Training Loss: 0.15873127633875067, Training Accuracy: 0.9616477272727273\n",
            "Epoch 13/15, Batch Loss: 0.188337504863739, Average Training Loss: 0.16001850366592407, Training Accuracy: 0.9619565217391305\n",
            "Epoch 13/15, Batch Loss: 0.1899854689836502, Average Training Loss: 0.16126712722082934, Training Accuracy: 0.9615885416666666\n",
            "Epoch 13/15, Batch Loss: 0.16480229794979095, Average Training Loss: 0.16140853404998778, Training Accuracy: 0.96125\n",
            "Epoch 13/15, Batch Loss: 0.10537827014923096, Average Training Loss: 0.15925352389995867, Training Accuracy: 0.9621394230769231\n",
            "Epoch 13/15, Batch Loss: 0.13777679204940796, Average Training Loss: 0.15845808938697534, Training Accuracy: 0.9629629629629629\n",
            "Epoch 13/15, Batch Loss: 0.21988920867443085, Average Training Loss: 0.16065205793295587, Training Accuracy: 0.9620535714285714\n",
            "Epoch 13/15, Batch Loss: 0.21172066032886505, Average Training Loss: 0.16241304422247, Training Accuracy: 0.9612068965517241\n",
            "Epoch 13/15, Average Training Loss: 0.16241304422247, Training Accuracy: 0.9612068965517241\n",
            "Epoch 13/15, Validation Loss: 8.453465759754181, Validation Accuracy: 0.6573275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.66      0.66        99\n",
            "                Educational Opportunity       0.49      0.48      0.49        87\n",
            "                         Family Support       0.77      0.90      0.83        93\n",
            "                      Financial Support       0.64      0.65      0.64        89\n",
            "                 Program Implementation       0.70      0.58      0.64        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.65      0.66      0.65       464\n",
            "\n",
            "Epoch 14/15, Batch Loss: 0.18042708933353424, Average Training Loss: 0.18042708933353424, Training Accuracy: 0.953125\n",
            "Epoch 14/15, Batch Loss: 0.1053566038608551, Average Training Loss: 0.14289184659719467, Training Accuracy: 0.9765625\n",
            "Epoch 14/15, Batch Loss: 0.1829656958580017, Average Training Loss: 0.15624979635079703, Training Accuracy: 0.9635416666666666\n",
            "Epoch 14/15, Batch Loss: 0.21425503492355347, Average Training Loss: 0.17075110599398613, Training Accuracy: 0.9609375\n",
            "Epoch 14/15, Batch Loss: 0.1590234637260437, Average Training Loss: 0.16840557754039764, Training Accuracy: 0.9625\n",
            "Epoch 14/15, Batch Loss: 0.12101031094789505, Average Training Loss: 0.1605063664416472, Training Accuracy: 0.9661458333333334\n",
            "Epoch 14/15, Batch Loss: 0.12310843169689178, Average Training Loss: 0.1551638043352536, Training Accuracy: 0.9665178571428571\n",
            "Epoch 14/15, Batch Loss: 0.21353819966316223, Average Training Loss: 0.16246060375124216, Training Accuracy: 0.9609375\n",
            "Epoch 14/15, Batch Loss: 0.09278403967618942, Average Training Loss: 0.15471876329845852, Training Accuracy: 0.9652777777777778\n",
            "Epoch 14/15, Batch Loss: 0.1339976191520691, Average Training Loss: 0.15264664888381957, Training Accuracy: 0.9640625\n",
            "Epoch 14/15, Batch Loss: 0.1883055716753006, Average Training Loss: 0.15588836913759058, Training Accuracy: 0.9630681818181818\n",
            "Epoch 14/15, Batch Loss: 0.12909717857837677, Average Training Loss: 0.15365576992432275, Training Accuracy: 0.9635416666666666\n",
            "Epoch 14/15, Batch Loss: 0.12353982776403427, Average Training Loss: 0.15133915898891595, Training Accuracy: 0.9651442307692307\n",
            "Epoch 14/15, Batch Loss: 0.1187884733080864, Average Training Loss: 0.14901411001171386, Training Accuracy: 0.9665178571428571\n",
            "Epoch 14/15, Batch Loss: 0.24973738193511963, Average Training Loss: 0.15572899480660757, Training Accuracy: 0.9645833333333333\n",
            "Epoch 14/15, Batch Loss: 0.12913143634796143, Average Training Loss: 0.15406664740294218, Training Accuracy: 0.9638671875\n",
            "Epoch 14/15, Batch Loss: 0.21529489755630493, Average Training Loss: 0.1576683091766694, Training Accuracy: 0.9623161764705882\n",
            "Epoch 14/15, Batch Loss: 0.178056538105011, Average Training Loss: 0.15880098856157726, Training Accuracy: 0.9618055555555556\n",
            "Epoch 14/15, Batch Loss: 0.12586680054664612, Average Training Loss: 0.15706761024500193, Training Accuracy: 0.9629934210526315\n",
            "Epoch 14/15, Batch Loss: 0.13041934370994568, Average Training Loss: 0.15573519691824914, Training Accuracy: 0.96484375\n",
            "Epoch 14/15, Batch Loss: 0.09241080284118652, Average Training Loss: 0.15271974958124615, Training Accuracy: 0.9657738095238095\n",
            "Epoch 14/15, Batch Loss: 0.1712951362133026, Average Training Loss: 0.15356408533724872, Training Accuracy: 0.9651988636363636\n",
            "Epoch 14/15, Batch Loss: 0.13565930724143982, Average Training Loss: 0.15278561672438745, Training Accuracy: 0.9646739130434783\n",
            "Epoch 14/15, Batch Loss: 0.1035500317811966, Average Training Loss: 0.15073413401842117, Training Accuracy: 0.9661458333333334\n",
            "Epoch 14/15, Batch Loss: 0.18145282566547394, Average Training Loss: 0.15196288168430327, Training Accuracy: 0.964375\n",
            "Epoch 14/15, Batch Loss: 0.1650383621454239, Average Training Loss: 0.15246578477896178, Training Accuracy: 0.9639423076923077\n",
            "Epoch 14/15, Batch Loss: 0.14952409267425537, Average Training Loss: 0.1523568332195282, Training Accuracy: 0.9635416666666666\n",
            "Epoch 14/15, Batch Loss: 0.12939992547035217, Average Training Loss: 0.15153694365705764, Training Accuracy: 0.9637276785714286\n",
            "Epoch 14/15, Batch Loss: 0.2048160582780838, Average Training Loss: 0.15337415450605854, Training Accuracy: 0.962823275862069\n",
            "Epoch 14/15, Average Training Loss: 0.15337415450605854, Training Accuracy: 0.962823275862069\n",
            "Epoch 14/15, Validation Loss: 8.463855564594269, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.68      0.67        99\n",
            "                Educational Opportunity       0.51      0.46      0.48        87\n",
            "                         Family Support       0.78      0.90      0.84        93\n",
            "                      Financial Support       0.63      0.65      0.64        89\n",
            "                 Program Implementation       0.71      0.62      0.67        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.66      0.67      0.66       464\n",
            "\n",
            "Epoch 15/15, Batch Loss: 0.13675466179847717, Average Training Loss: 0.13675466179847717, Training Accuracy: 0.953125\n",
            "Epoch 15/15, Batch Loss: 0.09711465239524841, Average Training Loss: 0.11693465709686279, Training Accuracy: 0.96875\n",
            "Epoch 15/15, Batch Loss: 0.2703435719013214, Average Training Loss: 0.16807096203168234, Training Accuracy: 0.9479166666666666\n",
            "Epoch 15/15, Batch Loss: 0.11885455995798111, Average Training Loss: 0.15576686151325703, Training Accuracy: 0.953125\n",
            "Epoch 15/15, Batch Loss: 0.144634410738945, Average Training Loss: 0.15354037135839463, Training Accuracy: 0.95625\n",
            "Epoch 15/15, Batch Loss: 0.12845557928085327, Average Training Loss: 0.1493595726788044, Training Accuracy: 0.9583333333333334\n",
            "Epoch 15/15, Batch Loss: 0.2060217559337616, Average Training Loss: 0.15745417028665543, Training Accuracy: 0.9575892857142857\n",
            "Epoch 15/15, Batch Loss: 0.10374272614717484, Average Training Loss: 0.15074023976922035, Training Accuracy: 0.9609375\n",
            "Epoch 15/15, Batch Loss: 0.15779055655002594, Average Training Loss: 0.15152360830042097, Training Accuracy: 0.9583333333333334\n",
            "Epoch 15/15, Batch Loss: 0.1086977869272232, Average Training Loss: 0.1472410261631012, Training Accuracy: 0.9609375\n",
            "Epoch 15/15, Batch Loss: 0.13828930258750916, Average Training Loss: 0.14642723311077466, Training Accuracy: 0.9602272727272727\n",
            "Epoch 15/15, Batch Loss: 0.07750067114830017, Average Training Loss: 0.1406833529472351, Training Accuracy: 0.9635416666666666\n",
            "Epoch 15/15, Batch Loss: 0.21032652258872986, Average Training Loss: 0.1460405198427347, Training Accuracy: 0.9615384615384616\n",
            "Epoch 15/15, Batch Loss: 0.17666175961494446, Average Training Loss: 0.1482277512550354, Training Accuracy: 0.9587053571428571\n",
            "Epoch 15/15, Batch Loss: 0.19624613225460052, Average Training Loss: 0.1514289766550064, Training Accuracy: 0.959375\n",
            "Epoch 15/15, Batch Loss: 0.07834760844707489, Average Training Loss: 0.1468613911420107, Training Accuracy: 0.9619140625\n",
            "Epoch 15/15, Batch Loss: 0.09782503545284271, Average Training Loss: 0.14397689963088317, Training Accuracy: 0.9632352941176471\n",
            "Epoch 15/15, Batch Loss: 0.12869198620319366, Average Training Loss: 0.1431277377737893, Training Accuracy: 0.9626736111111112\n",
            "Epoch 15/15, Batch Loss: 0.132230743765831, Average Training Loss: 0.14255421177337044, Training Accuracy: 0.962171052631579\n",
            "Epoch 15/15, Batch Loss: 0.13330432772636414, Average Training Loss: 0.14209171757102013, Training Accuracy: 0.9625\n",
            "Epoch 15/15, Batch Loss: 0.1376415640115738, Average Training Loss: 0.14187980549676077, Training Accuracy: 0.9620535714285714\n",
            "Epoch 15/15, Batch Loss: 0.08102681487798691, Average Training Loss: 0.1391137604686347, Training Accuracy: 0.9630681818181818\n",
            "Epoch 15/15, Batch Loss: 0.17784859240055084, Average Training Loss: 0.1407978835961093, Training Accuracy: 0.9612771739130435\n",
            "Epoch 15/15, Batch Loss: 0.1475088745355606, Average Training Loss: 0.14107750821858644, Training Accuracy: 0.9615885416666666\n",
            "Epoch 15/15, Batch Loss: 0.14944882690906525, Average Training Loss: 0.1414123609662056, Training Accuracy: 0.9625\n",
            "Epoch 15/15, Batch Loss: 0.2129759043455124, Average Training Loss: 0.14416480494233277, Training Accuracy: 0.9615384615384616\n",
            "Epoch 15/15, Batch Loss: 0.12320330739021301, Average Training Loss: 0.14338845318114316, Training Accuracy: 0.9618055555555556\n",
            "Epoch 15/15, Batch Loss: 0.2511778175830841, Average Training Loss: 0.14723807333835534, Training Accuracy: 0.9598214285714286\n",
            "Epoch 15/15, Batch Loss: 0.21101562678813934, Average Training Loss: 0.14943729931938238, Training Accuracy: 0.9595905172413793\n",
            "Epoch 15/15, Average Training Loss: 0.14943729931938238, Training Accuracy: 0.9595905172413793\n",
            "Epoch 15/15, Validation Loss: 8.475159227848053, Validation Accuracy: 0.6594827586206896\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.68      0.67        99\n",
            "                Educational Opportunity       0.48      0.47      0.48        87\n",
            "                         Family Support       0.78      0.90      0.84        93\n",
            "                      Financial Support       0.64      0.63      0.63        89\n",
            "                 Program Implementation       0.71      0.60      0.65        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.66       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Handle NaN values in the 'Label' column\n",
        "df['Label'].fillna('default_label', inplace=True)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and validation data\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ArEQW0h0If",
        "outputId": "3cf5f50e-d4cb-4bb1-8768-22ddce3b3555"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-41-b943dbf73129>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch Loss: 1.5916208028793335, Average Training Loss: 1.5916208028793335, Training Accuracy: 0.25\n",
            "Epoch 1/10, Batch Loss: 1.607102394104004, Average Training Loss: 1.5993615984916687, Training Accuracy: 0.3125\n",
            "Epoch 1/10, Batch Loss: 1.6332834959030151, Average Training Loss: 1.6106688976287842, Training Accuracy: 0.3333333333333333\n",
            "Epoch 1/10, Batch Loss: 1.7683215141296387, Average Training Loss: 1.6500820517539978, Training Accuracy: 0.28125\n",
            "Epoch 1/10, Batch Loss: 1.7336218357086182, Average Training Loss: 1.6667900085449219, Training Accuracy: 0.25\n",
            "Epoch 1/10, Batch Loss: 1.5815730094909668, Average Training Loss: 1.6525871753692627, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/10, Batch Loss: 1.6780096292495728, Average Training Loss: 1.6562189544950212, Training Accuracy: 0.21428571428571427\n",
            "Epoch 1/10, Batch Loss: 1.6022987365722656, Average Training Loss: 1.6494789272546768, Training Accuracy: 0.2109375\n",
            "Epoch 1/10, Batch Loss: 1.5704214572906494, Average Training Loss: 1.6406947639253404, Training Accuracy: 0.2222222222222222\n",
            "Epoch 1/10, Batch Loss: 1.5688599348068237, Average Training Loss: 1.6335112810134889, Training Accuracy: 0.2125\n",
            "Epoch 1/10, Batch Loss: 1.5431863069534302, Average Training Loss: 1.6252999197353015, Training Accuracy: 0.22727272727272727\n",
            "Epoch 1/10, Batch Loss: 1.5344996452331543, Average Training Loss: 1.617733230193456, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/10, Batch Loss: 1.6040364503860474, Average Training Loss: 1.6166796317467322, Training Accuracy: 0.24519230769230768\n",
            "Epoch 1/10, Batch Loss: 1.5422407388687134, Average Training Loss: 1.611362567969731, Training Accuracy: 0.25\n",
            "Epoch 1/10, Batch Loss: 1.621431589126587, Average Training Loss: 1.6120338360468547, Training Accuracy: 0.2375\n",
            "Epoch 1/10, Batch Loss: 1.5729260444641113, Average Training Loss: 1.6095895990729332, Training Accuracy: 0.234375\n",
            "Epoch 1/10, Batch Loss: 1.599717378616333, Average Training Loss: 1.6090088802225448, Training Accuracy: 0.23161764705882354\n",
            "Epoch 1/10, Batch Loss: 1.5866377353668213, Average Training Loss: 1.6077660388416715, Training Accuracy: 0.2326388888888889\n",
            "Epoch 1/10, Batch Loss: 1.5082980394363403, Average Training Loss: 1.602530880978233, Training Accuracy: 0.24342105263157895\n",
            "Epoch 1/10, Batch Loss: 1.5671862363815308, Average Training Loss: 1.6007636487483978, Training Accuracy: 0.24375\n",
            "Epoch 1/10, Batch Loss: 1.605116844177246, Average Training Loss: 1.600970943768819, Training Accuracy: 0.24404761904761904\n",
            "Epoch 1/10, Batch Loss: 1.6471753120422363, Average Training Loss: 1.6030711423267017, Training Accuracy: 0.23579545454545456\n",
            "Epoch 1/10, Batch Loss: 1.4934910535812378, Average Training Loss: 1.5983067906421164, Training Accuracy: 0.24456521739130435\n",
            "Epoch 1/10, Batch Loss: 1.5367217063903809, Average Training Loss: 1.5957407454649608, Training Accuracy: 0.24479166666666666\n",
            "Epoch 1/10, Batch Loss: 1.4362305402755737, Average Training Loss: 1.5893603372573852, Training Accuracy: 0.2525\n",
            "Epoch 1/10, Batch Loss: 1.515834093093872, Average Training Loss: 1.586532404789558, Training Accuracy: 0.25721153846153844\n",
            "Epoch 1/10, Batch Loss: 1.6078510284423828, Average Training Loss: 1.587321983443366, Training Accuracy: 0.25462962962962965\n",
            "Epoch 1/10, Batch Loss: 1.6240469217300415, Average Training Loss: 1.588633588382176, Training Accuracy: 0.2544642857142857\n",
            "Epoch 1/10, Batch Loss: 1.4998151063919067, Average Training Loss: 1.5855708821066494, Training Accuracy: 0.2629310344827586\n",
            "Epoch 1/10, Batch Loss: 1.4547650814056396, Average Training Loss: 1.581210688749949, Training Accuracy: 0.26666666666666666\n",
            "Epoch 1/10, Batch Loss: 1.5262006521224976, Average Training Loss: 1.579436171439386, Training Accuracy: 0.27419354838709675\n",
            "Epoch 1/10, Batch Loss: 1.461044192314148, Average Training Loss: 1.5757364220917225, Training Accuracy: 0.27734375\n",
            "Epoch 1/10, Batch Loss: 1.4915275573730469, Average Training Loss: 1.5731846383123687, Training Accuracy: 0.2803030303030303\n",
            "Epoch 1/10, Batch Loss: 1.506144642829895, Average Training Loss: 1.5712128737393547, Training Accuracy: 0.28125\n",
            "Epoch 1/10, Batch Loss: 1.6134599447250366, Average Training Loss: 1.5724199329103743, Training Accuracy: 0.28035714285714286\n",
            "Epoch 1/10, Batch Loss: 1.5138412714004517, Average Training Loss: 1.570792747868432, Training Accuracy: 0.2847222222222222\n",
            "Epoch 1/10, Batch Loss: 1.5787198543548584, Average Training Loss: 1.5710069939896867, Training Accuracy: 0.28040540540540543\n",
            "Epoch 1/10, Batch Loss: 1.562074065208435, Average Training Loss: 1.570771916916496, Training Accuracy: 0.28125\n",
            "Epoch 1/10, Batch Loss: 1.5912044048309326, Average Training Loss: 1.57129582686302, Training Accuracy: 0.27724358974358976\n",
            "Epoch 1/10, Batch Loss: 1.5007731914520264, Average Training Loss: 1.569532760977745, Training Accuracy: 0.278125\n",
            "Epoch 1/10, Batch Loss: 1.6283633708953857, Average Training Loss: 1.5709676539025657, Training Accuracy: 0.2774390243902439\n",
            "Epoch 1/10, Batch Loss: 1.4563946723937988, Average Training Loss: 1.5682397257714045, Training Accuracy: 0.27976190476190477\n",
            "Epoch 1/10, Batch Loss: 1.6027615070343018, Average Training Loss: 1.5690425578937974, Training Accuracy: 0.2761627906976744\n",
            "Epoch 1/10, Batch Loss: 1.4709053039550781, Average Training Loss: 1.5668121657588265, Training Accuracy: 0.27982954545454547\n",
            "Epoch 1/10, Batch Loss: 1.4379005432128906, Average Training Loss: 1.5639474630355834, Training Accuracy: 0.2833333333333333\n",
            "Epoch 1/10, Batch Loss: 1.4346600770950317, Average Training Loss: 1.5611368676890498, Training Accuracy: 0.28396739130434784\n",
            "Epoch 1/10, Batch Loss: 1.4927624464035034, Average Training Loss: 1.5596820927680808, Training Accuracy: 0.2859042553191489\n",
            "Epoch 1/10, Batch Loss: 1.3238587379455566, Average Training Loss: 1.554769106209278, Training Accuracy: 0.29296875\n",
            "Epoch 1/10, Batch Loss: 1.4529951810836792, Average Training Loss: 1.5526920873291639, Training Accuracy: 0.29464285714285715\n",
            "Epoch 1/10, Batch Loss: 1.8729932308197021, Average Training Loss: 1.5590981101989747, Training Accuracy: 0.29\n",
            "Epoch 1/10, Batch Loss: 1.6361721754074097, Average Training Loss: 1.5606093663795322, Training Accuracy: 0.28921568627450983\n",
            "Epoch 1/10, Batch Loss: 1.522083044052124, Average Training Loss: 1.5598684755655436, Training Accuracy: 0.28966346153846156\n",
            "Epoch 1/10, Batch Loss: 1.579456090927124, Average Training Loss: 1.5602380532138753, Training Accuracy: 0.29127358490566035\n",
            "Epoch 1/10, Batch Loss: 1.6478506326675415, Average Training Loss: 1.5618605083889432, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/10, Batch Loss: 1.5424141883850098, Average Training Loss: 1.5615069389343261, Training Accuracy: 0.29318181818181815\n",
            "Epoch 1/10, Batch Loss: 1.4958577156066895, Average Training Loss: 1.560334631374904, Training Accuracy: 0.29799107142857145\n",
            "Epoch 1/10, Batch Loss: 1.4419889450073242, Average Training Loss: 1.5582583912631922, Training Accuracy: 0.3026315789473684\n",
            "Epoch 1/10, Batch Loss: 1.4085348844528198, Average Training Loss: 1.5556769514905995, Training Accuracy: 0.30495689655172414\n",
            "Epoch 1/10, Batch Loss: 1.4506678581237793, Average Training Loss: 1.553897136348789, Training Accuracy: 0.3061440677966102\n",
            "Epoch 1/10, Batch Loss: 1.436189889907837, Average Training Loss: 1.5519353489081065, Training Accuracy: 0.30625\n",
            "Epoch 1/10, Batch Loss: 1.3227999210357666, Average Training Loss: 1.548179030418396, Training Accuracy: 0.3094262295081967\n",
            "Epoch 1/10, Batch Loss: 1.4938409328460693, Average Training Loss: 1.5473026094898101, Training Accuracy: 0.31048387096774194\n",
            "Epoch 1/10, Batch Loss: 1.4446842670440674, Average Training Loss: 1.5456737469113062, Training Accuracy: 0.314484126984127\n",
            "Epoch 1/10, Batch Loss: 1.4600964784622192, Average Training Loss: 1.5443366020917892, Training Accuracy: 0.3173828125\n",
            "Epoch 1/10, Batch Loss: 1.5679596662521362, Average Training Loss: 1.5447000338481023, Training Accuracy: 0.3173076923076923\n",
            "Epoch 1/10, Batch Loss: 1.5978513956069946, Average Training Loss: 1.5455053575111157, Training Accuracy: 0.3181818181818182\n",
            "Epoch 1/10, Batch Loss: 1.5031416416168213, Average Training Loss: 1.5448730632440368, Training Accuracy: 0.31716417910447764\n",
            "Epoch 1/10, Batch Loss: 1.5686613321304321, Average Training Loss: 1.5452228907276602, Training Accuracy: 0.3161764705882353\n",
            "Epoch 1/10, Batch Loss: 1.3605844974517822, Average Training Loss: 1.5425469719845315, Training Accuracy: 0.3161231884057971\n",
            "Epoch 1/10, Batch Loss: 1.4066104888916016, Average Training Loss: 1.5406050222260612, Training Accuracy: 0.3196428571428571\n",
            "Epoch 1/10, Batch Loss: 1.315353274345398, Average Training Loss: 1.5374324623967561, Training Accuracy: 0.3221830985915493\n",
            "Epoch 1/10, Batch Loss: 1.4951449632644653, Average Training Loss: 1.5368451360199187, Training Accuracy: 0.3220486111111111\n",
            "Epoch 1/10, Batch Loss: 1.3535112142562866, Average Training Loss: 1.5343337124341154, Training Accuracy: 0.3236301369863014\n",
            "Epoch 1/10, Batch Loss: 1.299961805343628, Average Training Loss: 1.5311665245004602, Training Accuracy: 0.3277027027027027\n",
            "Epoch 1/10, Batch Loss: 1.1429697275161743, Average Training Loss: 1.5259905672073364, Training Accuracy: 0.3325\n",
            "Epoch 1/10, Batch Loss: 1.3182411193847656, Average Training Loss: 1.52325702184125, Training Accuracy: 0.3347039473684211\n",
            "Epoch 1/10, Batch Loss: 1.3914923667907715, Average Training Loss: 1.52154579255488, Training Accuracy: 0.3352272727272727\n",
            "Epoch 1/10, Batch Loss: 1.3656927347183228, Average Training Loss: 1.5195476764287703, Training Accuracy: 0.33814102564102566\n",
            "Epoch 1/10, Batch Loss: 1.1549549102783203, Average Training Loss: 1.5149325781230685, Training Accuracy: 0.34414556962025317\n",
            "Epoch 1/10, Batch Loss: 1.322939395904541, Average Training Loss: 1.5125326633453369, Training Accuracy: 0.34453125\n",
            "Epoch 1/10, Batch Loss: 1.165905475616455, Average Training Loss: 1.5082533153486841, Training Accuracy: 0.34953703703703703\n",
            "Epoch 1/10, Batch Loss: 1.3118879795074463, Average Training Loss: 1.505858616131108, Training Accuracy: 0.3513719512195122\n",
            "Epoch 1/10, Batch Loss: 1.3555618524551392, Average Training Loss: 1.5040478117494698, Training Accuracy: 0.35316265060240964\n",
            "Epoch 1/10, Batch Loss: 1.2298916578292847, Average Training Loss: 1.5007840480123247, Training Accuracy: 0.35639880952380953\n",
            "Epoch 1/10, Batch Loss: 1.1049127578735352, Average Training Loss: 1.4961267387165742, Training Accuracy: 0.3602941176470588\n",
            "Epoch 1/10, Batch Loss: 1.2847093343734741, Average Training Loss: 1.493668396805608, Training Accuracy: 0.36191860465116277\n",
            "Epoch 1/10, Batch Loss: 1.128560185432434, Average Training Loss: 1.4894717506978703, Training Accuracy: 0.3635057471264368\n",
            "Epoch 1/10, Batch Loss: 1.2167705297470093, Average Training Loss: 1.4863728731870651, Training Accuracy: 0.3650568181818182\n",
            "Epoch 1/10, Batch Loss: 1.3830080032348633, Average Training Loss: 1.4852114701538943, Training Accuracy: 0.3651685393258427\n",
            "Epoch 1/10, Batch Loss: 1.1277698278427124, Average Training Loss: 1.4812398963504367, Training Accuracy: 0.36666666666666664\n",
            "Epoch 1/10, Batch Loss: 1.0793664455413818, Average Training Loss: 1.4768237045833044, Training Accuracy: 0.3701923076923077\n",
            "Epoch 1/10, Batch Loss: 1.3121720552444458, Average Training Loss: 1.4750340127426644, Training Accuracy: 0.37228260869565216\n",
            "Epoch 1/10, Batch Loss: 1.216431975364685, Average Training Loss: 1.472253345674084, Training Accuracy: 0.3756720430107527\n",
            "Epoch 1/10, Batch Loss: 0.9004682302474976, Average Training Loss: 1.4661705252972055, Training Accuracy: 0.3803191489361702\n",
            "Epoch 1/10, Batch Loss: 1.1181076765060425, Average Training Loss: 1.462506705836246, Training Accuracy: 0.38421052631578945\n",
            "Epoch 1/10, Batch Loss: 1.0414525270462036, Average Training Loss: 1.458120724807183, Training Accuracy: 0.388671875\n",
            "Epoch 1/10, Batch Loss: 1.259651780128479, Average Training Loss: 1.456074653212557, Training Accuracy: 0.3904639175257732\n",
            "Epoch 1/10, Batch Loss: 0.9637894034385681, Average Training Loss: 1.4510513343373124, Training Accuracy: 0.3934948979591837\n",
            "Epoch 1/10, Batch Loss: 0.8994308114051819, Average Training Loss: 1.4454794098632504, Training Accuracy: 0.3970959595959596\n",
            "Epoch 1/10, Batch Loss: 1.1561447381973267, Average Training Loss: 1.4425860631465912, Training Accuracy: 0.39875\n",
            "Epoch 1/10, Batch Loss: 0.9935027360916138, Average Training Loss: 1.4381396935717894, Training Accuracy: 0.40160891089108913\n",
            "Epoch 1/10, Batch Loss: 1.0680118799209595, Average Training Loss: 1.4345109895163892, Training Accuracy: 0.40379901960784315\n",
            "Epoch 1/10, Batch Loss: 1.0771543979644775, Average Training Loss: 1.4310415080450114, Training Accuracy: 0.4053398058252427\n",
            "Epoch 1/10, Batch Loss: 1.0190895795822144, Average Training Loss: 1.427080431809792, Training Accuracy: 0.4074519230769231\n",
            "Epoch 1/10, Batch Loss: 1.2276486158370972, Average Training Loss: 1.4251810811814807, Training Accuracy: 0.4083333333333333\n",
            "Epoch 1/10, Batch Loss: 1.2347954511642456, Average Training Loss: 1.4233849903322615, Training Accuracy: 0.4097877358490566\n",
            "Epoch 1/10, Batch Loss: 0.7200660109519958, Average Training Loss: 1.4168119157586143, Training Accuracy: 0.4141355140186916\n",
            "Epoch 1/10, Batch Loss: 1.1653554439544678, Average Training Loss: 1.414483615093761, Training Accuracy: 0.41550925925925924\n",
            "Epoch 1/10, Batch Loss: 1.0807883739471436, Average Training Loss: 1.4114221908630582, Training Accuracy: 0.4180045871559633\n",
            "Epoch 1/10, Batch Loss: 1.4308024644851685, Average Training Loss: 1.4115983751687136, Training Accuracy: 0.41875\n",
            "Epoch 1/10, Batch Loss: 1.1658015251159668, Average Training Loss: 1.4093839891322024, Training Accuracy: 0.4206081081081081\n",
            "Epoch 1/10, Batch Loss: 1.0090219974517822, Average Training Loss: 1.4058093284921986, Training Accuracy: 0.42299107142857145\n",
            "Epoch 1/10, Batch Loss: 1.5037972927093506, Average Training Loss: 1.4066764786180141, Training Accuracy: 0.4231194690265487\n",
            "Epoch 1/10, Batch Loss: 1.1464334726333618, Average Training Loss: 1.404393645232184, Training Accuracy: 0.4243421052631579\n",
            "Epoch 1/10, Batch Loss: 0.9635282158851624, Average Training Loss: 1.4005600328030794, Training Accuracy: 0.4260869565217391\n",
            "Epoch 1/10, Batch Loss: 0.9496208429336548, Average Training Loss: 1.3966726259938602, Training Accuracy: 0.42887931034482757\n",
            "Epoch 1/10, Average Training Loss: 1.3966726259938602, Training Accuracy: 0.42887931034482757\n",
            "Epoch 1/10, Validation Loss: 29.79092973470688, Validation Accuracy: 0.6487068965517241\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.58      0.63        99\n",
            "                Educational Opportunity       0.48      0.38      0.42        87\n",
            "                         Family Support       0.71      1.00      0.83        93\n",
            "                      Financial Support       0.60      0.83      0.69        89\n",
            "                 Program Implementation       0.75      0.46      0.57        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.65      0.65      0.63       464\n",
            "                           weighted avg       0.65      0.65      0.63       464\n",
            "\n",
            "Epoch 2/10, Batch Loss: 1.2395641803741455, Average Training Loss: 1.2395641803741455, Training Accuracy: 0.5625\n",
            "Epoch 2/10, Batch Loss: 1.3835965394973755, Average Training Loss: 1.3115803599357605, Training Accuracy: 0.5625\n",
            "Epoch 2/10, Batch Loss: 1.3710416555404663, Average Training Loss: 1.3314007918039958, Training Accuracy: 0.5416666666666666\n",
            "Epoch 2/10, Batch Loss: 0.9506481289863586, Average Training Loss: 1.2362126260995865, Training Accuracy: 0.5625\n",
            "Epoch 2/10, Batch Loss: 1.203508973121643, Average Training Loss: 1.2296718955039978, Training Accuracy: 0.5625\n",
            "Epoch 2/10, Batch Loss: 1.0852776765823364, Average Training Loss: 1.2056061923503876, Training Accuracy: 0.53125\n",
            "Epoch 2/10, Batch Loss: 1.2654187679290771, Average Training Loss: 1.214150846004486, Training Accuracy: 0.5357142857142857\n",
            "Epoch 2/10, Batch Loss: 0.9771745204925537, Average Training Loss: 1.1845288053154945, Training Accuracy: 0.5546875\n",
            "Epoch 2/10, Batch Loss: 0.9808668494224548, Average Training Loss: 1.161899699105157, Training Accuracy: 0.5625\n",
            "Epoch 2/10, Batch Loss: 1.1956192255020142, Average Training Loss: 1.1652716517448425, Training Accuracy: 0.55625\n",
            "Epoch 2/10, Batch Loss: 0.832213819026947, Average Training Loss: 1.1349936669523066, Training Accuracy: 0.5795454545454546\n",
            "Epoch 2/10, Batch Loss: 1.1914759874343872, Average Training Loss: 1.13970052699248, Training Accuracy: 0.5885416666666666\n",
            "Epoch 2/10, Batch Loss: 1.0932506322860718, Average Training Loss: 1.13612745816891, Training Accuracy: 0.5913461538461539\n",
            "Epoch 2/10, Batch Loss: 0.9779934883117676, Average Training Loss: 1.1248321746076857, Training Accuracy: 0.6071428571428571\n",
            "Epoch 2/10, Batch Loss: 1.0627930164337158, Average Training Loss: 1.120696230729421, Training Accuracy: 0.6083333333333333\n",
            "Epoch 2/10, Batch Loss: 0.9684394598007202, Average Training Loss: 1.1111801825463772, Training Accuracy: 0.609375\n",
            "Epoch 2/10, Batch Loss: 1.2554445266723633, Average Training Loss: 1.119666320436141, Training Accuracy: 0.6139705882352942\n",
            "Epoch 2/10, Batch Loss: 0.9670948386192322, Average Training Loss: 1.1111901270018683, Training Accuracy: 0.6215277777777778\n",
            "Epoch 2/10, Batch Loss: 0.8681352138519287, Average Training Loss: 1.0983977631518715, Training Accuracy: 0.625\n",
            "Epoch 2/10, Batch Loss: 0.6728497743606567, Average Training Loss: 1.0771203637123108, Training Accuracy: 0.6375\n",
            "Epoch 2/10, Batch Loss: 1.050802230834961, Average Training Loss: 1.07586711928958, Training Accuracy: 0.6339285714285714\n",
            "Epoch 2/10, Batch Loss: 0.886422336101532, Average Training Loss: 1.0672559927810321, Training Accuracy: 0.6420454545454546\n",
            "Epoch 2/10, Batch Loss: 1.2427136898040771, Average Training Loss: 1.0748845883037732, Training Accuracy: 0.6331521739130435\n",
            "Epoch 2/10, Batch Loss: 0.9679486155509949, Average Training Loss: 1.0704289227724075, Training Accuracy: 0.6328125\n",
            "Epoch 2/10, Batch Loss: 0.9366944432258606, Average Training Loss: 1.0650795435905456, Training Accuracy: 0.6325\n",
            "Epoch 2/10, Batch Loss: 0.9708866477012634, Average Training Loss: 1.0614567399024963, Training Accuracy: 0.6322115384615384\n",
            "Epoch 2/10, Batch Loss: 1.0073195695877075, Average Training Loss: 1.059451659520467, Training Accuracy: 0.6319444444444444\n",
            "Epoch 2/10, Batch Loss: 0.768769383430481, Average Training Loss: 1.0490701496601105, Training Accuracy: 0.6361607142857143\n",
            "Epoch 2/10, Batch Loss: 1.0937762260437012, Average Training Loss: 1.050611738500924, Training Accuracy: 0.6271551724137931\n",
            "Epoch 2/10, Batch Loss: 1.0164053440093994, Average Training Loss: 1.0494715253512064, Training Accuracy: 0.6291666666666667\n",
            "Epoch 2/10, Batch Loss: 0.8850955367088318, Average Training Loss: 1.0441690741046783, Training Accuracy: 0.6310483870967742\n",
            "Epoch 2/10, Batch Loss: 0.7246615290641785, Average Training Loss: 1.0341844633221626, Training Accuracy: 0.634765625\n",
            "Epoch 2/10, Batch Loss: 0.7417715787887573, Average Training Loss: 1.0253234668211504, Training Accuracy: 0.6382575757575758\n",
            "Epoch 2/10, Batch Loss: 0.9715758562088013, Average Training Loss: 1.0237426547443165, Training Accuracy: 0.6378676470588235\n",
            "Epoch 2/10, Batch Loss: 0.6655911803245544, Average Training Loss: 1.0135097554751804, Training Accuracy: 0.6410714285714286\n",
            "Epoch 2/10, Batch Loss: 0.9325854778289795, Average Training Loss: 1.011261858873897, Training Accuracy: 0.6388888888888888\n",
            "Epoch 2/10, Batch Loss: 0.9114732146263123, Average Training Loss: 1.0085648684888273, Training Accuracy: 0.6402027027027027\n",
            "Epoch 2/10, Batch Loss: 1.0721601247787476, Average Training Loss: 1.0102384278648777, Training Accuracy: 0.6365131578947368\n",
            "Epoch 2/10, Batch Loss: 1.0356924533843994, Average Training Loss: 1.0108910951858912, Training Accuracy: 0.6362179487179487\n",
            "Epoch 2/10, Batch Loss: 0.787977397441864, Average Training Loss: 1.0053182527422906, Training Accuracy: 0.6359375\n",
            "Epoch 2/10, Batch Loss: 0.7728840112686157, Average Training Loss: 0.9996491249014692, Training Accuracy: 0.6402439024390244\n",
            "Epoch 2/10, Batch Loss: 1.2571756839752197, Average Training Loss: 1.0057807096413203, Training Accuracy: 0.6383928571428571\n",
            "Epoch 2/10, Batch Loss: 0.9489063620567322, Average Training Loss: 1.0044580503951672, Training Accuracy: 0.6395348837209303\n",
            "Epoch 2/10, Batch Loss: 0.8564425706863403, Average Training Loss: 1.0010940622199664, Training Accuracy: 0.6377840909090909\n",
            "Epoch 2/10, Batch Loss: 0.9485020041465759, Average Training Loss: 0.9999253498183356, Training Accuracy: 0.6388888888888888\n",
            "Epoch 2/10, Batch Loss: 0.6826961040496826, Average Training Loss: 0.9930290618668431, Training Accuracy: 0.6426630434782609\n",
            "Epoch 2/10, Batch Loss: 1.1396058797836304, Average Training Loss: 0.9961477175672003, Training Accuracy: 0.6409574468085106\n",
            "Epoch 2/10, Batch Loss: 0.7808020114898682, Average Training Loss: 0.9916613486905893, Training Accuracy: 0.64453125\n",
            "Epoch 2/10, Batch Loss: 1.4480420351028442, Average Training Loss: 1.000975240250023, Training Accuracy: 0.6403061224489796\n",
            "Epoch 2/10, Batch Loss: 0.702319860458374, Average Training Loss: 0.99500213265419, Training Accuracy: 0.645\n",
            "Epoch 2/10, Batch Loss: 0.7876858115196228, Average Training Loss: 0.9909371067495907, Training Accuracy: 0.6470588235294118\n",
            "Epoch 2/10, Batch Loss: 0.9348097443580627, Average Training Loss: 0.9898577343959075, Training Accuracy: 0.6454326923076923\n",
            "Epoch 2/10, Batch Loss: 1.4184952974319458, Average Training Loss: 0.9979452355852667, Training Accuracy: 0.6415094339622641\n",
            "Epoch 2/10, Batch Loss: 0.8867028951644897, Average Training Loss: 0.9958851922441412, Training Accuracy: 0.6423611111111112\n",
            "Epoch 2/10, Batch Loss: 0.9317425489425659, Average Training Loss: 0.9947189623659307, Training Accuracy: 0.6431818181818182\n",
            "Epoch 2/10, Batch Loss: 1.3477603197097778, Average Training Loss: 1.0010232723184995, Training Accuracy: 0.6417410714285714\n",
            "Epoch 2/10, Batch Loss: 0.9832552075386047, Average Training Loss: 1.0007115518837644, Training Accuracy: 0.6414473684210527\n",
            "Epoch 2/10, Batch Loss: 0.9520302414894104, Average Training Loss: 0.9998722189459307, Training Accuracy: 0.6422413793103449\n",
            "Epoch 2/10, Batch Loss: 1.331409215927124, Average Training Loss: 1.0054914900812053, Training Accuracy: 0.6408898305084746\n",
            "Epoch 2/10, Batch Loss: 0.49712255597114563, Average Training Loss: 0.9970186745127042, Training Accuracy: 0.6447916666666667\n",
            "Epoch 2/10, Batch Loss: 1.0770301818847656, Average Training Loss: 0.9983303385679839, Training Accuracy: 0.6434426229508197\n",
            "Epoch 2/10, Batch Loss: 0.8810803294181824, Average Training Loss: 0.9964392093881485, Training Accuracy: 0.6431451612903226\n",
            "Epoch 2/10, Batch Loss: 0.9741343259811401, Average Training Loss: 0.9960851636197832, Training Accuracy: 0.6428571428571429\n",
            "Epoch 2/10, Batch Loss: 0.8563134074211121, Average Training Loss: 0.993901229929179, Training Accuracy: 0.6435546875\n",
            "Epoch 2/10, Batch Loss: 0.9479434490203857, Average Training Loss: 0.9931941871459667, Training Accuracy: 0.6432692307692308\n",
            "Epoch 2/10, Batch Loss: 0.5754721164703369, Average Training Loss: 0.9868650648630026, Training Accuracy: 0.6448863636363636\n",
            "Epoch 2/10, Batch Loss: 0.7057538628578186, Average Training Loss: 0.9826693752808358, Training Accuracy: 0.648320895522388\n",
            "Epoch 2/10, Batch Loss: 1.1652017831802368, Average Training Loss: 0.9853536753970034, Training Accuracy: 0.6470588235294118\n",
            "Epoch 2/10, Batch Loss: 0.9900275468826294, Average Training Loss: 0.985421412664911, Training Accuracy: 0.6467391304347826\n",
            "Epoch 2/10, Batch Loss: 1.03531813621521, Average Training Loss: 0.9861342230013439, Training Accuracy: 0.6455357142857143\n",
            "Epoch 2/10, Batch Loss: 0.8330866098403931, Average Training Loss: 0.9839786228159784, Training Accuracy: 0.6461267605633803\n",
            "Epoch 2/10, Batch Loss: 0.6363536715507507, Average Training Loss: 0.9791504984928502, Training Accuracy: 0.6484375\n",
            "Epoch 2/10, Batch Loss: 0.9452166557312012, Average Training Loss: 0.9786856513317317, Training Accuracy: 0.648972602739726\n",
            "Epoch 2/10, Batch Loss: 0.9332111477851868, Average Training Loss: 0.9780711310135352, Training Accuracy: 0.6486486486486487\n",
            "Epoch 2/10, Batch Loss: 0.587100088596344, Average Training Loss: 0.972858183781306, Training Accuracy: 0.6508333333333334\n",
            "Epoch 2/10, Batch Loss: 0.954094409942627, Average Training Loss: 0.9726112920202707, Training Accuracy: 0.649671052631579\n",
            "Epoch 2/10, Batch Loss: 0.7474698424339294, Average Training Loss: 0.969687377090578, Training Accuracy: 0.6501623376623377\n",
            "Epoch 2/10, Batch Loss: 0.8453929424285889, Average Training Loss: 0.9680938586974756, Training Accuracy: 0.6514423076923077\n",
            "Epoch 2/10, Batch Loss: 1.2253555059432983, Average Training Loss: 0.971350335244891, Training Accuracy: 0.6487341772151899\n",
            "Epoch 2/10, Batch Loss: 0.45676106214523315, Average Training Loss: 0.9649179693311453, Training Accuracy: 0.6515625\n",
            "Epoch 2/10, Batch Loss: 1.1371374130249023, Average Training Loss: 0.9670441353026732, Training Accuracy: 0.6496913580246914\n",
            "Epoch 2/10, Batch Loss: 1.2071949243545532, Average Training Loss: 0.9699728034618424, Training Accuracy: 0.6486280487804879\n",
            "Epoch 2/10, Batch Loss: 0.524205207824707, Average Training Loss: 0.9646021095385034, Training Accuracy: 0.651355421686747\n",
            "Epoch 2/10, Batch Loss: 0.6214677691459656, Average Training Loss: 0.9605171769147828, Training Accuracy: 0.6532738095238095\n",
            "Epoch 2/10, Batch Loss: 1.057955026626587, Average Training Loss: 0.9616635045584511, Training Accuracy: 0.6536764705882353\n",
            "Epoch 2/10, Batch Loss: 1.0545796155929565, Average Training Loss: 0.9627439244542011, Training Accuracy: 0.6518895348837209\n",
            "Epoch 2/10, Batch Loss: 0.718072235584259, Average Training Loss: 0.9599316061913282, Training Accuracy: 0.6522988505747126\n",
            "Epoch 2/10, Batch Loss: 1.1137622594833374, Average Training Loss: 0.9616796817969192, Training Accuracy: 0.6519886363636364\n",
            "Epoch 2/10, Batch Loss: 1.0297399759292603, Average Training Loss: 0.9624444042029006, Training Accuracy: 0.6509831460674157\n",
            "Epoch 2/10, Batch Loss: 1.0379724502563477, Average Training Loss: 0.9632836047146055, Training Accuracy: 0.65\n",
            "Epoch 2/10, Batch Loss: 0.659360945224762, Average Training Loss: 0.9599437952696622, Training Accuracy: 0.6517857142857143\n",
            "Epoch 2/10, Batch Loss: 0.836635947227478, Average Training Loss: 0.9586034925735515, Training Accuracy: 0.6528532608695652\n",
            "Epoch 2/10, Batch Loss: 0.6936190724372864, Average Training Loss: 0.9557541977333767, Training Accuracy: 0.6518817204301075\n",
            "Epoch 2/10, Batch Loss: 1.0659613609313965, Average Training Loss: 0.9569266143631427, Training Accuracy: 0.651595744680851\n",
            "Epoch 2/10, Batch Loss: 0.7500953078269958, Average Training Loss: 0.9547494427153939, Training Accuracy: 0.6526315789473685\n",
            "Epoch 2/10, Batch Loss: 0.7660487294197083, Average Training Loss: 0.9527838102852305, Training Accuracy: 0.65234375\n",
            "Epoch 2/10, Batch Loss: 0.8867988586425781, Average Training Loss: 0.952103553051801, Training Accuracy: 0.6527061855670103\n",
            "Epoch 2/10, Batch Loss: 0.8562325239181519, Average Training Loss: 0.9511252772443148, Training Accuracy: 0.6524234693877551\n",
            "Epoch 2/10, Batch Loss: 0.7430475354194641, Average Training Loss: 0.9490234818723466, Training Accuracy: 0.6521464646464646\n",
            "Epoch 2/10, Batch Loss: 0.7419860363006592, Average Training Loss: 0.9469531074166297, Training Accuracy: 0.651875\n",
            "Epoch 2/10, Batch Loss: 0.9860550165176392, Average Training Loss: 0.9473402550314912, Training Accuracy: 0.6516089108910891\n",
            "Epoch 2/10, Batch Loss: 0.5591980218887329, Average Training Loss: 0.9435349390202877, Training Accuracy: 0.6531862745098039\n",
            "Epoch 2/10, Batch Loss: 1.324462652206421, Average Training Loss: 0.9472332663327745, Training Accuracy: 0.6516990291262136\n",
            "Epoch 2/10, Batch Loss: 0.8356425762176514, Average Training Loss: 0.9461602789278214, Training Accuracy: 0.6514423076923077\n",
            "Epoch 2/10, Batch Loss: 0.9169601202011108, Average Training Loss: 0.9458821821780432, Training Accuracy: 0.6517857142857143\n",
            "Epoch 2/10, Batch Loss: 1.1504852771759033, Average Training Loss: 0.9478124000553815, Training Accuracy: 0.6509433962264151\n",
            "Epoch 2/10, Batch Loss: 0.7655825614929199, Average Training Loss: 0.946109317451994, Training Accuracy: 0.6518691588785047\n",
            "Epoch 2/10, Batch Loss: 1.194926381111145, Average Training Loss: 0.9484131791525416, Training Accuracy: 0.6504629629629629\n",
            "Epoch 2/10, Batch Loss: 0.527217447757721, Average Training Loss: 0.9445489981305708, Training Accuracy: 0.6519495412844036\n",
            "Epoch 2/10, Batch Loss: 1.0859941244125366, Average Training Loss: 0.9458348629149523, Training Accuracy: 0.6511363636363636\n",
            "Epoch 2/10, Batch Loss: 0.8646191954612732, Average Training Loss: 0.9451031902351895, Training Accuracy: 0.651463963963964\n",
            "Epoch 2/10, Batch Loss: 1.2463210821151733, Average Training Loss: 0.9477926356984037, Training Accuracy: 0.6506696428571429\n",
            "Epoch 2/10, Batch Loss: 1.1175557374954224, Average Training Loss: 0.9492949640328905, Training Accuracy: 0.6504424778761062\n",
            "Epoch 2/10, Batch Loss: 1.1748560667037964, Average Training Loss: 0.9512735701966704, Training Accuracy: 0.649671052631579\n",
            "Epoch 2/10, Batch Loss: 0.6857756972312927, Average Training Loss: 0.9489648930404497, Training Accuracy: 0.6505434782608696\n",
            "Epoch 2/10, Batch Loss: 0.7231396436691284, Average Training Loss: 0.9470181236493176, Training Accuracy: 0.6519396551724138\n",
            "Epoch 2/10, Average Training Loss: 0.9470181236493176, Training Accuracy: 0.6519396551724138\n",
            "Epoch 2/10, Validation Loss: 28.74568146467209, Validation Accuracy: 0.6056034482758621\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.79      0.23      0.36        99\n",
            "                Educational Opportunity       0.36      0.44      0.39        87\n",
            "                         Family Support       0.74      0.99      0.84        93\n",
            "                      Financial Support       0.62      0.79      0.70        89\n",
            "                 Program Implementation       0.64      0.60      0.62        96\n",
            "\n",
            "                               accuracy                           0.61       464\n",
            "                              macro avg       0.63      0.61      0.58       464\n",
            "                           weighted avg       0.64      0.61      0.58       464\n",
            "\n",
            "Epoch 3/10, Batch Loss: 0.8829052448272705, Average Training Loss: 0.8829052448272705, Training Accuracy: 0.8125\n",
            "Epoch 3/10, Batch Loss: 0.7945523858070374, Average Training Loss: 0.8387288153171539, Training Accuracy: 0.75\n",
            "Epoch 3/10, Batch Loss: 0.9646443724632263, Average Training Loss: 0.8807006676991781, Training Accuracy: 0.7083333333333334\n",
            "Epoch 3/10, Batch Loss: 0.6305594444274902, Average Training Loss: 0.8181653618812561, Training Accuracy: 0.734375\n",
            "Epoch 3/10, Batch Loss: 0.8810839653015137, Average Training Loss: 0.8307490825653077, Training Accuracy: 0.7375\n",
            "Epoch 3/10, Batch Loss: 1.0046451091766357, Average Training Loss: 0.8597317536671957, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/10, Batch Loss: 0.9300912618637085, Average Training Loss: 0.8697831119809832, Training Accuracy: 0.7232142857142857\n",
            "Epoch 3/10, Batch Loss: 0.9483016729354858, Average Training Loss: 0.879597932100296, Training Accuracy: 0.71875\n",
            "Epoch 3/10, Batch Loss: 0.7924672365188599, Average Training Loss: 0.8699167437023587, Training Accuracy: 0.7152777777777778\n",
            "Epoch 3/10, Batch Loss: 0.7588083148002625, Average Training Loss: 0.858805900812149, Training Accuracy: 0.7125\n",
            "Epoch 3/10, Batch Loss: 0.7574521899223328, Average Training Loss: 0.8495919270948931, Training Accuracy: 0.7159090909090909\n",
            "Epoch 3/10, Batch Loss: 0.7113399505615234, Average Training Loss: 0.8380709290504456, Training Accuracy: 0.71875\n",
            "Epoch 3/10, Batch Loss: 0.5500280857086182, Average Training Loss: 0.8159137872549204, Training Accuracy: 0.7259615384615384\n",
            "Epoch 3/10, Batch Loss: 0.5972871780395508, Average Training Loss: 0.800297600882394, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/10, Batch Loss: 0.8421444296836853, Average Training Loss: 0.8030873894691467, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/10, Batch Loss: 0.434113085269928, Average Training Loss: 0.7800264954566956, Training Accuracy: 0.734375\n",
            "Epoch 3/10, Batch Loss: 0.8661894798278809, Average Training Loss: 0.7850949063020594, Training Accuracy: 0.7316176470588235\n",
            "Epoch 3/10, Batch Loss: 0.9365763068199158, Average Training Loss: 0.7935105396641625, Training Accuracy: 0.7256944444444444\n",
            "Epoch 3/10, Batch Loss: 0.8162388205528259, Average Training Loss: 0.7947067649740922, Training Accuracy: 0.7269736842105263\n",
            "Epoch 3/10, Batch Loss: 0.7209406495094299, Average Training Loss: 0.7910184592008591, Training Accuracy: 0.725\n",
            "Epoch 3/10, Batch Loss: 0.5847600102424622, Average Training Loss: 0.7811966282980782, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/10, Batch Loss: 0.6486035585403442, Average Training Loss: 0.7751696705818176, Training Accuracy: 0.7301136363636364\n",
            "Epoch 3/10, Batch Loss: 0.48294126987457275, Average Training Loss: 0.7624640879423722, Training Accuracy: 0.7309782608695652\n",
            "Epoch 3/10, Batch Loss: 0.7677465081214905, Average Training Loss: 0.7626841887831688, Training Accuracy: 0.7265625\n",
            "Epoch 3/10, Batch Loss: 0.6478797197341919, Average Training Loss: 0.7580920100212097, Training Accuracy: 0.73\n",
            "Epoch 3/10, Batch Loss: 0.5651313066482544, Average Training Loss: 0.7506704445068653, Training Accuracy: 0.7331730769230769\n",
            "Epoch 3/10, Batch Loss: 0.6592179536819458, Average Training Loss: 0.7472833152170535, Training Accuracy: 0.7337962962962963\n",
            "Epoch 3/10, Batch Loss: 0.9403514266014099, Average Training Loss: 0.7541786049093518, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/10, Batch Loss: 0.7819794416427612, Average Training Loss: 0.7551372544518833, Training Accuracy: 0.7349137931034483\n",
            "Epoch 3/10, Batch Loss: 1.0086711645126343, Average Training Loss: 0.7635883847872417, Training Accuracy: 0.73125\n",
            "Epoch 3/10, Batch Loss: 0.6927332878112793, Average Training Loss: 0.7613027364976944, Training Accuracy: 0.7338709677419355\n",
            "Epoch 3/10, Batch Loss: 0.9701968431472778, Average Training Loss: 0.7678306773304939, Training Accuracy: 0.732421875\n",
            "Epoch 3/10, Batch Loss: 0.6257365345954895, Average Training Loss: 0.763524794217312, Training Accuracy: 0.7329545454545454\n",
            "Epoch 3/10, Batch Loss: 0.9456659555435181, Average Training Loss: 0.7688818871974945, Training Accuracy: 0.7316176470588235\n",
            "Epoch 3/10, Batch Loss: 0.5626575946807861, Average Training Loss: 0.76298976455416, Training Accuracy: 0.7339285714285714\n",
            "Epoch 3/10, Batch Loss: 0.5942532420158386, Average Training Loss: 0.7583026389280955, Training Accuracy: 0.7378472222222222\n",
            "Epoch 3/10, Batch Loss: 0.9586260914802551, Average Training Loss: 0.7637167862943701, Training Accuracy: 0.7347972972972973\n",
            "Epoch 3/10, Batch Loss: 0.7993831634521484, Average Training Loss: 0.7646553751669432, Training Accuracy: 0.7351973684210527\n",
            "Epoch 3/10, Batch Loss: 0.803792417049408, Average Training Loss: 0.7656588890613654, Training Accuracy: 0.7323717948717948\n",
            "Epoch 3/10, Batch Loss: 0.7211794853210449, Average Training Loss: 0.7645469039678574, Training Accuracy: 0.7328125\n",
            "Epoch 3/10, Batch Loss: 0.9350475072860718, Average Training Loss: 0.7687054552683016, Training Accuracy: 0.7271341463414634\n",
            "Epoch 3/10, Batch Loss: 0.46343567967414856, Average Training Loss: 0.7614371272779646, Training Accuracy: 0.7306547619047619\n",
            "Epoch 3/10, Batch Loss: 0.6551646590232849, Average Training Loss: 0.7589656745278558, Training Accuracy: 0.7340116279069767\n",
            "Epoch 3/10, Batch Loss: 1.0412546396255493, Average Training Loss: 0.7653813328255307, Training Accuracy: 0.7329545454545454\n",
            "Epoch 3/10, Batch Loss: 0.7833916544914246, Average Training Loss: 0.7657815621958839, Training Accuracy: 0.7333333333333333\n",
            "Epoch 3/10, Batch Loss: 0.7315139174461365, Average Training Loss: 0.7650366133969763, Training Accuracy: 0.7336956521739131\n",
            "Epoch 3/10, Batch Loss: 0.8587386012077332, Average Training Loss: 0.7670302727120988, Training Accuracy: 0.7353723404255319\n",
            "Epoch 3/10, Batch Loss: 0.7414719462394714, Average Training Loss: 0.7664978075772524, Training Accuracy: 0.734375\n",
            "Epoch 3/10, Batch Loss: 0.7243290543556213, Average Training Loss: 0.765637220776811, Training Accuracy: 0.7346938775510204\n",
            "Epoch 3/10, Batch Loss: 0.6729834079742432, Average Training Loss: 0.7637841445207596, Training Accuracy: 0.735\n",
            "Epoch 3/10, Batch Loss: 0.896514356136322, Average Training Loss: 0.7663866976896921, Training Accuracy: 0.7328431372549019\n",
            "Epoch 3/10, Batch Loss: 0.6623938083648682, Average Training Loss: 0.7643868344334456, Training Accuracy: 0.7307692307692307\n",
            "Epoch 3/10, Batch Loss: 0.9813532829284668, Average Training Loss: 0.7684805410088233, Training Accuracy: 0.7275943396226415\n",
            "Epoch 3/10, Batch Loss: 0.5487958788871765, Average Training Loss: 0.7644123065250891, Training Accuracy: 0.7303240740740741\n",
            "Epoch 3/10, Batch Loss: 0.8141345381736755, Average Training Loss: 0.765316347100518, Training Accuracy: 0.7295454545454545\n",
            "Epoch 3/10, Batch Loss: 0.7652822136878967, Average Training Loss: 0.7653157375752926, Training Accuracy: 0.7310267857142857\n",
            "Epoch 3/10, Batch Loss: 0.9201765656471252, Average Training Loss: 0.7680325942081317, Training Accuracy: 0.7302631578947368\n",
            "Epoch 3/10, Batch Loss: 0.5537322163581848, Average Training Loss: 0.7643377601072706, Training Accuracy: 0.7306034482758621\n",
            "Epoch 3/10, Batch Loss: 0.5233250260353088, Average Training Loss: 0.7602527985128306, Training Accuracy: 0.7330508474576272\n",
            "Epoch 3/10, Batch Loss: 0.8982723951339722, Average Training Loss: 0.762553125123183, Training Accuracy: 0.7302083333333333\n",
            "Epoch 3/10, Batch Loss: 0.9203348755836487, Average Training Loss: 0.7651397111963053, Training Accuracy: 0.7295081967213115\n",
            "Epoch 3/10, Batch Loss: 0.614526629447937, Average Training Loss: 0.7627104679422994, Training Accuracy: 0.7318548387096774\n",
            "Epoch 3/10, Batch Loss: 0.9287336468696594, Average Training Loss: 0.7653457564967019, Training Accuracy: 0.7301587301587301\n",
            "Epoch 3/10, Batch Loss: 1.0051686763763428, Average Training Loss: 0.7690929896198213, Training Accuracy: 0.728515625\n",
            "Epoch 3/10, Batch Loss: 0.7365976572036743, Average Training Loss: 0.7685930614288037, Training Accuracy: 0.7278846153846154\n",
            "Epoch 3/10, Batch Loss: 0.8826083540916443, Average Training Loss: 0.7703205658630892, Training Accuracy: 0.7272727272727273\n",
            "Epoch 3/10, Batch Loss: 0.7202446460723877, Average Training Loss: 0.7695731640751682, Training Accuracy: 0.7276119402985075\n",
            "Epoch 3/10, Batch Loss: 0.6117690801620483, Average Training Loss: 0.7672525157823282, Training Accuracy: 0.7288602941176471\n",
            "Epoch 3/10, Batch Loss: 0.27898114919662476, Average Training Loss: 0.7601761191651442, Training Accuracy: 0.7327898550724637\n",
            "Epoch 3/10, Batch Loss: 0.7036142349243164, Average Training Loss: 0.759368092247418, Training Accuracy: 0.7321428571428571\n",
            "Epoch 3/10, Batch Loss: 0.9241505265235901, Average Training Loss: 0.7616889716034204, Training Accuracy: 0.7315140845070423\n",
            "Epoch 3/10, Batch Loss: 0.6730469465255737, Average Training Loss: 0.7604578323662281, Training Accuracy: 0.7335069444444444\n",
            "Epoch 3/10, Batch Loss: 0.6849502325057983, Average Training Loss: 0.7594234816832085, Training Accuracy: 0.7337328767123288\n",
            "Epoch 3/10, Batch Loss: 0.8993239402770996, Average Training Loss: 0.7613140284209639, Training Accuracy: 0.731418918918919\n",
            "Epoch 3/10, Batch Loss: 1.0886669158935547, Average Training Loss: 0.765678733587265, Training Accuracy: 0.7308333333333333\n",
            "Epoch 3/10, Batch Loss: 0.5895322561264038, Average Training Loss: 0.7633610167785695, Training Accuracy: 0.7327302631578947\n",
            "Epoch 3/10, Batch Loss: 0.7220472097396851, Average Training Loss: 0.7628244738300125, Training Accuracy: 0.7337662337662337\n",
            "Epoch 3/10, Batch Loss: 1.1256712675094604, Average Training Loss: 0.7674763558002619, Training Accuracy: 0.7315705128205128\n",
            "Epoch 3/10, Batch Loss: 0.6386237144470215, Average Training Loss: 0.7658453097071829, Training Accuracy: 0.7318037974683544\n",
            "Epoch 3/10, Batch Loss: 0.616719663143158, Average Training Loss: 0.7639812391251326, Training Accuracy: 0.7328125\n",
            "Epoch 3/10, Batch Loss: 1.0259445905685425, Average Training Loss: 0.7672153545750512, Training Accuracy: 0.7314814814814815\n",
            "Epoch 3/10, Batch Loss: 0.596722424030304, Average Training Loss: 0.7651361724952372, Training Accuracy: 0.7317073170731707\n",
            "Epoch 3/10, Batch Loss: 0.7648878693580627, Average Training Loss: 0.7651331808911749, Training Accuracy: 0.7304216867469879\n",
            "Epoch 3/10, Batch Loss: 0.9766636490821838, Average Training Loss: 0.7676514007505917, Training Accuracy: 0.7299107142857143\n",
            "Epoch 3/10, Batch Loss: 0.6168026924133301, Average Training Loss: 0.7658767100642709, Training Accuracy: 0.7308823529411764\n",
            "Epoch 3/10, Batch Loss: 0.5266855359077454, Average Training Loss: 0.7630954173415206, Training Accuracy: 0.7318313953488372\n",
            "Epoch 3/10, Batch Loss: 0.8042430281639099, Average Training Loss: 0.7635683783854561, Training Accuracy: 0.7320402298850575\n",
            "Epoch 3/10, Batch Loss: 0.8479834794998169, Average Training Loss: 0.7645276408981193, Training Accuracy: 0.7322443181818182\n",
            "Epoch 3/10, Batch Loss: 0.8943333625793457, Average Training Loss: 0.7659861321529645, Training Accuracy: 0.7317415730337079\n",
            "Epoch 3/10, Batch Loss: 0.9329133033752441, Average Training Loss: 0.7678408784998788, Training Accuracy: 0.7298611111111111\n",
            "Epoch 3/10, Batch Loss: 0.7814211845397949, Average Training Loss: 0.7679901126321855, Training Accuracy: 0.7300824175824175\n",
            "Epoch 3/10, Batch Loss: 0.6635734438896179, Average Training Loss: 0.7668551488415055, Training Accuracy: 0.7309782608695652\n",
            "Epoch 3/10, Batch Loss: 1.0131282806396484, Average Training Loss: 0.7695032470328833, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/10, Batch Loss: 0.5261754989624023, Average Training Loss: 0.7669146539683037, Training Accuracy: 0.7313829787234043\n",
            "Epoch 3/10, Batch Loss: 0.8267487287521362, Average Training Loss: 0.7675444863344494, Training Accuracy: 0.7302631578947368\n",
            "Epoch 3/10, Batch Loss: 0.7809095978736877, Average Training Loss: 0.7676837062463164, Training Accuracy: 0.73046875\n",
            "Epoch 3/10, Batch Loss: 0.6457892656326294, Average Training Loss: 0.7664270625286496, Training Accuracy: 0.7313144329896907\n",
            "Epoch 3/10, Batch Loss: 0.6511687636375427, Average Training Loss: 0.7652509574379239, Training Accuracy: 0.7315051020408163\n",
            "Epoch 3/10, Batch Loss: 1.3197333812713623, Average Training Loss: 0.7708517900018981, Training Accuracy: 0.7297979797979798\n",
            "Epoch 3/10, Batch Loss: 0.8672026991844177, Average Training Loss: 0.7718152990937233, Training Accuracy: 0.729375\n",
            "Epoch 3/10, Batch Loss: 0.8842736482620239, Average Training Loss: 0.7729287480953897, Training Accuracy: 0.7277227722772277\n",
            "Epoch 3/10, Batch Loss: 0.48993298411369324, Average Training Loss: 0.7701542798210593, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/10, Batch Loss: 0.6202152967453003, Average Training Loss: 0.7686985615387704, Training Accuracy: 0.7299757281553398\n",
            "Epoch 3/10, Batch Loss: 0.9412230253219604, Average Training Loss: 0.7703574506136087, Training Accuracy: 0.7277644230769231\n",
            "Epoch 3/10, Batch Loss: 1.331165075302124, Average Training Loss: 0.7756984756106422, Training Accuracy: 0.7261904761904762\n",
            "Epoch 3/10, Batch Loss: 0.9141343235969543, Average Training Loss: 0.7770044741765508, Training Accuracy: 0.7252358490566038\n",
            "Epoch 3/10, Batch Loss: 0.69273841381073, Average Training Loss: 0.7762169409021039, Training Accuracy: 0.7260514018691588\n",
            "Epoch 3/10, Batch Loss: 0.9619263410568237, Average Training Loss: 0.777936472385018, Training Accuracy: 0.7251157407407407\n",
            "Epoch 3/10, Batch Loss: 0.7048332095146179, Average Training Loss: 0.7772658002485923, Training Accuracy: 0.7259174311926605\n",
            "Epoch 3/10, Batch Loss: 1.0725291967391968, Average Training Loss: 0.7799500129439614, Training Accuracy: 0.725\n",
            "Epoch 3/10, Batch Loss: 0.6733790636062622, Average Training Loss: 0.7789899143012794, Training Accuracy: 0.7252252252252253\n",
            "Epoch 3/10, Batch Loss: 0.5717176198959351, Average Training Loss: 0.7771392688155174, Training Accuracy: 0.7260044642857143\n",
            "Epoch 3/10, Batch Loss: 0.8661358952522278, Average Training Loss: 0.7779268495804441, Training Accuracy: 0.7256637168141593\n",
            "Epoch 3/10, Batch Loss: 0.8001803755760193, Average Training Loss: 0.7781220559488263, Training Accuracy: 0.7258771929824561\n",
            "Epoch 3/10, Batch Loss: 0.541346549987793, Average Training Loss: 0.7760631385056869, Training Accuracy: 0.7271739130434782\n",
            "Epoch 3/10, Batch Loss: 0.6556006073951721, Average Training Loss: 0.7750246684099066, Training Accuracy: 0.7273706896551724\n",
            "Epoch 3/10, Average Training Loss: 0.7750246684099066, Training Accuracy: 0.7273706896551724\n",
            "Epoch 3/10, Validation Loss: 26.484470695257187, Validation Accuracy: 0.6616379310344828\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.61      0.74      0.67        99\n",
            "                Educational Opportunity       0.45      0.40      0.43        87\n",
            "                         Family Support       0.79      0.96      0.86        93\n",
            "                      Financial Support       0.68      0.67      0.68        89\n",
            "                 Program Implementation       0.76      0.52      0.62        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 4/10, Batch Loss: 0.7494419813156128, Average Training Loss: 0.7494419813156128, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.5649269819259644, Average Training Loss: 0.6571844816207886, Training Accuracy: 0.75\n",
            "Epoch 4/10, Batch Loss: 0.6305240988731384, Average Training Loss: 0.6482976873715719, Training Accuracy: 0.7708333333333334\n",
            "Epoch 4/10, Batch Loss: 0.6903432011604309, Average Training Loss: 0.6588090658187866, Training Accuracy: 0.78125\n",
            "Epoch 4/10, Batch Loss: 0.6259775161743164, Average Training Loss: 0.6522427558898926, Training Accuracy: 0.775\n",
            "Epoch 4/10, Batch Loss: 0.6104329824447632, Average Training Loss: 0.6452744603157043, Training Accuracy: 0.7708333333333334\n",
            "Epoch 4/10, Batch Loss: 0.4531513452529907, Average Training Loss: 0.6178283010210309, Training Accuracy: 0.7857142857142857\n",
            "Epoch 4/10, Batch Loss: 0.4489930272102356, Average Training Loss: 0.5967238917946815, Training Accuracy: 0.8046875\n",
            "Epoch 4/10, Batch Loss: 0.7059519290924072, Average Training Loss: 0.6088603403833177, Training Accuracy: 0.7986111111111112\n",
            "Epoch 4/10, Batch Loss: 0.5605341196060181, Average Training Loss: 0.6040277183055878, Training Accuracy: 0.8\n",
            "Epoch 4/10, Batch Loss: 0.5219328999519348, Average Training Loss: 0.5965645530007102, Training Accuracy: 0.8011363636363636\n",
            "Epoch 4/10, Batch Loss: 0.678054928779602, Average Training Loss: 0.6033554176489512, Training Accuracy: 0.796875\n",
            "Epoch 4/10, Batch Loss: 0.41499635577201843, Average Training Loss: 0.5888662590430334, Training Accuracy: 0.8028846153846154\n",
            "Epoch 4/10, Batch Loss: 0.5031058192253113, Average Training Loss: 0.5827405133417675, Training Accuracy: 0.8080357142857143\n",
            "Epoch 4/10, Batch Loss: 0.4063469171524048, Average Training Loss: 0.5709809402624766, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.5573423504829407, Average Training Loss: 0.5701285284012556, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.39585086703300476, Average Training Loss: 0.5598769012619468, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.4580100178718567, Average Training Loss: 0.5542176299624972, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.4772180914878845, Average Training Loss: 0.5501650226743597, Training Accuracy: 0.8157894736842105\n",
            "Epoch 4/10, Batch Loss: 0.7398298382759094, Average Training Loss: 0.5596482634544373, Training Accuracy: 0.815625\n",
            "Epoch 4/10, Batch Loss: 0.326406329870224, Average Training Loss: 0.5485415047123319, Training Accuracy: 0.8214285714285714\n",
            "Epoch 4/10, Batch Loss: 0.8401317000389099, Average Training Loss: 0.5617956044999036, Training Accuracy: 0.8181818181818182\n",
            "Epoch 4/10, Batch Loss: 0.4212627708911896, Average Training Loss: 0.5556854812995248, Training Accuracy: 0.8233695652173914\n",
            "Epoch 4/10, Batch Loss: 0.39691123366355896, Average Training Loss: 0.5490698876480261, Training Accuracy: 0.8255208333333334\n",
            "Epoch 4/10, Batch Loss: 0.5241661667823792, Average Training Loss: 0.5480737388134003, Training Accuracy: 0.825\n",
            "Epoch 4/10, Batch Loss: 0.5960980653762817, Average Training Loss: 0.5499208282965881, Training Accuracy: 0.8245192307692307\n",
            "Epoch 4/10, Batch Loss: 0.5923160910606384, Average Training Loss: 0.5514910232137751, Training Accuracy: 0.8263888888888888\n",
            "Epoch 4/10, Batch Loss: 0.7049176096916199, Average Training Loss: 0.5569705441594124, Training Accuracy: 0.8191964285714286\n",
            "Epoch 4/10, Batch Loss: 0.3229815661907196, Average Training Loss: 0.548901958712216, Training Accuracy: 0.8211206896551724\n",
            "Epoch 4/10, Batch Loss: 0.5622640252113342, Average Training Loss: 0.5493473609288534, Training Accuracy: 0.8208333333333333\n",
            "Epoch 4/10, Batch Loss: 0.5385411977767944, Average Training Loss: 0.5489987750207225, Training Accuracy: 0.8205645161290323\n",
            "Epoch 4/10, Batch Loss: 0.9809820652008057, Average Training Loss: 0.56249825283885, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.8628491163253784, Average Training Loss: 0.5715997941566237, Training Accuracy: 0.8106060606060606\n",
            "Epoch 4/10, Batch Loss: 0.5189663171768188, Average Training Loss: 0.5700517507160411, Training Accuracy: 0.8088235294117647\n",
            "Epoch 4/10, Batch Loss: 0.5054439902305603, Average Training Loss: 0.5682058147021702, Training Accuracy: 0.8107142857142857\n",
            "Epoch 4/10, Batch Loss: 0.6011769771575928, Average Training Loss: 0.569121680325932, Training Accuracy: 0.8090277777777778\n",
            "Epoch 4/10, Batch Loss: 0.39347803592681885, Average Training Loss: 0.5643745548016316, Training Accuracy: 0.8108108108108109\n",
            "Epoch 4/10, Batch Loss: 0.6675220727920532, Average Training Loss: 0.5670889631698006, Training Accuracy: 0.8092105263157895\n",
            "Epoch 4/10, Batch Loss: 0.4608001112937927, Average Training Loss: 0.5643636079934927, Training Accuracy: 0.8108974358974359\n",
            "Epoch 4/10, Batch Loss: 0.56953364610672, Average Training Loss: 0.5644928589463234, Training Accuracy: 0.809375\n",
            "Epoch 4/10, Batch Loss: 0.46674156188964844, Average Training Loss: 0.5621086809693313, Training Accuracy: 0.8109756097560976\n",
            "Epoch 4/10, Batch Loss: 0.6556991338729858, Average Training Loss: 0.564337025086085, Training Accuracy: 0.8110119047619048\n",
            "Epoch 4/10, Batch Loss: 0.8138481974601746, Average Training Loss: 0.5701396104901336, Training Accuracy: 0.809593023255814\n",
            "Epoch 4/10, Batch Loss: 0.401592880487442, Average Training Loss: 0.5663090029900725, Training Accuracy: 0.8110795454545454\n",
            "Epoch 4/10, Batch Loss: 0.4905425012111664, Average Training Loss: 0.5646253029505411, Training Accuracy: 0.8097222222222222\n",
            "Epoch 4/10, Batch Loss: 0.37011411786079407, Average Training Loss: 0.560396798926851, Training Accuracy: 0.811141304347826\n",
            "Epoch 4/10, Batch Loss: 0.4153015911579132, Average Training Loss: 0.5573096668466608, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.6727811694145203, Average Training Loss: 0.5597153231501579, Training Accuracy: 0.8098958333333334\n",
            "Epoch 4/10, Batch Loss: 0.4234253764152527, Average Training Loss: 0.5569338956657721, Training Accuracy: 0.8099489795918368\n",
            "Epoch 4/10, Batch Loss: 0.6441232562065125, Average Training Loss: 0.5586776828765869, Training Accuracy: 0.81\n",
            "Epoch 4/10, Batch Loss: 0.6749780774116516, Average Training Loss: 0.5609580827694313, Training Accuracy: 0.8100490196078431\n",
            "Epoch 4/10, Batch Loss: 0.5105946660041809, Average Training Loss: 0.5599895555239457, Training Accuracy: 0.8100961538461539\n",
            "Epoch 4/10, Batch Loss: 0.37105658650398254, Average Training Loss: 0.5564247825235691, Training Accuracy: 0.8113207547169812\n",
            "Epoch 4/10, Batch Loss: 0.7808364033699036, Average Training Loss: 0.5605805532799827, Training Accuracy: 0.8101851851851852\n",
            "Epoch 4/10, Batch Loss: 0.5715886950492859, Average Training Loss: 0.5607807013121519, Training Accuracy: 0.8113636363636364\n",
            "Epoch 4/10, Batch Loss: 0.7581402063369751, Average Training Loss: 0.5643049781875951, Training Accuracy: 0.8113839285714286\n",
            "Epoch 4/10, Batch Loss: 0.21823833882808685, Average Training Loss: 0.5582336336374283, Training Accuracy: 0.8146929824561403\n",
            "Epoch 4/10, Batch Loss: 0.8459583520889282, Average Training Loss: 0.5631944046452128, Training Accuracy: 0.8125\n",
            "Epoch 4/10, Batch Loss: 0.7400457262992859, Average Training Loss: 0.5661918846732479, Training Accuracy: 0.8103813559322034\n",
            "Epoch 4/10, Batch Loss: 0.4467863142490387, Average Training Loss: 0.5642017918328445, Training Accuracy: 0.8114583333333333\n",
            "Epoch 4/10, Batch Loss: 0.6990631818771362, Average Training Loss: 0.5664126342925869, Training Accuracy: 0.8104508196721312\n",
            "Epoch 4/10, Batch Loss: 0.24982409179210663, Average Training Loss: 0.5613063674780631, Training Accuracy: 0.811491935483871\n",
            "Epoch 4/10, Batch Loss: 0.7600632905960083, Average Training Loss: 0.5644612392735859, Training Accuracy: 0.810515873015873\n",
            "Epoch 4/10, Batch Loss: 0.8848860859870911, Average Training Loss: 0.5694678775034845, Training Accuracy: 0.80859375\n",
            "Epoch 4/10, Batch Loss: 0.947324275970459, Average Training Loss: 0.5752810528645149, Training Accuracy: 0.8067307692307693\n",
            "Epoch 4/10, Batch Loss: 0.6732932925224304, Average Training Loss: 0.5767660867987257, Training Accuracy: 0.8039772727272727\n",
            "Epoch 4/10, Batch Loss: 0.6048749685287476, Average Training Loss: 0.5771856223469349, Training Accuracy: 0.8031716417910447\n",
            "Epoch 4/10, Batch Loss: 0.4860748052597046, Average Training Loss: 0.5758457573897698, Training Accuracy: 0.8042279411764706\n",
            "Epoch 4/10, Batch Loss: 0.5059451460838318, Average Training Loss: 0.5748327050520026, Training Accuracy: 0.8061594202898551\n",
            "Epoch 4/10, Batch Loss: 0.3962186872959137, Average Training Loss: 0.5722810762269156, Training Accuracy: 0.8071428571428572\n",
            "Epoch 4/10, Batch Loss: 0.810254693031311, Average Training Loss: 0.5756328173086677, Training Accuracy: 0.8054577464788732\n",
            "Epoch 4/10, Batch Loss: 0.4940202534198761, Average Training Loss: 0.5744993094768789, Training Accuracy: 0.8072916666666666\n",
            "Epoch 4/10, Batch Loss: 0.617013692855835, Average Training Loss: 0.5750816982902892, Training Accuracy: 0.8082191780821918\n",
            "Epoch 4/10, Batch Loss: 0.660301923751831, Average Training Loss: 0.5762333229586885, Training Accuracy: 0.8074324324324325\n",
            "Epoch 4/10, Batch Loss: 0.5770140290260315, Average Training Loss: 0.5762437323729197, Training Accuracy: 0.8075\n",
            "Epoch 4/10, Batch Loss: 0.8124643564224243, Average Training Loss: 0.5793518984788343, Training Accuracy: 0.8075657894736842\n",
            "Epoch 4/10, Batch Loss: 0.44848886132240295, Average Training Loss: 0.5776523785157637, Training Accuracy: 0.8076298701298701\n",
            "Epoch 4/10, Batch Loss: 0.3549049198627472, Average Training Loss: 0.574796641866366, Training Accuracy: 0.8092948717948718\n",
            "Epoch 4/10, Batch Loss: 0.6151480078697205, Average Training Loss: 0.5753074186512187, Training Accuracy: 0.8085443037974683\n",
            "Epoch 4/10, Batch Loss: 0.9548937678337097, Average Training Loss: 0.5800522480159997, Training Accuracy: 0.80625\n",
            "Epoch 4/10, Batch Loss: 0.5871448516845703, Average Training Loss: 0.5801398110242537, Training Accuracy: 0.8055555555555556\n",
            "Epoch 4/10, Batch Loss: 0.5468027591705322, Average Training Loss: 0.5797332616114035, Training Accuracy: 0.805640243902439\n",
            "Epoch 4/10, Batch Loss: 0.5084856152534485, Average Training Loss: 0.5788748562335968, Training Accuracy: 0.8064759036144579\n",
            "Epoch 4/10, Batch Loss: 0.5420151352882385, Average Training Loss: 0.5784360500318664, Training Accuracy: 0.8072916666666666\n",
            "Epoch 4/10, Batch Loss: 1.120574712753296, Average Training Loss: 0.5848141519462361, Training Accuracy: 0.8036764705882353\n",
            "Epoch 4/10, Batch Loss: 0.7329870462417603, Average Training Loss: 0.5865370925775794, Training Accuracy: 0.8045058139534884\n",
            "Epoch 4/10, Batch Loss: 0.7137308120727539, Average Training Loss: 0.587999089353386, Training Accuracy: 0.8010057471264368\n",
            "Epoch 4/10, Batch Loss: 0.511387825012207, Average Training Loss: 0.5871285068040545, Training Accuracy: 0.8011363636363636\n",
            "Epoch 4/10, Batch Loss: 0.2640708088874817, Average Training Loss: 0.5834986450297109, Training Accuracy: 0.8033707865168539\n",
            "Epoch 4/10, Batch Loss: 0.5644385814666748, Average Training Loss: 0.5832868665456772, Training Accuracy: 0.8027777777777778\n",
            "Epoch 4/10, Batch Loss: 0.520229697227478, Average Training Loss: 0.5825939306191036, Training Accuracy: 0.8035714285714286\n",
            "Epoch 4/10, Batch Loss: 0.4328567087650299, Average Training Loss: 0.5809663521206897, Training Accuracy: 0.8036684782608695\n",
            "Epoch 4/10, Batch Loss: 0.602107048034668, Average Training Loss: 0.5811936714315927, Training Accuracy: 0.803763440860215\n",
            "Epoch 4/10, Batch Loss: 0.979953944683075, Average Training Loss: 0.5854358019980979, Training Accuracy: 0.8025265957446809\n",
            "Epoch 4/10, Batch Loss: 0.4534014165401459, Average Training Loss: 0.5840459663616984, Training Accuracy: 0.8032894736842106\n",
            "Epoch 4/10, Batch Loss: 0.3668079376220703, Average Training Loss: 0.5817830702289939, Training Accuracy: 0.8046875\n",
            "Epoch 4/10, Batch Loss: 0.4232392907142639, Average Training Loss: 0.5801485982752338, Training Accuracy: 0.8047680412371134\n",
            "Epoch 4/10, Batch Loss: 0.5654447078704834, Average Training Loss: 0.5799985585772262, Training Accuracy: 0.8042091836734694\n",
            "Epoch 4/10, Batch Loss: 0.5376898050308228, Average Training Loss: 0.5795711974302927, Training Accuracy: 0.8042929292929293\n",
            "Epoch 4/10, Batch Loss: 0.33114802837371826, Average Training Loss: 0.5770869657397271, Training Accuracy: 0.805625\n",
            "Epoch 4/10, Batch Loss: 0.6319035291671753, Average Training Loss: 0.577629703991484, Training Accuracy: 0.8050742574257426\n",
            "Epoch 4/10, Batch Loss: 0.46396806836128235, Average Training Loss: 0.5765153742304036, Training Accuracy: 0.8057598039215687\n",
            "Epoch 4/10, Batch Loss: 0.28819531202316284, Average Training Loss: 0.5737161503254788, Training Accuracy: 0.8070388349514563\n",
            "Epoch 4/10, Batch Loss: 0.4235087037086487, Average Training Loss: 0.5722718479541632, Training Accuracy: 0.8076923076923077\n",
            "Epoch 4/10, Batch Loss: 0.4879660904407501, Average Training Loss: 0.571468935977845, Training Accuracy: 0.8083333333333333\n",
            "Epoch 4/10, Batch Loss: 0.3593418300151825, Average Training Loss: 0.5694677368649896, Training Accuracy: 0.8089622641509434\n",
            "Epoch 4/10, Batch Loss: 0.15334315598011017, Average Training Loss: 0.5655787220903646, Training Accuracy: 0.8107476635514018\n",
            "Epoch 4/10, Batch Loss: 0.9633810520172119, Average Training Loss: 0.5692620769970946, Training Accuracy: 0.8101851851851852\n",
            "Epoch 4/10, Batch Loss: 0.7452101707458496, Average Training Loss: 0.5708762796920374, Training Accuracy: 0.8090596330275229\n",
            "Epoch 4/10, Batch Loss: 0.5566545128822327, Average Training Loss: 0.5707469909028573, Training Accuracy: 0.8090909090909091\n",
            "Epoch 4/10, Batch Loss: 0.5276058316230774, Average Training Loss: 0.5703583318102468, Training Accuracy: 0.8096846846846847\n",
            "Epoch 4/10, Batch Loss: 0.9410247206687927, Average Training Loss: 0.5736678531393409, Training Accuracy: 0.8074776785714286\n",
            "Epoch 4/10, Batch Loss: 0.5381955504417419, Average Training Loss: 0.5733539389561763, Training Accuracy: 0.8064159292035398\n",
            "Epoch 4/10, Batch Loss: 0.8876102566719055, Average Training Loss: 0.5761105733221037, Training Accuracy: 0.805921052631579\n",
            "Epoch 4/10, Batch Loss: 0.3440527319908142, Average Training Loss: 0.5740926790496578, Training Accuracy: 0.8070652173913043\n",
            "Epoch 4/10, Batch Loss: 0.20042388141155243, Average Training Loss: 0.5708713963113982, Training Accuracy: 0.8081896551724138\n",
            "Epoch 4/10, Average Training Loss: 0.5708713963113982, Training Accuracy: 0.8081896551724138\n",
            "Epoch 4/10, Validation Loss: 28.5178045630455, Validation Accuracy: 0.6573275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.71      0.63      0.67        99\n",
            "                Educational Opportunity       0.47      0.43      0.45        87\n",
            "                         Family Support       0.78      0.97      0.86        93\n",
            "                      Financial Support       0.61      0.73      0.66        89\n",
            "                 Program Implementation       0.68      0.53      0.60        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.65      0.66      0.65       464\n",
            "\n",
            "Epoch 5/10, Batch Loss: 0.39971789717674255, Average Training Loss: 0.39971789717674255, Training Accuracy: 0.8125\n",
            "Epoch 5/10, Batch Loss: 0.3305082321166992, Average Training Loss: 0.3651130646467209, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.2566586136817932, Average Training Loss: 0.328961580991745, Training Accuracy: 0.9166666666666666\n",
            "Epoch 5/10, Batch Loss: 0.3787974417209625, Average Training Loss: 0.3414205461740494, Training Accuracy: 0.90625\n",
            "Epoch 5/10, Batch Loss: 0.3054295480251312, Average Training Loss: 0.33422234654426575, Training Accuracy: 0.9125\n",
            "Epoch 5/10, Batch Loss: 0.1534086912870407, Average Training Loss: 0.30408673733472824, Training Accuracy: 0.9270833333333334\n",
            "Epoch 5/10, Batch Loss: 0.5585340857505798, Average Training Loss: 0.3404363585369928, Training Accuracy: 0.9107142857142857\n",
            "Epoch 5/10, Batch Loss: 0.4059962034225464, Average Training Loss: 0.34863133914768696, Training Accuracy: 0.8984375\n",
            "Epoch 5/10, Batch Loss: 0.2140664905309677, Average Training Loss: 0.3336796893013848, Training Accuracy: 0.9027777777777778\n",
            "Epoch 5/10, Batch Loss: 0.907595157623291, Average Training Loss: 0.3910712361335754, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.5588607788085938, Average Training Loss: 0.40632483092221344, Training Accuracy: 0.8693181818181818\n",
            "Epoch 5/10, Batch Loss: 0.2949214577674866, Average Training Loss: 0.3970412164926529, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.45250749588012695, Average Training Loss: 0.4013078533686124, Training Accuracy: 0.8701923076923077\n",
            "Epoch 5/10, Batch Loss: 0.5773573517799377, Average Training Loss: 0.41388281754084993, Training Accuracy: 0.8660714285714286\n",
            "Epoch 5/10, Batch Loss: 0.301582008600235, Average Training Loss: 0.40639609694480894, Training Accuracy: 0.8666666666666667\n",
            "Epoch 5/10, Batch Loss: 0.3806920647621155, Average Training Loss: 0.4047895949333906, Training Accuracy: 0.8671875\n",
            "Epoch 5/10, Batch Loss: 0.35528987646102905, Average Training Loss: 0.40187784678795757, Training Accuracy: 0.8676470588235294\n",
            "Epoch 5/10, Batch Loss: 0.589138925075531, Average Training Loss: 0.4122812400261561, Training Accuracy: 0.8645833333333334\n",
            "Epoch 5/10, Batch Loss: 0.16888028383255005, Average Training Loss: 0.39947066338438736, Training Accuracy: 0.8717105263157895\n",
            "Epoch 5/10, Batch Loss: 0.45776310563087463, Average Training Loss: 0.4023852854967117, Training Accuracy: 0.86875\n",
            "Epoch 5/10, Batch Loss: 0.16867943108081818, Average Training Loss: 0.39125643528643106, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.4530988335609436, Average Training Loss: 0.394067453389818, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.4248697757720947, Average Training Loss: 0.3954066847977431, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.23586851358413696, Average Training Loss: 0.38875926099717617, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.5735593438148499, Average Training Loss: 0.3961512643098831, Training Accuracy: 0.8725\n",
            "Epoch 5/10, Batch Loss: 0.34486648440361023, Average Training Loss: 0.39417877277502644, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.2123265415430069, Average Training Loss: 0.38744350495161833, Training Accuracy: 0.8796296296296297\n",
            "Epoch 5/10, Batch Loss: 0.5107272267341614, Average Training Loss: 0.39184649501528057, Training Accuracy: 0.8794642857142857\n",
            "Epoch 5/10, Batch Loss: 0.5318760275840759, Average Training Loss: 0.39667509958661834, Training Accuracy: 0.8771551724137931\n",
            "Epoch 5/10, Batch Loss: 0.33886802196502686, Average Training Loss: 0.39474819699923197, Training Accuracy: 0.8791666666666667\n",
            "Epoch 5/10, Batch Loss: 0.3270990252494812, Average Training Loss: 0.3925659656524658, Training Accuracy: 0.8790322580645161\n",
            "Epoch 5/10, Batch Loss: 0.6080582141876221, Average Training Loss: 0.39930009841918945, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.6017751693725586, Average Training Loss: 0.4054357066298976, Training Accuracy: 0.8712121212121212\n",
            "Epoch 5/10, Batch Loss: 0.2389749139547348, Average Training Loss: 0.40053980096298103, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.16360491514205933, Average Training Loss: 0.393770232796669, Training Accuracy: 0.8785714285714286\n",
            "Epoch 5/10, Batch Loss: 0.3898632526397705, Average Training Loss: 0.3936617055700885, Training Accuracy: 0.8784722222222222\n",
            "Epoch 5/10, Batch Loss: 0.34229379892349243, Average Training Loss: 0.39227338376882914, Training Accuracy: 0.8783783783783784\n",
            "Epoch 5/10, Batch Loss: 0.6730446815490723, Average Training Loss: 0.39966210213146713, Training Accuracy: 0.8733552631578947\n",
            "Epoch 5/10, Batch Loss: 0.4859943091869354, Average Training Loss: 0.4018757484662227, Training Accuracy: 0.8733974358974359\n",
            "Epoch 5/10, Batch Loss: 0.7472447752952576, Average Training Loss: 0.41050997413694856, Training Accuracy: 0.86875\n",
            "Epoch 5/10, Batch Loss: 0.6405002474784851, Average Training Loss: 0.4161194929989373, Training Accuracy: 0.864329268292683\n",
            "Epoch 5/10, Batch Loss: 0.16859234869480133, Average Training Loss: 0.4102259895631245, Training Accuracy: 0.8675595238095238\n",
            "Epoch 5/10, Batch Loss: 0.2973543107509613, Average Training Loss: 0.407601066800051, Training Accuracy: 0.8691860465116279\n",
            "Epoch 5/10, Batch Loss: 0.5909621119499207, Average Training Loss: 0.4117683632807298, Training Accuracy: 0.8664772727272727\n",
            "Epoch 5/10, Batch Loss: 0.22424867749214172, Average Training Loss: 0.4076012591520945, Training Accuracy: 0.8680555555555556\n",
            "Epoch 5/10, Batch Loss: 0.15143047273159027, Average Training Loss: 0.40203232901251834, Training Accuracy: 0.8709239130434783\n",
            "Epoch 5/10, Batch Loss: 0.24812597036361694, Average Training Loss: 0.3987577256370098, Training Accuracy: 0.8723404255319149\n",
            "Epoch 5/10, Batch Loss: 0.1607375144958496, Average Training Loss: 0.39379897123823565, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.3534794747829437, Average Training Loss: 0.3929761243718011, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.18439659476280212, Average Training Loss: 0.3888045337796211, Training Accuracy: 0.87625\n",
            "Epoch 5/10, Batch Loss: 0.31538915634155273, Average Training Loss: 0.3873650165749531, Training Accuracy: 0.8762254901960784\n",
            "Epoch 5/10, Batch Loss: 0.513741672039032, Average Training Loss: 0.38979533687233925, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.43059802055358887, Average Training Loss: 0.39056519882858926, Training Accuracy: 0.8761792452830188\n",
            "Epoch 5/10, Batch Loss: 0.5340120792388916, Average Training Loss: 0.3932216225398911, Training Accuracy: 0.8761574074074074\n",
            "Epoch 5/10, Batch Loss: 0.21463412046432495, Average Training Loss: 0.38997457704760813, Training Accuracy: 0.8772727272727273\n",
            "Epoch 5/10, Batch Loss: 0.534551739692688, Average Training Loss: 0.3925563120948417, Training Accuracy: 0.8761160714285714\n",
            "Epoch 5/10, Batch Loss: 0.25599735975265503, Average Training Loss: 0.39016054100111913, Training Accuracy: 0.8771929824561403\n",
            "Epoch 5/10, Batch Loss: 0.31855079531669617, Average Training Loss: 0.38892589021345664, Training Accuracy: 0.8771551724137931\n",
            "Epoch 5/10, Batch Loss: 0.7636379599571228, Average Training Loss: 0.3952769422430103, Training Accuracy: 0.8760593220338984\n",
            "Epoch 5/10, Batch Loss: 0.5485631227493286, Average Training Loss: 0.3978317119181156, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.4465939998626709, Average Training Loss: 0.3986310936876985, Training Accuracy: 0.875\n",
            "Epoch 5/10, Batch Loss: 0.24438542127609253, Average Training Loss: 0.3961432602617048, Training Accuracy: 0.876008064516129\n",
            "Epoch 5/10, Batch Loss: 0.41387614607810974, Average Training Loss: 0.39642473463974304, Training Accuracy: 0.8759920634920635\n",
            "Epoch 5/10, Batch Loss: 0.3069301247596741, Average Training Loss: 0.39502638136036694, Training Accuracy: 0.876953125\n",
            "Epoch 5/10, Batch Loss: 0.41096919775009155, Average Training Loss: 0.3952716554586704, Training Accuracy: 0.8778846153846154\n",
            "Epoch 5/10, Batch Loss: 0.34451356530189514, Average Training Loss: 0.39450259348659805, Training Accuracy: 0.8778409090909091\n",
            "Epoch 5/10, Batch Loss: 0.43668973445892334, Average Training Loss: 0.3951322523070805, Training Accuracy: 0.878731343283582\n",
            "Epoch 5/10, Batch Loss: 0.4781661033630371, Average Training Loss: 0.396353338352021, Training Accuracy: 0.8777573529411765\n",
            "Epoch 5/10, Batch Loss: 0.13617254793643951, Average Training Loss: 0.3925826022590416, Training Accuracy: 0.8786231884057971\n",
            "Epoch 5/10, Batch Loss: 0.4028017222881317, Average Training Loss: 0.3927285896880286, Training Accuracy: 0.8776785714285714\n",
            "Epoch 5/10, Batch Loss: 0.4171011745929718, Average Training Loss: 0.3930718655317602, Training Accuracy: 0.8776408450704225\n",
            "Epoch 5/10, Batch Loss: 0.5192021131515503, Average Training Loss: 0.3948236745264795, Training Accuracy: 0.8767361111111112\n",
            "Epoch 5/10, Batch Loss: 0.6987740397453308, Average Training Loss: 0.39898737815961444, Training Accuracy: 0.8741438356164384\n",
            "Epoch 5/10, Batch Loss: 0.4731312692165375, Average Training Loss: 0.3999893226333567, Training Accuracy: 0.8733108108108109\n",
            "Epoch 5/10, Batch Loss: 0.4353049099445343, Average Training Loss: 0.400460197130839, Training Accuracy: 0.8716666666666667\n",
            "Epoch 5/10, Batch Loss: 0.5822867751121521, Average Training Loss: 0.40285265210427734, Training Accuracy: 0.8700657894736842\n",
            "Epoch 5/10, Batch Loss: 0.5496281981468201, Average Training Loss: 0.40475882802690777, Training Accuracy: 0.8685064935064936\n",
            "Epoch 5/10, Batch Loss: 0.45712557435035706, Average Training Loss: 0.4054301965695161, Training Accuracy: 0.8685897435897436\n",
            "Epoch 5/10, Batch Loss: 0.7228868007659912, Average Training Loss: 0.4094486345973196, Training Accuracy: 0.8670886075949367\n",
            "Epoch 5/10, Batch Loss: 0.2825085520744324, Average Training Loss: 0.4078618835657835, Training Accuracy: 0.8671875\n",
            "Epoch 5/10, Batch Loss: 0.4119715690612793, Average Training Loss: 0.4079126204237526, Training Accuracy: 0.8665123456790124\n",
            "Epoch 5/10, Batch Loss: 0.647920548915863, Average Training Loss: 0.4108395463809734, Training Accuracy: 0.8658536585365854\n",
            "Epoch 5/10, Batch Loss: 0.2451648861169815, Average Training Loss: 0.408843466136829, Training Accuracy: 0.8667168674698795\n",
            "Epoch 5/10, Batch Loss: 0.37075620889663696, Average Training Loss: 0.40839004640777904, Training Accuracy: 0.8660714285714286\n",
            "Epoch 5/10, Batch Loss: 0.3504631519317627, Average Training Loss: 0.40770855353159063, Training Accuracy: 0.8661764705882353\n",
            "Epoch 5/10, Batch Loss: 0.4208303391933441, Average Training Loss: 0.4078611324346343, Training Accuracy: 0.8662790697674418\n",
            "Epoch 5/10, Batch Loss: 0.28900662064552307, Average Training Loss: 0.40649498862096634, Training Accuracy: 0.867816091954023\n",
            "Epoch 5/10, Batch Loss: 0.2842501103878021, Average Training Loss: 0.40510584227740765, Training Accuracy: 0.8678977272727273\n",
            "Epoch 5/10, Batch Loss: 0.23522187769412994, Average Training Loss: 0.4031970336865843, Training Accuracy: 0.8679775280898876\n",
            "Epoch 5/10, Batch Loss: 0.35768017172813416, Average Training Loss: 0.40269129077593485, Training Accuracy: 0.8673611111111111\n",
            "Epoch 5/10, Batch Loss: 0.6362965703010559, Average Training Loss: 0.4052583817597274, Training Accuracy: 0.8653846153846154\n",
            "Epoch 5/10, Batch Loss: 0.7494051456451416, Average Training Loss: 0.4089991074541341, Training Accuracy: 0.8641304347826086\n",
            "Epoch 5/10, Batch Loss: 0.3213236629962921, Average Training Loss: 0.4080563607395336, Training Accuracy: 0.8649193548387096\n",
            "Epoch 5/10, Batch Loss: 0.6738798022270203, Average Training Loss: 0.41088426969152814, Training Accuracy: 0.8636968085106383\n",
            "Epoch 5/10, Batch Loss: 0.4776199460029602, Average Training Loss: 0.41158675049480636, Training Accuracy: 0.8625\n",
            "Epoch 5/10, Batch Loss: 0.2943459153175354, Average Training Loss: 0.41036549179504317, Training Accuracy: 0.8626302083333334\n",
            "Epoch 5/10, Batch Loss: 0.3133198916912079, Average Training Loss: 0.4093650216908799, Training Accuracy: 0.8627577319587629\n",
            "Epoch 5/10, Batch Loss: 0.4714404046535492, Average Training Loss: 0.40999844396600915, Training Accuracy: 0.8628826530612245\n",
            "Epoch 5/10, Batch Loss: 0.24393433332443237, Average Training Loss: 0.4083210287070034, Training Accuracy: 0.8636363636363636\n",
            "Epoch 5/10, Batch Loss: 0.13761916756629944, Average Training Loss: 0.40561401009559633, Training Accuracy: 0.865\n",
            "Epoch 5/10, Batch Loss: 0.25146353244781494, Average Training Loss: 0.404087767742648, Training Accuracy: 0.8657178217821783\n",
            "Epoch 5/10, Batch Loss: 0.2734694480895996, Average Training Loss: 0.40280719598134357, Training Accuracy: 0.8658088235294118\n",
            "Epoch 5/10, Batch Loss: 1.1943880319595337, Average Training Loss: 0.4104924468160833, Training Accuracy: 0.8640776699029126\n",
            "Epoch 5/10, Batch Loss: 0.5697143077850342, Average Training Loss: 0.41202342624847704, Training Accuracy: 0.8641826923076923\n",
            "Epoch 5/10, Batch Loss: 0.5939071178436279, Average Training Loss: 0.41375565188271657, Training Accuracy: 0.8636904761904762\n",
            "Epoch 5/10, Batch Loss: 0.20184068381786346, Average Training Loss: 0.411756454070784, Training Accuracy: 0.8643867924528302\n",
            "Epoch 5/10, Batch Loss: 1.0958768129348755, Average Training Loss: 0.4181501022844671, Training Accuracy: 0.8621495327102804\n",
            "Epoch 5/10, Batch Loss: 0.16830264031887054, Average Training Loss: 0.41583669985885974, Training Accuracy: 0.8634259259259259\n",
            "Epoch 5/10, Batch Loss: 0.29025402665138245, Average Training Loss: 0.41468456524227737, Training Accuracy: 0.8635321100917431\n",
            "Epoch 5/10, Batch Loss: 0.4085184931755066, Average Training Loss: 0.41462851004167034, Training Accuracy: 0.8636363636363636\n",
            "Epoch 5/10, Batch Loss: 0.1712673306465149, Average Training Loss: 0.4124360669840563, Training Accuracy: 0.8648648648648649\n",
            "Epoch 5/10, Batch Loss: 0.7880129218101501, Average Training Loss: 0.41578943175928934, Training Accuracy: 0.8638392857142857\n",
            "Epoch 5/10, Batch Loss: 0.49326375126838684, Average Training Loss: 0.4164750452062725, Training Accuracy: 0.8633849557522124\n",
            "Epoch 5/10, Batch Loss: 0.5981280207633972, Average Training Loss: 0.4180684923602824, Training Accuracy: 0.8634868421052632\n",
            "Epoch 5/10, Batch Loss: 0.3399863839149475, Average Training Loss: 0.417389517504236, Training Accuracy: 0.8635869565217391\n",
            "Epoch 5/10, Batch Loss: 0.2289554923772812, Average Training Loss: 0.4157650862531415, Training Accuracy: 0.8647629310344828\n",
            "Epoch 5/10, Average Training Loss: 0.4157650862531415, Training Accuracy: 0.8647629310344828\n",
            "Epoch 5/10, Validation Loss: 27.152538985013962, Validation Accuracy: 0.6594827586206896\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.70      0.69        99\n",
            "                Educational Opportunity       0.46      0.45      0.45        87\n",
            "                         Family Support       0.80      0.88      0.84        93\n",
            "                      Financial Support       0.68      0.57      0.62        89\n",
            "                 Program Implementation       0.64      0.68      0.66        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.66       464\n",
            "\n",
            "Epoch 6/10, Batch Loss: 0.3056812286376953, Average Training Loss: 0.3056812286376953, Training Accuracy: 0.9375\n",
            "Epoch 6/10, Batch Loss: 0.17389726638793945, Average Training Loss: 0.23978924751281738, Training Accuracy: 0.9375\n",
            "Epoch 6/10, Batch Loss: 0.29057225584983826, Average Training Loss: 0.256716916958491, Training Accuracy: 0.9375\n",
            "Epoch 6/10, Batch Loss: 0.10862667858600616, Average Training Loss: 0.2196943573653698, Training Accuracy: 0.953125\n",
            "Epoch 6/10, Batch Loss: 0.3765866756439209, Average Training Loss: 0.25107282102108003, Training Accuracy: 0.9125\n",
            "Epoch 6/10, Batch Loss: 0.3288734555244446, Average Training Loss: 0.26403959343830746, Training Accuracy: 0.9166666666666666\n",
            "Epoch 6/10, Batch Loss: 0.24015763401985168, Average Training Loss: 0.26062788494995665, Training Accuracy: 0.9196428571428571\n",
            "Epoch 6/10, Batch Loss: 0.3832346796989441, Average Training Loss: 0.27595373429358006, Training Accuracy: 0.9140625\n",
            "Epoch 6/10, Batch Loss: 0.2953510284423828, Average Training Loss: 0.27810898919900257, Training Accuracy: 0.9097222222222222\n",
            "Epoch 6/10, Batch Loss: 0.34462791681289673, Average Training Loss: 0.284760881960392, Training Accuracy: 0.9125\n",
            "Epoch 6/10, Batch Loss: 0.23476506769657135, Average Training Loss: 0.2802158079364083, Training Accuracy: 0.9147727272727273\n",
            "Epoch 6/10, Batch Loss: 0.1392291635274887, Average Training Loss: 0.26846692090233165, Training Accuracy: 0.921875\n",
            "Epoch 6/10, Batch Loss: 0.3108847737312317, Average Training Loss: 0.2717298326584009, Training Accuracy: 0.9182692307692307\n",
            "Epoch 6/10, Batch Loss: 0.35035908222198486, Average Training Loss: 0.27734620762722834, Training Accuracy: 0.9196428571428571\n",
            "Epoch 6/10, Batch Loss: 0.35650187730789185, Average Training Loss: 0.2826232522726059, Training Accuracy: 0.9166666666666666\n",
            "Epoch 6/10, Batch Loss: 0.3531087636947632, Average Training Loss: 0.2870285967364907, Training Accuracy: 0.9140625\n",
            "Epoch 6/10, Batch Loss: 0.11602246761322021, Average Training Loss: 0.27696941267041597, Training Accuracy: 0.9191176470588235\n",
            "Epoch 6/10, Batch Loss: 0.18990124762058258, Average Training Loss: 0.2721322923898697, Training Accuracy: 0.9236111111111112\n",
            "Epoch 6/10, Batch Loss: 0.37836775183677673, Average Training Loss: 0.27772363236075953, Training Accuracy: 0.9210526315789473\n",
            "Epoch 6/10, Batch Loss: 0.13527962565422058, Average Training Loss: 0.2706014320254326, Training Accuracy: 0.925\n",
            "Epoch 6/10, Batch Loss: 0.394180029630661, Average Training Loss: 0.27648612714949106, Training Accuracy: 0.9226190476190477\n",
            "Epoch 6/10, Batch Loss: 0.13196498155593872, Average Training Loss: 0.269916984167966, Training Accuracy: 0.9261363636363636\n",
            "Epoch 6/10, Batch Loss: 0.15265488624572754, Average Training Loss: 0.2648186320843904, Training Accuracy: 0.9293478260869565\n",
            "Epoch 6/10, Batch Loss: 0.8144732713699341, Average Training Loss: 0.287720908721288, Training Accuracy: 0.9192708333333334\n",
            "Epoch 6/10, Batch Loss: 0.5877963304519653, Average Training Loss: 0.29972392559051514, Training Accuracy: 0.9175\n",
            "Epoch 6/10, Batch Loss: 0.3638753890991211, Average Training Loss: 0.30219128957161534, Training Accuracy: 0.9158653846153846\n",
            "Epoch 6/10, Batch Loss: 0.33663544058799744, Average Training Loss: 0.3034669988685184, Training Accuracy: 0.9166666666666666\n",
            "Epoch 6/10, Batch Loss: 0.3120085895061493, Average Training Loss: 0.3037720556770052, Training Accuracy: 0.9174107142857143\n",
            "Epoch 6/10, Batch Loss: 0.4268321394920349, Average Training Loss: 0.30801550684304074, Training Accuracy: 0.9181034482758621\n",
            "Epoch 6/10, Batch Loss: 0.18054068088531494, Average Training Loss: 0.3037663459777832, Training Accuracy: 0.91875\n",
            "Epoch 6/10, Batch Loss: 0.32763195037841797, Average Training Loss: 0.3045362041842553, Training Accuracy: 0.9173387096774194\n",
            "Epoch 6/10, Batch Loss: 0.19763165712356567, Average Training Loss: 0.30119543708860874, Training Accuracy: 0.919921875\n",
            "Epoch 6/10, Batch Loss: 0.2167988270521164, Average Training Loss: 0.2986379640571999, Training Accuracy: 0.9204545454545454\n",
            "Epoch 6/10, Batch Loss: 0.32092076539993286, Average Training Loss: 0.29929334056728024, Training Accuracy: 0.9209558823529411\n",
            "Epoch 6/10, Batch Loss: 0.3441489040851593, Average Training Loss: 0.30057492809636255, Training Accuracy: 0.9214285714285714\n",
            "Epoch 6/10, Batch Loss: 0.10572392493486404, Average Training Loss: 0.29516240023076534, Training Accuracy: 0.9236111111111112\n",
            "Epoch 6/10, Batch Loss: 0.1818024069070816, Average Training Loss: 0.29209861662742254, Training Accuracy: 0.9256756756756757\n",
            "Epoch 6/10, Batch Loss: 0.4787251055240631, Average Training Loss: 0.2970098400194394, Training Accuracy: 0.9210526315789473\n",
            "Epoch 6/10, Batch Loss: 0.15430805087089539, Average Training Loss: 0.2933508197848613, Training Accuracy: 0.9230769230769231\n",
            "Epoch 6/10, Batch Loss: 0.24762248992919922, Average Training Loss: 0.2922076115384698, Training Accuracy: 0.9234375\n",
            "Epoch 6/10, Batch Loss: 0.5643361210823059, Average Training Loss: 0.29884489225905114, Training Accuracy: 0.9222560975609756\n",
            "Epoch 6/10, Batch Loss: 0.19039718806743622, Average Training Loss: 0.29626280406401273, Training Accuracy: 0.9241071428571429\n",
            "Epoch 6/10, Batch Loss: 0.19441065192222595, Average Training Loss: 0.2938941493630409, Training Accuracy: 0.9244186046511628\n",
            "Epoch 6/10, Batch Loss: 0.07135053724050522, Average Training Loss: 0.2888363399966197, Training Accuracy: 0.9261363636363636\n",
            "Epoch 6/10, Batch Loss: 0.3437764346599579, Average Training Loss: 0.29005723098913827, Training Accuracy: 0.9263888888888889\n",
            "Epoch 6/10, Batch Loss: 0.22498202323913574, Average Training Loss: 0.2886425525597904, Training Accuracy: 0.9266304347826086\n",
            "Epoch 6/10, Batch Loss: 0.2548818290233612, Average Training Loss: 0.2879242392930579, Training Accuracy: 0.9268617021276596\n",
            "Epoch 6/10, Batch Loss: 0.2959362864494324, Average Training Loss: 0.288091156942149, Training Accuracy: 0.9270833333333334\n",
            "Epoch 6/10, Batch Loss: 0.1979493796825409, Average Training Loss: 0.2862515288348101, Training Accuracy: 0.9272959183673469\n",
            "Epoch 6/10, Batch Loss: 0.3105129599571228, Average Training Loss: 0.2867367574572563, Training Accuracy: 0.925\n",
            "Epoch 6/10, Batch Loss: 0.3551901578903198, Average Training Loss: 0.28807898099515955, Training Accuracy: 0.9252450980392157\n",
            "Epoch 6/10, Batch Loss: 0.3399484157562256, Average Training Loss: 0.28907647012518, Training Accuracy: 0.9230769230769231\n",
            "Epoch 6/10, Batch Loss: 0.6310743689537048, Average Training Loss: 0.29552926066911445, Training Accuracy: 0.9221698113207547\n",
            "Epoch 6/10, Batch Loss: 0.14552512764930725, Average Training Loss: 0.2927514063539328, Training Accuracy: 0.9236111111111112\n",
            "Epoch 6/10, Batch Loss: 0.2749256491661072, Average Training Loss: 0.2924273016777906, Training Accuracy: 0.9238636363636363\n",
            "Epoch 6/10, Batch Loss: 0.39426133036613464, Average Training Loss: 0.2942457664757967, Training Accuracy: 0.9229910714285714\n",
            "Epoch 6/10, Batch Loss: 0.20301936566829681, Average Training Loss: 0.2926453033037353, Training Accuracy: 0.9243421052631579\n",
            "Epoch 6/10, Batch Loss: 0.4453016519546509, Average Training Loss: 0.295277309314958, Training Accuracy: 0.9234913793103449\n",
            "Epoch 6/10, Batch Loss: 0.22687870264053345, Average Training Loss: 0.2941180108967474, Training Accuracy: 0.9226694915254238\n",
            "Epoch 6/10, Batch Loss: 0.40556252002716064, Average Training Loss: 0.2959754193822543, Training Accuracy: 0.9208333333333333\n",
            "Epoch 6/10, Batch Loss: 0.39087268710136414, Average Training Loss: 0.2975311122956823, Training Accuracy: 0.9200819672131147\n",
            "Epoch 6/10, Batch Loss: 0.45872750878334045, Average Training Loss: 0.3001310541745155, Training Accuracy: 0.9193548387096774\n",
            "Epoch 6/10, Batch Loss: 0.1803041249513626, Average Training Loss: 0.29822903942494167, Training Accuracy: 0.9196428571428571\n",
            "Epoch 6/10, Batch Loss: 0.13119331002235413, Average Training Loss: 0.2956191061530262, Training Accuracy: 0.9208984375\n",
            "Epoch 6/10, Batch Loss: 0.3642234206199646, Average Training Loss: 0.29667455714482527, Training Accuracy: 0.9201923076923076\n",
            "Epoch 6/10, Batch Loss: 0.07720980793237686, Average Training Loss: 0.2933493336719094, Training Accuracy: 0.9214015151515151\n",
            "Epoch 6/10, Batch Loss: 0.41894447803497314, Average Training Loss: 0.29522388806538796, Training Accuracy: 0.9216417910447762\n",
            "Epoch 6/10, Batch Loss: 0.20212680101394653, Average Training Loss: 0.2938548132558079, Training Accuracy: 0.9209558823529411\n",
            "Epoch 6/10, Batch Loss: 0.45361757278442383, Average Training Loss: 0.29617021556781686, Training Accuracy: 0.9211956521739131\n",
            "Epoch 6/10, Batch Loss: 0.3268521726131439, Average Training Loss: 0.29660852923989295, Training Accuracy: 0.9205357142857142\n",
            "Epoch 6/10, Batch Loss: 0.1420321762561798, Average Training Loss: 0.294431397507728, Training Accuracy: 0.9216549295774648\n",
            "Epoch 6/10, Batch Loss: 0.6077706217765808, Average Training Loss: 0.2987833311781287, Training Accuracy: 0.9201388888888888\n",
            "Epoch 6/10, Batch Loss: 0.42617273330688477, Average Training Loss: 0.30052839148126237, Training Accuracy: 0.9203767123287672\n",
            "Epoch 6/10, Batch Loss: 0.21296148002147675, Average Training Loss: 0.2993450548399139, Training Accuracy: 0.9206081081081081\n",
            "Epoch 6/10, Batch Loss: 0.3407337963581085, Average Training Loss: 0.2998969047268232, Training Accuracy: 0.9208333333333333\n",
            "Epoch 6/10, Batch Loss: 0.1583031713962555, Average Training Loss: 0.29803382928826305, Training Accuracy: 0.9210526315789473\n",
            "Epoch 6/10, Batch Loss: 0.16184961795806885, Average Training Loss: 0.2962652031670917, Training Accuracy: 0.922077922077922\n",
            "Epoch 6/10, Batch Loss: 0.09987372905015945, Average Training Loss: 0.29374736375533617, Training Accuracy: 0.9230769230769231\n",
            "Epoch 6/10, Batch Loss: 0.25773885846138, Average Training Loss: 0.2932915598908557, Training Accuracy: 0.9232594936708861\n",
            "Epoch 6/10, Batch Loss: 0.17241135239601135, Average Training Loss: 0.2917805572971702, Training Accuracy: 0.92421875\n",
            "Epoch 6/10, Batch Loss: 0.23639076948165894, Average Training Loss: 0.29109673275623793, Training Accuracy: 0.9243827160493827\n",
            "Epoch 6/10, Batch Loss: 0.06713225692510605, Average Training Loss: 0.2883654586607363, Training Accuracy: 0.9253048780487805\n",
            "Epoch 6/10, Batch Loss: 0.09570959955453873, Average Training Loss: 0.286044303731746, Training Accuracy: 0.9262048192771084\n",
            "Epoch 6/10, Batch Loss: 0.20344208180904388, Average Training Loss: 0.2850609439469519, Training Accuracy: 0.9263392857142857\n",
            "Epoch 6/10, Batch Loss: 0.5568729639053345, Average Training Loss: 0.2882587324170505, Training Accuracy: 0.925\n",
            "Epoch 6/10, Batch Loss: 0.09926851093769073, Average Training Loss: 0.28606117170217427, Training Accuracy: 0.9258720930232558\n",
            "Epoch 6/10, Batch Loss: 0.2561182677745819, Average Training Loss: 0.2857170003926617, Training Accuracy: 0.9260057471264368\n",
            "Epoch 6/10, Batch Loss: 0.2421329766511917, Average Training Loss: 0.28522172739559953, Training Accuracy: 0.9254261363636364\n",
            "Epoch 6/10, Batch Loss: 0.17756173014640808, Average Training Loss: 0.2840120645051592, Training Accuracy: 0.925561797752809\n",
            "Epoch 6/10, Batch Loss: 0.27754127979278564, Average Training Loss: 0.28394016689724394, Training Accuracy: 0.9256944444444445\n",
            "Epoch 6/10, Batch Loss: 0.4233480989933014, Average Training Loss: 0.2854721221950028, Training Accuracy: 0.9251373626373627\n",
            "Epoch 6/10, Batch Loss: 0.21333874762058258, Average Training Loss: 0.2846880637757156, Training Accuracy: 0.9252717391304348\n",
            "Epoch 6/10, Batch Loss: 0.20725730061531067, Average Training Loss: 0.28385547492452845, Training Accuracy: 0.9247311827956989\n",
            "Epoch 6/10, Batch Loss: 0.15101079642772675, Average Training Loss: 0.2824422336639242, Training Accuracy: 0.9248670212765957\n",
            "Epoch 6/10, Batch Loss: 0.619930624961853, Average Training Loss: 0.28599474304600764, Training Accuracy: 0.9230263157894737\n",
            "Epoch 6/10, Batch Loss: 0.1315363496541977, Average Training Loss: 0.2843858014481763, Training Accuracy: 0.9231770833333334\n",
            "Epoch 6/10, Batch Loss: 0.21423906087875366, Average Training Loss: 0.2836626391742647, Training Accuracy: 0.9233247422680413\n",
            "Epoch 6/10, Batch Loss: 0.1653168499469757, Average Training Loss: 0.2824550290801087, Training Accuracy: 0.923469387755102\n",
            "Epoch 6/10, Batch Loss: 0.37451183795928955, Average Training Loss: 0.2833848958364641, Training Accuracy: 0.922979797979798\n",
            "Epoch 6/10, Batch Loss: 0.33604466915130615, Average Training Loss: 0.2839114935696125, Training Accuracy: 0.9225\n",
            "Epoch 6/10, Batch Loss: 0.2564738094806671, Average Training Loss: 0.2836398333311081, Training Accuracy: 0.9220297029702971\n",
            "Epoch 6/10, Batch Loss: 0.16696354746818542, Average Training Loss: 0.28249594817558926, Training Accuracy: 0.9227941176470589\n",
            "Epoch 6/10, Batch Loss: 0.34978312253952026, Average Training Loss: 0.28314922171310314, Training Accuracy: 0.9229368932038835\n",
            "Epoch 6/10, Batch Loss: 0.22146360576152802, Average Training Loss: 0.2825560907904918, Training Accuracy: 0.9230769230769231\n",
            "Epoch 6/10, Batch Loss: 0.2780797481536865, Average Training Loss: 0.2825134589558556, Training Accuracy: 0.9232142857142858\n",
            "Epoch 6/10, Batch Loss: 0.13420239090919495, Average Training Loss: 0.28111429793654746, Training Accuracy: 0.9239386792452831\n",
            "Epoch 6/10, Batch Loss: 0.11613566428422928, Average Training Loss: 0.27957244154727345, Training Accuracy: 0.9246495327102804\n",
            "Epoch 6/10, Batch Loss: 0.41332295536994934, Average Training Loss: 0.28081087223081674, Training Accuracy: 0.9247685185185185\n",
            "Epoch 6/10, Batch Loss: 0.3898697793483734, Average Training Loss: 0.28181141266308796, Training Accuracy: 0.9243119266055045\n",
            "Epoch 6/10, Batch Loss: 0.10092825442552567, Average Training Loss: 0.28016702031547375, Training Accuracy: 0.925\n",
            "Epoch 6/10, Batch Loss: 0.06944166123867035, Average Training Loss: 0.27826859365712414, Training Accuracy: 0.9256756756756757\n",
            "Epoch 6/10, Batch Loss: 0.2562878131866455, Average Training Loss: 0.27807233668863773, Training Accuracy: 0.92578125\n",
            "Epoch 6/10, Batch Loss: 0.30423703789711, Average Training Loss: 0.27830388271703127, Training Accuracy: 0.9253318584070797\n",
            "Epoch 6/10, Batch Loss: 0.32889115810394287, Average Training Loss: 0.278747630746741, Training Accuracy: 0.924890350877193\n",
            "Epoch 6/10, Batch Loss: 0.24908651411533356, Average Training Loss: 0.2784897079934245, Training Accuracy: 0.925\n",
            "Epoch 6/10, Batch Loss: 0.40273863077163696, Average Training Loss: 0.2795608193966849, Training Accuracy: 0.9245689655172413\n",
            "Epoch 6/10, Average Training Loss: 0.2795608193966849, Training Accuracy: 0.9245689655172413\n",
            "Epoch 6/10, Validation Loss: 30.714766919612885, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.64      0.66        99\n",
            "                Educational Opportunity       0.46      0.51      0.48        87\n",
            "                         Family Support       0.81      0.95      0.87        93\n",
            "                      Financial Support       0.64      0.67      0.66        89\n",
            "                 Program Implementation       0.74      0.56      0.64        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.67      0.67      0.66       464\n",
            "                           weighted avg       0.67      0.67      0.66       464\n",
            "\n",
            "Epoch 7/10, Batch Loss: 0.12263894081115723, Average Training Loss: 0.12263894081115723, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.12303611636161804, Average Training Loss: 0.12283752858638763, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.15830959379673004, Average Training Loss: 0.13466155032316843, Training Accuracy: 0.9791666666666666\n",
            "Epoch 7/10, Batch Loss: 0.06820594519376755, Average Training Loss: 0.11804764904081821, Training Accuracy: 0.984375\n",
            "Epoch 7/10, Batch Loss: 0.594488799571991, Average Training Loss: 0.21333587914705276, Training Accuracy: 0.95\n",
            "Epoch 7/10, Batch Loss: 0.3207474946975708, Average Training Loss: 0.2312378150721391, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.10952528566122055, Average Training Loss: 0.21385031087057932, Training Accuracy: 0.9464285714285714\n",
            "Epoch 7/10, Batch Loss: 0.17463496327400208, Average Training Loss: 0.20894839242100716, Training Accuracy: 0.9453125\n",
            "Epoch 7/10, Batch Loss: 0.17354094982147217, Average Training Loss: 0.20501423213216993, Training Accuracy: 0.9444444444444444\n",
            "Epoch 7/10, Batch Loss: 0.11114788055419922, Average Training Loss: 0.19562759697437287, Training Accuracy: 0.95\n",
            "Epoch 7/10, Batch Loss: 0.3121483623981476, Average Training Loss: 0.20622039383107965, Training Accuracy: 0.9488636363636364\n",
            "Epoch 7/10, Batch Loss: 0.12419954687356949, Average Training Loss: 0.19938532325128713, Training Accuracy: 0.953125\n",
            "Epoch 7/10, Batch Loss: 0.12264834344387054, Average Training Loss: 0.19348247865071663, Training Accuracy: 0.9567307692307693\n",
            "Epoch 7/10, Batch Loss: 0.39275461435317993, Average Training Loss: 0.20771620262946403, Training Accuracy: 0.9508928571428571\n",
            "Epoch 7/10, Batch Loss: 0.2514340877532959, Average Training Loss: 0.21063072830438614, Training Accuracy: 0.9458333333333333\n",
            "Epoch 7/10, Batch Loss: 0.1553070843219757, Average Training Loss: 0.2071730005554855, Training Accuracy: 0.9453125\n",
            "Epoch 7/10, Batch Loss: 0.4308561384677887, Average Training Loss: 0.22033083219738567, Training Accuracy: 0.9411764705882353\n",
            "Epoch 7/10, Batch Loss: 0.09174683690071106, Average Training Loss: 0.21318727690312597, Training Accuracy: 0.9444444444444444\n",
            "Epoch 7/10, Batch Loss: 0.17583338916301727, Average Training Loss: 0.21122128281154132, Training Accuracy: 0.944078947368421\n",
            "Epoch 7/10, Batch Loss: 0.5016463994979858, Average Training Loss: 0.22574253864586352, Training Accuracy: 0.940625\n",
            "Epoch 7/10, Batch Loss: 0.1840844303369522, Average Training Loss: 0.22375881920258203, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.5857601761817932, Average Training Loss: 0.24021342633800072, Training Accuracy: 0.9346590909090909\n",
            "Epoch 7/10, Batch Loss: 0.29066285490989685, Average Training Loss: 0.24240687975417013, Training Accuracy: 0.9347826086956522\n",
            "Epoch 7/10, Batch Loss: 0.06551695615053177, Average Training Loss: 0.2350364662706852, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.311073899269104, Average Training Loss: 0.23807796359062194, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.2811194062232971, Average Training Loss: 0.23973340369187868, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.22929330170154572, Average Training Loss: 0.2393467332477923, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.2097826600074768, Average Training Loss: 0.23829087348920958, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.2621065378189087, Average Training Loss: 0.23911210329368196, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.40085020661354065, Average Training Loss: 0.24450337340434392, Training Accuracy: 0.9354166666666667\n",
            "Epoch 7/10, Batch Loss: 0.2482890635728836, Average Training Loss: 0.24462549244203874, Training Accuracy: 0.9354838709677419\n",
            "Epoch 7/10, Batch Loss: 0.1825510710477829, Average Training Loss: 0.24268566677346826, Training Accuracy: 0.935546875\n",
            "Epoch 7/10, Batch Loss: 0.30967432260513306, Average Training Loss: 0.24471562604109445, Training Accuracy: 0.9356060606060606\n",
            "Epoch 7/10, Batch Loss: 0.11672168225049973, Average Training Loss: 0.24095109828254757, Training Accuracy: 0.9375\n",
            "Epoch 7/10, Batch Loss: 0.09495431184768677, Average Training Loss: 0.23677976152726582, Training Accuracy: 0.9392857142857143\n",
            "Epoch 7/10, Batch Loss: 0.05183219164609909, Average Training Loss: 0.23164232903056675, Training Accuracy: 0.9409722222222222\n",
            "Epoch 7/10, Batch Loss: 0.2763482928276062, Average Training Loss: 0.23285059832237862, Training Accuracy: 0.9391891891891891\n",
            "Epoch 7/10, Batch Loss: 0.1115466058254242, Average Training Loss: 0.2296583879935114, Training Accuracy: 0.9407894736842105\n",
            "Epoch 7/10, Batch Loss: 0.44262874126434326, Average Training Loss: 0.2351191662825071, Training Accuracy: 0.9391025641025641\n",
            "Epoch 7/10, Batch Loss: 0.41096675395965576, Average Training Loss: 0.2395153559744358, Training Accuracy: 0.9390625\n",
            "Epoch 7/10, Batch Loss: 0.11491788923740387, Average Training Loss: 0.23647639337109355, Training Accuracy: 0.9405487804878049\n",
            "Epoch 7/10, Batch Loss: 0.34485897421836853, Average Training Loss: 0.2390569310103144, Training Accuracy: 0.9404761904761905\n",
            "Epoch 7/10, Batch Loss: 0.14505316317081451, Average Training Loss: 0.23687079687451207, Training Accuracy: 0.940406976744186\n",
            "Epoch 7/10, Batch Loss: 0.14214399456977844, Average Training Loss: 0.23471791500394995, Training Accuracy: 0.9389204545454546\n",
            "Epoch 7/10, Batch Loss: 0.08665250241756439, Average Training Loss: 0.23142757250203028, Training Accuracy: 0.9402777777777778\n",
            "Epoch 7/10, Batch Loss: 0.22593717277050018, Average Training Loss: 0.23130821598612744, Training Accuracy: 0.9402173913043478\n",
            "Epoch 7/10, Batch Loss: 0.26350143551826477, Average Training Loss: 0.2319931781038325, Training Accuracy: 0.9401595744680851\n",
            "Epoch 7/10, Batch Loss: 0.09161821007728577, Average Training Loss: 0.22906869960327944, Training Accuracy: 0.94140625\n",
            "Epoch 7/10, Batch Loss: 0.2960563004016876, Average Training Loss: 0.2304357934971245, Training Accuracy: 0.9413265306122449\n",
            "Epoch 7/10, Batch Loss: 0.13877667486667633, Average Training Loss: 0.22860261112451552, Training Accuracy: 0.9425\n",
            "Epoch 7/10, Batch Loss: 0.080235056579113, Average Training Loss: 0.22569344338833117, Training Accuracy: 0.9436274509803921\n",
            "Epoch 7/10, Batch Loss: 0.13110782206058502, Average Training Loss: 0.22387448913202837, Training Accuracy: 0.9435096153846154\n",
            "Epoch 7/10, Batch Loss: 0.07342404127120972, Average Training Loss: 0.22103580143654122, Training Accuracy: 0.9445754716981132\n",
            "Epoch 7/10, Batch Loss: 0.1876184493303299, Average Training Loss: 0.22041696158272248, Training Accuracy: 0.9432870370370371\n",
            "Epoch 7/10, Batch Loss: 0.0865107849240303, Average Training Loss: 0.2179823038252917, Training Accuracy: 0.9443181818181818\n",
            "Epoch 7/10, Batch Loss: 0.08233785629272461, Average Training Loss: 0.21556008154792444, Training Accuracy: 0.9453125\n",
            "Epoch 7/10, Batch Loss: 0.09343951940536499, Average Training Loss: 0.2134176155454234, Training Accuracy: 0.9462719298245614\n",
            "Epoch 7/10, Batch Loss: 0.6376331448554993, Average Training Loss: 0.22073167639559713, Training Accuracy: 0.9439655172413793\n",
            "Epoch 7/10, Batch Loss: 0.16399304568767548, Average Training Loss: 0.2197700046886832, Training Accuracy: 0.9438559322033898\n",
            "Epoch 7/10, Batch Loss: 0.19832466542720795, Average Training Loss: 0.21941258236765862, Training Accuracy: 0.9427083333333334\n",
            "Epoch 7/10, Batch Loss: 0.24242988228797913, Average Training Loss: 0.21978991515323765, Training Accuracy: 0.9426229508196722\n",
            "Epoch 7/10, Batch Loss: 0.10154261440038681, Average Training Loss: 0.21788270062496584, Training Accuracy: 0.9435483870967742\n",
            "Epoch 7/10, Batch Loss: 0.3609490394592285, Average Training Loss: 0.22015359489217637, Training Accuracy: 0.9424603174603174\n",
            "Epoch 7/10, Batch Loss: 0.25879257917404175, Average Training Loss: 0.22075732902158052, Training Accuracy: 0.9423828125\n",
            "Epoch 7/10, Batch Loss: 0.19124044477939606, Average Training Loss: 0.2203032231101623, Training Accuracy: 0.9423076923076923\n",
            "Epoch 7/10, Batch Loss: 0.10057566314935684, Average Training Loss: 0.2184891691713622, Training Accuracy: 0.9431818181818182\n",
            "Epoch 7/10, Batch Loss: 0.10848365724086761, Average Training Loss: 0.21684729585896678, Training Accuracy: 0.9440298507462687\n",
            "Epoch 7/10, Batch Loss: 0.21481241285800934, Average Training Loss: 0.2168173711089527, Training Accuracy: 0.9439338235294118\n",
            "Epoch 7/10, Batch Loss: 0.15905584394931793, Average Training Loss: 0.215980247526929, Training Accuracy: 0.9447463768115942\n",
            "Epoch 7/10, Batch Loss: 0.3652990758419037, Average Training Loss: 0.21811337364571434, Training Accuracy: 0.9446428571428571\n",
            "Epoch 7/10, Batch Loss: 0.17443732917308807, Average Training Loss: 0.21749821808976186, Training Accuracy: 0.9445422535211268\n",
            "Epoch 7/10, Batch Loss: 0.19532720744609833, Average Training Loss: 0.21719028738637766, Training Accuracy: 0.9444444444444444\n",
            "Epoch 7/10, Batch Loss: 0.4478248357772827, Average Training Loss: 0.22034966476159554, Training Accuracy: 0.9426369863013698\n",
            "Epoch 7/10, Batch Loss: 0.09443648904561996, Average Training Loss: 0.2186481353600283, Training Accuracy: 0.9434121621621622\n",
            "Epoch 7/10, Batch Loss: 0.07853785157203674, Average Training Loss: 0.21677999824285507, Training Accuracy: 0.9441666666666667\n",
            "Epoch 7/10, Batch Loss: 0.1831137090921402, Average Training Loss: 0.21633702075402989, Training Accuracy: 0.944078947368421\n",
            "Epoch 7/10, Batch Loss: 0.11908628046512604, Average Training Loss: 0.21507402412690124, Training Accuracy: 0.9448051948051948\n",
            "Epoch 7/10, Batch Loss: 0.3970036506652832, Average Training Loss: 0.2174064552363677, Training Accuracy: 0.9431089743589743\n",
            "Epoch 7/10, Batch Loss: 0.1075618788599968, Average Training Loss: 0.21601601756071742, Training Accuracy: 0.9438291139240507\n",
            "Epoch 7/10, Batch Loss: 0.10716293007135391, Average Training Loss: 0.2146553539671004, Training Accuracy: 0.94453125\n",
            "Epoch 7/10, Batch Loss: 0.24622824788093567, Average Training Loss: 0.21504514278085143, Training Accuracy: 0.9444444444444444\n",
            "Epoch 7/10, Batch Loss: 0.10100871324539185, Average Training Loss: 0.21365445461578486, Training Accuracy: 0.9451219512195121\n",
            "Epoch 7/10, Batch Loss: 0.17780721187591553, Average Training Loss: 0.21322256012494306, Training Accuracy: 0.9450301204819277\n",
            "Epoch 7/10, Batch Loss: 0.05087452009320259, Average Training Loss: 0.21128984536266043, Training Accuracy: 0.9456845238095238\n",
            "Epoch 7/10, Batch Loss: 0.16937653720378876, Average Training Loss: 0.2107967476196149, Training Accuracy: 0.9455882352941176\n",
            "Epoch 7/10, Batch Loss: 0.3534121811389923, Average Training Loss: 0.21245506661402624, Training Accuracy: 0.9447674418604651\n",
            "Epoch 7/10, Batch Loss: 0.19336144626140594, Average Training Loss: 0.2122355997134214, Training Accuracy: 0.9454022988505747\n",
            "Epoch 7/10, Batch Loss: 0.4963837265968323, Average Training Loss: 0.2154645557007329, Training Accuracy: 0.9438920454545454\n",
            "Epoch 7/10, Batch Loss: 0.0637386217713356, Average Training Loss: 0.2137597699262453, Training Accuracy: 0.9445224719101124\n",
            "Epoch 7/10, Batch Loss: 0.22983907163143158, Average Training Loss: 0.2139384288340807, Training Accuracy: 0.9444444444444444\n",
            "Epoch 7/10, Batch Loss: 0.5107979774475098, Average Training Loss: 0.2172006216759865, Training Accuracy: 0.9429945054945055\n",
            "Epoch 7/10, Batch Loss: 0.12931488454341888, Average Training Loss: 0.21624534192454556, Training Accuracy: 0.9436141304347826\n",
            "Epoch 7/10, Batch Loss: 0.23292703926563263, Average Training Loss: 0.21642471501423466, Training Accuracy: 0.9435483870967742\n",
            "Epoch 7/10, Batch Loss: 0.07990090548992157, Average Training Loss: 0.21497233406184835, Training Accuracy: 0.9441489361702128\n",
            "Epoch 7/10, Batch Loss: 0.18366476893424988, Average Training Loss: 0.21464278074471574, Training Accuracy: 0.944078947368421\n",
            "Epoch 7/10, Batch Loss: 0.41873690485954285, Average Training Loss: 0.21676876120424518, Training Accuracy: 0.943359375\n",
            "Epoch 7/10, Batch Loss: 0.04676603153347969, Average Training Loss: 0.21501615574372182, Training Accuracy: 0.9439432989690721\n",
            "Epoch 7/10, Batch Loss: 0.45978325605392456, Average Training Loss: 0.21751377921627493, Training Accuracy: 0.9426020408163265\n",
            "Epoch 7/10, Batch Loss: 0.07993663847446442, Average Training Loss: 0.2161241111279738, Training Accuracy: 0.9431818181818182\n",
            "Epoch 7/10, Batch Loss: 0.05970997363328934, Average Training Loss: 0.21455996975302696, Training Accuracy: 0.94375\n",
            "Epoch 7/10, Batch Loss: 0.17732205986976624, Average Training Loss: 0.21419127757596498, Training Accuracy: 0.943069306930693\n",
            "Epoch 7/10, Batch Loss: 0.10180984437465668, Average Training Loss: 0.2130894988190894, Training Accuracy: 0.9436274509803921\n",
            "Epoch 7/10, Batch Loss: 0.2411453276872635, Average Training Loss: 0.21336188550712992, Training Accuracy: 0.9435679611650486\n",
            "Epoch 7/10, Batch Loss: 0.15308891236782074, Average Training Loss: 0.21278233768848273, Training Accuracy: 0.9435096153846154\n",
            "Epoch 7/10, Batch Loss: 0.1668846756219864, Average Training Loss: 0.21234521709737322, Training Accuracy: 0.9434523809523809\n",
            "Epoch 7/10, Batch Loss: 0.40209320187568665, Average Training Loss: 0.21413529242547052, Training Accuracy: 0.9428066037735849\n",
            "Epoch 7/10, Batch Loss: 0.05003891885280609, Average Training Loss: 0.21260168145750172, Training Accuracy: 0.9433411214953271\n",
            "Epoch 7/10, Batch Loss: 0.5632898807525635, Average Training Loss: 0.21584879441393745, Training Accuracy: 0.9427083333333334\n",
            "Epoch 7/10, Batch Loss: 0.09196998178958893, Average Training Loss: 0.21471229154582416, Training Accuracy: 0.9432339449541285\n",
            "Epoch 7/10, Batch Loss: 0.3100428879261017, Average Training Loss: 0.21557893333109943, Training Accuracy: 0.9431818181818182\n",
            "Epoch 7/10, Batch Loss: 0.1757798194885254, Average Training Loss: 0.2152203827559411, Training Accuracy: 0.9425675675675675\n",
            "Epoch 7/10, Batch Loss: 0.1498928964138031, Average Training Loss: 0.2146371016278863, Training Accuracy: 0.9425223214285714\n",
            "Epoch 7/10, Batch Loss: 0.30595117807388306, Average Training Loss: 0.21544519079997476, Training Accuracy: 0.9424778761061947\n",
            "Epoch 7/10, Batch Loss: 0.12174239754676819, Average Training Loss: 0.21462323647319226, Training Accuracy: 0.9424342105263158\n",
            "Epoch 7/10, Batch Loss: 0.07661665230989456, Average Training Loss: 0.21342317921959836, Training Accuracy: 0.9429347826086957\n",
            "Epoch 7/10, Batch Loss: 0.07323905825614929, Average Training Loss: 0.21221469541818933, Training Accuracy: 0.943426724137931\n",
            "Epoch 7/10, Average Training Loss: 0.21221469541818933, Training Accuracy: 0.943426724137931\n",
            "Epoch 7/10, Validation Loss: 31.97199723124504, Validation Accuracy: 0.6594827586206896\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.64      0.67        99\n",
            "                Educational Opportunity       0.45      0.48      0.47        87\n",
            "                         Family Support       0.79      0.94      0.86        93\n",
            "                      Financial Support       0.65      0.62      0.63        89\n",
            "                 Program Implementation       0.69      0.61      0.65        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.66      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.66       464\n",
            "\n",
            "Epoch 8/10, Batch Loss: 0.4483775198459625, Average Training Loss: 0.4483775198459625, Training Accuracy: 0.875\n",
            "Epoch 8/10, Batch Loss: 0.06608705967664719, Average Training Loss: 0.25723228976130486, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.16304510831832886, Average Training Loss: 0.22583656261364618, Training Accuracy: 0.9583333333333334\n",
            "Epoch 8/10, Batch Loss: 0.1411438286304474, Average Training Loss: 0.2046633791178465, Training Accuracy: 0.953125\n",
            "Epoch 8/10, Batch Loss: 0.2961571514606476, Average Training Loss: 0.2229621335864067, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.2713344097137451, Average Training Loss: 0.23102417960762978, Training Accuracy: 0.9270833333333334\n",
            "Epoch 8/10, Batch Loss: 0.28177329897880554, Average Training Loss: 0.23827405380351202, Training Accuracy: 0.9285714285714286\n",
            "Epoch 8/10, Batch Loss: 0.20494452118873596, Average Training Loss: 0.23410786222666502, Training Accuracy: 0.9296875\n",
            "Epoch 8/10, Batch Loss: 0.2612738609313965, Average Training Loss: 0.23712630652719074, Training Accuracy: 0.9305555555555556\n",
            "Epoch 8/10, Batch Loss: 0.15605579316616058, Average Training Loss: 0.22901925519108773, Training Accuracy: 0.925\n",
            "Epoch 8/10, Batch Loss: 0.49936914443969727, Average Training Loss: 0.2535965178500522, Training Accuracy: 0.9147727272727273\n",
            "Epoch 8/10, Batch Loss: 0.197782501578331, Average Training Loss: 0.2489453498274088, Training Accuracy: 0.9166666666666666\n",
            "Epoch 8/10, Batch Loss: 0.2674418091773987, Average Training Loss: 0.25036815439279264, Training Accuracy: 0.9134615384615384\n",
            "Epoch 8/10, Batch Loss: 0.21778111159801483, Average Training Loss: 0.24804050847887993, Training Accuracy: 0.9151785714285714\n",
            "Epoch 8/10, Batch Loss: 0.07479437440633774, Average Training Loss: 0.2364907662073771, Training Accuracy: 0.9208333333333333\n",
            "Epoch 8/10, Batch Loss: 0.13958609104156494, Average Training Loss: 0.23043422400951385, Training Accuracy: 0.921875\n",
            "Epoch 8/10, Batch Loss: 0.32457098364830017, Average Training Loss: 0.23597168045885422, Training Accuracy: 0.9227941176470589\n",
            "Epoch 8/10, Batch Loss: 0.07089821249246597, Average Training Loss: 0.22680093223849931, Training Accuracy: 0.9270833333333334\n",
            "Epoch 8/10, Batch Loss: 0.17901447415351868, Average Training Loss: 0.22428585549718455, Training Accuracy: 0.9276315789473685\n",
            "Epoch 8/10, Batch Loss: 0.09581717848777771, Average Training Loss: 0.2178624216467142, Training Accuracy: 0.93125\n",
            "Epoch 8/10, Batch Loss: 0.05374525487422943, Average Training Loss: 0.21004731846707209, Training Accuracy: 0.9345238095238095\n",
            "Epoch 8/10, Batch Loss: 0.11606109887361526, Average Training Loss: 0.20577521757646042, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.251228392124176, Average Training Loss: 0.20775144255679587, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.20612460374832153, Average Training Loss: 0.20768365760644278, Training Accuracy: 0.9348958333333334\n",
            "Epoch 8/10, Batch Loss: 0.07869602739810944, Average Training Loss: 0.20252415239810945, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.04339917376637459, Average Training Loss: 0.19640396091227347, Training Accuracy: 0.9399038461538461\n",
            "Epoch 8/10, Batch Loss: 0.2509050965309143, Average Training Loss: 0.19842252149074166, Training Accuracy: 0.9398148148148148\n",
            "Epoch 8/10, Batch Loss: 0.14746440947055817, Average Training Loss: 0.19660258891859225, Training Accuracy: 0.9419642857142857\n",
            "Epoch 8/10, Batch Loss: 0.10916822403669357, Average Training Loss: 0.19358761081921644, Training Accuracy: 0.9439655172413793\n",
            "Epoch 8/10, Batch Loss: 0.09904806315898895, Average Training Loss: 0.1904362925638755, Training Accuracy: 0.9458333333333333\n",
            "Epoch 8/10, Batch Loss: 0.14815768599510193, Average Training Loss: 0.18907246654552798, Training Accuracy: 0.9455645161290323\n",
            "Epoch 8/10, Batch Loss: 0.05451209843158722, Average Training Loss: 0.18486745504196733, Training Accuracy: 0.947265625\n",
            "Epoch 8/10, Batch Loss: 0.039031364023685455, Average Training Loss: 0.18044817955656486, Training Accuracy: 0.9488636363636364\n",
            "Epoch 8/10, Batch Loss: 0.2564931809902191, Average Training Loss: 0.18268479724578998, Training Accuracy: 0.9485294117647058\n",
            "Epoch 8/10, Batch Loss: 0.19485487043857574, Average Training Loss: 0.1830325136227267, Training Accuracy: 0.9464285714285714\n",
            "Epoch 8/10, Batch Loss: 0.10604377090930939, Average Training Loss: 0.1808939374362429, Training Accuracy: 0.9479166666666666\n",
            "Epoch 8/10, Batch Loss: 0.06824768334627151, Average Training Loss: 0.1778494440824599, Training Accuracy: 0.9493243243243243\n",
            "Epoch 8/10, Batch Loss: 0.38593676686286926, Average Training Loss: 0.1833254262608917, Training Accuracy: 0.9490131578947368\n",
            "Epoch 8/10, Batch Loss: 0.2046681046485901, Average Training Loss: 0.18387267442467886, Training Accuracy: 0.9487179487179487\n",
            "Epoch 8/10, Batch Loss: 0.08603963255882263, Average Training Loss: 0.18142684837803244, Training Accuracy: 0.95\n",
            "Epoch 8/10, Batch Loss: 0.3039074242115021, Average Training Loss: 0.18441417949592195, Training Accuracy: 0.948170731707317\n",
            "Epoch 8/10, Batch Loss: 0.24366934597492218, Average Training Loss: 0.185825016793041, Training Accuracy: 0.9479166666666666\n",
            "Epoch 8/10, Batch Loss: 0.11936953663825989, Average Training Loss: 0.18427954051037168, Training Accuracy: 0.9476744186046512\n",
            "Epoch 8/10, Batch Loss: 0.21844860911369324, Average Training Loss: 0.18505611025135627, Training Accuracy: 0.9474431818181818\n",
            "Epoch 8/10, Batch Loss: 0.21748706698417664, Average Training Loss: 0.18577679817875226, Training Accuracy: 0.9472222222222222\n",
            "Epoch 8/10, Batch Loss: 0.22167463600635529, Average Training Loss: 0.1865571859576132, Training Accuracy: 0.9470108695652174\n",
            "Epoch 8/10, Batch Loss: 0.17253828048706055, Average Training Loss: 0.18625891137313336, Training Accuracy: 0.9468085106382979\n",
            "Epoch 8/10, Batch Loss: 0.10415927320718765, Average Training Loss: 0.18454850224467614, Training Accuracy: 0.9479166666666666\n",
            "Epoch 8/10, Batch Loss: 0.10557940602302551, Average Training Loss: 0.18293688803607103, Training Accuracy: 0.9489795918367347\n",
            "Epoch 8/10, Batch Loss: 0.0666939988732338, Average Training Loss: 0.1806120302528143, Training Accuracy: 0.95\n",
            "Epoch 8/10, Batch Loss: 0.06594087183475494, Average Training Loss: 0.17836357616618567, Training Accuracy: 0.9509803921568627\n",
            "Epoch 8/10, Batch Loss: 0.3294316530227661, Average Training Loss: 0.1812687314903507, Training Accuracy: 0.9507211538461539\n",
            "Epoch 8/10, Batch Loss: 0.12260866165161133, Average Training Loss: 0.18016193771980843, Training Accuracy: 0.9516509433962265\n",
            "Epoch 8/10, Batch Loss: 0.1352996677160263, Average Training Loss: 0.1793311549419606, Training Accuracy: 0.9525462962962963\n",
            "Epoch 8/10, Batch Loss: 0.11160849034786224, Average Training Loss: 0.17809983376752248, Training Accuracy: 0.9534090909090909\n",
            "Epoch 8/10, Batch Loss: 0.07512158155441284, Average Training Loss: 0.1762609364065741, Training Accuracy: 0.9542410714285714\n",
            "Epoch 8/10, Batch Loss: 0.06482628732919693, Average Training Loss: 0.17430594256311133, Training Accuracy: 0.9550438596491229\n",
            "Epoch 8/10, Batch Loss: 0.058365598320961, Average Training Loss: 0.17230697111066046, Training Accuracy: 0.9558189655172413\n",
            "Epoch 8/10, Batch Loss: 0.0862923413515091, Average Training Loss: 0.17084909602999687, Training Accuracy: 0.9565677966101694\n",
            "Epoch 8/10, Batch Loss: 0.06285256147384644, Average Training Loss: 0.16904915378739435, Training Accuracy: 0.9572916666666667\n",
            "Epoch 8/10, Batch Loss: 0.06056628376245499, Average Training Loss: 0.1672707460820675, Training Accuracy: 0.9579918032786885\n",
            "Epoch 8/10, Batch Loss: 0.1938742846250534, Average Training Loss: 0.16769983541340597, Training Accuracy: 0.9566532258064516\n",
            "Epoch 8/10, Batch Loss: 0.09469594061374664, Average Training Loss: 0.16654104343245899, Training Accuracy: 0.9573412698412699\n",
            "Epoch 8/10, Batch Loss: 0.43876174092292786, Average Training Loss: 0.17079449183074757, Training Accuracy: 0.9560546875\n",
            "Epoch 8/10, Batch Loss: 0.0839228704571724, Average Training Loss: 0.1694580053480772, Training Accuracy: 0.9567307692307693\n",
            "Epoch 8/10, Batch Loss: 0.18592338263988495, Average Training Loss: 0.16970748076158942, Training Accuracy: 0.9564393939393939\n",
            "Epoch 8/10, Batch Loss: 0.05259145796298981, Average Training Loss: 0.1679594804213118, Training Accuracy: 0.957089552238806\n",
            "Epoch 8/10, Batch Loss: 0.1607242077589035, Average Training Loss: 0.167853079352747, Training Accuracy: 0.9568014705882353\n",
            "Epoch 8/10, Batch Loss: 0.048844993114471436, Average Training Loss: 0.1661283244797285, Training Accuracy: 0.957427536231884\n",
            "Epoch 8/10, Batch Loss: 0.20647931098937988, Average Training Loss: 0.16670476714415208, Training Accuracy: 0.9571428571428572\n",
            "Epoch 8/10, Batch Loss: 0.21820971369743347, Average Training Loss: 0.16743018892659267, Training Accuracy: 0.9568661971830986\n",
            "Epoch 8/10, Batch Loss: 0.24928061664104462, Average Training Loss: 0.16856700042262673, Training Accuracy: 0.9565972222222222\n",
            "Epoch 8/10, Batch Loss: 0.36341822147369385, Average Training Loss: 0.17123619523154546, Training Accuracy: 0.9563356164383562\n",
            "Epoch 8/10, Batch Loss: 0.0782105103135109, Average Training Loss: 0.16997909138130174, Training Accuracy: 0.9569256756756757\n",
            "Epoch 8/10, Batch Loss: 0.060904037207365036, Average Training Loss: 0.16852475732564925, Training Accuracy: 0.9575\n",
            "Epoch 8/10, Batch Loss: 0.08350743353366852, Average Training Loss: 0.16740610832838634, Training Accuracy: 0.9580592105263158\n",
            "Epoch 8/10, Batch Loss: 0.3028830289840698, Average Training Loss: 0.16916554885638224, Training Accuracy: 0.9577922077922078\n",
            "Epoch 8/10, Batch Loss: 0.13777244091033936, Average Training Loss: 0.16876307311348426, Training Accuracy: 0.9583333333333334\n",
            "Epoch 8/10, Batch Loss: 0.5031045079231262, Average Training Loss: 0.1729952431743658, Training Accuracy: 0.9556962025316456\n",
            "Epoch 8/10, Batch Loss: 0.12288479506969452, Average Training Loss: 0.17236886257305742, Training Accuracy: 0.95546875\n",
            "Epoch 8/10, Batch Loss: 0.04204254224896431, Average Training Loss: 0.17075989565547603, Training Accuracy: 0.9560185185185185\n",
            "Epoch 8/10, Batch Loss: 0.07688754051923752, Average Training Loss: 0.1696151108367414, Training Accuracy: 0.9565548780487805\n",
            "Epoch 8/10, Batch Loss: 0.4338132441043854, Average Training Loss: 0.1727982208761106, Training Accuracy: 0.9563253012048193\n",
            "Epoch 8/10, Batch Loss: 0.1512066274881363, Average Training Loss: 0.17254117809768235, Training Accuracy: 0.9561011904761905\n",
            "Epoch 8/10, Batch Loss: 0.19253577291965485, Average Training Loss: 0.17277640862499966, Training Accuracy: 0.9558823529411765\n",
            "Epoch 8/10, Batch Loss: 0.07702821493148804, Average Training Loss: 0.17166305753554023, Training Accuracy: 0.9563953488372093\n",
            "Epoch 8/10, Batch Loss: 0.14278176426887512, Average Training Loss: 0.17133108864741764, Training Accuracy: 0.9561781609195402\n",
            "Epoch 8/10, Batch Loss: 0.2139952927827835, Average Training Loss: 0.1718159091489559, Training Accuracy: 0.9559659090909091\n",
            "Epoch 8/10, Batch Loss: 0.3246414363384247, Average Training Loss: 0.17353304990389373, Training Accuracy: 0.9557584269662921\n",
            "Epoch 8/10, Batch Loss: 0.286533921957016, Average Training Loss: 0.17478861514892843, Training Accuracy: 0.9555555555555556\n",
            "Epoch 8/10, Batch Loss: 0.06593683362007141, Average Training Loss: 0.1735924417255344, Training Accuracy: 0.9560439560439561\n",
            "Epoch 8/10, Batch Loss: 0.17167805135250092, Average Training Loss: 0.17357163313452317, Training Accuracy: 0.9558423913043478\n",
            "Epoch 8/10, Batch Loss: 0.055370572954416275, Average Training Loss: 0.1723006539928016, Training Accuracy: 0.9563172043010753\n",
            "Epoch 8/10, Batch Loss: 0.2092638462781906, Average Training Loss: 0.17269387944264614, Training Accuracy: 0.9561170212765957\n",
            "Epoch 8/10, Batch Loss: 0.13492734730243683, Average Training Loss: 0.172296336999065, Training Accuracy: 0.9559210526315789\n",
            "Epoch 8/10, Batch Loss: 0.3190102279186249, Average Training Loss: 0.17382460669614375, Training Accuracy: 0.9557291666666666\n",
            "Epoch 8/10, Batch Loss: 0.05086153373122215, Average Training Loss: 0.17255694615011363, Training Accuracy: 0.9561855670103093\n",
            "Epoch 8/10, Batch Loss: 0.054484836757183075, Average Training Loss: 0.17135212870732863, Training Accuracy: 0.9566326530612245\n",
            "Epoch 8/10, Batch Loss: 0.15475985407829285, Average Training Loss: 0.171184529973702, Training Accuracy: 0.9564393939393939\n",
            "Epoch 8/10, Batch Loss: 0.16320465505123138, Average Training Loss: 0.17110473122447728, Training Accuracy: 0.95625\n",
            "Epoch 8/10, Batch Loss: 0.08727749437093735, Average Training Loss: 0.17027475858236304, Training Accuracy: 0.9566831683168316\n",
            "Epoch 8/10, Batch Loss: 0.1776333898305893, Average Training Loss: 0.1703469020259731, Training Accuracy: 0.9564950980392157\n",
            "Epoch 8/10, Batch Loss: 0.1145700141787529, Average Training Loss: 0.16980537884299038, Training Accuracy: 0.9563106796116505\n",
            "Epoch 8/10, Batch Loss: 0.05361560732126236, Average Training Loss: 0.1686881695014353, Training Accuracy: 0.9567307692307693\n",
            "Epoch 8/10, Batch Loss: 0.06925718486309052, Average Training Loss: 0.16774120774297488, Training Accuracy: 0.9571428571428572\n",
            "Epoch 8/10, Batch Loss: 0.06270487606525421, Average Training Loss: 0.16675029895356241, Training Accuracy: 0.9575471698113207\n",
            "Epoch 8/10, Batch Loss: 0.06764142960309982, Average Training Loss: 0.16582404783813753, Training Accuracy: 0.9579439252336449\n",
            "Epoch 8/10, Batch Loss: 0.150590181350708, Average Training Loss: 0.16568299351880947, Training Accuracy: 0.9577546296296297\n",
            "Epoch 8/10, Batch Loss: 0.21534249186515808, Average Training Loss: 0.16613858524675762, Training Accuracy: 0.9575688073394495\n",
            "Epoch 8/10, Batch Loss: 0.06169065833091736, Average Training Loss: 0.1651890586384318, Training Accuracy: 0.9579545454545455\n",
            "Epoch 8/10, Batch Loss: 0.05933915078639984, Average Training Loss: 0.16423545586499008, Training Accuracy: 0.9583333333333334\n",
            "Epoch 8/10, Batch Loss: 0.12563151121139526, Average Training Loss: 0.16389077778772584, Training Accuracy: 0.9581473214285714\n",
            "Epoch 8/10, Batch Loss: 0.1270061582326889, Average Training Loss: 0.16356436522529189, Training Accuracy: 0.9579646017699115\n",
            "Epoch 8/10, Batch Loss: 0.0929291844367981, Average Training Loss: 0.16294475837627, Training Accuracy: 0.9583333333333334\n",
            "Epoch 8/10, Batch Loss: 0.211781844496727, Average Training Loss: 0.16336942869036095, Training Accuracy: 0.9581521739130435\n",
            "Epoch 8/10, Batch Loss: 0.18012364208698273, Average Training Loss: 0.16351386156446976, Training Accuracy: 0.9579741379310345\n",
            "Epoch 8/10, Average Training Loss: 0.16351386156446976, Training Accuracy: 0.9579741379310345\n",
            "Epoch 8/10, Validation Loss: 32.928919821977615, Validation Accuracy: 0.6551724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.65      0.67        99\n",
            "                Educational Opportunity       0.47      0.43      0.45        87\n",
            "                         Family Support       0.77      0.96      0.86        93\n",
            "                      Financial Support       0.60      0.64      0.62        89\n",
            "                 Program Implementation       0.70      0.59      0.64        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.65      0.66      0.65       464\n",
            "\n",
            "Epoch 9/10, Batch Loss: 0.21212603151798248, Average Training Loss: 0.21212603151798248, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.13023796677589417, Average Training Loss: 0.17118199914693832, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.150396466255188, Average Training Loss: 0.16425348818302155, Training Accuracy: 0.9583333333333334\n",
            "Epoch 9/10, Batch Loss: 0.03105883114039898, Average Training Loss: 0.1309548239223659, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.04907047003507614, Average Training Loss: 0.11457795314490796, Training Accuracy: 0.975\n",
            "Epoch 9/10, Batch Loss: 0.2167086899280548, Average Training Loss: 0.13159974260876575, Training Accuracy: 0.9583333333333334\n",
            "Epoch 9/10, Batch Loss: 0.031866151839494705, Average Training Loss: 0.11735208678458418, Training Accuracy: 0.9642857142857143\n",
            "Epoch 9/10, Batch Loss: 0.2158479243516922, Average Training Loss: 0.12966406648047268, Training Accuracy: 0.9609375\n",
            "Epoch 9/10, Batch Loss: 0.09235019981861115, Average Training Loss: 0.1255180812958214, Training Accuracy: 0.9652777777777778\n",
            "Epoch 9/10, Batch Loss: 0.2420767992734909, Average Training Loss: 0.13717395309358835, Training Accuracy: 0.9625\n",
            "Epoch 9/10, Batch Loss: 0.10577116906642914, Average Training Loss: 0.1343191545456648, Training Accuracy: 0.9659090909090909\n",
            "Epoch 9/10, Batch Loss: 0.057646557688713074, Average Training Loss: 0.12792977147425214, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.06286567449569702, Average Training Loss: 0.12292484093744022, Training Accuracy: 0.9711538461538461\n",
            "Epoch 9/10, Batch Loss: 0.03151989355683327, Average Training Loss: 0.11639591612453971, Training Accuracy: 0.9732142857142857\n",
            "Epoch 9/10, Batch Loss: 0.04607073590159416, Average Training Loss: 0.11170757077634334, Training Accuracy: 0.975\n",
            "Epoch 9/10, Batch Loss: 0.07191222161054611, Average Training Loss: 0.10922036145348102, Training Accuracy: 0.9765625\n",
            "Epoch 9/10, Batch Loss: 0.1322537064552307, Average Training Loss: 0.11057526410064276, Training Accuracy: 0.9742647058823529\n",
            "Epoch 9/10, Batch Loss: 0.20894405245780945, Average Training Loss: 0.11604019678715202, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.04265192896127701, Average Training Loss: 0.11217765637526386, Training Accuracy: 0.9703947368421053\n",
            "Epoch 9/10, Batch Loss: 0.1433485746383667, Average Training Loss: 0.113736202288419, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.053327158093452454, Average Training Loss: 0.11085958113627774, Training Accuracy: 0.9702380952380952\n",
            "Epoch 9/10, Batch Loss: 0.04971936345100403, Average Training Loss: 0.10808048033240167, Training Accuracy: 0.9715909090909091\n",
            "Epoch 9/10, Batch Loss: 0.18578115105628967, Average Training Loss: 0.11145877036387505, Training Accuracy: 0.970108695652174\n",
            "Epoch 9/10, Batch Loss: 0.14144203066825867, Average Training Loss: 0.11270807287655771, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.09407677501440048, Average Training Loss: 0.11196282096207141, Training Accuracy: 0.97\n",
            "Epoch 9/10, Batch Loss: 0.056068602949380875, Average Training Loss: 0.10981304334619871, Training Accuracy: 0.9711538461538461\n",
            "Epoch 9/10, Batch Loss: 0.042551372200250626, Average Training Loss: 0.10732187034079323, Training Accuracy: 0.9722222222222222\n",
            "Epoch 9/10, Batch Loss: 0.09579596668481827, Average Training Loss: 0.1069102309245084, Training Accuracy: 0.9732142857142857\n",
            "Epoch 9/10, Batch Loss: 0.2782702147960663, Average Training Loss: 0.11281919588559661, Training Accuracy: 0.9698275862068966\n",
            "Epoch 9/10, Batch Loss: 0.2373298555612564, Average Training Loss: 0.1169695512081186, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.08089053630828857, Average Training Loss: 0.1158057120178015, Training Accuracy: 0.969758064516129\n",
            "Epoch 9/10, Batch Loss: 0.037256158888339996, Average Training Loss: 0.11335103848250583, Training Accuracy: 0.970703125\n",
            "Epoch 9/10, Batch Loss: 0.07053711265325546, Average Training Loss: 0.11205364679071037, Training Accuracy: 0.9715909090909091\n",
            "Epoch 9/10, Batch Loss: 0.2479425072669983, Average Training Loss: 0.11605037798118942, Training Accuracy: 0.9705882352941176\n",
            "Epoch 9/10, Batch Loss: 0.5813355445861816, Average Training Loss: 0.1293442398841892, Training Accuracy: 0.9678571428571429\n",
            "Epoch 9/10, Batch Loss: 0.10955803096294403, Average Training Loss: 0.12879462296971017, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.04161209613084793, Average Training Loss: 0.12643833846055172, Training Accuracy: 0.9695945945945946\n",
            "Epoch 9/10, Batch Loss: 0.1306833028793335, Average Training Loss: 0.12655004805051967, Training Accuracy: 0.9703947368421053\n",
            "Epoch 9/10, Batch Loss: 0.04480278119444847, Average Training Loss: 0.12445396428497937, Training Accuracy: 0.9711538461538461\n",
            "Epoch 9/10, Batch Loss: 0.22695450484752655, Average Training Loss: 0.12701647779904307, Training Accuracy: 0.9703125\n",
            "Epoch 9/10, Batch Loss: 0.10114748775959015, Average Training Loss: 0.12638552682247103, Training Accuracy: 0.9710365853658537\n",
            "Epoch 9/10, Batch Loss: 0.19163669645786285, Average Training Loss: 0.12793912609950417, Training Accuracy: 0.9702380952380952\n",
            "Epoch 9/10, Batch Loss: 0.1380629986524582, Average Training Loss: 0.1281745649960845, Training Accuracy: 0.9694767441860465\n",
            "Epoch 9/10, Batch Loss: 0.22560612857341766, Average Training Loss: 0.13038891871375116, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.041296783834695816, Average Training Loss: 0.12840909349421661, Training Accuracy: 0.9694444444444444\n",
            "Epoch 9/10, Batch Loss: 0.0739908441901207, Average Training Loss: 0.12722608807456234, Training Accuracy: 0.970108695652174\n",
            "Epoch 9/10, Batch Loss: 0.05619259178638458, Average Training Loss: 0.12571473708970748, Training Accuracy: 0.9707446808510638\n",
            "Epoch 9/10, Batch Loss: 0.05266433581709862, Average Training Loss: 0.12419285372986148, Training Accuracy: 0.9713541666666666\n",
            "Epoch 9/10, Batch Loss: 0.189944788813591, Average Training Loss: 0.12553472995606005, Training Accuracy: 0.9706632653061225\n",
            "Epoch 9/10, Batch Loss: 0.1353445202112198, Average Training Loss: 0.12573092576116324, Training Accuracy: 0.97\n",
            "Epoch 9/10, Batch Loss: 0.24667641520500183, Average Training Loss: 0.12810240594633654, Training Accuracy: 0.9693627450980392\n",
            "Epoch 9/10, Batch Loss: 0.20229190587997437, Average Training Loss: 0.1295291270989065, Training Accuracy: 0.96875\n",
            "Epoch 9/10, Batch Loss: 0.0340188592672348, Average Training Loss: 0.12772704657378062, Training Accuracy: 0.9693396226415094\n",
            "Epoch 9/10, Batch Loss: 0.13054031133651733, Average Training Loss: 0.12777914406938684, Training Accuracy: 0.9699074074074074\n",
            "Epoch 9/10, Batch Loss: 0.10048751533031464, Average Training Loss: 0.12728293263776735, Training Accuracy: 0.9704545454545455\n",
            "Epoch 9/10, Batch Loss: 0.06928490847349167, Average Training Loss: 0.12624725363483386, Training Accuracy: 0.9709821428571429\n",
            "Epoch 9/10, Batch Loss: 0.052654121071100235, Average Training Loss: 0.12495614604599643, Training Accuracy: 0.9714912280701754\n",
            "Epoch 9/10, Batch Loss: 0.1294051855802536, Average Training Loss: 0.12503285362417327, Training Accuracy: 0.9709051724137931\n",
            "Epoch 9/10, Batch Loss: 0.08854441344738007, Average Training Loss: 0.12441440548558357, Training Accuracy: 0.9713983050847458\n",
            "Epoch 9/10, Batch Loss: 0.042493078857660294, Average Training Loss: 0.12304905004178485, Training Accuracy: 0.971875\n",
            "Epoch 9/10, Batch Loss: 0.05946122109889984, Average Training Loss: 0.12200662661649164, Training Accuracy: 0.9723360655737705\n",
            "Epoch 9/10, Batch Loss: 0.26234227418899536, Average Training Loss: 0.12427010480314493, Training Accuracy: 0.9707661290322581\n",
            "Epoch 9/10, Batch Loss: 0.07432296872138977, Average Training Loss: 0.12347729311930755, Training Accuracy: 0.9712301587301587\n",
            "Epoch 9/10, Batch Loss: 0.05876429006457329, Average Training Loss: 0.12246615244657733, Training Accuracy: 0.9716796875\n",
            "Epoch 9/10, Batch Loss: 0.11968927085399628, Average Training Loss: 0.12242343119130684, Training Accuracy: 0.9711538461538461\n",
            "Epoch 9/10, Batch Loss: 0.10797536373138428, Average Training Loss: 0.12220452107827771, Training Accuracy: 0.9715909090909091\n",
            "Epoch 9/10, Batch Loss: 0.04698013886809349, Average Training Loss: 0.12108176910499138, Training Accuracy: 0.9720149253731343\n",
            "Epoch 9/10, Batch Loss: 0.35969674587249756, Average Training Loss: 0.12459081288098413, Training Accuracy: 0.9705882352941176\n",
            "Epoch 9/10, Batch Loss: 0.14392979443073273, Average Training Loss: 0.12487108797590801, Training Accuracy: 0.970108695652174\n",
            "Epoch 9/10, Batch Loss: 0.18934854865074158, Average Training Loss: 0.12579219455697707, Training Accuracy: 0.9696428571428571\n",
            "Epoch 9/10, Batch Loss: 0.10235820710659027, Average Training Loss: 0.12546213839570403, Training Accuracy: 0.9700704225352113\n",
            "Epoch 9/10, Batch Loss: 0.0632111132144928, Average Training Loss: 0.12459754082374275, Training Accuracy: 0.9704861111111112\n",
            "Epoch 9/10, Batch Loss: 0.11539287120103836, Average Training Loss: 0.12447144945904817, Training Accuracy: 0.9700342465753424\n",
            "Epoch 9/10, Batch Loss: 0.04687435179948807, Average Training Loss: 0.12342284003121627, Training Accuracy: 0.9704391891891891\n",
            "Epoch 9/10, Batch Loss: 0.24861891567707062, Average Training Loss: 0.12509212103982767, Training Accuracy: 0.97\n",
            "Epoch 9/10, Batch Loss: 0.05993587151169777, Average Training Loss: 0.12423480196708911, Training Accuracy: 0.9703947368421053\n",
            "Epoch 9/10, Batch Loss: 0.21176107227802277, Average Training Loss: 0.12537150677632203, Training Accuracy: 0.9699675324675324\n",
            "Epoch 9/10, Batch Loss: 0.3608621060848236, Average Training Loss: 0.12839061702386692, Training Accuracy: 0.969551282051282\n",
            "Epoch 9/10, Batch Loss: 0.038334768265485764, Average Training Loss: 0.12725066957122919, Training Accuracy: 0.9699367088607594\n",
            "Epoch 9/10, Batch Loss: 0.046208467334508896, Average Training Loss: 0.12623764204327018, Training Accuracy: 0.9703125\n",
            "Epoch 9/10, Batch Loss: 0.23125410079956055, Average Training Loss: 0.12753414153408857, Training Accuracy: 0.9699074074074074\n",
            "Epoch 9/10, Batch Loss: 0.10522697120904922, Average Training Loss: 0.1272621028715881, Training Accuracy: 0.9702743902439024\n",
            "Epoch 9/10, Batch Loss: 0.1741688847541809, Average Training Loss: 0.12782724482198077, Training Accuracy: 0.9698795180722891\n",
            "Epoch 9/10, Batch Loss: 0.17422787845134735, Average Training Loss: 0.12837963331756846, Training Accuracy: 0.9694940476190477\n",
            "Epoch 9/10, Batch Loss: 0.041146405041217804, Average Training Loss: 0.12735336004372905, Training Accuracy: 0.9698529411764706\n",
            "Epoch 9/10, Batch Loss: 0.04904203861951828, Average Training Loss: 0.12644276328298243, Training Accuracy: 0.970203488372093\n",
            "Epoch 9/10, Batch Loss: 0.10550157725811005, Average Training Loss: 0.1262020599953402, Training Accuracy: 0.9705459770114943\n",
            "Epoch 9/10, Batch Loss: 0.22636255621910095, Average Training Loss: 0.1273402474524284, Training Accuracy: 0.9701704545454546\n",
            "Epoch 9/10, Batch Loss: 0.034528762102127075, Average Training Loss: 0.12629742177433512, Training Accuracy: 0.9705056179775281\n",
            "Epoch 9/10, Batch Loss: 0.12479516118764877, Average Training Loss: 0.12628072999003861, Training Accuracy: 0.9708333333333333\n",
            "Epoch 9/10, Batch Loss: 0.23255035281181335, Average Training Loss: 0.12744852804302514, Training Accuracy: 0.9697802197802198\n",
            "Epoch 9/10, Batch Loss: 0.06401383131742477, Average Training Loss: 0.1267590204699208, Training Accuracy: 0.970108695652174\n",
            "Epoch 9/10, Batch Loss: 0.031047463417053223, Average Training Loss: 0.1257298639424706, Training Accuracy: 0.9704301075268817\n",
            "Epoch 9/10, Batch Loss: 0.0573388896882534, Average Training Loss: 0.12500230038657467, Training Accuracy: 0.9707446808510638\n",
            "Epoch 9/10, Batch Loss: 0.14531046152114868, Average Training Loss: 0.12521607050378072, Training Accuracy: 0.9710526315789474\n",
            "Epoch 9/10, Batch Loss: 0.17014837265014648, Average Training Loss: 0.12568411531780535, Training Accuracy: 0.970703125\n",
            "Epoch 9/10, Batch Loss: 0.09593284130096436, Average Training Loss: 0.12537740115268328, Training Accuracy: 0.970360824742268\n",
            "Epoch 9/10, Batch Loss: 0.08365146815776825, Average Training Loss: 0.12495162632620456, Training Accuracy: 0.9706632653061225\n",
            "Epoch 9/10, Batch Loss: 0.057875268161296844, Average Training Loss: 0.12427408735484186, Training Accuracy: 0.9709595959595959\n",
            "Epoch 9/10, Batch Loss: 0.046476949006319046, Average Training Loss: 0.12349611597135662, Training Accuracy: 0.97125\n",
            "Epoch 9/10, Batch Loss: 0.043402474373579025, Average Training Loss: 0.12270310961890339, Training Accuracy: 0.9715346534653465\n",
            "Epoch 9/10, Batch Loss: 0.07631400972604752, Average Training Loss: 0.1222483145219146, Training Accuracy: 0.9718137254901961\n",
            "Epoch 9/10, Batch Loss: 0.0441826693713665, Average Training Loss: 0.12149039563695782, Training Accuracy: 0.9720873786407767\n",
            "Epoch 9/10, Batch Loss: 0.07809942960739136, Average Training Loss: 0.12107317480975045, Training Accuracy: 0.9723557692307693\n",
            "Epoch 9/10, Batch Loss: 0.024775294587016106, Average Training Loss: 0.1201560521409625, Training Accuracy: 0.9726190476190476\n",
            "Epoch 9/10, Batch Loss: 0.04001423344016075, Average Training Loss: 0.11939999724755872, Training Accuracy: 0.972877358490566\n",
            "Epoch 9/10, Batch Loss: 0.03811410814523697, Average Training Loss: 0.11864031604099497, Training Accuracy: 0.9731308411214953\n",
            "Epoch 9/10, Batch Loss: 0.3665732443332672, Average Training Loss: 0.12093599130296045, Training Accuracy: 0.9716435185185185\n",
            "Epoch 9/10, Batch Loss: 0.11412078142166138, Average Training Loss: 0.12087346644166412, Training Accuracy: 0.9719036697247706\n",
            "Epoch 9/10, Batch Loss: 0.3062291741371155, Average Training Loss: 0.12255851832980459, Training Accuracy: 0.9715909090909091\n",
            "Epoch 9/10, Batch Loss: 0.04548833891749382, Average Training Loss: 0.12186419238915315, Training Accuracy: 0.9718468468468469\n",
            "Epoch 9/10, Batch Loss: 0.18286149203777313, Average Training Loss: 0.12240881113601583, Training Accuracy: 0.9715401785714286\n",
            "Epoch 9/10, Batch Loss: 0.05454849451780319, Average Training Loss: 0.1218082773606334, Training Accuracy: 0.9717920353982301\n",
            "Epoch 9/10, Batch Loss: 0.34193140268325806, Average Training Loss: 0.12373918196872662, Training Accuracy: 0.9714912280701754\n",
            "Epoch 9/10, Batch Loss: 0.07478739321231842, Average Training Loss: 0.12331351424041001, Training Accuracy: 0.9717391304347827\n",
            "Epoch 9/10, Batch Loss: 0.07726288586854935, Average Training Loss: 0.12291652606479053, Training Accuracy: 0.9714439655172413\n",
            "Epoch 9/10, Average Training Loss: 0.12291652606479053, Training Accuracy: 0.9714439655172413\n",
            "Epoch 9/10, Validation Loss: 34.07850417494774, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.64      0.66        99\n",
            "                Educational Opportunity       0.48      0.45      0.46        87\n",
            "                         Family Support       0.79      0.95      0.86        93\n",
            "                      Financial Support       0.62      0.67      0.65        89\n",
            "                 Program Implementation       0.70      0.61      0.66        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.66      0.66       464\n",
            "                           weighted avg       0.66      0.67      0.66       464\n",
            "\n",
            "Epoch 10/10, Batch Loss: 0.07075067609548569, Average Training Loss: 0.07075067609548569, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.21207205951213837, Average Training Loss: 0.14141136780381203, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.06131577491760254, Average Training Loss: 0.1147128368417422, Training Accuracy: 0.9791666666666666\n",
            "Epoch 10/10, Batch Loss: 0.04530102387070656, Average Training Loss: 0.09735988359898329, Training Accuracy: 0.984375\n",
            "Epoch 10/10, Batch Loss: 0.25037306547164917, Average Training Loss: 0.12796251997351646, Training Accuracy: 0.9625\n",
            "Epoch 10/10, Batch Loss: 0.0335455983877182, Average Training Loss: 0.11222636637588342, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.15610672533512115, Average Training Loss: 0.11849498908434596, Training Accuracy: 0.9642857142857143\n",
            "Epoch 10/10, Batch Loss: 0.04624684900045395, Average Training Loss: 0.10946397157385945, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.24312449991703033, Average Training Loss: 0.12431514138976733, Training Accuracy: 0.9513888888888888\n",
            "Epoch 10/10, Batch Loss: 0.07934296876192093, Average Training Loss: 0.1198179241269827, Training Accuracy: 0.95625\n",
            "Epoch 10/10, Batch Loss: 0.04430578649044037, Average Training Loss: 0.11295318434184248, Training Accuracy: 0.9602272727272727\n",
            "Epoch 10/10, Batch Loss: 0.05937041714787483, Average Training Loss: 0.10848795374234517, Training Accuracy: 0.9635416666666666\n",
            "Epoch 10/10, Batch Loss: 0.2703888416290283, Average Training Loss: 0.12094186819516696, Training Accuracy: 0.9567307692307693\n",
            "Epoch 10/10, Batch Loss: 0.05501788854598999, Average Training Loss: 0.11623301250594002, Training Accuracy: 0.9598214285714286\n",
            "Epoch 10/10, Batch Loss: 0.09088984876871109, Average Training Loss: 0.11454346825679143, Training Accuracy: 0.9625\n",
            "Epoch 10/10, Batch Loss: 0.2892591953277588, Average Training Loss: 0.1254632011987269, Training Accuracy: 0.95703125\n",
            "Epoch 10/10, Batch Loss: 0.09862947463989258, Average Training Loss: 0.12388474669526606, Training Accuracy: 0.9595588235294118\n",
            "Epoch 10/10, Batch Loss: 0.05216784030199051, Average Training Loss: 0.11990047411786185, Training Accuracy: 0.9618055555555556\n",
            "Epoch 10/10, Batch Loss: 0.04963967204093933, Average Training Loss: 0.11620253716644488, Training Accuracy: 0.9638157894736842\n",
            "Epoch 10/10, Batch Loss: 0.10277403146028519, Average Training Loss: 0.11553111188113689, Training Accuracy: 0.9625\n",
            "Epoch 10/10, Batch Loss: 0.061482254415750504, Average Training Loss: 0.11295735676373754, Training Accuracy: 0.9642857142857143\n",
            "Epoch 10/10, Batch Loss: 0.03161022812128067, Average Training Loss: 0.10925976000726223, Training Accuracy: 0.9659090909090909\n",
            "Epoch 10/10, Batch Loss: 0.20816847681999207, Average Training Loss: 0.11356013899912006, Training Accuracy: 0.9646739130434783\n",
            "Epoch 10/10, Batch Loss: 0.0727795660495758, Average Training Loss: 0.1118609484595557, Training Accuracy: 0.9661458333333334\n",
            "Epoch 10/10, Batch Loss: 0.20916599035263062, Average Training Loss: 0.1157531501352787, Training Accuracy: 0.965\n",
            "Epoch 10/10, Batch Loss: 0.10103985667228699, Average Training Loss: 0.11518725423285595, Training Accuracy: 0.9639423076923077\n",
            "Epoch 10/10, Batch Loss: 0.07873235642910004, Average Training Loss: 0.11383707283271684, Training Accuracy: 0.9652777777777778\n",
            "Epoch 10/10, Batch Loss: 0.07675304263830185, Average Training Loss: 0.1125126431829163, Training Accuracy: 0.9665178571428571\n",
            "Epoch 10/10, Batch Loss: 0.0542522631585598, Average Training Loss: 0.11050366456138677, Training Accuracy: 0.9676724137931034\n",
            "Epoch 10/10, Batch Loss: 0.20330464839935303, Average Training Loss: 0.11359703068931898, Training Accuracy: 0.9666666666666667\n",
            "Epoch 10/10, Batch Loss: 0.07452262938022614, Average Training Loss: 0.11233656613096114, Training Accuracy: 0.967741935483871\n",
            "Epoch 10/10, Batch Loss: 0.029802560806274414, Average Training Loss: 0.10975737846456468, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.04076743870973587, Average Training Loss: 0.10766677422956987, Training Accuracy: 0.9696969696969697\n",
            "Epoch 10/10, Batch Loss: 0.07101608067750931, Average Training Loss: 0.10658881265450926, Training Accuracy: 0.9705882352941176\n",
            "Epoch 10/10, Batch Loss: 0.2229129672050476, Average Training Loss: 0.10991235992738178, Training Accuracy: 0.9696428571428571\n",
            "Epoch 10/10, Batch Loss: 0.20447799563407898, Average Training Loss: 0.11253918314145671, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.05414561927318573, Average Training Loss: 0.11096097871258452, Training Accuracy: 0.9695945945945946\n",
            "Epoch 10/10, Batch Loss: 0.07300326973199844, Average Training Loss: 0.10996209163414805, Training Accuracy: 0.9703947368421053\n",
            "Epoch 10/10, Batch Loss: 0.07090525329113007, Average Training Loss: 0.10896063424073733, Training Accuracy: 0.9711538461538461\n",
            "Epoch 10/10, Batch Loss: 0.04801435396075249, Average Training Loss: 0.10743697723373771, Training Accuracy: 0.971875\n",
            "Epoch 10/10, Batch Loss: 0.08010725677013397, Average Training Loss: 0.10677039868584494, Training Accuracy: 0.9725609756097561\n",
            "Epoch 10/10, Batch Loss: 0.07158276438713074, Average Training Loss: 0.10593259786920887, Training Accuracy: 0.9732142857142857\n",
            "Epoch 10/10, Batch Loss: 0.06399015337228775, Average Training Loss: 0.10495719218323397, Training Accuracy: 0.9738372093023255\n",
            "Epoch 10/10, Batch Loss: 0.0631704181432724, Average Training Loss: 0.10400749277323484, Training Accuracy: 0.9744318181818182\n",
            "Epoch 10/10, Batch Loss: 0.06138690933585167, Average Training Loss: 0.10306036869684855, Training Accuracy: 0.975\n",
            "Epoch 10/10, Batch Loss: 0.45868444442749023, Average Training Loss: 0.11079132686490598, Training Accuracy: 0.9728260869565217\n",
            "Epoch 10/10, Batch Loss: 0.10472025722265244, Average Training Loss: 0.11066215517038995, Training Accuracy: 0.973404255319149\n",
            "Epoch 10/10, Batch Loss: 0.05522676557302475, Average Training Loss: 0.10950725122044484, Training Accuracy: 0.9739583333333334\n",
            "Epoch 10/10, Batch Loss: 0.11313915997743607, Average Training Loss: 0.1095813718073222, Training Accuracy: 0.9732142857142857\n",
            "Epoch 10/10, Batch Loss: 0.059370677918195724, Average Training Loss: 0.10857715792953967, Training Accuracy: 0.97375\n",
            "Epoch 10/10, Batch Loss: 0.07326705008745193, Average Training Loss: 0.10788480287381247, Training Accuracy: 0.9742647058823529\n",
            "Epoch 10/10, Batch Loss: 0.26348963379859924, Average Training Loss: 0.11087720346851991, Training Accuracy: 0.9735576923076923\n",
            "Epoch 10/10, Batch Loss: 0.06276370584964752, Average Training Loss: 0.10996940162665439, Training Accuracy: 0.9740566037735849\n",
            "Epoch 10/10, Batch Loss: 0.1232513040304184, Average Training Loss: 0.11021536278227965, Training Accuracy: 0.9733796296296297\n",
            "Epoch 10/10, Batch Loss: 0.11617426574230194, Average Training Loss: 0.11032370647246187, Training Accuracy: 0.9738636363636364\n",
            "Epoch 10/10, Batch Loss: 0.0459023118019104, Average Training Loss: 0.10917332442477345, Training Accuracy: 0.9743303571428571\n",
            "Epoch 10/10, Batch Loss: 0.047292377799749374, Average Training Loss: 0.10808769378222917, Training Accuracy: 0.9747807017543859\n",
            "Epoch 10/10, Batch Loss: 0.04764386638998985, Average Training Loss: 0.10704555882719057, Training Accuracy: 0.9752155172413793\n",
            "Epoch 10/10, Batch Loss: 0.1407988965511322, Average Training Loss: 0.10761764929708788, Training Accuracy: 0.975635593220339\n",
            "Epoch 10/10, Batch Loss: 0.03827294334769249, Average Training Loss: 0.10646190419793129, Training Accuracy: 0.9760416666666667\n",
            "Epoch 10/10, Batch Loss: 0.043552376329898834, Average Training Loss: 0.10543060046238978, Training Accuracy: 0.9764344262295082\n",
            "Epoch 10/10, Batch Loss: 0.08602713793516159, Average Training Loss: 0.10511764138936996, Training Accuracy: 0.9768145161290323\n",
            "Epoch 10/10, Batch Loss: 0.03593193367123604, Average Training Loss: 0.10401945555257419, Training Accuracy: 0.9771825396825397\n",
            "Epoch 10/10, Batch Loss: 0.0331059992313385, Average Training Loss: 0.10291143279755488, Training Accuracy: 0.9775390625\n",
            "Epoch 10/10, Batch Loss: 0.06399577856063843, Average Training Loss: 0.10231273042467924, Training Accuracy: 0.9778846153846154\n",
            "Epoch 10/10, Batch Loss: 0.029663635417819023, Average Training Loss: 0.10121198656093894, Training Accuracy: 0.978219696969697\n",
            "Epoch 10/10, Batch Loss: 0.05997823178768158, Average Training Loss: 0.10059655738521868, Training Accuracy: 0.9785447761194029\n",
            "Epoch 10/10, Batch Loss: 0.06979513168334961, Average Training Loss: 0.10014359524254413, Training Accuracy: 0.9788602941176471\n",
            "Epoch 10/10, Batch Loss: 0.039488498121500015, Average Training Loss: 0.09926453586397828, Training Accuracy: 0.9791666666666666\n",
            "Epoch 10/10, Batch Loss: 0.18270368874073029, Average Training Loss: 0.10045652376221759, Training Accuracy: 0.9785714285714285\n",
            "Epoch 10/10, Batch Loss: 0.11160408705472946, Average Training Loss: 0.10061353169591494, Training Accuracy: 0.9779929577464789\n",
            "Epoch 10/10, Batch Loss: 0.09162040054798126, Average Training Loss: 0.10048862709663808, Training Accuracy: 0.9782986111111112\n",
            "Epoch 10/10, Batch Loss: 0.12445370107889175, Average Training Loss: 0.1008169157813265, Training Accuracy: 0.9777397260273972\n",
            "Epoch 10/10, Batch Loss: 0.05792510509490967, Average Training Loss: 0.10023729671799653, Training Accuracy: 0.9780405405405406\n",
            "Epoch 10/10, Batch Loss: 0.06752435117959976, Average Training Loss: 0.09980112411081792, Training Accuracy: 0.9783333333333334\n",
            "Epoch 10/10, Batch Loss: 0.31784307956695557, Average Training Loss: 0.10267009720892499, Training Accuracy: 0.977796052631579\n",
            "Epoch 10/10, Batch Loss: 0.030234120786190033, Average Training Loss: 0.10172937024239596, Training Accuracy: 0.9780844155844156\n",
            "Epoch 10/10, Batch Loss: 0.05800674110651016, Average Training Loss: 0.1011688237150128, Training Accuracy: 0.9783653846153846\n",
            "Epoch 10/10, Batch Loss: 0.0651891678571701, Average Training Loss: 0.10071338503326796, Training Accuracy: 0.9786392405063291\n",
            "Epoch 10/10, Batch Loss: 0.3355323374271393, Average Training Loss: 0.10364862193819135, Training Accuracy: 0.97734375\n",
            "Epoch 10/10, Batch Loss: 0.022800831124186516, Average Training Loss: 0.10265050106394438, Training Accuracy: 0.9776234567901234\n",
            "Epoch 10/10, Batch Loss: 0.04298477619886398, Average Training Loss: 0.10192287027290682, Training Accuracy: 0.9778963414634146\n",
            "Epoch 10/10, Batch Loss: 0.255056768655777, Average Training Loss: 0.10376785700041127, Training Accuracy: 0.9774096385542169\n",
            "Epoch 10/10, Batch Loss: 0.042343806475400925, Average Training Loss: 0.10303661830368496, Training Accuracy: 0.9776785714285714\n",
            "Epoch 10/10, Batch Loss: 0.10486266016960144, Average Training Loss: 0.10305810114916633, Training Accuracy: 0.9772058823529411\n",
            "Epoch 10/10, Batch Loss: 0.12300966680049896, Average Training Loss: 0.10329009609860043, Training Accuracy: 0.9767441860465116\n",
            "Epoch 10/10, Batch Loss: 0.043807871639728546, Average Training Loss: 0.10260639236918812, Training Accuracy: 0.9770114942528736\n",
            "Epoch 10/10, Batch Loss: 0.04023313894867897, Average Training Loss: 0.10189760539850051, Training Accuracy: 0.9772727272727273\n",
            "Epoch 10/10, Batch Loss: 0.0612778477370739, Average Training Loss: 0.1014412036270238, Training Accuracy: 0.9775280898876404\n",
            "Epoch 10/10, Batch Loss: 0.05237581580877304, Average Training Loss: 0.10089603265126547, Training Accuracy: 0.9777777777777777\n",
            "Epoch 10/10, Batch Loss: 0.040708597749471664, Average Training Loss: 0.10023463226772927, Training Accuracy: 0.978021978021978\n",
            "Epoch 10/10, Batch Loss: 0.13696275651454926, Average Training Loss: 0.10063385100954253, Training Accuracy: 0.9775815217391305\n",
            "Epoch 10/10, Batch Loss: 0.09158927202224731, Average Training Loss: 0.10053659747204473, Training Accuracy: 0.9778225806451613\n",
            "Epoch 10/10, Batch Loss: 0.17231687903404236, Average Training Loss: 0.10130021748866172, Training Accuracy: 0.9780585106382979\n",
            "Epoch 10/10, Batch Loss: 0.03829074278473854, Average Training Loss: 0.10063695986019938, Training Accuracy: 0.9782894736842105\n",
            "Epoch 10/10, Batch Loss: 0.11457497626543045, Average Training Loss: 0.1007821475310872, Training Accuracy: 0.9778645833333334\n",
            "Epoch 10/10, Batch Loss: 0.36774134635925293, Average Training Loss: 0.10353430422003736, Training Accuracy: 0.976159793814433\n",
            "Epoch 10/10, Batch Loss: 0.07866381108760834, Average Training Loss: 0.10328052367786972, Training Accuracy: 0.9757653061224489\n",
            "Epoch 10/10, Batch Loss: 0.04767046123743057, Average Training Loss: 0.10271880587544104, Training Accuracy: 0.976010101010101\n",
            "Epoch 10/10, Batch Loss: 0.07142635434865952, Average Training Loss: 0.10240588136017323, Training Accuracy: 0.97625\n",
            "Epoch 10/10, Batch Loss: 0.24723589420318604, Average Training Loss: 0.10383984188337138, Training Accuracy: 0.9758663366336634\n",
            "Epoch 10/10, Batch Loss: 0.122328020632267, Average Training Loss: 0.1040210985377723, Training Accuracy: 0.9754901960784313\n",
            "Epoch 10/10, Batch Loss: 0.05726996064186096, Average Training Loss: 0.10356720399509356, Training Accuracy: 0.9757281553398058\n",
            "Epoch 10/10, Batch Loss: 0.052506547421216965, Average Training Loss: 0.10307623614342167, Training Accuracy: 0.9759615384615384\n",
            "Epoch 10/10, Batch Loss: 0.051896460354328156, Average Training Loss: 0.10258880970733507, Training Accuracy: 0.9761904761904762\n",
            "Epoch 10/10, Batch Loss: 0.43161725997924805, Average Training Loss: 0.10569285169103236, Training Accuracy: 0.9752358490566038\n",
            "Epoch 10/10, Batch Loss: 0.03005107119679451, Average Training Loss: 0.10498591916304882, Training Accuracy: 0.9754672897196262\n",
            "Epoch 10/10, Batch Loss: 0.131649449467659, Average Training Loss: 0.10523280370290633, Training Accuracy: 0.9751157407407407\n",
            "Epoch 10/10, Batch Loss: 0.045928847044706345, Average Training Loss: 0.10468873070604211, Training Accuracy: 0.9753440366972477\n",
            "Epoch 10/10, Batch Loss: 0.08588586747646332, Average Training Loss: 0.1045177955857732, Training Accuracy: 0.9755681818181818\n",
            "Epoch 10/10, Batch Loss: 0.10905934125185013, Average Training Loss: 0.10455871041159372, Training Accuracy: 0.9752252252252253\n",
            "Epoch 10/10, Batch Loss: 0.035526975989341736, Average Training Loss: 0.10394235563996647, Training Accuracy: 0.9754464285714286\n",
            "Epoch 10/10, Batch Loss: 0.23362889885902405, Average Training Loss: 0.10509002416402893, Training Accuracy: 0.9751106194690266\n",
            "Epoch 10/10, Batch Loss: 0.08833359181880951, Average Training Loss: 0.10494303791538666, Training Accuracy: 0.975328947368421\n",
            "Epoch 10/10, Batch Loss: 0.4842050075531006, Average Training Loss: 0.10824096808614939, Training Accuracy: 0.9744565217391304\n",
            "Epoch 10/10, Batch Loss: 0.06998313963413239, Average Training Loss: 0.10791115922018371, Training Accuracy: 0.974676724137931\n",
            "Epoch 10/10, Average Training Loss: 0.10791115922018371, Training Accuracy: 0.974676724137931\n",
            "Epoch 10/10, Validation Loss: 33.97514219582081, Validation Accuracy: 0.6681034482758621\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.66      0.68        99\n",
            "                Educational Opportunity       0.48      0.47      0.47        87\n",
            "                         Family Support       0.81      0.94      0.87        93\n",
            "                      Financial Support       0.62      0.65      0.63        89\n",
            "                 Program Implementation       0.71      0.61      0.66        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.66      0.67      0.66       464\n",
            "                           weighted avg       0.67      0.67      0.66       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Handle NaN values in the 'Label' column\n",
        "df['Label'].fillna('default_label', inplace=True)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and validation data\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UiQvJXf174nh",
        "outputId": "0a63d593-4b8e-4108-ba50-ac8641decb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-42-37758020bac2>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.6141594648361206, Average Training Loss: 1.6141594648361206, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.5217159986495972, Average Training Loss: 1.5679377317428589, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.6075111627578735, Average Training Loss: 1.5811288754145305, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/5, Batch Loss: 1.6291139125823975, Average Training Loss: 1.5931251347064972, Training Accuracy: 0.1875\n",
            "Epoch 1/5, Batch Loss: 1.6105462312698364, Average Training Loss: 1.596609354019165, Training Accuracy: 0.1875\n",
            "Epoch 1/5, Batch Loss: 1.6292423009872437, Average Training Loss: 1.6020481785138447, Training Accuracy: 0.19791666666666666\n",
            "Epoch 1/5, Batch Loss: 1.6729230880737305, Average Training Loss: 1.6121731655938285, Training Accuracy: 0.19642857142857142\n",
            "Epoch 1/5, Batch Loss: 1.6519626379013062, Average Training Loss: 1.6171468496322632, Training Accuracy: 0.203125\n",
            "Epoch 1/5, Batch Loss: 1.6739495992660522, Average Training Loss: 1.6234582662582397, Training Accuracy: 0.2013888888888889\n",
            "Epoch 1/5, Batch Loss: 1.6009867191314697, Average Training Loss: 1.6212111115455627, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.6443002223968506, Average Training Loss: 1.6233101216229526, Training Accuracy: 0.21022727272727273\n",
            "Epoch 1/5, Batch Loss: 1.5682339668273926, Average Training Loss: 1.6187204420566559, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.6217877864837646, Average Training Loss: 1.618956391627972, Training Accuracy: 0.21634615384615385\n",
            "Epoch 1/5, Batch Loss: 1.6824522018432617, Average Training Loss: 1.6234918066433497, Training Accuracy: 0.20535714285714285\n",
            "Epoch 1/5, Batch Loss: 1.5319262742996216, Average Training Loss: 1.6173874378204345, Training Accuracy: 0.20833333333333334\n",
            "Epoch 1/5, Batch Loss: 1.616977334022522, Average Training Loss: 1.617361806333065, Training Accuracy: 0.2109375\n",
            "Epoch 1/5, Batch Loss: 1.577906608581543, Average Training Loss: 1.6150409123476814, Training Accuracy: 0.21323529411764705\n",
            "Epoch 1/5, Batch Loss: 1.6241916418075562, Average Training Loss: 1.6155492862065632, Training Accuracy: 0.21180555555555555\n",
            "Epoch 1/5, Batch Loss: 1.564656138420105, Average Training Loss: 1.6128706994809603, Training Accuracy: 0.21710526315789475\n",
            "Epoch 1/5, Batch Loss: 1.620678186416626, Average Training Loss: 1.6132610738277435, Training Accuracy: 0.2125\n",
            "Epoch 1/5, Batch Loss: 1.5280070304870605, Average Training Loss: 1.6092013574781872, Training Accuracy: 0.22023809523809523\n",
            "Epoch 1/5, Batch Loss: 1.6382195949554443, Average Training Loss: 1.610520368272608, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.6051368713378906, Average Training Loss: 1.6102863031884898, Training Accuracy: 0.22010869565217392\n",
            "Epoch 1/5, Batch Loss: 1.6361613273620605, Average Training Loss: 1.6113644291957219, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.478200078010559, Average Training Loss: 1.6060378551483154, Training Accuracy: 0.2325\n",
            "Epoch 1/5, Batch Loss: 1.5777007341384888, Average Training Loss: 1.6049479658787067, Training Accuracy: 0.23317307692307693\n",
            "Epoch 1/5, Batch Loss: 1.5148030519485474, Average Training Loss: 1.601609265362775, Training Accuracy: 0.24074074074074073\n",
            "Epoch 1/5, Batch Loss: 1.5599786043167114, Average Training Loss: 1.6001224560397012, Training Accuracy: 0.24107142857142858\n",
            "Epoch 1/5, Batch Loss: 1.6000980138778687, Average Training Loss: 1.6001216132065346, Training Accuracy: 0.23922413793103448\n",
            "Epoch 1/5, Batch Loss: 1.5553854703903198, Average Training Loss: 1.5986304084459941, Training Accuracy: 0.23541666666666666\n",
            "Epoch 1/5, Batch Loss: 1.5724607706069946, Average Training Loss: 1.5977862265802198, Training Accuracy: 0.23588709677419356\n",
            "Epoch 1/5, Batch Loss: 1.5322598218917847, Average Training Loss: 1.5957385264337063, Training Accuracy: 0.23828125\n",
            "Epoch 1/5, Batch Loss: 1.4701941013336182, Average Training Loss: 1.5919341499155217, Training Accuracy: 0.24431818181818182\n",
            "Epoch 1/5, Batch Loss: 1.6046370267868042, Average Training Loss: 1.5923077639411478, Training Accuracy: 0.24448529411764705\n",
            "Epoch 1/5, Batch Loss: 1.5459846258163452, Average Training Loss: 1.5909842457090104, Training Accuracy: 0.24642857142857144\n",
            "Epoch 1/5, Batch Loss: 1.60854971408844, Average Training Loss: 1.5914721753862169, Training Accuracy: 0.2465277777777778\n",
            "Epoch 1/5, Batch Loss: 1.462722659111023, Average Training Loss: 1.5879924587301306, Training Accuracy: 0.2516891891891892\n",
            "Epoch 1/5, Batch Loss: 1.4585456848144531, Average Training Loss: 1.584585964679718, Training Accuracy: 0.2565789473684211\n",
            "Epoch 1/5, Batch Loss: 1.5162837505340576, Average Training Loss: 1.5828346258554704, Training Accuracy: 0.26121794871794873\n",
            "Epoch 1/5, Batch Loss: 1.57256019115448, Average Training Loss: 1.5825777649879456, Training Accuracy: 0.2625\n",
            "Epoch 1/5, Batch Loss: 1.529152274131775, Average Training Loss: 1.581274704235356, Training Accuracy: 0.26371951219512196\n",
            "Epoch 1/5, Batch Loss: 1.675834059715271, Average Training Loss: 1.5835261174610682, Training Accuracy: 0.2619047619047619\n",
            "Epoch 1/5, Batch Loss: 1.443756341934204, Average Training Loss: 1.5802756575650947, Training Accuracy: 0.26744186046511625\n",
            "Epoch 1/5, Batch Loss: 1.4111576080322266, Average Training Loss: 1.5764320655302568, Training Accuracy: 0.2727272727272727\n",
            "Epoch 1/5, Batch Loss: 1.5139614343643188, Average Training Loss: 1.575043829282125, Training Accuracy: 0.2763888888888889\n",
            "Epoch 1/5, Batch Loss: 1.4903539419174194, Average Training Loss: 1.5732027447741965, Training Accuracy: 0.27853260869565216\n",
            "Epoch 1/5, Batch Loss: 1.4561797380447388, Average Training Loss: 1.5707128935671868, Training Accuracy: 0.28058510638297873\n",
            "Epoch 1/5, Batch Loss: 1.531105637550354, Average Training Loss: 1.5698877424001694, Training Accuracy: 0.28125\n",
            "Epoch 1/5, Batch Loss: 1.443252682685852, Average Training Loss: 1.5673033534264078, Training Accuracy: 0.28316326530612246\n",
            "Epoch 1/5, Batch Loss: 1.4884002208709717, Average Training Loss: 1.565725290775299, Training Accuracy: 0.28375\n",
            "Epoch 1/5, Batch Loss: 1.4848604202270508, Average Training Loss: 1.5641397050782746, Training Accuracy: 0.28431372549019607\n",
            "Epoch 1/5, Batch Loss: 1.27646803855896, Average Training Loss: 1.5586075576452108, Training Accuracy: 0.28966346153846156\n",
            "Epoch 1/5, Batch Loss: 1.3777347803115845, Average Training Loss: 1.5551948637332556, Training Accuracy: 0.2971698113207547\n",
            "Epoch 1/5, Batch Loss: 1.5260485410690308, Average Training Loss: 1.5546551170172516, Training Accuracy: 0.2962962962962963\n",
            "Epoch 1/5, Batch Loss: 1.5040013790130615, Average Training Loss: 1.5537341399626299, Training Accuracy: 0.29545454545454547\n",
            "Epoch 1/5, Batch Loss: 1.5820552110671997, Average Training Loss: 1.5542398733752114, Training Accuracy: 0.29575892857142855\n",
            "Epoch 1/5, Batch Loss: 1.6184104681015015, Average Training Loss: 1.5553656732826902, Training Accuracy: 0.2949561403508772\n",
            "Epoch 1/5, Batch Loss: 1.4935070276260376, Average Training Loss: 1.5542991449092995, Training Accuracy: 0.2974137931034483\n",
            "Epoch 1/5, Batch Loss: 1.5404589176177979, Average Training Loss: 1.554064564785715, Training Accuracy: 0.2966101694915254\n",
            "Epoch 1/5, Batch Loss: 1.3492032289505005, Average Training Loss: 1.5506502091884613, Training Accuracy: 0.3\n",
            "Epoch 1/5, Batch Loss: 1.5047380924224854, Average Training Loss: 1.54989755153656, Training Accuracy: 0.29918032786885246\n",
            "Epoch 1/5, Batch Loss: 1.4733412265777588, Average Training Loss: 1.5486627721017407, Training Accuracy: 0.3024193548387097\n",
            "Epoch 1/5, Batch Loss: 1.4570097923278809, Average Training Loss: 1.547207962898981, Training Accuracy: 0.30158730158730157\n",
            "Epoch 1/5, Batch Loss: 1.3068140745162964, Average Training Loss: 1.5434518083930016, Training Accuracy: 0.3056640625\n",
            "Epoch 1/5, Batch Loss: 1.4794895648956299, Average Training Loss: 1.5424677738776573, Training Accuracy: 0.30480769230769234\n",
            "Epoch 1/5, Batch Loss: 1.376022219657898, Average Training Loss: 1.5399458715409944, Training Accuracy: 0.3087121212121212\n",
            "Epoch 1/5, Batch Loss: 1.637258529663086, Average Training Loss: 1.54139829927416, Training Accuracy: 0.30783582089552236\n",
            "Epoch 1/5, Batch Loss: 1.560957431793213, Average Training Loss: 1.5416859335759108, Training Accuracy: 0.3069852941176471\n",
            "Epoch 1/5, Batch Loss: 1.2459228038787842, Average Training Loss: 1.5373995114063872, Training Accuracy: 0.3125\n",
            "Epoch 1/5, Batch Loss: 1.4308481216430664, Average Training Loss: 1.5358773486954824, Training Accuracy: 0.3125\n",
            "Epoch 1/5, Batch Loss: 1.5105640888214111, Average Training Loss: 1.5355208239085238, Training Accuracy: 0.31338028169014087\n",
            "Epoch 1/5, Batch Loss: 1.4346585273742676, Average Training Loss: 1.5341199586788814, Training Accuracy: 0.3151041666666667\n",
            "Epoch 1/5, Batch Loss: 1.5331408977508545, Average Training Loss: 1.5341065468853468, Training Accuracy: 0.3167808219178082\n",
            "Epoch 1/5, Batch Loss: 1.338592529296875, Average Training Loss: 1.5314644655665837, Training Accuracy: 0.31925675675675674\n",
            "Epoch 1/5, Batch Loss: 1.3272995948791504, Average Training Loss: 1.5287422672907511, Training Accuracy: 0.32166666666666666\n",
            "Epoch 1/5, Batch Loss: 1.5015681982040405, Average Training Loss: 1.5283847137501365, Training Accuracy: 0.3223684210526316\n",
            "Epoch 1/5, Batch Loss: 1.4105087518692017, Average Training Loss: 1.5268538571023322, Training Accuracy: 0.3246753246753247\n",
            "Epoch 1/5, Batch Loss: 1.39145028591156, Average Training Loss: 1.5251179138819377, Training Accuracy: 0.32532051282051283\n",
            "Epoch 1/5, Batch Loss: 1.5406135320663452, Average Training Loss: 1.525314060947563, Training Accuracy: 0.3251582278481013\n",
            "Epoch 1/5, Batch Loss: 1.350749135017395, Average Training Loss: 1.523131999373436, Training Accuracy: 0.3265625\n",
            "Epoch 1/5, Batch Loss: 1.5630182027816772, Average Training Loss: 1.5236244216377353, Training Accuracy: 0.3279320987654321\n",
            "Epoch 1/5, Batch Loss: 1.406449794769287, Average Training Loss: 1.522195462773486, Training Accuracy: 0.32926829268292684\n",
            "Epoch 1/5, Batch Loss: 1.4167174100875854, Average Training Loss: 1.5209246428616077, Training Accuracy: 0.3313253012048193\n",
            "Epoch 1/5, Batch Loss: 1.3711562156677246, Average Training Loss: 1.5191416853950137, Training Accuracy: 0.3318452380952381\n",
            "Epoch 1/5, Batch Loss: 1.1521539688110352, Average Training Loss: 1.5148241828469668, Training Accuracy: 0.3352941176470588\n",
            "Epoch 1/5, Batch Loss: 1.5433316230773926, Average Training Loss: 1.5151556647101114, Training Accuracy: 0.33430232558139533\n",
            "Epoch 1/5, Batch Loss: 1.44130277633667, Average Training Loss: 1.514306780935704, Training Accuracy: 0.33477011494252873\n",
            "Epoch 1/5, Batch Loss: 1.3201448917388916, Average Training Loss: 1.5121003958311947, Training Accuracy: 0.3366477272727273\n",
            "Epoch 1/5, Batch Loss: 1.4272640943527222, Average Training Loss: 1.51114717896065, Training Accuracy: 0.33707865168539325\n",
            "Epoch 1/5, Batch Loss: 1.4298062324523926, Average Training Loss: 1.510243390666114, Training Accuracy: 0.33819444444444446\n",
            "Epoch 1/5, Batch Loss: 1.4035104513168335, Average Training Loss: 1.5090705012227152, Training Accuracy: 0.3392857142857143\n",
            "Epoch 1/5, Batch Loss: 1.3338816165924072, Average Training Loss: 1.507166274215864, Training Accuracy: 0.33967391304347827\n",
            "Epoch 1/5, Batch Loss: 1.4418139457702637, Average Training Loss: 1.5064635610067716, Training Accuracy: 0.3393817204301075\n",
            "Epoch 1/5, Batch Loss: 1.395755410194397, Average Training Loss: 1.5052858147215336, Training Accuracy: 0.3384308510638298\n",
            "Epoch 1/5, Batch Loss: 1.2419575452804565, Average Training Loss: 1.5025139382011012, Training Accuracy: 0.34342105263157896\n",
            "Epoch 1/5, Batch Loss: 1.159327745437622, Average Training Loss: 1.4989390820264816, Training Accuracy: 0.3463541666666667\n",
            "Epoch 1/5, Batch Loss: 1.4007641077041626, Average Training Loss: 1.4979269688891381, Training Accuracy: 0.3479381443298969\n",
            "Epoch 1/5, Batch Loss: 1.3037934303283691, Average Training Loss: 1.4959460144140282, Training Accuracy: 0.3494897959183674\n",
            "Epoch 1/5, Batch Loss: 1.245452880859375, Average Training Loss: 1.493415780741759, Training Accuracy: 0.3503787878787879\n",
            "Epoch 1/5, Batch Loss: 1.21177339553833, Average Training Loss: 1.4905993568897247, Training Accuracy: 0.3525\n",
            "Epoch 1/5, Batch Loss: 1.3231066465377808, Average Training Loss: 1.4889410132228738, Training Accuracy: 0.35457920792079206\n",
            "Epoch 1/5, Batch Loss: 1.418275237083435, Average Training Loss: 1.4882482114960165, Training Accuracy: 0.3553921568627451\n",
            "Epoch 1/5, Batch Loss: 1.518649697303772, Average Training Loss: 1.4885433715524026, Training Accuracy: 0.3549757281553398\n",
            "Epoch 1/5, Batch Loss: 1.4804542064666748, Average Training Loss: 1.488465591118886, Training Accuracy: 0.3551682692307692\n",
            "Epoch 1/5, Batch Loss: 1.3334940671920776, Average Training Loss: 1.4869896718433926, Training Accuracy: 0.35654761904761906\n",
            "Epoch 1/5, Batch Loss: 1.2872852087020874, Average Training Loss: 1.485105667474135, Training Accuracy: 0.3584905660377358\n",
            "Epoch 1/5, Batch Loss: 1.3159042596817017, Average Training Loss: 1.4835243459059813, Training Accuracy: 0.36039719626168226\n",
            "Epoch 1/5, Batch Loss: 1.1579673290252686, Average Training Loss: 1.4805099290830117, Training Accuracy: 0.36400462962962965\n",
            "Epoch 1/5, Batch Loss: 1.2699068784713745, Average Training Loss: 1.4785777910040059, Training Accuracy: 0.3658256880733945\n",
            "Epoch 1/5, Batch Loss: 1.391007661819458, Average Training Loss: 1.47778169892051, Training Accuracy: 0.36704545454545456\n",
            "Epoch 1/5, Batch Loss: 1.1704975366592407, Average Training Loss: 1.4750133731343724, Training Accuracy: 0.36936936936936937\n",
            "Epoch 1/5, Batch Loss: 1.2902154922485352, Average Training Loss: 1.4733633920550346, Training Accuracy: 0.3705357142857143\n",
            "Epoch 1/5, Batch Loss: 1.1714861392974854, Average Training Loss: 1.470691911942136, Training Accuracy: 0.37168141592920356\n",
            "Epoch 1/5, Batch Loss: 1.2993197441101074, Average Training Loss: 1.4691886473120304, Training Accuracy: 0.37335526315789475\n",
            "Epoch 1/5, Batch Loss: 1.187632441520691, Average Training Loss: 1.4667403324790622, Training Accuracy: 0.3755434782608696\n",
            "Epoch 1/5, Batch Loss: 1.1787358522415161, Average Training Loss: 1.464257535235635, Training Accuracy: 0.3766163793103448\n",
            "Epoch 1/5, Average Training Loss: 1.464257535235635, Training Accuracy: 0.3766163793103448\n",
            "Epoch 1/5, Validation Loss: 32.23532509803772, Validation Accuracy: 0.6336206896551724\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.58      0.63      0.60        99\n",
            "                Educational Opportunity       0.45      0.41      0.43        87\n",
            "                         Family Support       0.69      0.97      0.80        93\n",
            "                      Financial Support       0.79      0.60      0.68        89\n",
            "                 Program Implementation       0.66      0.55      0.60        96\n",
            "\n",
            "                               accuracy                           0.63       464\n",
            "                              macro avg       0.64      0.63      0.62       464\n",
            "                           weighted avg       0.64      0.63      0.63       464\n",
            "\n",
            "Epoch 2/5, Batch Loss: 1.0907083749771118, Average Training Loss: 1.0907083749771118, Training Accuracy: 0.5\n",
            "Epoch 2/5, Batch Loss: 1.221292495727539, Average Training Loss: 1.1560004353523254, Training Accuracy: 0.5\n",
            "Epoch 2/5, Batch Loss: 1.0426734685897827, Average Training Loss: 1.1182247797648113, Training Accuracy: 0.5208333333333334\n",
            "Epoch 2/5, Batch Loss: 1.1184718608856201, Average Training Loss: 1.1182865500450134, Training Accuracy: 0.578125\n",
            "Epoch 2/5, Batch Loss: 1.1518641710281372, Average Training Loss: 1.1250020742416382, Training Accuracy: 0.5875\n",
            "Epoch 2/5, Batch Loss: 1.0752410888671875, Average Training Loss: 1.1167085766792297, Training Accuracy: 0.6145833333333334\n",
            "Epoch 2/5, Batch Loss: 1.2710157632827759, Average Training Loss: 1.1387524604797363, Training Accuracy: 0.5982142857142857\n",
            "Epoch 2/5, Batch Loss: 1.1319072246551514, Average Training Loss: 1.1378968060016632, Training Accuracy: 0.6015625\n",
            "Epoch 2/5, Batch Loss: 1.141939401626587, Average Training Loss: 1.1383459832933214, Training Accuracy: 0.6111111111111112\n",
            "Epoch 2/5, Batch Loss: 1.2809089422225952, Average Training Loss: 1.1526022791862487, Training Accuracy: 0.59375\n",
            "Epoch 2/5, Batch Loss: 0.8966383337974548, Average Training Loss: 1.1293328296054492, Training Accuracy: 0.6136363636363636\n",
            "Epoch 2/5, Batch Loss: 1.1938199996948242, Average Training Loss: 1.1347067604462306, Training Accuracy: 0.6041666666666666\n",
            "Epoch 2/5, Batch Loss: 1.0403752326965332, Average Training Loss: 1.1274504890808692, Training Accuracy: 0.6057692307692307\n",
            "Epoch 2/5, Batch Loss: 0.9444520473480225, Average Training Loss: 1.1143791718142373, Training Accuracy: 0.6160714285714286\n",
            "Epoch 2/5, Batch Loss: 1.0101416110992432, Average Training Loss: 1.1074300010999043, Training Accuracy: 0.6166666666666667\n",
            "Epoch 2/5, Batch Loss: 0.802669882774353, Average Training Loss: 1.0883824937045574, Training Accuracy: 0.62890625\n",
            "Epoch 2/5, Batch Loss: 1.0161621570587158, Average Training Loss: 1.0841342386077433, Training Accuracy: 0.6286764705882353\n",
            "Epoch 2/5, Batch Loss: 0.8728721141815186, Average Training Loss: 1.0723974539173975, Training Accuracy: 0.6354166666666666\n",
            "Epoch 2/5, Batch Loss: 1.0543015003204346, Average Training Loss: 1.0714450353070308, Training Accuracy: 0.631578947368421\n",
            "Epoch 2/5, Batch Loss: 1.3066247701644897, Average Training Loss: 1.083204022049904, Training Accuracy: 0.625\n",
            "Epoch 2/5, Batch Loss: 1.0498079061508179, Average Training Loss: 1.081613730816614, Training Accuracy: 0.625\n",
            "Epoch 2/5, Batch Loss: 0.7875661849975586, Average Training Loss: 1.0682479332793842, Training Accuracy: 0.6278409090909091\n",
            "Epoch 2/5, Batch Loss: 1.206974744796753, Average Training Loss: 1.0742795337801394, Training Accuracy: 0.6277173913043478\n",
            "Epoch 2/5, Batch Loss: 0.957223653793335, Average Training Loss: 1.069402205447356, Training Accuracy: 0.6302083333333334\n",
            "Epoch 2/5, Batch Loss: 1.2853336334228516, Average Training Loss: 1.0780394625663758, Training Accuracy: 0.6225\n",
            "Epoch 2/5, Batch Loss: 0.7870804071426392, Average Training Loss: 1.0668487296654627, Training Accuracy: 0.6298076923076923\n",
            "Epoch 2/5, Batch Loss: 0.945304274559021, Average Training Loss: 1.062347083180039, Training Accuracy: 0.6319444444444444\n",
            "Epoch 2/5, Batch Loss: 1.1827168464660645, Average Training Loss: 1.066646003297397, Training Accuracy: 0.6272321428571429\n",
            "Epoch 2/5, Batch Loss: 0.8814072608947754, Average Training Loss: 1.0602584604559273, Training Accuracy: 0.6314655172413793\n",
            "Epoch 2/5, Batch Loss: 0.9863938689231873, Average Training Loss: 1.057796307404836, Training Accuracy: 0.6270833333333333\n",
            "Epoch 2/5, Batch Loss: 1.4061018228530884, Average Training Loss: 1.0690319691934893, Training Accuracy: 0.6169354838709677\n",
            "Epoch 2/5, Batch Loss: 0.699967086315155, Average Training Loss: 1.0574986916035414, Training Accuracy: 0.623046875\n",
            "Epoch 2/5, Batch Loss: 1.366074562072754, Average Training Loss: 1.0668494755571538, Training Accuracy: 0.615530303030303\n",
            "Epoch 2/5, Batch Loss: 1.334416389465332, Average Training Loss: 1.0747190906721003, Training Accuracy: 0.6084558823529411\n",
            "Epoch 2/5, Batch Loss: 0.8509515523910522, Average Training Loss: 1.0683257324354989, Training Accuracy: 0.6142857142857143\n",
            "Epoch 2/5, Batch Loss: 1.0590547323226929, Average Training Loss: 1.0680682046545877, Training Accuracy: 0.6128472222222222\n",
            "Epoch 2/5, Batch Loss: 1.0598111152648926, Average Training Loss: 1.0678450400764878, Training Accuracy: 0.6148648648648649\n",
            "Epoch 2/5, Batch Loss: 1.1554148197174072, Average Training Loss: 1.070149507961775, Training Accuracy: 0.6118421052631579\n",
            "Epoch 2/5, Batch Loss: 0.8785163164138794, Average Training Loss: 1.0652358363836238, Training Accuracy: 0.6137820512820513\n",
            "Epoch 2/5, Batch Loss: 0.8651602864265442, Average Training Loss: 1.060233947634697, Training Accuracy: 0.615625\n",
            "Epoch 2/5, Batch Loss: 0.9059355854988098, Average Training Loss: 1.0564705729484558, Training Accuracy: 0.6173780487804879\n",
            "Epoch 2/5, Batch Loss: 0.9046705365180969, Average Training Loss: 1.055404541104339, Training Accuracy: 0.6148255813953488\n",
            "Epoch 2/5, Batch Loss: 1.2196251153945923, Average Training Loss: 1.0591368268836627, Training Accuracy: 0.6107954545454546\n",
            "Epoch 2/5, Batch Loss: 1.0216814279556274, Average Training Loss: 1.058304484685262, Training Accuracy: 0.6138888888888889\n",
            "Epoch 2/5, Batch Loss: 0.9981561899185181, Average Training Loss: 1.056996913059898, Training Accuracy: 0.6141304347826086\n",
            "Epoch 2/5, Batch Loss: 1.0123380422592163, Average Training Loss: 1.056046724319458, Training Accuracy: 0.613031914893617\n",
            "Epoch 2/5, Batch Loss: 0.8304222822189331, Average Training Loss: 1.0513462151090305, Training Accuracy: 0.6145833333333334\n",
            "Epoch 2/5, Batch Loss: 1.129162073135376, Average Training Loss: 1.0529342938442618, Training Accuracy: 0.6160714285714286\n",
            "Epoch 2/5, Batch Loss: 0.7925031781196594, Average Training Loss: 1.0477256715297698, Training Accuracy: 0.62\n",
            "Epoch 2/5, Batch Loss: 1.1422039270401, Average Training Loss: 1.049578186343698, Training Accuracy: 0.6188725490196079\n",
            "Epoch 2/5, Batch Loss: 0.8611903786659241, Average Training Loss: 1.0459553438883562, Training Accuracy: 0.6201923076923077\n",
            "Epoch 2/5, Batch Loss: 0.6701201796531677, Average Training Loss: 1.0388641143744846, Training Accuracy: 0.6238207547169812\n",
            "Epoch 2/5, Batch Loss: 0.8738985061645508, Average Training Loss: 1.0358091957039304, Training Accuracy: 0.6238425925925926\n",
            "Epoch 2/5, Batch Loss: 0.8997448086738586, Average Training Loss: 1.033335297757929, Training Accuracy: 0.6272727272727273\n",
            "Epoch 2/5, Batch Loss: 0.7247315645217896, Average Training Loss: 1.0278245168072837, Training Accuracy: 0.6294642857142857\n",
            "Epoch 2/5, Batch Loss: 1.0140725374221802, Average Training Loss: 1.0275832540110539, Training Accuracy: 0.631578947368421\n",
            "Epoch 2/5, Batch Loss: 1.166182041168213, Average Training Loss: 1.0299728882723842, Training Accuracy: 0.6314655172413793\n",
            "Epoch 2/5, Batch Loss: 1.2041780948638916, Average Training Loss: 1.0329255188925792, Training Accuracy: 0.6271186440677966\n",
            "Epoch 2/5, Batch Loss: 0.8468661904335022, Average Training Loss: 1.0298245300849278, Training Accuracy: 0.6291666666666667\n",
            "Epoch 2/5, Batch Loss: 0.9246866703033447, Average Training Loss: 1.0281009586130987, Training Accuracy: 0.6301229508196722\n",
            "Epoch 2/5, Batch Loss: 0.8843930959701538, Average Training Loss: 1.0257830898607931, Training Accuracy: 0.6280241935483871\n",
            "Epoch 2/5, Batch Loss: 1.0246790647506714, Average Training Loss: 1.0257655656526958, Training Accuracy: 0.6279761904761905\n",
            "Epoch 2/5, Batch Loss: 0.9884443283081055, Average Training Loss: 1.0251824213191867, Training Accuracy: 0.62890625\n",
            "Epoch 2/5, Batch Loss: 0.8904040455818176, Average Training Loss: 1.023108907846304, Training Accuracy: 0.6288461538461538\n",
            "Epoch 2/5, Batch Loss: 0.8237020969390869, Average Training Loss: 1.020087592529528, Training Accuracy: 0.6287878787878788\n",
            "Epoch 2/5, Batch Loss: 1.5191009044647217, Average Training Loss: 1.0275355524091578, Training Accuracy: 0.6259328358208955\n",
            "Epoch 2/5, Batch Loss: 0.8572128415107727, Average Training Loss: 1.0250308066606522, Training Accuracy: 0.6268382352941176\n",
            "Epoch 2/5, Batch Loss: 0.9561048150062561, Average Training Loss: 1.024031879245371, Training Accuracy: 0.6277173913043478\n",
            "Epoch 2/5, Batch Loss: 0.8709338903427124, Average Training Loss: 1.0218447651181901, Training Accuracy: 0.6294642857142857\n",
            "Epoch 2/5, Batch Loss: 0.9059959053993225, Average Training Loss: 1.0202130910376428, Training Accuracy: 0.6294014084507042\n",
            "Epoch 2/5, Batch Loss: 0.9590110778808594, Average Training Loss: 1.019363063077132, Training Accuracy: 0.6284722222222222\n",
            "Epoch 2/5, Batch Loss: 1.293228268623352, Average Training Loss: 1.0231146412352994, Training Accuracy: 0.6267123287671232\n",
            "Epoch 2/5, Batch Loss: 1.1203055381774902, Average Training Loss: 1.024428031734518, Training Accuracy: 0.6275337837837838\n",
            "Epoch 2/5, Batch Loss: 0.9418786764144897, Average Training Loss: 1.0233273736635844, Training Accuracy: 0.6283333333333333\n",
            "Epoch 2/5, Batch Loss: 0.8733246326446533, Average Training Loss: 1.0213536533870196, Training Accuracy: 0.6291118421052632\n",
            "Epoch 2/5, Batch Loss: 0.8671537041664124, Average Training Loss: 1.0193510566438948, Training Accuracy: 0.6298701298701299\n",
            "Epoch 2/5, Batch Loss: 0.574496328830719, Average Training Loss: 1.0136477909027002, Training Accuracy: 0.6330128205128205\n",
            "Epoch 2/5, Batch Loss: 1.131401538848877, Average Training Loss: 1.0151383446741709, Training Accuracy: 0.632120253164557\n",
            "Epoch 2/5, Batch Loss: 0.9402713775634766, Average Training Loss: 1.0142025075852872, Training Accuracy: 0.6328125\n",
            "Epoch 2/5, Batch Loss: 0.4856506288051605, Average Training Loss: 1.0076771757484955, Training Accuracy: 0.6358024691358025\n",
            "Epoch 2/5, Batch Loss: 0.9795656204223633, Average Training Loss: 1.0073343519030549, Training Accuracy: 0.6364329268292683\n",
            "Epoch 2/5, Batch Loss: 1.3838766813278198, Average Training Loss: 1.0118710064744374, Training Accuracy: 0.6332831325301205\n",
            "Epoch 2/5, Batch Loss: 1.0431830883026123, Average Training Loss: 1.0122437693533444, Training Accuracy: 0.6331845238095238\n",
            "Epoch 2/5, Batch Loss: 0.8967879414558411, Average Training Loss: 1.0108854654957267, Training Accuracy: 0.6345588235294117\n",
            "Epoch 2/5, Batch Loss: 0.69169682264328, Average Training Loss: 1.007173969648605, Training Accuracy: 0.6366279069767442\n",
            "Epoch 2/5, Batch Loss: 1.1128990650177002, Average Training Loss: 1.0083892006298592, Training Accuracy: 0.6364942528735632\n",
            "Epoch 2/5, Batch Loss: 0.8549898862838745, Average Training Loss: 1.0066460266032002, Training Accuracy: 0.6349431818181818\n",
            "Epoch 2/5, Batch Loss: 0.9636543989181519, Average Training Loss: 1.006162974606739, Training Accuracy: 0.6355337078651685\n",
            "Epoch 2/5, Batch Loss: 0.9059167504310608, Average Training Loss: 1.0050491276714537, Training Accuracy: 0.6361111111111111\n",
            "Epoch 2/5, Batch Loss: 1.1233251094818115, Average Training Loss: 1.0063488637353037, Training Accuracy: 0.6353021978021978\n",
            "Epoch 2/5, Batch Loss: 0.687766969203949, Average Training Loss: 1.002886017055615, Training Accuracy: 0.6372282608695652\n",
            "Epoch 2/5, Batch Loss: 0.9106944799423218, Average Training Loss: 1.0018947102049345, Training Accuracy: 0.6377688172043011\n",
            "Epoch 2/5, Batch Loss: 0.8614919185638428, Average Training Loss: 1.0004010634853484, Training Accuracy: 0.6376329787234043\n",
            "Epoch 2/5, Batch Loss: 0.8528324961662292, Average Training Loss: 0.9988477101451472, Training Accuracy: 0.6388157894736842\n",
            "Epoch 2/5, Batch Loss: 1.0479086637496948, Average Training Loss: 0.9993587617451946, Training Accuracy: 0.6373697916666666\n",
            "Epoch 2/5, Batch Loss: 0.5057061314582825, Average Training Loss: 0.9942695593711027, Training Accuracy: 0.6398195876288659\n",
            "Epoch 2/5, Batch Loss: 0.9676568508148193, Average Training Loss: 0.9939980011205284, Training Accuracy: 0.639030612244898\n",
            "Epoch 2/5, Batch Loss: 0.7121667861938477, Average Training Loss: 0.991151221171774, Training Accuracy: 0.6407828282828283\n",
            "Epoch 2/5, Batch Loss: 1.1596132516860962, Average Training Loss: 0.9928358414769173, Training Accuracy: 0.63875\n",
            "Epoch 2/5, Batch Loss: 1.0897319316864014, Average Training Loss: 0.9937952087067141, Training Accuracy: 0.6373762376237624\n",
            "Epoch 2/5, Batch Loss: 0.7705911993980408, Average Training Loss: 0.9916069341056487, Training Accuracy: 0.6390931372549019\n",
            "Epoch 2/5, Batch Loss: 1.2649624347686768, Average Training Loss: 0.9942608710052898, Training Accuracy: 0.6377427184466019\n",
            "Epoch 2/5, Batch Loss: 0.9167640805244446, Average Training Loss: 0.9935157095583586, Training Accuracy: 0.6382211538461539\n",
            "Epoch 2/5, Batch Loss: 0.9507566094398499, Average Training Loss: 0.9931084800334203, Training Accuracy: 0.638095238095238\n",
            "Epoch 2/5, Batch Loss: 0.586201548576355, Average Training Loss: 0.989269735397033, Training Accuracy: 0.6397405660377359\n",
            "Epoch 2/5, Batch Loss: 1.1368424892425537, Average Training Loss: 0.9906489200124117, Training Accuracy: 0.639018691588785\n",
            "Epoch 2/5, Batch Loss: 0.7330182790756226, Average Training Loss: 0.9882634511148488, Training Accuracy: 0.6400462962962963\n",
            "Epoch 2/5, Batch Loss: 1.0542904138565063, Average Training Loss: 0.9888692030666071, Training Accuracy: 0.6404816513761468\n",
            "Epoch 2/5, Batch Loss: 1.1257983446121216, Average Training Loss: 0.9901140134442936, Training Accuracy: 0.6397727272727273\n",
            "Epoch 2/5, Batch Loss: 1.2561736106872559, Average Training Loss: 0.9925109467527888, Training Accuracy: 0.6396396396396397\n",
            "Epoch 2/5, Batch Loss: 0.967989444732666, Average Training Loss: 0.9922920047704663, Training Accuracy: 0.6400669642857143\n",
            "Epoch 2/5, Batch Loss: 1.0557576417922974, Average Training Loss: 0.9928536475759692, Training Accuracy: 0.6388274336283186\n",
            "Epoch 2/5, Batch Loss: 0.7635398507118225, Average Training Loss: 0.9908421230420732, Training Accuracy: 0.6398026315789473\n",
            "Epoch 2/5, Batch Loss: 1.185455322265625, Average Training Loss: 0.9925344117309736, Training Accuracy: 0.6391304347826087\n",
            "Epoch 2/5, Batch Loss: 0.8462854623794556, Average Training Loss: 0.9912736449262192, Training Accuracy: 0.6390086206896551\n",
            "Epoch 2/5, Average Training Loss: 0.9912736449262192, Training Accuracy: 0.6390086206896551\n",
            "Epoch 2/5, Validation Loss: 27.12255507707596, Validation Accuracy: 0.646551724137931\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.75      0.54      0.62        99\n",
            "                Educational Opportunity       0.43      0.52      0.47        87\n",
            "                         Family Support       0.79      0.87      0.83        93\n",
            "                      Financial Support       0.76      0.63      0.69        89\n",
            "                 Program Implementation       0.58      0.68      0.62        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.66      0.65      0.65       464\n",
            "                           weighted avg       0.66      0.65      0.65       464\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.7494237422943115, Average Training Loss: 0.7494237422943115, Training Accuracy: 0.8125\n",
            "Epoch 3/5, Batch Loss: 0.9113085865974426, Average Training Loss: 0.8303661644458771, Training Accuracy: 0.78125\n",
            "Epoch 3/5, Batch Loss: 0.9782170057296753, Average Training Loss: 0.8796497782071432, Training Accuracy: 0.75\n",
            "Epoch 3/5, Batch Loss: 0.7600271105766296, Average Training Loss: 0.8497441112995148, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.8498464226722717, Average Training Loss: 0.8497645735740662, Training Accuracy: 0.75\n",
            "Epoch 3/5, Batch Loss: 0.9057837724685669, Average Training Loss: 0.8591011067231497, Training Accuracy: 0.7395833333333334\n",
            "Epoch 3/5, Batch Loss: 0.7666997313499451, Average Training Loss: 0.8459009102412632, Training Accuracy: 0.7410714285714286\n",
            "Epoch 3/5, Batch Loss: 0.7464332580566406, Average Training Loss: 0.8334674537181854, Training Accuracy: 0.7421875\n",
            "Epoch 3/5, Batch Loss: 0.7268037796020508, Average Training Loss: 0.8216159343719482, Training Accuracy: 0.7430555555555556\n",
            "Epoch 3/5, Batch Loss: 0.5750963091850281, Average Training Loss: 0.7969639718532562, Training Accuracy: 0.75\n",
            "Epoch 3/5, Batch Loss: 1.117080807685852, Average Training Loss: 0.8260655023834922, Training Accuracy: 0.7386363636363636\n",
            "Epoch 3/5, Batch Loss: 0.8348227739334106, Average Training Loss: 0.826795275012652, Training Accuracy: 0.734375\n",
            "Epoch 3/5, Batch Loss: 0.7408004403114319, Average Training Loss: 0.8201802877279428, Training Accuracy: 0.7355769230769231\n",
            "Epoch 3/5, Batch Loss: 0.5812113881111145, Average Training Loss: 0.8031110806124551, Training Accuracy: 0.7410714285714286\n",
            "Epoch 3/5, Batch Loss: 1.0555126667022705, Average Training Loss: 0.8199378530184428, Training Accuracy: 0.7333333333333333\n",
            "Epoch 3/5, Batch Loss: 1.0499871969223022, Average Training Loss: 0.834315937012434, Training Accuracy: 0.7265625\n",
            "Epoch 3/5, Batch Loss: 0.598349928855896, Average Training Loss: 0.8204355835914612, Training Accuracy: 0.7316176470588235\n",
            "Epoch 3/5, Batch Loss: 0.914423406124115, Average Training Loss: 0.8256571292877197, Training Accuracy: 0.7326388888888888\n",
            "Epoch 3/5, Batch Loss: 1.0114326477050781, Average Training Loss: 0.8354347881517912, Training Accuracy: 0.7302631578947368\n",
            "Epoch 3/5, Batch Loss: 1.0183196067810059, Average Training Loss: 0.844579029083252, Training Accuracy: 0.725\n",
            "Epoch 3/5, Batch Loss: 1.0562589168548584, Average Training Loss: 0.8546590237390428, Training Accuracy: 0.7261904761904762\n",
            "Epoch 3/5, Batch Loss: 0.9571059346199036, Average Training Loss: 0.8593157015063546, Training Accuracy: 0.7244318181818182\n",
            "Epoch 3/5, Batch Loss: 0.5714317560195923, Average Training Loss: 0.8467990082243214, Training Accuracy: 0.7309782608695652\n",
            "Epoch 3/5, Batch Loss: 0.5260704159736633, Average Training Loss: 0.8334353168805441, Training Accuracy: 0.734375\n",
            "Epoch 3/5, Batch Loss: 0.5498833656311035, Average Training Loss: 0.8220932388305664, Training Accuracy: 0.745\n",
            "Epoch 3/5, Batch Loss: 0.8993486762046814, Average Training Loss: 0.8250646018064939, Training Accuracy: 0.7403846153846154\n",
            "Epoch 3/5, Batch Loss: 0.8480497598648071, Average Training Loss: 0.8259159039568018, Training Accuracy: 0.7407407407407407\n",
            "Epoch 3/5, Batch Loss: 0.9947317838668823, Average Training Loss: 0.831945042525019, Training Accuracy: 0.734375\n",
            "Epoch 3/5, Batch Loss: 0.702390730381012, Average Training Loss: 0.8274776524510877, Training Accuracy: 0.7370689655172413\n",
            "Epoch 3/5, Batch Loss: 0.6254690885543823, Average Training Loss: 0.8207440336545309, Training Accuracy: 0.7375\n",
            "Epoch 3/5, Batch Loss: 0.6097733378410339, Average Training Loss: 0.8139385273379665, Training Accuracy: 0.7419354838709677\n",
            "Epoch 3/5, Batch Loss: 0.626605749130249, Average Training Loss: 0.8080843780189753, Training Accuracy: 0.744140625\n",
            "Epoch 3/5, Batch Loss: 0.7947608232498169, Average Training Loss: 0.8076806339350614, Training Accuracy: 0.740530303030303\n",
            "Epoch 3/5, Batch Loss: 0.7184901237487793, Average Training Loss: 0.8050573836354649, Training Accuracy: 0.7389705882352942\n",
            "Epoch 3/5, Batch Loss: 0.5954543948173523, Average Training Loss: 0.7990687268120902, Training Accuracy: 0.7446428571428572\n",
            "Epoch 3/5, Batch Loss: 0.9722887277603149, Average Training Loss: 0.8038803935050964, Training Accuracy: 0.7430555555555556\n",
            "Epoch 3/5, Batch Loss: 1.1345652341842651, Average Training Loss: 0.8128178216315605, Training Accuracy: 0.7398648648648649\n",
            "Epoch 3/5, Batch Loss: 0.5856224298477173, Average Training Loss: 0.8068389955319857, Training Accuracy: 0.7401315789473685\n",
            "Epoch 3/5, Batch Loss: 0.5124282240867615, Average Training Loss: 0.7992900013923645, Training Accuracy: 0.7435897435897436\n",
            "Epoch 3/5, Batch Loss: 0.8026204705238342, Average Training Loss: 0.7993732631206513, Training Accuracy: 0.74375\n",
            "Epoch 3/5, Batch Loss: 1.0092264413833618, Average Training Loss: 0.8044916333221808, Training Accuracy: 0.7408536585365854\n",
            "Epoch 3/5, Batch Loss: 0.9541597366333008, Average Training Loss: 0.8080551595914931, Training Accuracy: 0.7395833333333334\n",
            "Epoch 3/5, Batch Loss: 0.8666494488716125, Average Training Loss: 0.8094178174817285, Training Accuracy: 0.7369186046511628\n",
            "Epoch 3/5, Batch Loss: 0.56381756067276, Average Training Loss: 0.8038359934633429, Training Accuracy: 0.7386363636363636\n",
            "Epoch 3/5, Batch Loss: 0.5647215843200684, Average Training Loss: 0.7985223399268256, Training Accuracy: 0.7402777777777778\n",
            "Epoch 3/5, Batch Loss: 1.0953377485275269, Average Training Loss: 0.8049748488094496, Training Accuracy: 0.7364130434782609\n",
            "Epoch 3/5, Batch Loss: 0.9828383922576904, Average Training Loss: 0.8087591795211143, Training Accuracy: 0.7353723404255319\n",
            "Epoch 3/5, Batch Loss: 0.47444626688957214, Average Training Loss: 0.8017943271746238, Training Accuracy: 0.73828125\n",
            "Epoch 3/5, Batch Loss: 0.7359734177589417, Average Training Loss: 0.8004510433089976, Training Accuracy: 0.7397959183673469\n",
            "Epoch 3/5, Batch Loss: 0.7658658623695374, Average Training Loss: 0.7997593396902084, Training Accuracy: 0.73875\n",
            "Epoch 3/5, Batch Loss: 0.9246340990066528, Average Training Loss: 0.8022078643826878, Training Accuracy: 0.7365196078431373\n",
            "Epoch 3/5, Batch Loss: 0.9616154432296753, Average Training Loss: 0.8052733947451298, Training Accuracy: 0.7331730769230769\n",
            "Epoch 3/5, Batch Loss: 0.764468252658844, Average Training Loss: 0.8045034864038791, Training Accuracy: 0.7334905660377359\n",
            "Epoch 3/5, Batch Loss: 0.7801156640052795, Average Training Loss: 0.8040518600631643, Training Accuracy: 0.7337962962962963\n",
            "Epoch 3/5, Batch Loss: 0.7715806365013123, Average Training Loss: 0.8034614741802215, Training Accuracy: 0.7352272727272727\n",
            "Epoch 3/5, Batch Loss: 0.7467105388641357, Average Training Loss: 0.8024480646210057, Training Accuracy: 0.7332589285714286\n",
            "Epoch 3/5, Batch Loss: 0.8751527070999146, Average Training Loss: 0.8037235846644953, Training Accuracy: 0.7335526315789473\n",
            "Epoch 3/5, Batch Loss: 1.1137301921844482, Average Training Loss: 0.80906852617346, Training Accuracy: 0.728448275862069\n",
            "Epoch 3/5, Batch Loss: 0.9332063794136047, Average Training Loss: 0.81117255758431, Training Accuracy: 0.725635593220339\n",
            "Epoch 3/5, Batch Loss: 0.5909475088119507, Average Training Loss: 0.8075021401047706, Training Accuracy: 0.728125\n",
            "Epoch 3/5, Batch Loss: 0.741386353969574, Average Training Loss: 0.806418274758292, Training Accuracy: 0.7274590163934426\n",
            "Epoch 3/5, Batch Loss: 0.9804492592811584, Average Training Loss: 0.8092252261215641, Training Accuracy: 0.7258064516129032\n",
            "Epoch 3/5, Batch Loss: 0.6589193344116211, Average Training Loss: 0.8068394183166443, Training Accuracy: 0.7261904761904762\n",
            "Epoch 3/5, Batch Loss: 1.020677089691162, Average Training Loss: 0.8101806319318712, Training Accuracy: 0.724609375\n",
            "Epoch 3/5, Batch Loss: 0.8850595355033875, Average Training Loss: 0.8113326150637407, Training Accuracy: 0.7240384615384615\n",
            "Epoch 3/5, Batch Loss: 0.9918103814125061, Average Training Loss: 0.8140671266750856, Training Accuracy: 0.7225378787878788\n",
            "Epoch 3/5, Batch Loss: 0.8296502232551575, Average Training Loss: 0.8142997102061315, Training Accuracy: 0.7229477611940298\n",
            "Epoch 3/5, Batch Loss: 0.4434375464916229, Average Training Loss: 0.8088458548573887, Training Accuracy: 0.7251838235294118\n",
            "Epoch 3/5, Batch Loss: 1.0455834865570068, Average Training Loss: 0.8122768350269484, Training Accuracy: 0.7228260869565217\n",
            "Epoch 3/5, Batch Loss: 0.5071397423744202, Average Training Loss: 0.8079177337033409, Training Accuracy: 0.7241071428571428\n",
            "Epoch 3/5, Batch Loss: 0.7544494867324829, Average Training Loss: 0.8071646598023428, Training Accuracy: 0.7235915492957746\n",
            "Epoch 3/5, Batch Loss: 0.6150349974632263, Average Training Loss: 0.804496192269855, Training Accuracy: 0.7239583333333334\n",
            "Epoch 3/5, Batch Loss: 0.7184010148048401, Average Training Loss: 0.8033168062771836, Training Accuracy: 0.723458904109589\n",
            "Epoch 3/5, Batch Loss: 0.7413671612739563, Average Training Loss: 0.8024796489122752, Training Accuracy: 0.7238175675675675\n",
            "Epoch 3/5, Batch Loss: 1.083859920501709, Average Training Loss: 0.806231385866801, Training Accuracy: 0.7225\n",
            "Epoch 3/5, Batch Loss: 0.5047304034233093, Average Training Loss: 0.802264267676755, Training Accuracy: 0.7245065789473685\n",
            "Epoch 3/5, Batch Loss: 0.8607516288757324, Average Training Loss: 0.8030238437962223, Training Accuracy: 0.724025974025974\n",
            "Epoch 3/5, Batch Loss: 0.6293767094612122, Average Training Loss: 0.8007975984842349, Training Accuracy: 0.7235576923076923\n",
            "Epoch 3/5, Batch Loss: 0.8392492532730103, Average Training Loss: 0.8012843282916878, Training Accuracy: 0.7231012658227848\n",
            "Epoch 3/5, Batch Loss: 0.7665022015571594, Average Training Loss: 0.8008495517075062, Training Accuracy: 0.72421875\n",
            "Epoch 3/5, Batch Loss: 0.8848063945770264, Average Training Loss: 0.8018860559404632, Training Accuracy: 0.7245370370370371\n",
            "Epoch 3/5, Batch Loss: 0.5064606666564941, Average Training Loss: 0.7982833072906588, Training Accuracy: 0.725609756097561\n",
            "Epoch 3/5, Batch Loss: 0.8920126557350159, Average Training Loss: 0.7994125765490244, Training Accuracy: 0.7243975903614458\n",
            "Epoch 3/5, Batch Loss: 1.1445058584213257, Average Training Loss: 0.8035208299046471, Training Accuracy: 0.7224702380952381\n",
            "Epoch 3/5, Batch Loss: 0.7133177518844604, Average Training Loss: 0.8024596172220567, Training Accuracy: 0.7235294117647059\n",
            "Epoch 3/5, Batch Loss: 0.5545069575309753, Average Training Loss: 0.7995764467605325, Training Accuracy: 0.7245639534883721\n",
            "Epoch 3/5, Batch Loss: 0.9372842311859131, Average Training Loss: 0.8011592948573759, Training Accuracy: 0.7241379310344828\n",
            "Epoch 3/5, Batch Loss: 0.4921700060367584, Average Training Loss: 0.7976480529389598, Training Accuracy: 0.7258522727272727\n",
            "Epoch 3/5, Batch Loss: 0.5965311527252197, Average Training Loss: 0.79538831248712, Training Accuracy: 0.7268258426966292\n",
            "Epoch 3/5, Batch Loss: 0.7179839611053467, Average Training Loss: 0.7945282641384337, Training Accuracy: 0.7270833333333333\n",
            "Epoch 3/5, Batch Loss: 0.9747713208198547, Average Training Loss: 0.7965089570689987, Training Accuracy: 0.7252747252747253\n",
            "Epoch 3/5, Batch Loss: 1.2971724271774292, Average Training Loss: 0.8019509513093077, Training Accuracy: 0.7241847826086957\n",
            "Epoch 3/5, Batch Loss: 0.6223622560501099, Average Training Loss: 0.8000198900699615, Training Accuracy: 0.7244623655913979\n",
            "Epoch 3/5, Batch Loss: 0.6261008381843567, Average Training Loss: 0.7981696873903275, Training Accuracy: 0.7247340425531915\n",
            "Epoch 3/5, Batch Loss: 0.7041043639183044, Average Training Loss: 0.7971795260906219, Training Accuracy: 0.7243421052631579\n",
            "Epoch 3/5, Batch Loss: 0.732914388179779, Average Training Loss: 0.7965100975707173, Training Accuracy: 0.7239583333333334\n",
            "Epoch 3/5, Batch Loss: 0.6861176490783691, Average Training Loss: 0.7953720310914147, Training Accuracy: 0.7235824742268041\n",
            "Epoch 3/5, Batch Loss: 0.6530176401138306, Average Training Loss: 0.7939194352651129, Training Accuracy: 0.7244897959183674\n",
            "Epoch 3/5, Batch Loss: 0.7825167775154114, Average Training Loss: 0.7938042569040048, Training Accuracy: 0.7247474747474747\n",
            "Epoch 3/5, Batch Loss: 0.6864588260650635, Average Training Loss: 0.7927308025956153, Training Accuracy: 0.725625\n",
            "Epoch 3/5, Batch Loss: 0.7863063216209412, Average Training Loss: 0.7926671938730938, Training Accuracy: 0.7246287128712872\n",
            "Epoch 3/5, Batch Loss: 0.96934574842453, Average Training Loss: 0.7943993365647746, Training Accuracy: 0.7230392156862745\n",
            "Epoch 3/5, Batch Loss: 0.7298270463943481, Average Training Loss: 0.7937724211262268, Training Accuracy: 0.7233009708737864\n",
            "Epoch 3/5, Batch Loss: 0.4030429720878601, Average Training Loss: 0.7900154071931655, Training Accuracy: 0.7247596153846154\n",
            "Epoch 3/5, Batch Loss: 0.4798170328140259, Average Training Loss: 0.7870611369609832, Training Accuracy: 0.7261904761904762\n",
            "Epoch 3/5, Batch Loss: 0.8554359674453735, Average Training Loss: 0.7877061825315907, Training Accuracy: 0.7252358490566038\n",
            "Epoch 3/5, Batch Loss: 0.5987889766693115, Average Training Loss: 0.7859406011683918, Training Accuracy: 0.7260514018691588\n",
            "Epoch 3/5, Batch Loss: 0.7191988229751587, Average Training Loss: 0.7853226217406767, Training Accuracy: 0.7268518518518519\n",
            "Epoch 3/5, Batch Loss: 0.9403509497642517, Average Training Loss: 0.7867448999794251, Training Accuracy: 0.7264908256880734\n",
            "Epoch 3/5, Batch Loss: 0.6547099947929382, Average Training Loss: 0.785544582659548, Training Accuracy: 0.7272727272727273\n",
            "Epoch 3/5, Batch Loss: 0.6566871404647827, Average Training Loss: 0.7843837048019375, Training Accuracy: 0.7280405405405406\n",
            "Epoch 3/5, Batch Loss: 0.7927607893943787, Average Training Loss: 0.7844585002000842, Training Accuracy: 0.7276785714285714\n",
            "Epoch 3/5, Batch Loss: 0.7610006332397461, Average Training Loss: 0.7842509084570725, Training Accuracy: 0.7273230088495575\n",
            "Epoch 3/5, Batch Loss: 0.4838341176509857, Average Training Loss: 0.7816156734500015, Training Accuracy: 0.7280701754385965\n",
            "Epoch 3/5, Batch Loss: 0.4719700813293457, Average Training Loss: 0.7789231030837349, Training Accuracy: 0.7293478260869565\n",
            "Epoch 3/5, Batch Loss: 1.096337080001831, Average Training Loss: 0.7816594304709599, Training Accuracy: 0.7279094827586207\n",
            "Epoch 3/5, Average Training Loss: 0.7816594304709599, Training Accuracy: 0.7279094827586207\n",
            "Epoch 3/5, Validation Loss: 24.948015064001083, Validation Accuracy: 0.6810344827586207\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.65      0.74      0.69        99\n",
            "                Educational Opportunity       0.49      0.45      0.47        87\n",
            "                         Family Support       0.81      0.91      0.86        93\n",
            "                      Financial Support       0.71      0.69      0.70        89\n",
            "                 Program Implementation       0.71      0.60      0.65        96\n",
            "\n",
            "                               accuracy                           0.68       464\n",
            "                              macro avg       0.67      0.68      0.67       464\n",
            "                           weighted avg       0.68      0.68      0.68       464\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.8913103938102722, Average Training Loss: 0.8913103938102722, Training Accuracy: 0.5\n",
            "Epoch 4/5, Batch Loss: 0.6305868029594421, Average Training Loss: 0.7609485983848572, Training Accuracy: 0.6875\n",
            "Epoch 4/5, Batch Loss: 0.5717093348503113, Average Training Loss: 0.6978688438733419, Training Accuracy: 0.75\n",
            "Epoch 4/5, Batch Loss: 0.40448814630508423, Average Training Loss: 0.6245236694812775, Training Accuracy: 0.796875\n",
            "Epoch 4/5, Batch Loss: 0.5606670379638672, Average Training Loss: 0.6117523431777954, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.4909536838531494, Average Training Loss: 0.5916192332903544, Training Accuracy: 0.8020833333333334\n",
            "Epoch 4/5, Batch Loss: 0.6076821684837341, Average Training Loss: 0.5939139383179801, Training Accuracy: 0.7946428571428571\n",
            "Epoch 4/5, Batch Loss: 0.5009932518005371, Average Training Loss: 0.5822988525032997, Training Accuracy: 0.8046875\n",
            "Epoch 4/5, Batch Loss: 0.47374260425567627, Average Training Loss: 0.5702370471424527, Training Accuracy: 0.8194444444444444\n",
            "Epoch 4/5, Batch Loss: 0.8401914834976196, Average Training Loss: 0.5972324907779694, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.7877200245857239, Average Training Loss: 0.614549539305947, Training Accuracy: 0.8068181818181818\n",
            "Epoch 4/5, Batch Loss: 0.7900738716125488, Average Training Loss: 0.6291765669981638, Training Accuracy: 0.8072916666666666\n",
            "Epoch 4/5, Batch Loss: 0.5646343231201172, Average Training Loss: 0.6242117790075449, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.5886024236679077, Average Training Loss: 0.6216682536261422, Training Accuracy: 0.8125\n",
            "Epoch 4/5, Batch Loss: 0.7615921497344971, Average Training Loss: 0.6309965133666993, Training Accuracy: 0.8041666666666667\n",
            "Epoch 4/5, Batch Loss: 0.657322347164154, Average Training Loss: 0.6326418779790401, Training Accuracy: 0.7890625\n",
            "Epoch 4/5, Batch Loss: 0.5654334425926208, Average Training Loss: 0.6286884406033684, Training Accuracy: 0.7941176470588235\n",
            "Epoch 4/5, Batch Loss: 0.6647686958312988, Average Training Loss: 0.6306928992271423, Training Accuracy: 0.7951388888888888\n",
            "Epoch 4/5, Batch Loss: 0.43551355600357056, Average Training Loss: 0.6204203022153754, Training Accuracy: 0.7993421052631579\n",
            "Epoch 4/5, Batch Loss: 0.436491996049881, Average Training Loss: 0.6112238869071007, Training Accuracy: 0.803125\n",
            "Epoch 4/5, Batch Loss: 0.8101802468299866, Average Training Loss: 0.620697999284381, Training Accuracy: 0.7946428571428571\n",
            "Epoch 4/5, Batch Loss: 0.39699259400367737, Average Training Loss: 0.6105295717716217, Training Accuracy: 0.7982954545454546\n",
            "Epoch 4/5, Batch Loss: 0.42644375562667847, Average Training Loss: 0.602525840634885, Training Accuracy: 0.8016304347826086\n",
            "Epoch 4/5, Batch Loss: 0.43638551235198975, Average Training Loss: 0.595603326956431, Training Accuracy: 0.8020833333333334\n",
            "Epoch 4/5, Batch Loss: 0.756060779094696, Average Training Loss: 0.6020216250419617, Training Accuracy: 0.8025\n",
            "Epoch 4/5, Batch Loss: 0.6857433915138245, Average Training Loss: 0.6052416929831872, Training Accuracy: 0.7956730769230769\n",
            "Epoch 4/5, Batch Loss: 0.7300232648849487, Average Training Loss: 0.6098632326832524, Training Accuracy: 0.7939814814814815\n",
            "Epoch 4/5, Batch Loss: 0.9293051958084106, Average Training Loss: 0.6212718742234367, Training Accuracy: 0.7879464285714286\n",
            "Epoch 4/5, Batch Loss: 0.37809813022613525, Average Training Loss: 0.6128865727062883, Training Accuracy: 0.7931034482758621\n",
            "Epoch 4/5, Batch Loss: 0.6061275005340576, Average Training Loss: 0.6126612703005473, Training Accuracy: 0.79375\n",
            "Epoch 4/5, Batch Loss: 0.5591830015182495, Average Training Loss: 0.610936164855957, Training Accuracy: 0.7963709677419355\n",
            "Epoch 4/5, Batch Loss: 0.9446488618850708, Average Training Loss: 0.6213646866381168, Training Accuracy: 0.791015625\n",
            "Epoch 4/5, Batch Loss: 0.5785257816314697, Average Training Loss: 0.6200665380015518, Training Accuracy: 0.7916666666666666\n",
            "Epoch 4/5, Batch Loss: 0.8608713150024414, Average Training Loss: 0.6271490314427544, Training Accuracy: 0.7904411764705882\n",
            "Epoch 4/5, Batch Loss: 0.5793959498405457, Average Training Loss: 0.6257846576826913, Training Accuracy: 0.7910714285714285\n",
            "Epoch 4/5, Batch Loss: 0.780322790145874, Average Training Loss: 0.6300773835844464, Training Accuracy: 0.7881944444444444\n",
            "Epoch 4/5, Batch Loss: 0.32388773560523987, Average Training Loss: 0.6218019876931165, Training Accuracy: 0.7922297297297297\n",
            "Epoch 4/5, Batch Loss: 0.6030662655830383, Average Training Loss: 0.6213089423744302, Training Accuracy: 0.7944078947368421\n",
            "Epoch 4/5, Batch Loss: 0.7531720399856567, Average Training Loss: 0.6246900474413847, Training Accuracy: 0.7948717948717948\n",
            "Epoch 4/5, Batch Loss: 0.28652095794677734, Average Training Loss: 0.6162358202040196, Training Accuracy: 0.8\n",
            "Epoch 4/5, Batch Loss: 0.5696676969528198, Average Training Loss: 0.6151000123198439, Training Accuracy: 0.7987804878048781\n",
            "Epoch 4/5, Batch Loss: 0.8124430179595947, Average Training Loss: 0.6197986553112665, Training Accuracy: 0.7961309523809523\n",
            "Epoch 4/5, Batch Loss: 0.4398305416107178, Average Training Loss: 0.6156133503414863, Training Accuracy: 0.7994186046511628\n",
            "Epoch 4/5, Batch Loss: 0.6420847177505493, Average Training Loss: 0.616214972328056, Training Accuracy: 0.7997159090909091\n",
            "Epoch 4/5, Batch Loss: 0.9682772755622864, Average Training Loss: 0.6240385790665944, Training Accuracy: 0.7958333333333333\n",
            "Epoch 4/5, Batch Loss: 0.808212161064148, Average Training Loss: 0.6280423525882803, Training Accuracy: 0.7948369565217391\n",
            "Epoch 4/5, Batch Loss: 0.35011008381843567, Average Training Loss: 0.6221289000612624, Training Accuracy: 0.7978723404255319\n",
            "Epoch 4/5, Batch Loss: 0.6264310479164124, Average Training Loss: 0.6222185281415781, Training Accuracy: 0.796875\n",
            "Epoch 4/5, Batch Loss: 0.7848214507102966, Average Training Loss: 0.6255369551327764, Training Accuracy: 0.7959183673469388\n",
            "Epoch 4/5, Batch Loss: 0.5700162053108215, Average Training Loss: 0.6244265401363372, Training Accuracy: 0.79625\n",
            "Epoch 4/5, Batch Loss: 0.5262516736984253, Average Training Loss: 0.6225015427552018, Training Accuracy: 0.7977941176470589\n",
            "Epoch 4/5, Batch Loss: 0.8400987386703491, Average Training Loss: 0.6266861042151084, Training Accuracy: 0.7944711538461539\n",
            "Epoch 4/5, Batch Loss: 0.9627392292022705, Average Training Loss: 0.6330267292148662, Training Accuracy: 0.7924528301886793\n",
            "Epoch 4/5, Batch Loss: 0.5120694041252136, Average Training Loss: 0.630786778750243, Training Accuracy: 0.7928240740740741\n",
            "Epoch 4/5, Batch Loss: 0.38536515831947327, Average Training Loss: 0.6263245674696836, Training Accuracy: 0.7954545454545454\n",
            "Epoch 4/5, Batch Loss: 0.4325666129589081, Average Training Loss: 0.6228646039962769, Training Accuracy: 0.7957589285714286\n",
            "Epoch 4/5, Batch Loss: 0.7079129815101624, Average Training Loss: 0.624356680794766, Training Accuracy: 0.7949561403508771\n",
            "Epoch 4/5, Batch Loss: 0.28646576404571533, Average Training Loss: 0.6185309753335756, Training Accuracy: 0.7974137931034483\n",
            "Epoch 4/5, Batch Loss: 0.8525598645210266, Average Training Loss: 0.6224975666757357, Training Accuracy: 0.7966101694915254\n",
            "Epoch 4/5, Batch Loss: 0.7837894558906555, Average Training Loss: 0.6251857648293178, Training Accuracy: 0.79375\n",
            "Epoch 4/5, Batch Loss: 0.8701263070106506, Average Training Loss: 0.6292011835536019, Training Accuracy: 0.7920081967213115\n",
            "Epoch 4/5, Batch Loss: 0.7790588736534119, Average Training Loss: 0.6316182430713407, Training Accuracy: 0.7903225806451613\n",
            "Epoch 4/5, Batch Loss: 0.7970389127731323, Average Training Loss: 0.6342439679872423, Training Accuracy: 0.7876984126984127\n",
            "Epoch 4/5, Batch Loss: 0.40000179409980774, Average Training Loss: 0.630583934020251, Training Accuracy: 0.7900390625\n",
            "Epoch 4/5, Batch Loss: 0.807675302028656, Average Training Loss: 0.6333084166049957, Training Accuracy: 0.7884615384615384\n",
            "Epoch 4/5, Batch Loss: 0.6290783882141113, Average Training Loss: 0.6332443252657399, Training Accuracy: 0.7869318181818182\n",
            "Epoch 4/5, Batch Loss: 0.5249365568161011, Average Training Loss: 0.6316277914082826, Training Accuracy: 0.7882462686567164\n",
            "Epoch 4/5, Batch Loss: 0.4750097393989563, Average Training Loss: 0.6293245847610867, Training Accuracy: 0.7886029411764706\n",
            "Epoch 4/5, Batch Loss: 0.7262888550758362, Average Training Loss: 0.6307298640410105, Training Accuracy: 0.7889492753623188\n",
            "Epoch 4/5, Batch Loss: 0.6586843729019165, Average Training Loss: 0.6311292141675949, Training Accuracy: 0.7883928571428571\n",
            "Epoch 4/5, Batch Loss: 1.1055139303207397, Average Training Loss: 0.6378106890429913, Training Accuracy: 0.784330985915493\n",
            "Epoch 4/5, Batch Loss: 0.6549454927444458, Average Training Loss: 0.6380486724277338, Training Accuracy: 0.7847222222222222\n",
            "Epoch 4/5, Batch Loss: 0.6278382539749146, Average Training Loss: 0.6379088036818047, Training Accuracy: 0.7842465753424658\n",
            "Epoch 4/5, Batch Loss: 0.2731434106826782, Average Training Loss: 0.632979541614249, Training Accuracy: 0.7863175675675675\n",
            "Epoch 4/5, Batch Loss: 0.6018204689025879, Average Training Loss: 0.6325640873114268, Training Accuracy: 0.7858333333333334\n",
            "Epoch 4/5, Batch Loss: 0.7310660481452942, Average Training Loss: 0.6338601657434514, Training Accuracy: 0.7853618421052632\n",
            "Epoch 4/5, Batch Loss: 0.23865610361099243, Average Training Loss: 0.6287276454560169, Training Accuracy: 0.7881493506493507\n",
            "Epoch 4/5, Batch Loss: 0.7661459445953369, Average Training Loss: 0.6304894185219055, Training Accuracy: 0.7868589743589743\n",
            "Epoch 4/5, Batch Loss: 0.7555342316627502, Average Training Loss: 0.6320722642578657, Training Accuracy: 0.7863924050632911\n",
            "Epoch 4/5, Batch Loss: 0.6555494070053101, Average Training Loss: 0.6323657285422086, Training Accuracy: 0.7859375\n",
            "Epoch 4/5, Batch Loss: 0.9917747974395752, Average Training Loss: 0.6368028775409416, Training Accuracy: 0.7839506172839507\n",
            "Epoch 4/5, Batch Loss: 0.3933086693286896, Average Training Loss: 0.6338334359773775, Training Accuracy: 0.7858231707317073\n",
            "Epoch 4/5, Batch Loss: 0.41300928592681885, Average Training Loss: 0.6311729040490576, Training Accuracy: 0.7868975903614458\n",
            "Epoch 4/5, Batch Loss: 0.7806355357170105, Average Training Loss: 0.6329522210927236, Training Accuracy: 0.7849702380952381\n",
            "Epoch 4/5, Batch Loss: 0.45586705207824707, Average Training Loss: 0.6308688661631416, Training Accuracy: 0.7860294117647059\n",
            "Epoch 4/5, Batch Loss: 0.39890071749687195, Average Training Loss: 0.6281715621088826, Training Accuracy: 0.7863372093023255\n",
            "Epoch 4/5, Batch Loss: 0.653416097164154, Average Training Loss: 0.6284617291784834, Training Accuracy: 0.7866379310344828\n",
            "Epoch 4/5, Batch Loss: 0.6355199217796326, Average Training Loss: 0.6285419359125874, Training Accuracy: 0.7862215909090909\n",
            "Epoch 4/5, Batch Loss: 0.8505310416221619, Average Training Loss: 0.6310361955273017, Training Accuracy: 0.785814606741573\n",
            "Epoch 4/5, Batch Loss: 0.4201878309249878, Average Training Loss: 0.6286934359206093, Training Accuracy: 0.7868055555555555\n",
            "Epoch 4/5, Batch Loss: 0.5622600317001343, Average Training Loss: 0.6279633985115931, Training Accuracy: 0.7864010989010989\n",
            "Epoch 4/5, Batch Loss: 1.0950616598129272, Average Training Loss: 0.6330405535257381, Training Accuracy: 0.7839673913043478\n",
            "Epoch 4/5, Batch Loss: 0.6250143647193909, Average Training Loss: 0.6329542504202935, Training Accuracy: 0.7842741935483871\n",
            "Epoch 4/5, Batch Loss: 0.25614994764328003, Average Training Loss: 0.6289456940077721, Training Accuracy: 0.7865691489361702\n",
            "Epoch 4/5, Batch Loss: 0.5316505432128906, Average Training Loss: 0.6279215345257207, Training Accuracy: 0.7868421052631579\n",
            "Epoch 4/5, Batch Loss: 0.3065076172351837, Average Training Loss: 0.6245734728872776, Training Accuracy: 0.7884114583333334\n",
            "Epoch 4/5, Batch Loss: 0.5145196318626404, Average Training Loss: 0.6234388972066113, Training Accuracy: 0.788659793814433\n",
            "Epoch 4/5, Batch Loss: 0.5119224786758423, Average Training Loss: 0.6223009745685422, Training Accuracy: 0.7889030612244898\n",
            "Epoch 4/5, Batch Loss: 0.420816034078598, Average Training Loss: 0.6202657731494519, Training Accuracy: 0.7897727272727273\n",
            "Epoch 4/5, Batch Loss: 0.5431225895881653, Average Training Loss: 0.619494341313839, Training Accuracy: 0.790625\n",
            "Epoch 4/5, Batch Loss: 0.5419023633003235, Average Training Loss: 0.6187261039077645, Training Accuracy: 0.7914603960396039\n",
            "Epoch 4/5, Batch Loss: 0.693653404712677, Average Training Loss: 0.6194606852882049, Training Accuracy: 0.7916666666666666\n",
            "Epoch 4/5, Batch Loss: 0.3068211078643799, Average Training Loss: 0.6164253495850609, Training Accuracy: 0.7930825242718447\n",
            "Epoch 4/5, Batch Loss: 0.6902025938034058, Average Training Loss: 0.6171347461640835, Training Accuracy: 0.7926682692307693\n",
            "Epoch 4/5, Batch Loss: 0.7455053925514221, Average Training Loss: 0.6183573237487248, Training Accuracy: 0.7922619047619047\n",
            "Epoch 4/5, Batch Loss: 1.0317742824554443, Average Training Loss: 0.622257483736524, Training Accuracy: 0.7906839622641509\n",
            "Epoch 4/5, Batch Loss: 0.3460123836994171, Average Training Loss: 0.6196757538296352, Training Accuracy: 0.7920560747663551\n",
            "Epoch 4/5, Batch Loss: 0.5320212244987488, Average Training Loss: 0.6188641378173122, Training Accuracy: 0.7922453703703703\n",
            "Epoch 4/5, Batch Loss: 0.6287650465965271, Average Training Loss: 0.6189549718428096, Training Accuracy: 0.7912844036697247\n",
            "Epoch 4/5, Batch Loss: 0.45315831899642944, Average Training Loss: 0.6174477295442061, Training Accuracy: 0.7914772727272728\n",
            "Epoch 4/5, Batch Loss: 0.34398552775382996, Average Training Loss: 0.6149841061046531, Training Accuracy: 0.7922297297297297\n",
            "Epoch 4/5, Batch Loss: 0.7007830739021301, Average Training Loss: 0.6157501683171306, Training Accuracy: 0.79296875\n",
            "Epoch 4/5, Batch Loss: 0.8410624265670776, Average Training Loss: 0.6177440821069532, Training Accuracy: 0.7914823008849557\n",
            "Epoch 4/5, Batch Loss: 0.965484082698822, Average Training Loss: 0.620794432989338, Training Accuracy: 0.7911184210526315\n",
            "Epoch 4/5, Batch Loss: 0.5402260422706604, Average Training Loss: 0.6200938382874365, Training Accuracy: 0.7913043478260869\n",
            "Epoch 4/5, Batch Loss: 0.4670442044734955, Average Training Loss: 0.6187744448924887, Training Accuracy: 0.7925646551724138\n",
            "Epoch 4/5, Average Training Loss: 0.6187744448924887, Training Accuracy: 0.7925646551724138\n",
            "Epoch 4/5, Validation Loss: 25.56556659936905, Validation Accuracy: 0.6767241379310345\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.71      0.62      0.66        99\n",
            "                Educational Opportunity       0.46      0.52      0.49        87\n",
            "                         Family Support       0.78      0.92      0.85        93\n",
            "                      Financial Support       0.71      0.73      0.72        89\n",
            "                 Program Implementation       0.71      0.59      0.65        96\n",
            "\n",
            "                               accuracy                           0.68       464\n",
            "                              macro avg       0.68      0.68      0.67       464\n",
            "                           weighted avg       0.68      0.68      0.67       464\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.32945653796195984, Average Training Loss: 0.32945653796195984, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.5955361723899841, Average Training Loss: 0.462496355175972, Training Accuracy: 0.875\n",
            "Epoch 5/5, Batch Loss: 0.5010703206062317, Average Training Loss: 0.4753543436527252, Training Accuracy: 0.8541666666666666\n",
            "Epoch 5/5, Batch Loss: 0.2914079427719116, Average Training Loss: 0.4293677434325218, Training Accuracy: 0.875\n",
            "Epoch 5/5, Batch Loss: 0.9228649735450745, Average Training Loss: 0.5280671894550324, Training Accuracy: 0.825\n",
            "Epoch 5/5, Batch Loss: 0.2765123248100281, Average Training Loss: 0.486141378680865, Training Accuracy: 0.84375\n",
            "Epoch 5/5, Batch Loss: 0.5934997797012329, Average Training Loss: 0.5014782931123462, Training Accuracy: 0.8392857142857143\n",
            "Epoch 5/5, Batch Loss: 0.36928191781044006, Average Training Loss: 0.48495374619960785, Training Accuracy: 0.84375\n",
            "Epoch 5/5, Batch Loss: 0.6648794412612915, Average Training Loss: 0.5049454900953505, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/5, Batch Loss: 0.4476216733455658, Average Training Loss: 0.49921310842037203, Training Accuracy: 0.84375\n",
            "Epoch 5/5, Batch Loss: 0.3439459204673767, Average Training Loss: 0.48509790951555426, Training Accuracy: 0.8579545454545454\n",
            "Epoch 5/5, Batch Loss: 0.23861606419086456, Average Training Loss: 0.4645577557384968, Training Accuracy: 0.8697916666666666\n",
            "Epoch 5/5, Batch Loss: 0.21446943283081055, Average Training Loss: 0.44532019243790555, Training Accuracy: 0.8798076923076923\n",
            "Epoch 5/5, Batch Loss: 0.5660951137542725, Average Training Loss: 0.4539469725319317, Training Accuracy: 0.8794642857142857\n",
            "Epoch 5/5, Batch Loss: 0.625389575958252, Average Training Loss: 0.46537647942701976, Training Accuracy: 0.8708333333333333\n",
            "Epoch 5/5, Batch Loss: 0.42358651757240295, Average Training Loss: 0.4627646068111062, Training Accuracy: 0.875\n",
            "Epoch 5/5, Batch Loss: 0.7560243010520935, Average Training Loss: 0.48001517706057606, Training Accuracy: 0.8713235294117647\n",
            "Epoch 5/5, Batch Loss: 0.3328604996204376, Average Training Loss: 0.47183991720279056, Training Accuracy: 0.875\n",
            "Epoch 5/5, Batch Loss: 0.5621825456619263, Average Training Loss: 0.47659479238485036, Training Accuracy: 0.8717105263157895\n",
            "Epoch 5/5, Batch Loss: 0.4587380886077881, Average Training Loss: 0.4757019571959972, Training Accuracy: 0.86875\n",
            "Epoch 5/5, Batch Loss: 0.7650646567344666, Average Training Loss: 0.4894811333644958, Training Accuracy: 0.8660714285714286\n",
            "Epoch 5/5, Batch Loss: 0.4710538387298584, Average Training Loss: 0.48864352906292136, Training Accuracy: 0.8664772727272727\n",
            "Epoch 5/5, Batch Loss: 0.6780826449394226, Average Training Loss: 0.49688001236189966, Training Accuracy: 0.8614130434782609\n",
            "Epoch 5/5, Batch Loss: 0.8028978705406189, Average Training Loss: 0.5096307564526796, Training Accuracy: 0.8541666666666666\n",
            "Epoch 5/5, Batch Loss: 0.4775744080543518, Average Training Loss: 0.5083485025167466, Training Accuracy: 0.8525\n",
            "Epoch 5/5, Batch Loss: 0.5005276203155518, Average Training Loss: 0.5080476993551621, Training Accuracy: 0.8485576923076923\n",
            "Epoch 5/5, Batch Loss: 0.5093350410461426, Average Training Loss: 0.5080953786770502, Training Accuracy: 0.8495370370370371\n",
            "Epoch 5/5, Batch Loss: 0.28485438227653503, Average Training Loss: 0.5001224859484604, Training Accuracy: 0.8549107142857143\n",
            "Epoch 5/5, Batch Loss: 0.49163585901260376, Average Training Loss: 0.49982984364032745, Training Accuracy: 0.8556034482758621\n",
            "Epoch 5/5, Batch Loss: 0.3301982283592224, Average Training Loss: 0.4941754564642906, Training Accuracy: 0.8583333333333333\n",
            "Epoch 5/5, Batch Loss: 0.5864198207855225, Average Training Loss: 0.4971510811198142, Training Accuracy: 0.8568548387096774\n",
            "Epoch 5/5, Batch Loss: 0.8477280139923096, Average Training Loss: 0.5081066102720797, Training Accuracy: 0.8515625\n",
            "Epoch 5/5, Batch Loss: 0.4258299767971039, Average Training Loss: 0.5056133789546562, Training Accuracy: 0.8522727272727273\n",
            "Epoch 5/5, Batch Loss: 0.3412840962409973, Average Training Loss: 0.5007801647571957, Training Accuracy: 0.8566176470588235\n",
            "Epoch 5/5, Batch Loss: 0.47488224506378174, Average Training Loss: 0.5000402241945267, Training Accuracy: 0.8571428571428571\n",
            "Epoch 5/5, Batch Loss: 0.5448733568191528, Average Training Loss: 0.5012855889896551, Training Accuracy: 0.8559027777777778\n",
            "Epoch 5/5, Batch Loss: 0.5391119122505188, Average Training Loss: 0.5023079220507596, Training Accuracy: 0.856418918918919\n",
            "Epoch 5/5, Batch Loss: 0.47119057178497314, Average Training Loss: 0.5014890444121862, Training Accuracy: 0.8552631578947368\n",
            "Epoch 5/5, Batch Loss: 0.3809319734573364, Average Training Loss: 0.498397837464626, Training Accuracy: 0.8557692307692307\n",
            "Epoch 5/5, Batch Loss: 0.3579702377319336, Average Training Loss: 0.4948871474713087, Training Accuracy: 0.8578125\n",
            "Epoch 5/5, Batch Loss: 0.9860366582870483, Average Training Loss: 0.5068664038326682, Training Accuracy: 0.8536585365853658\n",
            "Epoch 5/5, Batch Loss: 0.5361272692680359, Average Training Loss: 0.5075630911049389, Training Accuracy: 0.8556547619047619\n",
            "Epoch 5/5, Batch Loss: 0.5461254119873047, Average Training Loss: 0.5084598892649939, Training Accuracy: 0.8531976744186046\n",
            "Epoch 5/5, Batch Loss: 0.31814807653427124, Average Training Loss: 0.5041346207938411, Training Accuracy: 0.8551136363636364\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-37758020bac2>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mtotal_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Handle NaN values in the 'Label' column\n",
        "df['Label'].fillna('default_label', inplace=True)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and validation data\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRHwIJAyJfDv",
        "outputId": "ffd056b7-eb69-4b53-e26c-3b6b912fe24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-40-9aec1aab4fe3>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch Loss: 1.6330713033676147, Average Training Loss: 1.6330713033676147, Training Accuracy: 0.25\n",
            "Epoch 1/10, Batch Loss: 1.6665178537368774, Average Training Loss: 1.649794578552246, Training Accuracy: 0.1875\n",
            "Epoch 1/10, Batch Loss: 1.6421445608139038, Average Training Loss: 1.6472445726394653, Training Accuracy: 0.17708333333333334\n",
            "Epoch 1/10, Batch Loss: 1.6814308166503906, Average Training Loss: 1.6557911336421967, Training Accuracy: 0.171875\n",
            "Epoch 1/10, Batch Loss: 1.668810486793518, Average Training Loss: 1.658395004272461, Training Accuracy: 0.16875\n",
            "Epoch 1/10, Batch Loss: 1.6404330730438232, Average Training Loss: 1.655401349067688, Training Accuracy: 0.16666666666666666\n",
            "Epoch 1/10, Batch Loss: 1.6395388841629028, Average Training Loss: 1.6531352826527186, Training Accuracy: 0.17857142857142858\n",
            "Epoch 1/10, Batch Loss: 1.6691361665725708, Average Training Loss: 1.6551353931427002, Training Accuracy: 0.171875\n",
            "Epoch 1/10, Batch Loss: 1.5530335903167725, Average Training Loss: 1.6437907483842638, Training Accuracy: 0.1840277777777778\n",
            "Epoch 1/10, Batch Loss: 1.5484036207199097, Average Training Loss: 1.6342520356178283, Training Accuracy: 0.20625\n",
            "Epoch 1/10, Batch Loss: 1.5835397243499756, Average Training Loss: 1.629641825502569, Training Accuracy: 0.21306818181818182\n",
            "Epoch 1/10, Batch Loss: 1.562710165977478, Average Training Loss: 1.6240641872088115, Training Accuracy: 0.22395833333333334\n",
            "Epoch 1/10, Batch Loss: 1.5890636444091797, Average Training Loss: 1.621371837762686, Training Accuracy: 0.22596153846153846\n",
            "Epoch 1/10, Batch Loss: 1.629307746887207, Average Training Loss: 1.6219386884144373, Training Accuracy: 0.22321428571428573\n",
            "Epoch 1/10, Batch Loss: 1.559839129447937, Average Training Loss: 1.6177987178166708, Training Accuracy: 0.23125\n",
            "Epoch 1/10, Batch Loss: 1.5799407958984375, Average Training Loss: 1.6154325976967812, Training Accuracy: 0.232421875\n",
            "Epoch 1/10, Batch Loss: 1.5889670848846436, Average Training Loss: 1.613875802825479, Training Accuracy: 0.23713235294117646\n",
            "Epoch 1/10, Batch Loss: 1.595543622970581, Average Training Loss: 1.6128573483890958, Training Accuracy: 0.2378472222222222\n",
            "Epoch 1/10, Batch Loss: 1.514757513999939, Average Training Loss: 1.607694199210719, Training Accuracy: 0.2450657894736842\n",
            "Epoch 1/10, Batch Loss: 1.5916575193405151, Average Training Loss: 1.606892365217209, Training Accuracy: 0.2453125\n",
            "Epoch 1/10, Batch Loss: 1.499893307685852, Average Training Loss: 1.60179717200143, Training Accuracy: 0.24851190476190477\n",
            "Epoch 1/10, Batch Loss: 1.5112214088439941, Average Training Loss: 1.5976800918579102, Training Accuracy: 0.2528409090909091\n",
            "Epoch 1/10, Batch Loss: 1.5310885906219482, Average Training Loss: 1.594784809195477, Training Accuracy: 0.25407608695652173\n",
            "Epoch 1/10, Batch Loss: 1.611956238746643, Average Training Loss: 1.5955002854267757, Training Accuracy: 0.2526041666666667\n",
            "Epoch 1/10, Batch Loss: 1.4711976051330566, Average Training Loss: 1.590528178215027, Training Accuracy: 0.26125\n",
            "Epoch 1/10, Batch Loss: 1.4547843933105469, Average Training Loss: 1.5853072634110084, Training Accuracy: 0.2692307692307692\n",
            "Epoch 1/10, Batch Loss: 1.5993807315826416, Average Training Loss: 1.5858285029729207, Training Accuracy: 0.2708333333333333\n",
            "Epoch 1/10, Batch Loss: 1.4487872123718262, Average Training Loss: 1.5809341711657388, Training Accuracy: 0.2779017857142857\n",
            "Epoch 1/10, Batch Loss: 1.4936227798461914, Average Training Loss: 1.5779234335340302, Training Accuracy: 0.28125\n",
            "Epoch 1/10, Batch Loss: 1.538438320159912, Average Training Loss: 1.5766072630882264, Training Accuracy: 0.2864583333333333\n",
            "Epoch 1/10, Batch Loss: 1.4023046493530273, Average Training Loss: 1.5709845981290262, Training Accuracy: 0.2933467741935484\n",
            "Epoch 1/10, Batch Loss: 1.4152226448059082, Average Training Loss: 1.566117037087679, Training Accuracy: 0.298828125\n",
            "Epoch 1/10, Batch Loss: 1.488191843032837, Average Training Loss: 1.5637556675708655, Training Accuracy: 0.30492424242424243\n",
            "Epoch 1/10, Batch Loss: 1.4602738618850708, Average Training Loss: 1.560712085050695, Training Accuracy: 0.31066176470588236\n",
            "Epoch 1/10, Batch Loss: 1.4712644815444946, Average Training Loss: 1.5581564392362321, Training Accuracy: 0.31339285714285714\n",
            "Epoch 1/10, Batch Loss: 1.3905794620513916, Average Training Loss: 1.55350152320332, Training Accuracy: 0.3177083333333333\n",
            "Epoch 1/10, Batch Loss: 1.4853508472442627, Average Training Loss: 1.5516596130422644, Training Accuracy: 0.32010135135135137\n",
            "Epoch 1/10, Batch Loss: 1.4662833213806152, Average Training Loss: 1.5494128685248525, Training Accuracy: 0.3190789473684211\n",
            "Epoch 1/10, Batch Loss: 1.3798604011535645, Average Training Loss: 1.5450653693614862, Training Accuracy: 0.32371794871794873\n",
            "Epoch 1/10, Batch Loss: 1.2315394878387451, Average Training Loss: 1.5372272223234176, Training Accuracy: 0.33125\n",
            "Epoch 1/10, Batch Loss: 1.328856110572815, Average Training Loss: 1.532145000085598, Training Accuracy: 0.33384146341463417\n",
            "Epoch 1/10, Batch Loss: 1.39207124710083, Average Training Loss: 1.528809910728818, Training Accuracy: 0.33630952380952384\n",
            "Epoch 1/10, Batch Loss: 1.3726766109466553, Average Training Loss: 1.5251789037571397, Training Accuracy: 0.3386627906976744\n",
            "Epoch 1/10, Batch Loss: 1.3772534132003784, Average Training Loss: 1.5218169607899406, Training Accuracy: 0.3387784090909091\n",
            "Epoch 1/10, Batch Loss: 1.5089231729507446, Average Training Loss: 1.5215304321712917, Training Accuracy: 0.3368055555555556\n",
            "Epoch 1/10, Batch Loss: 1.4044493436813354, Average Training Loss: 1.5189851911171623, Training Accuracy: 0.33695652173913043\n",
            "Epoch 1/10, Batch Loss: 1.4308489561080933, Average Training Loss: 1.5171099520744162, Training Accuracy: 0.3384308510638298\n",
            "Epoch 1/10, Batch Loss: 1.2701963186264038, Average Training Loss: 1.5119659180442493, Training Accuracy: 0.3430989583333333\n",
            "Epoch 1/10, Batch Loss: 1.2434136867523193, Average Training Loss: 1.5064852602627812, Training Accuracy: 0.3475765306122449\n",
            "Epoch 1/10, Batch Loss: 1.399773359298706, Average Training Loss: 1.5043510222434997, Training Accuracy: 0.349375\n",
            "Epoch 1/10, Batch Loss: 1.3064907789230347, Average Training Loss: 1.500471409629373, Training Accuracy: 0.35171568627450983\n",
            "Epoch 1/10, Batch Loss: 1.3218897581100464, Average Training Loss: 1.4970371471001551, Training Accuracy: 0.35396634615384615\n",
            "Epoch 1/10, Batch Loss: 1.2684123516082764, Average Training Loss: 1.492723471713516, Training Accuracy: 0.357311320754717\n",
            "Epoch 1/10, Batch Loss: 1.2384841442108154, Average Training Loss: 1.4880153360190216, Training Accuracy: 0.3599537037037037\n",
            "Epoch 1/10, Batch Loss: 1.3220936059951782, Average Training Loss: 1.4849985772913152, Training Accuracy: 0.36363636363636365\n",
            "Epoch 1/10, Batch Loss: 1.4237315654754639, Average Training Loss: 1.4839045235088892, Training Accuracy: 0.36495535714285715\n",
            "Epoch 1/10, Batch Loss: 1.424046516418457, Average Training Loss: 1.4828543830336185, Training Accuracy: 0.3651315789473684\n",
            "Epoch 1/10, Batch Loss: 1.2063268423080444, Average Training Loss: 1.478086666814212, Training Accuracy: 0.36907327586206895\n",
            "Epoch 1/10, Average Training Loss: 1.478086666814212, Training Accuracy: 0.36907327586206895\n",
            "Epoch 1/10, Validation Loss: 17.661293625831604, Validation Accuracy: 0.5797413793103449\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.53      0.61      0.57        99\n",
            "                Educational Opportunity       0.22      0.06      0.09        87\n",
            "                         Family Support       0.65      0.85      0.74        93\n",
            "                      Financial Support       0.61      0.74      0.67        89\n",
            "                 Program Implementation       0.60      0.61      0.61        96\n",
            "\n",
            "                               accuracy                           0.58       464\n",
            "                              macro avg       0.52      0.57      0.53       464\n",
            "                           weighted avg       0.53      0.58      0.54       464\n",
            "\n",
            "Epoch 2/10, Batch Loss: 1.1609612703323364, Average Training Loss: 1.1609612703323364, Training Accuracy: 0.65625\n",
            "Epoch 2/10, Batch Loss: 1.190454125404358, Average Training Loss: 1.1757076978683472, Training Accuracy: 0.625\n",
            "Epoch 2/10, Batch Loss: 1.0400303602218628, Average Training Loss: 1.1304819186528523, Training Accuracy: 0.65625\n",
            "Epoch 2/10, Batch Loss: 1.0318098068237305, Average Training Loss: 1.105813890695572, Training Accuracy: 0.65625\n",
            "Epoch 2/10, Batch Loss: 1.2596476078033447, Average Training Loss: 1.1365806341171265, Training Accuracy: 0.6125\n",
            "Epoch 2/10, Batch Loss: 1.0909268856048584, Average Training Loss: 1.1289716760317485, Training Accuracy: 0.609375\n",
            "Epoch 2/10, Batch Loss: 1.1426970958709717, Average Training Loss: 1.1309324502944946, Training Accuracy: 0.5982142857142857\n",
            "Epoch 2/10, Batch Loss: 1.2007631063461304, Average Training Loss: 1.139661282300949, Training Accuracy: 0.59375\n",
            "Epoch 2/10, Batch Loss: 1.1507800817489624, Average Training Loss: 1.1408967044618394, Training Accuracy: 0.5972222222222222\n",
            "Epoch 2/10, Batch Loss: 1.08760404586792, Average Training Loss: 1.1355674386024475, Training Accuracy: 0.6125\n",
            "Epoch 2/10, Batch Loss: 1.119350790977478, Average Training Loss: 1.1340931979092685, Training Accuracy: 0.6079545454545454\n",
            "Epoch 2/10, Batch Loss: 1.079497218132019, Average Training Loss: 1.129543532927831, Training Accuracy: 0.6145833333333334\n",
            "Epoch 2/10, Batch Loss: 0.9277005791664124, Average Training Loss: 1.1140171518692603, Training Accuracy: 0.6201923076923077\n",
            "Epoch 2/10, Batch Loss: 0.9821910262107849, Average Training Loss: 1.104601000036512, Training Accuracy: 0.6294642857142857\n",
            "Epoch 2/10, Batch Loss: 1.0634757280349731, Average Training Loss: 1.1018593152364096, Training Accuracy: 0.6270833333333333\n",
            "Epoch 2/10, Batch Loss: 0.7595832943916321, Average Training Loss: 1.080467063933611, Training Accuracy: 0.640625\n",
            "Epoch 2/10, Batch Loss: 1.1154783964157104, Average Training Loss: 1.0825265540796167, Training Accuracy: 0.6378676470588235\n",
            "Epoch 2/10, Batch Loss: 1.0552393198013306, Average Training Loss: 1.0810105966197119, Training Accuracy: 0.6354166666666666\n",
            "Epoch 2/10, Batch Loss: 1.2520860433578491, Average Training Loss: 1.0900145675006665, Training Accuracy: 0.6282894736842105\n",
            "Epoch 2/10, Batch Loss: 1.0401943922042847, Average Training Loss: 1.0875235587358474, Training Accuracy: 0.628125\n",
            "Epoch 2/10, Batch Loss: 1.1338905096054077, Average Training Loss: 1.089731508777255, Training Accuracy: 0.6264880952380952\n",
            "Epoch 2/10, Batch Loss: 1.0010939836502075, Average Training Loss: 1.0857025303623893, Training Accuracy: 0.6278409090909091\n",
            "Epoch 2/10, Batch Loss: 1.088346004486084, Average Training Loss: 1.0858174640199412, Training Accuracy: 0.6277173913043478\n",
            "Epoch 2/10, Batch Loss: 0.9110884666442871, Average Training Loss: 1.078537089129289, Training Accuracy: 0.6276041666666666\n",
            "Epoch 2/10, Batch Loss: 0.9837849736213684, Average Training Loss: 1.0747470045089722, Training Accuracy: 0.62875\n",
            "Epoch 2/10, Batch Loss: 0.9628167152404785, Average Training Loss: 1.070441993383261, Training Accuracy: 0.6286057692307693\n",
            "Epoch 2/10, Batch Loss: 0.9618750214576721, Average Training Loss: 1.0664209944230538, Training Accuracy: 0.6296296296296297\n",
            "Epoch 2/10, Batch Loss: 0.9574427604675293, Average Training Loss: 1.062528914638928, Training Accuracy: 0.6316964285714286\n",
            "Epoch 2/10, Batch Loss: 1.1113173961639404, Average Training Loss: 1.0642112760708249, Training Accuracy: 0.6293103448275862\n",
            "Epoch 2/10, Batch Loss: 0.9170464873313904, Average Training Loss: 1.0593057831128438, Training Accuracy: 0.6322916666666667\n",
            "Epoch 2/10, Batch Loss: 0.8602927923202515, Average Training Loss: 1.0528860092163086, Training Accuracy: 0.6340725806451613\n",
            "Epoch 2/10, Batch Loss: 1.145933747291565, Average Training Loss: 1.0557937510311604, Training Accuracy: 0.62890625\n",
            "Epoch 2/10, Batch Loss: 1.0365463495254517, Average Training Loss: 1.0552104964400784, Training Accuracy: 0.6278409090909091\n",
            "Epoch 2/10, Batch Loss: 1.0978795289993286, Average Training Loss: 1.0564654679859387, Training Accuracy: 0.6268382352941176\n",
            "Epoch 2/10, Batch Loss: 0.9520920515060425, Average Training Loss: 1.0534833703722273, Training Accuracy: 0.6258928571428571\n",
            "Epoch 2/10, Batch Loss: 1.2864179611206055, Average Training Loss: 1.0599537756707933, Training Accuracy: 0.6206597222222222\n",
            "Epoch 2/10, Batch Loss: 1.2356929779052734, Average Training Loss: 1.0647034838392928, Training Accuracy: 0.6173986486486487\n",
            "Epoch 2/10, Batch Loss: 1.0389790534973145, Average Training Loss: 1.0640265251460828, Training Accuracy: 0.618421052631579\n",
            "Epoch 2/10, Batch Loss: 1.0298652648925781, Average Training Loss: 1.063150595395993, Training Accuracy: 0.6185897435897436\n",
            "Epoch 2/10, Batch Loss: 1.0783700942993164, Average Training Loss: 1.063531082868576, Training Accuracy: 0.615625\n",
            "Epoch 2/10, Batch Loss: 1.0597705841064453, Average Training Loss: 1.0634393633865729, Training Accuracy: 0.6166158536585366\n",
            "Epoch 2/10, Batch Loss: 0.7589520812034607, Average Training Loss: 1.056189666191737, Training Accuracy: 0.6190476190476191\n",
            "Epoch 2/10, Batch Loss: 1.0431548357009888, Average Training Loss: 1.0558865305989287, Training Accuracy: 0.6162790697674418\n",
            "Epoch 2/10, Batch Loss: 1.2199681997299194, Average Training Loss: 1.059615659442815, Training Accuracy: 0.6143465909090909\n",
            "Epoch 2/10, Batch Loss: 1.0237247943878174, Average Training Loss: 1.0588180846638149, Training Accuracy: 0.6152777777777778\n",
            "Epoch 2/10, Batch Loss: 0.8359075784683228, Average Training Loss: 1.0539722040943478, Training Accuracy: 0.6168478260869565\n",
            "Epoch 2/10, Batch Loss: 1.078072190284729, Average Training Loss: 1.0544849697579728, Training Accuracy: 0.6163563829787234\n",
            "Epoch 2/10, Batch Loss: 1.1949290037155151, Average Training Loss: 1.0574108871320884, Training Accuracy: 0.61328125\n",
            "Epoch 2/10, Batch Loss: 0.9727369546890259, Average Training Loss: 1.0556828476944748, Training Accuracy: 0.6160714285714286\n",
            "Epoch 2/10, Batch Loss: 0.7864564657211304, Average Training Loss: 1.050298320055008, Training Accuracy: 0.619375\n",
            "Epoch 2/10, Batch Loss: 1.0872255563735962, Average Training Loss: 1.0510223835122352, Training Accuracy: 0.6182598039215687\n",
            "Epoch 2/10, Batch Loss: 1.115418553352356, Average Training Loss: 1.052260771393776, Training Accuracy: 0.6171875\n",
            "Epoch 2/10, Batch Loss: 0.8906159996986389, Average Training Loss: 1.0492108700410374, Training Accuracy: 0.6179245283018868\n",
            "Epoch 2/10, Batch Loss: 0.7524389028549194, Average Training Loss: 1.0437150928709242, Training Accuracy: 0.6186342592592593\n",
            "Epoch 2/10, Batch Loss: 1.0684432983398438, Average Training Loss: 1.0441646966067228, Training Accuracy: 0.61875\n",
            "Epoch 2/10, Batch Loss: 0.909163773059845, Average Training Loss: 1.0417539658291, Training Accuracy: 0.6199776785714286\n",
            "Epoch 2/10, Batch Loss: 0.8603315353393555, Average Training Loss: 1.038571116171385, Training Accuracy: 0.6206140350877193\n",
            "Epoch 2/10, Batch Loss: 0.8014352321624756, Average Training Loss: 1.0344825664470936, Training Accuracy: 0.6233836206896551\n",
            "Epoch 2/10, Average Training Loss: 1.0344825664470936, Training Accuracy: 0.6233836206896551\n",
            "Epoch 2/10, Validation Loss: 14.41169947385788, Validation Accuracy: 0.6487068965517241\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.65      0.55      0.59        99\n",
            "                Educational Opportunity       0.42      0.57      0.48        87\n",
            "                         Family Support       0.72      0.99      0.84        93\n",
            "                      Financial Support       0.80      0.66      0.72        89\n",
            "                 Program Implementation       0.77      0.48      0.59        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.67      0.65      0.65       464\n",
            "                           weighted avg       0.67      0.65      0.65       464\n",
            "\n",
            "Epoch 3/10, Batch Loss: 0.9363734722137451, Average Training Loss: 0.9363734722137451, Training Accuracy: 0.71875\n",
            "Epoch 3/10, Batch Loss: 1.0388214588165283, Average Training Loss: 0.9875974655151367, Training Accuracy: 0.625\n",
            "Epoch 3/10, Batch Loss: 0.9737515449523926, Average Training Loss: 0.9829821586608887, Training Accuracy: 0.6145833333333334\n",
            "Epoch 3/10, Batch Loss: 1.0467371940612793, Average Training Loss: 0.9989209175109863, Training Accuracy: 0.6015625\n",
            "Epoch 3/10, Batch Loss: 0.9557441473007202, Average Training Loss: 0.9902855634689331, Training Accuracy: 0.625\n",
            "Epoch 3/10, Batch Loss: 0.8762294054031372, Average Training Loss: 0.9712762037913004, Training Accuracy: 0.640625\n",
            "Epoch 3/10, Batch Loss: 0.9650387167930603, Average Training Loss: 0.9703851342201233, Training Accuracy: 0.6473214285714286\n",
            "Epoch 3/10, Batch Loss: 0.9280511140823364, Average Training Loss: 0.9650933817028999, Training Accuracy: 0.6484375\n",
            "Epoch 3/10, Batch Loss: 0.9610841274261475, Average Training Loss: 0.964647909005483, Training Accuracy: 0.6423611111111112\n",
            "Epoch 3/10, Batch Loss: 0.6040573716163635, Average Training Loss: 0.9285888552665711, Training Accuracy: 0.6625\n",
            "Epoch 3/10, Batch Loss: 0.7975667119026184, Average Training Loss: 0.9166777513243936, Training Accuracy: 0.6676136363636364\n",
            "Epoch 3/10, Batch Loss: 0.538998544216156, Average Training Loss: 0.8852044840653738, Training Accuracy: 0.6796875\n",
            "Epoch 3/10, Batch Loss: 0.7850216031074524, Average Training Loss: 0.8774981086070721, Training Accuracy: 0.6875\n",
            "Epoch 3/10, Batch Loss: 0.9839997887611389, Average Training Loss: 0.8851053714752197, Training Accuracy: 0.6830357142857143\n",
            "Epoch 3/10, Batch Loss: 0.7561454176902771, Average Training Loss: 0.8765080412228902, Training Accuracy: 0.6854166666666667\n",
            "Epoch 3/10, Batch Loss: 0.5993309617042542, Average Training Loss: 0.8591844737529755, Training Accuracy: 0.6953125\n",
            "Epoch 3/10, Batch Loss: 0.7654467225074768, Average Training Loss: 0.8536704883855932, Training Accuracy: 0.7003676470588235\n",
            "Epoch 3/10, Batch Loss: 1.0588473081588745, Average Training Loss: 0.86506920059522, Training Accuracy: 0.6979166666666666\n",
            "Epoch 3/10, Batch Loss: 0.9446128606796265, Average Training Loss: 0.869255709020715, Training Accuracy: 0.6990131578947368\n",
            "Epoch 3/10, Batch Loss: 0.8771568536758423, Average Training Loss: 0.8696507662534714, Training Accuracy: 0.69375\n",
            "Epoch 3/10, Batch Loss: 0.7207996249198914, Average Training Loss: 0.8625626166661581, Training Accuracy: 0.7008928571428571\n",
            "Epoch 3/10, Batch Loss: 0.6421739459037781, Average Training Loss: 0.8525449498133226, Training Accuracy: 0.7073863636363636\n",
            "Epoch 3/10, Batch Loss: 0.8212122321128845, Average Training Loss: 0.8511826577393905, Training Accuracy: 0.7078804347826086\n",
            "Epoch 3/10, Batch Loss: 0.8203193545341492, Average Training Loss: 0.8498966867725054, Training Accuracy: 0.70703125\n",
            "Epoch 3/10, Batch Loss: 0.6745544672012329, Average Training Loss: 0.8428829979896545, Training Accuracy: 0.71125\n",
            "Epoch 3/10, Batch Loss: 0.5058588981628418, Average Training Loss: 0.8299205326117002, Training Accuracy: 0.7175480769230769\n",
            "Epoch 3/10, Batch Loss: 0.8048261404037476, Average Training Loss: 0.8289911106780723, Training Accuracy: 0.7175925925925926\n",
            "Epoch 3/10, Batch Loss: 0.984870433807373, Average Training Loss: 0.8345582293612617, Training Accuracy: 0.7154017857142857\n",
            "Epoch 3/10, Batch Loss: 0.803227961063385, Average Training Loss: 0.8334778752820245, Training Accuracy: 0.7144396551724138\n",
            "Epoch 3/10, Batch Loss: 0.8944672346115112, Average Training Loss: 0.8355108539263407, Training Accuracy: 0.7145833333333333\n",
            "Epoch 3/10, Batch Loss: 0.7229616641998291, Average Training Loss: 0.8318802349029049, Training Accuracy: 0.7167338709677419\n",
            "Epoch 3/10, Batch Loss: 1.0727359056472778, Average Training Loss: 0.8394069746136665, Training Accuracy: 0.7119140625\n",
            "Epoch 3/10, Batch Loss: 0.7649900317192078, Average Training Loss: 0.8371519157380769, Training Accuracy: 0.7130681818181818\n",
            "Epoch 3/10, Batch Loss: 0.694488525390625, Average Training Loss: 0.8329559336690342, Training Accuracy: 0.7123161764705882\n",
            "Epoch 3/10, Batch Loss: 0.765209972858429, Average Training Loss: 0.8310203347887312, Training Accuracy: 0.7133928571428572\n",
            "Epoch 3/10, Batch Loss: 1.100621223449707, Average Training Loss: 0.8385092483626472, Training Accuracy: 0.7126736111111112\n",
            "Epoch 3/10, Batch Loss: 0.8124154210090637, Average Training Loss: 0.8378040097855233, Training Accuracy: 0.7111486486486487\n",
            "Epoch 3/10, Batch Loss: 0.6831352710723877, Average Training Loss: 0.8337337798193881, Training Accuracy: 0.7129934210526315\n",
            "Epoch 3/10, Batch Loss: 0.7645134329795837, Average Training Loss: 0.831958899131188, Training Accuracy: 0.7147435897435898\n",
            "Epoch 3/10, Batch Loss: 0.7640111446380615, Average Training Loss: 0.8302602052688599, Training Accuracy: 0.71640625\n",
            "Epoch 3/10, Batch Loss: 0.9099645018577576, Average Training Loss: 0.8322042125027355, Training Accuracy: 0.7157012195121951\n",
            "Epoch 3/10, Batch Loss: 0.9008066654205322, Average Training Loss: 0.8338376042388734, Training Accuracy: 0.7165178571428571\n",
            "Epoch 3/10, Batch Loss: 0.859492838382721, Average Training Loss: 0.834434237591056, Training Accuracy: 0.717296511627907\n",
            "Epoch 3/10, Batch Loss: 0.7723881602287292, Average Training Loss: 0.8330240994691849, Training Accuracy: 0.7166193181818182\n",
            "Epoch 3/10, Batch Loss: 0.6725362539291382, Average Training Loss: 0.8294577029016282, Training Accuracy: 0.7180555555555556\n",
            "Epoch 3/10, Batch Loss: 0.9727551341056824, Average Training Loss: 0.8325728644495425, Training Accuracy: 0.7167119565217391\n",
            "Epoch 3/10, Batch Loss: 0.9300121068954468, Average Training Loss: 0.8346460398207319, Training Accuracy: 0.7147606382978723\n",
            "Epoch 3/10, Batch Loss: 0.688581645488739, Average Training Loss: 0.8316030316054821, Training Accuracy: 0.7161458333333334\n",
            "Epoch 3/10, Batch Loss: 1.0691694021224976, Average Training Loss: 0.8364513248813396, Training Accuracy: 0.7136479591836735\n",
            "Epoch 3/10, Batch Loss: 0.8500908017158508, Average Training Loss: 0.8367241144180297, Training Accuracy: 0.711875\n",
            "Epoch 3/10, Batch Loss: 0.9182897210121155, Average Training Loss: 0.8383234400375217, Training Accuracy: 0.710171568627451\n",
            "Epoch 3/10, Batch Loss: 0.571106493473053, Average Training Loss: 0.8331846526035895, Training Accuracy: 0.7115384615384616\n",
            "Epoch 3/10, Batch Loss: 0.6977318525314331, Average Training Loss: 0.830628939394681, Training Accuracy: 0.7140330188679245\n",
            "Epoch 3/10, Batch Loss: 0.81227046251297, Average Training Loss: 0.8302889676005752, Training Accuracy: 0.7135416666666666\n",
            "Epoch 3/10, Batch Loss: 0.648087739944458, Average Training Loss: 0.8269762180068276, Training Accuracy: 0.7142045454545455\n",
            "Epoch 3/10, Batch Loss: 0.8433006405830383, Average Training Loss: 0.8272677255528313, Training Accuracy: 0.7142857142857143\n",
            "Epoch 3/10, Batch Loss: 1.1115751266479492, Average Training Loss: 0.832255574694851, Training Accuracy: 0.7110745614035088\n",
            "Epoch 3/10, Batch Loss: 0.9308170676231384, Average Training Loss: 0.8339549107798214, Training Accuracy: 0.7106681034482759\n",
            "Epoch 3/10, Average Training Loss: 0.8339549107798214, Training Accuracy: 0.7106681034482759\n",
            "Epoch 3/10, Validation Loss: 13.481532394886017, Validation Accuracy: 0.6530172413793104\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.56      0.63        99\n",
            "                Educational Opportunity       0.44      0.36      0.39        87\n",
            "                         Family Support       0.75      0.98      0.85        93\n",
            "                      Financial Support       0.72      0.73      0.73        89\n",
            "                 Program Implementation       0.58      0.64      0.60        96\n",
            "\n",
            "                               accuracy                           0.65       464\n",
            "                              macro avg       0.64      0.65      0.64       464\n",
            "                           weighted avg       0.64      0.65      0.64       464\n",
            "\n",
            "Epoch 4/10, Batch Loss: 0.6967284083366394, Average Training Loss: 0.6967284083366394, Training Accuracy: 0.84375\n",
            "Epoch 4/10, Batch Loss: 0.8384729027748108, Average Training Loss: 0.7676006555557251, Training Accuracy: 0.765625\n",
            "Epoch 4/10, Batch Loss: 0.477419912815094, Average Training Loss: 0.670873741308848, Training Accuracy: 0.7916666666666666\n",
            "Epoch 4/10, Batch Loss: 0.8701987862586975, Average Training Loss: 0.7207050025463104, Training Accuracy: 0.765625\n",
            "Epoch 4/10, Batch Loss: 0.7972790002822876, Average Training Loss: 0.7360198020935058, Training Accuracy: 0.7625\n",
            "Epoch 4/10, Batch Loss: 0.6003227233886719, Average Training Loss: 0.7134036223093668, Training Accuracy: 0.7604166666666666\n",
            "Epoch 4/10, Batch Loss: 0.48142969608306885, Average Training Loss: 0.6802644899913243, Training Accuracy: 0.78125\n",
            "Epoch 4/10, Batch Loss: 0.7520008683204651, Average Training Loss: 0.6892315372824669, Training Accuracy: 0.77734375\n",
            "Epoch 4/10, Batch Loss: 0.7760618329048157, Average Training Loss: 0.6988793479071723, Training Accuracy: 0.7708333333333334\n",
            "Epoch 4/10, Batch Loss: 0.6273155808448792, Average Training Loss: 0.691722971200943, Training Accuracy: 0.771875\n",
            "Epoch 4/10, Batch Loss: 0.6609719395637512, Average Training Loss: 0.6889274228702892, Training Accuracy: 0.7698863636363636\n",
            "Epoch 4/10, Batch Loss: 0.6094258427619934, Average Training Loss: 0.6823022911945978, Training Accuracy: 0.7734375\n",
            "Epoch 4/10, Batch Loss: 0.735092282295227, Average Training Loss: 0.6863630597408001, Training Accuracy: 0.7692307692307693\n",
            "Epoch 4/10, Batch Loss: 0.7957680821418762, Average Training Loss: 0.6941777041980198, Training Accuracy: 0.7678571428571429\n",
            "Epoch 4/10, Batch Loss: 0.5528421998023987, Average Training Loss: 0.6847553372383117, Training Accuracy: 0.775\n",
            "Epoch 4/10, Batch Loss: 0.5050408244132996, Average Training Loss: 0.6735231801867485, Training Accuracy: 0.77734375\n",
            "Epoch 4/10, Batch Loss: 0.6518003344535828, Average Training Loss: 0.6722453657318564, Training Accuracy: 0.7775735294117647\n",
            "Epoch 4/10, Batch Loss: 0.6280741095542908, Average Training Loss: 0.669791407055325, Training Accuracy: 0.78125\n",
            "Epoch 4/10, Batch Loss: 0.7089703679084778, Average Training Loss: 0.6718534576265436, Training Accuracy: 0.7779605263157895\n",
            "Epoch 4/10, Batch Loss: 0.6138942837715149, Average Training Loss: 0.6689554989337921, Training Accuracy: 0.7765625\n",
            "Epoch 4/10, Batch Loss: 0.7585244178771973, Average Training Loss: 0.6732206855501447, Training Accuracy: 0.7738095238095238\n",
            "Epoch 4/10, Batch Loss: 0.7340545058250427, Average Training Loss: 0.6759858591990038, Training Accuracy: 0.7698863636363636\n",
            "Epoch 4/10, Batch Loss: 0.49695563316345215, Average Training Loss: 0.6682019363278928, Training Accuracy: 0.7758152173913043\n",
            "Epoch 4/10, Batch Loss: 0.7770686745643616, Average Training Loss: 0.672738050421079, Training Accuracy: 0.7760416666666666\n",
            "Epoch 4/10, Batch Loss: 0.7318258285522461, Average Training Loss: 0.6751015615463257, Training Accuracy: 0.77375\n",
            "Epoch 4/10, Batch Loss: 0.8063797950744629, Average Training Loss: 0.680150724374331, Training Accuracy: 0.7668269230769231\n",
            "Epoch 4/10, Batch Loss: 0.6802154779434204, Average Training Loss: 0.6801531226546677, Training Accuracy: 0.7662037037037037\n",
            "Epoch 4/10, Batch Loss: 0.3644829988479614, Average Training Loss: 0.668879189661571, Training Accuracy: 0.7723214285714286\n",
            "Epoch 4/10, Batch Loss: 0.45921358466148376, Average Training Loss: 0.6616493412132921, Training Accuracy: 0.7769396551724138\n",
            "Epoch 4/10, Batch Loss: 0.8491312265396118, Average Training Loss: 0.667898737390836, Training Accuracy: 0.7729166666666667\n",
            "Epoch 4/10, Batch Loss: 0.7038487195968628, Average Training Loss: 0.6690584142361918, Training Accuracy: 0.7741935483870968\n",
            "Epoch 4/10, Batch Loss: 0.7837978005409241, Average Training Loss: 0.6726440200582147, Training Accuracy: 0.7724609375\n",
            "Epoch 4/10, Batch Loss: 0.5911464691162109, Average Training Loss: 0.6701743973023964, Training Accuracy: 0.7708333333333334\n",
            "Epoch 4/10, Batch Loss: 0.9012239575386047, Average Training Loss: 0.6769699726034614, Training Accuracy: 0.765625\n",
            "Epoch 4/10, Batch Loss: 0.6250302195549011, Average Training Loss: 0.6754859796592168, Training Accuracy: 0.7660714285714286\n",
            "Epoch 4/10, Batch Loss: 0.664941668510437, Average Training Loss: 0.6751930821273062, Training Accuracy: 0.7664930555555556\n",
            "Epoch 4/10, Batch Loss: 0.5973978042602539, Average Training Loss: 0.6730905070498183, Training Accuracy: 0.7668918918918919\n",
            "Epoch 4/10, Batch Loss: 0.6698547005653381, Average Training Loss: 0.6730053542475951, Training Accuracy: 0.7672697368421053\n",
            "Epoch 4/10, Batch Loss: 0.6181522607803345, Average Training Loss: 0.6715988646715115, Training Accuracy: 0.7676282051282052\n",
            "Epoch 4/10, Batch Loss: 0.6535419225692749, Average Training Loss: 0.6711474411189556, Training Accuracy: 0.76796875\n",
            "Epoch 4/10, Batch Loss: 0.7030295729637146, Average Training Loss: 0.671925054090779, Training Accuracy: 0.7675304878048781\n",
            "Epoch 4/10, Batch Loss: 0.7584396004676819, Average Training Loss: 0.67398492424261, Training Accuracy: 0.7671130952380952\n",
            "Epoch 4/10, Batch Loss: 0.5871871709823608, Average Training Loss: 0.6719663718412089, Training Accuracy: 0.7674418604651163\n",
            "Epoch 4/10, Batch Loss: 0.7446878552436829, Average Training Loss: 0.6736191328276288, Training Accuracy: 0.7663352272727273\n",
            "Epoch 4/10, Batch Loss: 0.4845173954963684, Average Training Loss: 0.6694168719980452, Training Accuracy: 0.7673611111111112\n",
            "Epoch 4/10, Batch Loss: 0.6816785931587219, Average Training Loss: 0.6696834311537121, Training Accuracy: 0.766983695652174\n",
            "Epoch 4/10, Batch Loss: 0.9864410758018494, Average Training Loss: 0.6764229555079277, Training Accuracy: 0.7632978723404256\n",
            "Epoch 4/10, Batch Loss: 0.9495294690132141, Average Training Loss: 0.6821126745392879, Training Accuracy: 0.76171875\n",
            "Epoch 4/10, Batch Loss: 0.39198577404022217, Average Training Loss: 0.6761917173862457, Training Accuracy: 0.764030612244898\n",
            "Epoch 4/10, Batch Loss: 0.5770736932754517, Average Training Loss: 0.6742093569040298, Training Accuracy: 0.765\n",
            "Epoch 4/10, Batch Loss: 0.6337418556213379, Average Training Loss: 0.6734158764867222, Training Accuracy: 0.7653186274509803\n",
            "Epoch 4/10, Batch Loss: 0.8692836761474609, Average Training Loss: 0.6771825649417363, Training Accuracy: 0.7644230769230769\n",
            "Epoch 4/10, Batch Loss: 0.6736188530921936, Average Training Loss: 0.6771153250955185, Training Accuracy: 0.7647405660377359\n",
            "Epoch 4/10, Batch Loss: 0.9478200078010559, Average Training Loss: 0.6821283747752508, Training Accuracy: 0.7633101851851852\n",
            "Epoch 4/10, Batch Loss: 0.8204337358474731, Average Training Loss: 0.6846430177038366, Training Accuracy: 0.7619318181818182\n",
            "Epoch 4/10, Batch Loss: 0.6403257250785828, Average Training Loss: 0.6838516374783856, Training Accuracy: 0.7622767857142857\n",
            "Epoch 4/10, Batch Loss: 0.5877525806427002, Average Training Loss: 0.6821656891128474, Training Accuracy: 0.762609649122807\n",
            "Epoch 4/10, Batch Loss: 0.6589483022689819, Average Training Loss: 0.6817653893396772, Training Accuracy: 0.7629310344827587\n",
            "Epoch 4/10, Average Training Loss: 0.6817653893396772, Training Accuracy: 0.7629310344827587\n",
            "Epoch 4/10, Validation Loss: 13.487182974815369, Validation Accuracy: 0.6573275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.72      0.56      0.63        99\n",
            "                Educational Opportunity       0.44      0.44      0.44        87\n",
            "                         Family Support       0.78      0.89      0.83        93\n",
            "                      Financial Support       0.68      0.75      0.71        89\n",
            "                 Program Implementation       0.65      0.65      0.65        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 5/10, Batch Loss: 0.5428293943405151, Average Training Loss: 0.5428293943405151, Training Accuracy: 0.84375\n",
            "Epoch 5/10, Batch Loss: 0.39066368341445923, Average Training Loss: 0.4667465388774872, Training Accuracy: 0.84375\n",
            "Epoch 5/10, Batch Loss: 0.48974165320396423, Average Training Loss: 0.47441157698631287, Training Accuracy: 0.8541666666666666\n",
            "Epoch 5/10, Batch Loss: 0.43208518624305725, Average Training Loss: 0.46382997930049896, Training Accuracy: 0.8671875\n",
            "Epoch 5/10, Batch Loss: 0.7108950018882751, Average Training Loss: 0.5132429838180542, Training Accuracy: 0.85\n",
            "Epoch 5/10, Batch Loss: 0.8193039894104004, Average Training Loss: 0.5642531514167786, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/10, Batch Loss: 0.40709471702575684, Average Training Loss: 0.5418019465037754, Training Accuracy: 0.8392857142857143\n",
            "Epoch 5/10, Batch Loss: 0.7586326003074646, Average Training Loss: 0.5689057782292366, Training Accuracy: 0.8203125\n",
            "Epoch 5/10, Batch Loss: 0.370807945728302, Average Training Loss: 0.546894907951355, Training Accuracy: 0.8263888888888888\n",
            "Epoch 5/10, Batch Loss: 0.5758965015411377, Average Training Loss: 0.5497950673103332, Training Accuracy: 0.821875\n",
            "Epoch 5/10, Batch Loss: 0.4130249619483948, Average Training Loss: 0.5373614213683389, Training Accuracy: 0.8267045454545454\n",
            "Epoch 5/10, Batch Loss: 0.48599496483802795, Average Training Loss: 0.5330808833241463, Training Accuracy: 0.8229166666666666\n",
            "Epoch 5/10, Batch Loss: 0.4630279839038849, Average Training Loss: 0.5276921987533569, Training Accuracy: 0.8269230769230769\n",
            "Epoch 5/10, Batch Loss: 0.5957909226417542, Average Training Loss: 0.5325563933168139, Training Accuracy: 0.8214285714285714\n",
            "Epoch 5/10, Batch Loss: 0.5108257532119751, Average Training Loss: 0.5311076839764913, Training Accuracy: 0.825\n",
            "Epoch 5/10, Batch Loss: 0.5550662279129028, Average Training Loss: 0.532605092972517, Training Accuracy: 0.822265625\n",
            "Epoch 5/10, Batch Loss: 0.5893457531929016, Average Training Loss: 0.5359427788678337, Training Accuracy: 0.8198529411764706\n",
            "Epoch 5/10, Batch Loss: 0.5361772179603577, Average Training Loss: 0.5359558032618629, Training Accuracy: 0.8177083333333334\n",
            "Epoch 5/10, Batch Loss: 0.5673084855079651, Average Training Loss: 0.5376059444327104, Training Accuracy: 0.8174342105263158\n",
            "Epoch 5/10, Batch Loss: 0.5664150714874268, Average Training Loss: 0.5390464007854462, Training Accuracy: 0.8125\n",
            "Epoch 5/10, Batch Loss: 0.6150979995727539, Average Training Loss: 0.5426679054896036, Training Accuracy: 0.8154761904761905\n",
            "Epoch 5/10, Batch Loss: 0.30338841676712036, Average Training Loss: 0.5317915650931272, Training Accuracy: 0.8224431818181818\n",
            "Epoch 5/10, Batch Loss: 0.5352997779846191, Average Training Loss: 0.5319440960884094, Training Accuracy: 0.8247282608695652\n",
            "Epoch 5/10, Batch Loss: 0.5221540331840515, Average Training Loss: 0.5315361768007278, Training Accuracy: 0.82421875\n",
            "Epoch 5/10, Batch Loss: 0.4463118016719818, Average Training Loss: 0.528127201795578, Training Accuracy: 0.8275\n",
            "Epoch 5/10, Batch Loss: 0.4289119243621826, Average Training Loss: 0.5243112295866013, Training Accuracy: 0.8293269230769231\n",
            "Epoch 5/10, Batch Loss: 0.4369608163833618, Average Training Loss: 0.5210760290975924, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/10, Batch Loss: 0.4508402645587921, Average Training Loss: 0.5185676089354924, Training Accuracy: 0.8337053571428571\n",
            "Epoch 5/10, Batch Loss: 0.3948605954647064, Average Training Loss: 0.5143018498502928, Training Accuracy: 0.8351293103448276\n",
            "Epoch 5/10, Batch Loss: 0.4509985148906708, Average Training Loss: 0.5121917386849721, Training Accuracy: 0.8364583333333333\n",
            "Epoch 5/10, Batch Loss: 0.6048124432563782, Average Training Loss: 0.5151795033485659, Training Accuracy: 0.8356854838709677\n",
            "Epoch 5/10, Batch Loss: 0.5830984711647034, Average Training Loss: 0.5173019710928202, Training Accuracy: 0.8369140625\n",
            "Epoch 5/10, Batch Loss: 0.6551723480224609, Average Training Loss: 0.5214798613028093, Training Accuracy: 0.8361742424242424\n",
            "Epoch 5/10, Batch Loss: 0.568996787071228, Average Training Loss: 0.5228774179430569, Training Accuracy: 0.8354779411764706\n",
            "Epoch 5/10, Batch Loss: 0.58783358335495, Average Training Loss: 0.5247333083833967, Training Accuracy: 0.8330357142857143\n",
            "Epoch 5/10, Batch Loss: 0.5502325892448425, Average Training Loss: 0.5254416217406591, Training Accuracy: 0.8324652777777778\n",
            "Epoch 5/10, Batch Loss: 0.9020608067512512, Average Training Loss: 0.5356205186328372, Training Accuracy: 0.8285472972972973\n",
            "Epoch 5/10, Batch Loss: 0.563153088092804, Average Training Loss: 0.5363450599344153, Training Accuracy: 0.828125\n",
            "Epoch 5/10, Batch Loss: 0.35439157485961914, Average Training Loss: 0.5316795859581385, Training Accuracy: 0.8309294871794872\n",
            "Epoch 5/10, Batch Loss: 0.49819982051849365, Average Training Loss: 0.5308425918221473, Training Accuracy: 0.83203125\n",
            "Epoch 5/10, Batch Loss: 0.5635496377944946, Average Training Loss: 0.5316403246507412, Training Accuracy: 0.8323170731707317\n",
            "Epoch 5/10, Batch Loss: 0.36017587780952454, Average Training Loss: 0.5275578378211885, Training Accuracy: 0.8333333333333334\n",
            "Epoch 5/10, Batch Loss: 0.4563693106174469, Average Training Loss: 0.5259022906769154, Training Accuracy: 0.8335755813953488\n",
            "Epoch 5/10, Batch Loss: 0.5773528218269348, Average Training Loss: 0.5270716209303249, Training Accuracy: 0.8330965909090909\n",
            "Epoch 5/10, Batch Loss: 0.40036138892173767, Average Training Loss: 0.5242558379968008, Training Accuracy: 0.8340277777777778\n",
            "Epoch 5/10, Batch Loss: 0.4311794638633728, Average Training Loss: 0.5222324385591175, Training Accuracy: 0.8335597826086957\n",
            "Epoch 5/10, Batch Loss: 0.6373104453086853, Average Training Loss: 0.5246809067878317, Training Accuracy: 0.8331117021276596\n",
            "Epoch 5/10, Batch Loss: 0.462217777967453, Average Training Loss: 0.5233795916040739, Training Accuracy: 0.8326822916666666\n",
            "Epoch 5/10, Batch Loss: 0.5984199643135071, Average Training Loss: 0.5249110277818174, Training Accuracy: 0.8316326530612245\n",
            "Epoch 5/10, Batch Loss: 0.5584215521812439, Average Training Loss: 0.525581238269806, Training Accuracy: 0.830625\n",
            "Epoch 5/10, Batch Loss: 0.6161927580833435, Average Training Loss: 0.527357934736738, Training Accuracy: 0.8296568627450981\n",
            "Epoch 5/10, Batch Loss: 0.6114940047264099, Average Training Loss: 0.5289759360826932, Training Accuracy: 0.8293269230769231\n",
            "Epoch 5/10, Batch Loss: 0.49861499667167664, Average Training Loss: 0.5284030881692778, Training Accuracy: 0.8290094339622641\n",
            "Epoch 5/10, Batch Loss: 0.5468984246253967, Average Training Loss: 0.5287455943999467, Training Accuracy: 0.8287037037037037\n",
            "Epoch 5/10, Batch Loss: 0.576812744140625, Average Training Loss: 0.5296195425770499, Training Accuracy: 0.8272727272727273\n",
            "Epoch 5/10, Batch Loss: 0.44033998250961304, Average Training Loss: 0.5280252647187028, Training Accuracy: 0.8270089285714286\n",
            "Epoch 5/10, Batch Loss: 0.6429706811904907, Average Training Loss: 0.5300418509725939, Training Accuracy: 0.8256578947368421\n",
            "Epoch 5/10, Batch Loss: 0.45645707845687866, Average Training Loss: 0.528773147998185, Training Accuracy: 0.8259698275862069\n",
            "Epoch 5/10, Average Training Loss: 0.528773147998185, Training Accuracy: 0.8259698275862069\n",
            "Epoch 5/10, Validation Loss: 13.953237235546112, Validation Accuracy: 0.6551724137931034\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.74      0.54      0.62        99\n",
            "                Educational Opportunity       0.43      0.44      0.43        87\n",
            "                         Family Support       0.78      0.94      0.85        93\n",
            "                      Financial Support       0.70      0.72      0.71        89\n",
            "                 Program Implementation       0.63      0.65      0.64        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.65      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 6/10, Batch Loss: 0.3586384654045105, Average Training Loss: 0.3586384654045105, Training Accuracy: 0.875\n",
            "Epoch 6/10, Batch Loss: 0.4343450963497162, Average Training Loss: 0.39649178087711334, Training Accuracy: 0.875\n",
            "Epoch 6/10, Batch Loss: 0.4576476514339447, Average Training Loss: 0.4168770710627238, Training Accuracy: 0.875\n",
            "Epoch 6/10, Batch Loss: 0.3032133877277374, Average Training Loss: 0.3884611502289772, Training Accuracy: 0.8984375\n",
            "Epoch 6/10, Batch Loss: 0.41225358843803406, Average Training Loss: 0.39321963787078856, Training Accuracy: 0.89375\n",
            "Epoch 6/10, Batch Loss: 0.16541878879070282, Average Training Loss: 0.35525282969077426, Training Accuracy: 0.9114583333333334\n",
            "Epoch 6/10, Batch Loss: 0.45631879568099976, Average Training Loss: 0.3696908248322351, Training Accuracy: 0.90625\n",
            "Epoch 6/10, Batch Loss: 0.5565692782402039, Average Training Loss: 0.39305063150823116, Training Accuracy: 0.88671875\n",
            "Epoch 6/10, Batch Loss: 0.4291824996471405, Average Training Loss: 0.39706528352366555, Training Accuracy: 0.8888888888888888\n",
            "Epoch 6/10, Batch Loss: 0.3358621895313263, Average Training Loss: 0.39094497412443163, Training Accuracy: 0.89375\n",
            "Epoch 6/10, Batch Loss: 0.23525749146938324, Average Training Loss: 0.3767915666103363, Training Accuracy: 0.9005681818181818\n",
            "Epoch 6/10, Batch Loss: 0.355603963136673, Average Training Loss: 0.375025932987531, Training Accuracy: 0.9036458333333334\n",
            "Epoch 6/10, Batch Loss: 0.37073084712028503, Average Training Loss: 0.3746955417669736, Training Accuracy: 0.90625\n",
            "Epoch 6/10, Batch Loss: 0.35745200514793396, Average Training Loss: 0.3734638605798994, Training Accuracy: 0.9040178571428571\n",
            "Epoch 6/10, Batch Loss: 0.4444859027862549, Average Training Loss: 0.37819866339365643, Training Accuracy: 0.9041666666666667\n",
            "Epoch 6/10, Batch Loss: 0.40786123275756836, Average Training Loss: 0.3800525739789009, Training Accuracy: 0.90234375\n",
            "Epoch 6/10, Batch Loss: 0.2900245785713196, Average Training Loss: 0.3747568095431608, Training Accuracy: 0.9025735294117647\n",
            "Epoch 6/10, Batch Loss: 0.5974246859550476, Average Training Loss: 0.38712724712159896, Training Accuracy: 0.8975694444444444\n",
            "Epoch 6/10, Batch Loss: 0.25584641098976135, Average Training Loss: 0.3802177294304496, Training Accuracy: 0.899671052631579\n",
            "Epoch 6/10, Batch Loss: 0.2985168993473053, Average Training Loss: 0.3761326879262924, Training Accuracy: 0.9015625\n",
            "Epoch 6/10, Batch Loss: 0.3863335847854614, Average Training Loss: 0.3766184449195862, Training Accuracy: 0.9017857142857143\n",
            "Epoch 6/10, Batch Loss: 0.41480156779289246, Average Training Loss: 0.3783540414138274, Training Accuracy: 0.8977272727272727\n",
            "Epoch 6/10, Batch Loss: 0.22840029001235962, Average Training Loss: 0.3718343130920244, Training Accuracy: 0.9021739130434783\n",
            "Epoch 6/10, Batch Loss: 0.1714736372232437, Average Training Loss: 0.3634859515974919, Training Accuracy: 0.9049479166666666\n",
            "Epoch 6/10, Batch Loss: 0.472840815782547, Average Training Loss: 0.3678601461648941, Training Accuracy: 0.9025\n",
            "Epoch 6/10, Batch Loss: 0.3458596169948578, Average Training Loss: 0.36701397196604657, Training Accuracy: 0.9014423076923077\n",
            "Epoch 6/10, Batch Loss: 0.5541611909866333, Average Training Loss: 0.3739453504482905, Training Accuracy: 0.8958333333333334\n",
            "Epoch 6/10, Batch Loss: 0.5864827632904053, Average Training Loss: 0.3815359723355089, Training Accuracy: 0.8895089285714286\n",
            "Epoch 6/10, Batch Loss: 0.4588412046432495, Average Training Loss: 0.38420167000129307, Training Accuracy: 0.8890086206896551\n",
            "Epoch 6/10, Batch Loss: 0.6248381733894348, Average Training Loss: 0.3922228867808978, Training Accuracy: 0.8854166666666666\n",
            "Epoch 6/10, Batch Loss: 0.43867921829223633, Average Training Loss: 0.3937214781199732, Training Accuracy: 0.8840725806451613\n",
            "Epoch 6/10, Batch Loss: 0.5072603225708008, Average Training Loss: 0.3972695670090616, Training Accuracy: 0.880859375\n",
            "Epoch 6/10, Batch Loss: 0.37707167863845825, Average Training Loss: 0.39665750978570996, Training Accuracy: 0.8816287878787878\n",
            "Epoch 6/10, Batch Loss: 0.4623378813266754, Average Training Loss: 0.39858928541926775, Training Accuracy: 0.8795955882352942\n",
            "Epoch 6/10, Batch Loss: 0.3992151618003845, Average Training Loss: 0.3986071676015854, Training Accuracy: 0.8794642857142857\n",
            "Epoch 6/10, Batch Loss: 0.7549050450325012, Average Training Loss: 0.40850433086355525, Training Accuracy: 0.8776041666666666\n",
            "Epoch 6/10, Batch Loss: 0.44577765464782715, Average Training Loss: 0.4095117179928599, Training Accuracy: 0.8783783783783784\n",
            "Epoch 6/10, Batch Loss: 0.5390288829803467, Average Training Loss: 0.41292006443989904, Training Accuracy: 0.8774671052631579\n",
            "Epoch 6/10, Batch Loss: 0.34381139278411865, Average Training Loss: 0.41114804721795595, Training Accuracy: 0.8790064102564102\n",
            "Epoch 6/10, Batch Loss: 0.48687660694122314, Average Training Loss: 0.4130412612110376, Training Accuracy: 0.8796875\n",
            "Epoch 6/10, Batch Loss: 0.34333908557891846, Average Training Loss: 0.4113412081468396, Training Accuracy: 0.8803353658536586\n",
            "Epoch 6/10, Batch Loss: 0.35679304599761963, Average Training Loss: 0.410042442381382, Training Accuracy: 0.8802083333333334\n",
            "Epoch 6/10, Batch Loss: 0.34889888763427734, Average Training Loss: 0.4086204992477284, Training Accuracy: 0.8808139534883721\n",
            "Epoch 6/10, Batch Loss: 0.37857943773269653, Average Training Loss: 0.40793774784965947, Training Accuracy: 0.8792613636363636\n",
            "Epoch 6/10, Batch Loss: 0.26780569553375244, Average Training Loss: 0.4048237022426393, Training Accuracy: 0.8798611111111111\n",
            "Epoch 6/10, Batch Loss: 0.601803183555603, Average Training Loss: 0.40910586487987766, Training Accuracy: 0.8777173913043478\n",
            "Epoch 6/10, Batch Loss: 0.4833946228027344, Average Training Loss: 0.41068647675057673, Training Accuracy: 0.8769946808510638\n",
            "Epoch 6/10, Batch Loss: 0.5269474387168884, Average Training Loss: 0.4131085801248749, Training Accuracy: 0.8756510416666666\n",
            "Epoch 6/10, Batch Loss: 0.3768325448036194, Average Training Loss: 0.4123682528734207, Training Accuracy: 0.8762755102040817\n",
            "Epoch 6/10, Batch Loss: 0.3161291778087616, Average Training Loss: 0.41044347137212756, Training Accuracy: 0.87625\n",
            "Epoch 6/10, Batch Loss: 0.7625885009765625, Average Training Loss: 0.4173482758741753, Training Accuracy: 0.8743872549019608\n",
            "Epoch 6/10, Batch Loss: 0.5484737753868103, Average Training Loss: 0.4198699200955721, Training Accuracy: 0.8743990384615384\n",
            "Epoch 6/10, Batch Loss: 0.15775015950202942, Average Training Loss: 0.4149242642353166, Training Accuracy: 0.8767688679245284\n",
            "Epoch 6/10, Batch Loss: 0.3259000778198242, Average Training Loss: 0.41327566819058525, Training Accuracy: 0.8784722222222222\n",
            "Epoch 6/10, Batch Loss: 0.435205340385437, Average Training Loss: 0.4136743895032189, Training Accuracy: 0.8778409090909091\n",
            "Epoch 6/10, Batch Loss: 0.22845883667469025, Average Training Loss: 0.4103669689169952, Training Accuracy: 0.8783482142857143\n",
            "Epoch 6/10, Batch Loss: 0.5429695248603821, Average Training Loss: 0.4126933295475809, Training Accuracy: 0.8760964912280702\n",
            "Epoch 6/10, Batch Loss: 0.228725865483284, Average Training Loss: 0.40952147671888617, Training Accuracy: 0.8771551724137931\n",
            "Epoch 6/10, Average Training Loss: 0.40952147671888617, Training Accuracy: 0.8771551724137931\n",
            "Epoch 6/10, Validation Loss: 14.501514852046967, Validation Accuracy: 0.6573275862068966\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.73      0.57      0.64        99\n",
            "                Educational Opportunity       0.46      0.47      0.46        87\n",
            "                         Family Support       0.80      0.91      0.85        93\n",
            "                      Financial Support       0.66      0.73      0.69        89\n",
            "                 Program Implementation       0.63      0.60      0.62        96\n",
            "\n",
            "                               accuracy                           0.66       464\n",
            "                              macro avg       0.65      0.66      0.65       464\n",
            "                           weighted avg       0.66      0.66      0.65       464\n",
            "\n",
            "Epoch 7/10, Batch Loss: 0.3153765797615051, Average Training Loss: 0.3153765797615051, Training Accuracy: 0.875\n",
            "Epoch 7/10, Batch Loss: 0.47954264283180237, Average Training Loss: 0.39745961129665375, Training Accuracy: 0.859375\n",
            "Epoch 7/10, Batch Loss: 0.3303711712360382, Average Training Loss: 0.37509679794311523, Training Accuracy: 0.875\n",
            "Epoch 7/10, Batch Loss: 0.1691138595342636, Average Training Loss: 0.32360106334090233, Training Accuracy: 0.90625\n",
            "Epoch 7/10, Batch Loss: 0.3602043390274048, Average Training Loss: 0.33092171847820284, Training Accuracy: 0.89375\n",
            "Epoch 7/10, Batch Loss: 0.2324056774377823, Average Training Loss: 0.3145023783047994, Training Accuracy: 0.90625\n",
            "Epoch 7/10, Batch Loss: 0.5238968729972839, Average Training Loss: 0.3444158775465829, Training Accuracy: 0.8883928571428571\n",
            "Epoch 7/10, Batch Loss: 0.5425664782524109, Average Training Loss: 0.3691847026348114, Training Accuracy: 0.8828125\n",
            "Epoch 7/10, Batch Loss: 0.39669209718704224, Average Training Loss: 0.3722410798072815, Training Accuracy: 0.8854166666666666\n",
            "Epoch 7/10, Batch Loss: 0.21101585030555725, Average Training Loss: 0.3561185568571091, Training Accuracy: 0.89375\n",
            "Epoch 7/10, Batch Loss: 0.3415641784667969, Average Training Loss: 0.35479543154889887, Training Accuracy: 0.8920454545454546\n",
            "Epoch 7/10, Batch Loss: 0.4173002541065216, Average Training Loss: 0.3600041667620341, Training Accuracy: 0.8880208333333334\n",
            "Epoch 7/10, Batch Loss: 0.4003260135650635, Average Training Loss: 0.36310584728534406, Training Accuracy: 0.8870192307692307\n",
            "Epoch 7/10, Batch Loss: 0.24209627509117126, Average Training Loss: 0.3544623064143317, Training Accuracy: 0.8883928571428571\n",
            "Epoch 7/10, Batch Loss: 0.38633331656455994, Average Training Loss: 0.3565870404243469, Training Accuracy: 0.8916666666666667\n",
            "Epoch 7/10, Batch Loss: 0.4473206400871277, Average Training Loss: 0.3622578904032707, Training Accuracy: 0.888671875\n",
            "Epoch 7/10, Batch Loss: 0.3733369708061218, Average Training Loss: 0.36290960101520314, Training Accuracy: 0.8915441176470589\n",
            "Epoch 7/10, Batch Loss: 0.34428659081459045, Average Training Loss: 0.3618749893373913, Training Accuracy: 0.890625\n",
            "Epoch 7/10, Batch Loss: 0.5132014155387878, Average Training Loss: 0.3698395380848332, Training Accuracy: 0.8898026315789473\n",
            "Epoch 7/10, Batch Loss: 0.2722947299480438, Average Training Loss: 0.36496229767799376, Training Accuracy: 0.8921875\n",
            "Epoch 7/10, Batch Loss: 0.34192943572998047, Average Training Loss: 0.3638654947280884, Training Accuracy: 0.8913690476190477\n",
            "Epoch 7/10, Batch Loss: 0.32043933868408203, Average Training Loss: 0.3618915785442699, Training Accuracy: 0.8920454545454546\n",
            "Epoch 7/10, Batch Loss: 0.37098428606987, Average Training Loss: 0.3622869136540786, Training Accuracy: 0.8926630434782609\n",
            "Epoch 7/10, Batch Loss: 0.1424509584903717, Average Training Loss: 0.35312708218892414, Training Accuracy: 0.8958333333333334\n",
            "Epoch 7/10, Batch Loss: 0.2868383228778839, Average Training Loss: 0.35047553181648256, Training Accuracy: 0.8975\n",
            "Epoch 7/10, Batch Loss: 0.20664237439632416, Average Training Loss: 0.3449434873003226, Training Accuracy: 0.8990384615384616\n",
            "Epoch 7/10, Batch Loss: 0.3131214678287506, Average Training Loss: 0.3437648939865607, Training Accuracy: 0.9004629629629629\n",
            "Epoch 7/10, Batch Loss: 0.4381384551525116, Average Training Loss: 0.34713537831391605, Training Accuracy: 0.8995535714285714\n",
            "Epoch 7/10, Batch Loss: 0.14757278561592102, Average Training Loss: 0.3402539096001921, Training Accuracy: 0.9030172413793104\n",
            "Epoch 7/10, Batch Loss: 0.37386462092399597, Average Training Loss: 0.3413742666443189, Training Accuracy: 0.9020833333333333\n",
            "Epoch 7/10, Batch Loss: 0.4325157701969147, Average Training Loss: 0.3443143151460155, Training Accuracy: 0.9012096774193549\n",
            "Epoch 7/10, Batch Loss: 0.5599504113197327, Average Training Loss: 0.3510529431514442, Training Accuracy: 0.8984375\n",
            "Epoch 7/10, Batch Loss: 0.1822366714477539, Average Training Loss: 0.34593729855436267, Training Accuracy: 0.9005681818181818\n",
            "Epoch 7/10, Batch Loss: 0.36807623505592346, Average Training Loss: 0.34658844374558506, Training Accuracy: 0.9016544117647058\n",
            "Epoch 7/10, Batch Loss: 0.20484592020511627, Average Training Loss: 0.3425386573587145, Training Accuracy: 0.9035714285714286\n",
            "Epoch 7/10, Batch Loss: 0.2543041706085205, Average Training Loss: 0.34008769939343136, Training Accuracy: 0.9045138888888888\n",
            "Epoch 7/10, Batch Loss: 0.30371925234794617, Average Training Loss: 0.339104768392202, Training Accuracy: 0.9045608108108109\n",
            "Epoch 7/10, Batch Loss: 0.37392598390579224, Average Training Loss: 0.3400211161688754, Training Accuracy: 0.9037828947368421\n",
            "Epoch 7/10, Batch Loss: 0.38953283429145813, Average Training Loss: 0.3412906474027878, Training Accuracy: 0.9030448717948718\n",
            "Epoch 7/10, Batch Loss: 0.3839738965034485, Average Training Loss: 0.34235772863030434, Training Accuracy: 0.903125\n",
            "Epoch 7/10, Batch Loss: 0.4092826247215271, Average Training Loss: 0.34399004316911463, Training Accuracy: 0.9024390243902439\n",
            "Epoch 7/10, Batch Loss: 0.30171990394592285, Average Training Loss: 0.34298361128284816, Training Accuracy: 0.9017857142857143\n",
            "Epoch 7/10, Batch Loss: 0.4990139305591583, Average Training Loss: 0.34661222335904146, Training Accuracy: 0.8989825581395349\n",
            "Epoch 7/10, Batch Loss: 0.20434550940990448, Average Training Loss: 0.3433788889511065, Training Accuracy: 0.9005681818181818\n",
            "Epoch 7/10, Batch Loss: 0.26991769671440125, Average Training Loss: 0.34174641801251304, Training Accuracy: 0.9013888888888889\n",
            "Epoch 7/10, Batch Loss: 0.35988378524780273, Average Training Loss: 0.34214070860458456, Training Accuracy: 0.9008152173913043\n",
            "Epoch 7/10, Batch Loss: 0.38492754101753235, Average Training Loss: 0.34305106674103025, Training Accuracy: 0.898936170212766\n",
            "Epoch 7/10, Batch Loss: 0.3824705481529236, Average Training Loss: 0.3438723059371114, Training Accuracy: 0.8977864583333334\n",
            "Epoch 7/10, Batch Loss: 0.28771910071372986, Average Training Loss: 0.34272632215704235, Training Accuracy: 0.8992346938775511\n",
            "Epoch 7/10, Batch Loss: 0.4084632992744446, Average Training Loss: 0.3440410616993904, Training Accuracy: 0.898125\n",
            "Epoch 7/10, Batch Loss: 0.2880922257900238, Average Training Loss: 0.34294402570116755, Training Accuracy: 0.8982843137254902\n",
            "Epoch 7/10, Batch Loss: 0.43019771575927734, Average Training Loss: 0.3446219812792081, Training Accuracy: 0.8972355769230769\n",
            "Epoch 7/10, Batch Loss: 0.1170317754149437, Average Training Loss: 0.3403278264515805, Training Accuracy: 0.8991745283018868\n",
            "Epoch 7/10, Batch Loss: 0.2655889689922333, Average Training Loss: 0.3389437735356666, Training Accuracy: 0.8993055555555556\n",
            "Epoch 7/10, Batch Loss: 0.2721155881881714, Average Training Loss: 0.33772871562025764, Training Accuracy: 0.9\n",
            "Epoch 7/10, Batch Loss: 0.18832650780677795, Average Training Loss: 0.3350608190521598, Training Accuracy: 0.9006696428571429\n",
            "Epoch 7/10, Batch Loss: 0.22778436541557312, Average Training Loss: 0.3331787760059039, Training Accuracy: 0.9018640350877193\n",
            "Epoch 7/10, Batch Loss: 0.4158955216407776, Average Training Loss: 0.33460492679271203, Training Accuracy: 0.9019396551724138\n",
            "Epoch 7/10, Average Training Loss: 0.33460492679271203, Training Accuracy: 0.9019396551724138\n",
            "Epoch 7/10, Validation Loss: 15.005530178546906, Validation Accuracy: 0.6702586206896551\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.59      0.63        99\n",
            "                Educational Opportunity       0.49      0.56      0.53        87\n",
            "                         Family Support       0.80      0.92      0.86        93\n",
            "                      Financial Support       0.65      0.73      0.69        89\n",
            "                 Program Implementation       0.73      0.55      0.63        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.67      0.67      0.67       464\n",
            "                           weighted avg       0.67      0.67      0.67       464\n",
            "\n",
            "Epoch 8/10, Batch Loss: 0.24194775521755219, Average Training Loss: 0.24194775521755219, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.3946869373321533, Average Training Loss: 0.31831734627485275, Training Accuracy: 0.921875\n",
            "Epoch 8/10, Batch Loss: 0.5131326913833618, Average Training Loss: 0.3832557946443558, Training Accuracy: 0.8958333333333334\n",
            "Epoch 8/10, Batch Loss: 0.375154972076416, Average Training Loss: 0.38123058900237083, Training Accuracy: 0.90625\n",
            "Epoch 8/10, Batch Loss: 0.21047426760196686, Average Training Loss: 0.34707932472229003, Training Accuracy: 0.9125\n",
            "Epoch 8/10, Batch Loss: 0.34873151779174805, Average Training Loss: 0.3473546902338664, Training Accuracy: 0.9114583333333334\n",
            "Epoch 8/10, Batch Loss: 0.3438661992549896, Average Training Loss: 0.3468563343797411, Training Accuracy: 0.9017857142857143\n",
            "Epoch 8/10, Batch Loss: 0.3720036745071411, Average Training Loss: 0.3499997518956661, Training Accuracy: 0.90625\n",
            "Epoch 8/10, Batch Loss: 0.2745876610279083, Average Training Loss: 0.34162063068813747, Training Accuracy: 0.9097222222222222\n",
            "Epoch 8/10, Batch Loss: 0.2712402045726776, Average Training Loss: 0.33458258807659147, Training Accuracy: 0.9125\n",
            "Epoch 8/10, Batch Loss: 0.2649112343788147, Average Training Loss: 0.3282488286495209, Training Accuracy: 0.9176136363636364\n",
            "Epoch 8/10, Batch Loss: 0.19314153492450714, Average Training Loss: 0.31698988750576973, Training Accuracy: 0.9192708333333334\n",
            "Epoch 8/10, Batch Loss: 0.2929457426071167, Average Training Loss: 0.315140337898181, Training Accuracy: 0.9206730769230769\n",
            "Epoch 8/10, Batch Loss: 0.14630265533924103, Average Training Loss: 0.30308050342968534, Training Accuracy: 0.9263392857142857\n",
            "Epoch 8/10, Batch Loss: 0.31354251503944397, Average Training Loss: 0.3037779708703359, Training Accuracy: 0.925\n",
            "Epoch 8/10, Batch Loss: 0.26812440156936646, Average Training Loss: 0.3015496227890253, Training Accuracy: 0.923828125\n",
            "Epoch 8/10, Batch Loss: 0.17070531845092773, Average Training Loss: 0.29385289900443134, Training Accuracy: 0.9246323529411765\n",
            "Epoch 8/10, Batch Loss: 0.36288121342658997, Average Training Loss: 0.2976878053612179, Training Accuracy: 0.9236111111111112\n",
            "Epoch 8/10, Batch Loss: 0.4012683033943176, Average Training Loss: 0.30313941052085475, Training Accuracy: 0.9210526315789473\n",
            "Epoch 8/10, Batch Loss: 0.25953662395477295, Average Training Loss: 0.30095927119255067, Training Accuracy: 0.921875\n",
            "Epoch 8/10, Batch Loss: 0.3423157334327698, Average Training Loss: 0.302928626537323, Training Accuracy: 0.9211309523809523\n",
            "Epoch 8/10, Batch Loss: 0.31720271706581116, Average Training Loss: 0.30357744883407245, Training Accuracy: 0.9204545454545454\n",
            "Epoch 8/10, Batch Loss: 0.1474563032388687, Average Training Loss: 0.29678957293862884, Training Accuracy: 0.9225543478260869\n",
            "Epoch 8/10, Batch Loss: 0.3224627375602722, Average Training Loss: 0.2978592881311973, Training Accuracy: 0.921875\n",
            "Epoch 8/10, Batch Loss: 0.1780446618795395, Average Training Loss: 0.293066703081131, Training Accuracy: 0.9225\n",
            "Epoch 8/10, Batch Loss: 0.21204398572444916, Average Training Loss: 0.2899504447212586, Training Accuracy: 0.9230769230769231\n",
            "Epoch 8/10, Batch Loss: 0.27236220240592957, Average Training Loss: 0.2892990283392094, Training Accuracy: 0.9224537037037037\n",
            "Epoch 8/10, Batch Loss: 0.27263790369033813, Average Training Loss: 0.28870398817317827, Training Accuracy: 0.921875\n",
            "Epoch 8/10, Batch Loss: 0.17542414367198944, Average Training Loss: 0.2847977866386545, Training Accuracy: 0.9234913793103449\n",
            "Epoch 8/10, Batch Loss: 0.19254954159259796, Average Training Loss: 0.2817228451371193, Training Accuracy: 0.925\n",
            "Epoch 8/10, Batch Loss: 0.11787606030702591, Average Training Loss: 0.27643746498130983, Training Accuracy: 0.9274193548387096\n",
            "Epoch 8/10, Batch Loss: 0.11287209391593933, Average Training Loss: 0.271326047135517, Training Accuracy: 0.9296875\n",
            "Epoch 8/10, Batch Loss: 0.20504027605056763, Average Training Loss: 0.2693173874056701, Training Accuracy: 0.9299242424242424\n",
            "Epoch 8/10, Batch Loss: 0.18368695676326752, Average Training Loss: 0.26679884532795234, Training Accuracy: 0.9301470588235294\n",
            "Epoch 8/10, Batch Loss: 0.1963740885257721, Average Training Loss: 0.2647867094193186, Training Accuracy: 0.93125\n",
            "Epoch 8/10, Batch Loss: 0.10585241764783859, Average Training Loss: 0.2603718679812219, Training Accuracy: 0.9331597222222222\n",
            "Epoch 8/10, Batch Loss: 0.5071094632148743, Average Training Loss: 0.2670404516361855, Training Accuracy: 0.9315878378378378\n",
            "Epoch 8/10, Batch Loss: 0.2546076774597168, Average Training Loss: 0.2667132733683837, Training Accuracy: 0.9317434210526315\n",
            "Epoch 8/10, Batch Loss: 0.3835400342941284, Average Training Loss: 0.26970883134083873, Training Accuracy: 0.9294871794871795\n",
            "Epoch 8/10, Batch Loss: 0.44639962911605835, Average Training Loss: 0.2741261012852192, Training Accuracy: 0.92734375\n",
            "Epoch 8/10, Batch Loss: 0.3961471617221832, Average Training Loss: 0.277102224710511, Training Accuracy: 0.9260670731707317\n",
            "Epoch 8/10, Batch Loss: 0.1951030045747757, Average Training Loss: 0.2751498623263268, Training Accuracy: 0.9270833333333334\n",
            "Epoch 8/10, Batch Loss: 0.20927636325359344, Average Training Loss: 0.27361792048742606, Training Accuracy: 0.9273255813953488\n",
            "Epoch 8/10, Batch Loss: 0.24627572298049927, Average Training Loss: 0.27299650690772315, Training Accuracy: 0.9275568181818182\n",
            "Epoch 8/10, Batch Loss: 0.29746946692466736, Average Training Loss: 0.27354035046365527, Training Accuracy: 0.9277777777777778\n",
            "Epoch 8/10, Batch Loss: 0.2766915261745453, Average Training Loss: 0.2736088542834572, Training Accuracy: 0.9259510869565217\n",
            "Epoch 8/10, Batch Loss: 0.34948205947875977, Average Training Loss: 0.2752231777982509, Training Accuracy: 0.9248670212765957\n",
            "Epoch 8/10, Batch Loss: 0.2976280152797699, Average Training Loss: 0.27568994524578255, Training Accuracy: 0.9244791666666666\n",
            "Epoch 8/10, Batch Loss: 0.5301709175109863, Average Training Loss: 0.28088343447568465, Training Accuracy: 0.923469387755102\n",
            "Epoch 8/10, Batch Loss: 0.21446867287158966, Average Training Loss: 0.27955513924360276, Training Accuracy: 0.92375\n",
            "Epoch 8/10, Batch Loss: 0.2748609781265259, Average Training Loss: 0.2794630968687581, Training Accuracy: 0.9234068627450981\n",
            "Epoch 8/10, Batch Loss: 0.4905140697956085, Average Training Loss: 0.2835217694250437, Training Accuracy: 0.9224759615384616\n",
            "Epoch 8/10, Batch Loss: 0.1500675082206726, Average Training Loss: 0.2810037644966593, Training Accuracy: 0.9233490566037735\n",
            "Epoch 8/10, Batch Loss: 0.17434503138065338, Average Training Loss: 0.27902860277228886, Training Accuracy: 0.9241898148148148\n",
            "Epoch 8/10, Batch Loss: 0.1504097580909729, Average Training Loss: 0.27669007832353765, Training Accuracy: 0.925\n",
            "Epoch 8/10, Batch Loss: 0.3292984366416931, Average Training Loss: 0.2776295132935047, Training Accuracy: 0.9246651785714286\n",
            "Epoch 8/10, Batch Loss: 0.34343257546424866, Average Training Loss: 0.27878395298071074, Training Accuracy: 0.9237938596491229\n",
            "Epoch 8/10, Batch Loss: 0.38416391611099243, Average Training Loss: 0.2806008488967501, Training Accuracy: 0.9234913793103449\n",
            "Epoch 8/10, Average Training Loss: 0.2806008488967501, Training Accuracy: 0.9234913793103449\n",
            "Epoch 8/10, Validation Loss: 15.031224310398102, Validation Accuracy: 0.6767241379310345\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.65      0.71      0.68        99\n",
            "                Educational Opportunity       0.53      0.45      0.48        87\n",
            "                         Family Support       0.80      0.91      0.85        93\n",
            "                      Financial Support       0.65      0.71      0.68        89\n",
            "                 Program Implementation       0.71      0.59      0.65        96\n",
            "\n",
            "                               accuracy                           0.68       464\n",
            "                              macro avg       0.67      0.67      0.67       464\n",
            "                           weighted avg       0.67      0.68      0.67       464\n",
            "\n",
            "Epoch 9/10, Batch Loss: 0.310272753238678, Average Training Loss: 0.310272753238678, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.2966656982898712, Average Training Loss: 0.3034692257642746, Training Accuracy: 0.921875\n",
            "Epoch 9/10, Batch Loss: 0.2575625777244568, Average Training Loss: 0.288167009751002, Training Accuracy: 0.9166666666666666\n",
            "Epoch 9/10, Batch Loss: 0.3621414005756378, Average Training Loss: 0.30666060745716095, Training Accuracy: 0.8984375\n",
            "Epoch 9/10, Batch Loss: 0.1976153552532196, Average Training Loss: 0.28485155701637266, Training Accuracy: 0.9125\n",
            "Epoch 9/10, Batch Loss: 0.1734474003314972, Average Training Loss: 0.26628419756889343, Training Accuracy: 0.921875\n",
            "Epoch 9/10, Batch Loss: 0.21586914360523224, Average Training Loss: 0.25908204700265614, Training Accuracy: 0.9285714285714286\n",
            "Epoch 9/10, Batch Loss: 0.1586330682039261, Average Training Loss: 0.24652592465281487, Training Accuracy: 0.93359375\n",
            "Epoch 9/10, Batch Loss: 0.14956936240196228, Average Training Loss: 0.23575297329160902, Training Accuracy: 0.9409722222222222\n",
            "Epoch 9/10, Batch Loss: 0.13124790787696838, Average Training Loss: 0.22530246675014495, Training Accuracy: 0.94375\n",
            "Epoch 9/10, Batch Loss: 0.3879839777946472, Average Training Loss: 0.24009169502691788, Training Accuracy: 0.9403409090909091\n",
            "Epoch 9/10, Batch Loss: 0.3923400938510895, Average Training Loss: 0.2527790615955989, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.1315763145685196, Average Training Loss: 0.2434557733627466, Training Accuracy: 0.9399038461538461\n",
            "Epoch 9/10, Batch Loss: 0.4142487645149231, Average Training Loss: 0.2556552727307592, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.13679139316082, Average Training Loss: 0.24773101409276327, Training Accuracy: 0.9395833333333333\n",
            "Epoch 9/10, Batch Loss: 0.3087525963783264, Average Training Loss: 0.25154486298561096, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.21458792686462402, Average Training Loss: 0.24937092556672938, Training Accuracy: 0.9393382352941176\n",
            "Epoch 9/10, Batch Loss: 0.2654699981212616, Average Training Loss: 0.25026531848642564, Training Accuracy: 0.9409722222222222\n",
            "Epoch 9/10, Batch Loss: 0.10378175228834152, Average Training Loss: 0.2425556571075791, Training Accuracy: 0.944078947368421\n",
            "Epoch 9/10, Batch Loss: 0.2827701270580292, Average Training Loss: 0.24456638060510158, Training Accuracy: 0.94375\n",
            "Epoch 9/10, Batch Loss: 0.28670844435691833, Average Training Loss: 0.24657314554566429, Training Accuracy: 0.9404761904761905\n",
            "Epoch 9/10, Batch Loss: 0.24324938654899597, Average Training Loss: 0.24642206559127028, Training Accuracy: 0.9403409090909091\n",
            "Epoch 9/10, Batch Loss: 0.1295464038848877, Average Training Loss: 0.24134051508229712, Training Accuracy: 0.9415760869565217\n",
            "Epoch 9/10, Batch Loss: 0.16595757007598877, Average Training Loss: 0.2381995590403676, Training Accuracy: 0.9427083333333334\n",
            "Epoch 9/10, Batch Loss: 0.23811696469783783, Average Training Loss: 0.2381962552666664, Training Accuracy: 0.9425\n",
            "Epoch 9/10, Batch Loss: 0.18793009221553802, Average Training Loss: 0.23626294130316147, Training Accuracy: 0.9435096153846154\n",
            "Epoch 9/10, Batch Loss: 0.30973342061042786, Average Training Loss: 0.23898407016639356, Training Accuracy: 0.9421296296296297\n",
            "Epoch 9/10, Batch Loss: 0.18825271725654602, Average Training Loss: 0.237172236133899, Training Accuracy: 0.9419642857142857\n",
            "Epoch 9/10, Batch Loss: 0.2662239670753479, Average Training Loss: 0.23817401995946622, Training Accuracy: 0.9407327586206896\n",
            "Epoch 9/10, Batch Loss: 0.46442127227783203, Average Training Loss: 0.24571559503674506, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.23302774131298065, Average Training Loss: 0.24530630943275267, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.23946721851825714, Average Training Loss: 0.24512383784167469, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.20333991944789886, Average Training Loss: 0.24385765849640875, Training Accuracy: 0.9384469696969697\n",
            "Epoch 9/10, Batch Loss: 0.2582266330718994, Average Training Loss: 0.2442802753956879, Training Accuracy: 0.9384191176470589\n",
            "Epoch 9/10, Batch Loss: 0.21827815473079681, Average Training Loss: 0.24353735766240528, Training Accuracy: 0.9392857142857143\n",
            "Epoch 9/10, Batch Loss: 0.36149728298187256, Average Training Loss: 0.2468140222546127, Training Accuracy: 0.9366319444444444\n",
            "Epoch 9/10, Batch Loss: 0.28336742520332336, Average Training Loss: 0.24780195206403732, Training Accuracy: 0.9366554054054054\n",
            "Epoch 9/10, Batch Loss: 0.14606735110282898, Average Training Loss: 0.24512472572295288, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.24332965910434723, Average Training Loss: 0.24507869837375787, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.17106115818023682, Average Training Loss: 0.24322825986891985, Training Accuracy: 0.9375\n",
            "Epoch 9/10, Batch Loss: 0.11588656157255173, Average Training Loss: 0.24012236478852061, Training Accuracy: 0.9390243902439024\n",
            "Epoch 9/10, Batch Loss: 0.16052503883838654, Average Training Loss: 0.2382271903611365, Training Accuracy: 0.9404761904761905\n",
            "Epoch 9/10, Batch Loss: 0.14416979253292084, Average Training Loss: 0.23603980901629426, Training Accuracy: 0.9418604651162791\n",
            "Epoch 9/10, Batch Loss: 0.22539396584033966, Average Training Loss: 0.23579785803502257, Training Accuracy: 0.9424715909090909\n",
            "Epoch 9/10, Batch Loss: 0.1375056356191635, Average Training Loss: 0.23361358642578126, Training Accuracy: 0.9430555555555555\n",
            "Epoch 9/10, Batch Loss: 0.19840377569198608, Average Training Loss: 0.23284815575765527, Training Accuracy: 0.9429347826086957\n",
            "Epoch 9/10, Batch Loss: 0.14195133745670319, Average Training Loss: 0.2309141809001882, Training Accuracy: 0.9434840425531915\n",
            "Epoch 9/10, Batch Loss: 0.18398797512054443, Average Training Loss: 0.2299365516131123, Training Accuracy: 0.9440104166666666\n",
            "Epoch 9/10, Batch Loss: 0.41234707832336426, Average Training Loss: 0.2336592154235256, Training Accuracy: 0.9438775510204082\n",
            "Epoch 9/10, Batch Loss: 0.2542599141597748, Average Training Loss: 0.2340712293982506, Training Accuracy: 0.94375\n",
            "Epoch 9/10, Batch Loss: 0.1291380077600479, Average Training Loss: 0.2320137152484819, Training Accuracy: 0.9448529411764706\n",
            "Epoch 9/10, Batch Loss: 0.35083088278770447, Average Training Loss: 0.23429866077808234, Training Accuracy: 0.9435096153846154\n",
            "Epoch 9/10, Batch Loss: 0.11408762633800507, Average Training Loss: 0.23203052805279786, Training Accuracy: 0.9439858490566038\n",
            "Epoch 9/10, Batch Loss: 0.23536564409732819, Average Training Loss: 0.2320922894610299, Training Accuracy: 0.9438657407407407\n",
            "Epoch 9/10, Batch Loss: 0.25950562953948975, Average Training Loss: 0.2325907138260928, Training Accuracy: 0.9443181818181818\n",
            "Epoch 9/10, Batch Loss: 0.2051776796579361, Average Training Loss: 0.2321011953588043, Training Accuracy: 0.9447544642857143\n",
            "Epoch 9/10, Batch Loss: 0.3589233458042145, Average Training Loss: 0.2343261453666185, Training Accuracy: 0.9429824561403509\n",
            "Epoch 9/10, Batch Loss: 0.11554846912622452, Average Training Loss: 0.23227825439695654, Training Accuracy: 0.943426724137931\n",
            "Epoch 9/10, Average Training Loss: 0.23227825439695654, Training Accuracy: 0.943426724137931\n",
            "Epoch 9/10, Validation Loss: 15.39225709438324, Validation Accuracy: 0.6724137931034483\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.66      0.64      0.65        99\n",
            "                Educational Opportunity       0.52      0.53      0.53        87\n",
            "                         Family Support       0.80      0.90      0.85        93\n",
            "                      Financial Support       0.66      0.70      0.68        89\n",
            "                 Program Implementation       0.70      0.59      0.64        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.67      0.67      0.67       464\n",
            "                           weighted avg       0.67      0.67      0.67       464\n",
            "\n",
            "Epoch 10/10, Batch Loss: 0.14051301777362823, Average Training Loss: 0.14051301777362823, Training Accuracy: 0.96875\n",
            "Epoch 10/10, Batch Loss: 0.17207422852516174, Average Training Loss: 0.156293623149395, Training Accuracy: 0.984375\n",
            "Epoch 10/10, Batch Loss: 0.12248759716749191, Average Training Loss: 0.14502494782209396, Training Accuracy: 0.9895833333333334\n",
            "Epoch 10/10, Batch Loss: 0.12134048342704773, Average Training Loss: 0.1391038317233324, Training Accuracy: 0.984375\n",
            "Epoch 10/10, Batch Loss: 0.4369639754295349, Average Training Loss: 0.19867586046457292, Training Accuracy: 0.95625\n",
            "Epoch 10/10, Batch Loss: 0.21597063541412354, Average Training Loss: 0.2015583229561647, Training Accuracy: 0.9583333333333334\n",
            "Epoch 10/10, Batch Loss: 0.41956716775894165, Average Training Loss: 0.23270244364227569, Training Accuracy: 0.9508928571428571\n",
            "Epoch 10/10, Batch Loss: 0.21485094726085663, Average Training Loss: 0.2304710065945983, Training Accuracy: 0.953125\n",
            "Epoch 10/10, Batch Loss: 0.12464548647403717, Average Training Loss: 0.2187126154700915, Training Accuracy: 0.9548611111111112\n",
            "Epoch 10/10, Batch Loss: 0.129571795463562, Average Training Loss: 0.20979853346943855, Training Accuracy: 0.959375\n",
            "Epoch 10/10, Batch Loss: 0.33503592014312744, Average Training Loss: 0.2211837504397739, Training Accuracy: 0.9517045454545454\n",
            "Epoch 10/10, Batch Loss: 0.32509782910346985, Average Training Loss: 0.2298432569950819, Training Accuracy: 0.9479166666666666\n",
            "Epoch 10/10, Batch Loss: 0.21901720762252808, Average Training Loss: 0.22901048396642393, Training Accuracy: 0.9447115384615384\n",
            "Epoch 10/10, Batch Loss: 0.16302330791950226, Average Training Loss: 0.22429711424878665, Training Accuracy: 0.9464285714285714\n",
            "Epoch 10/10, Batch Loss: 0.15652507543563843, Average Training Loss: 0.2197789783279101, Training Accuracy: 0.9458333333333333\n",
            "Epoch 10/10, Batch Loss: 0.2028629630804062, Average Training Loss: 0.2187217273749411, Training Accuracy: 0.9453125\n",
            "Epoch 10/10, Batch Loss: 0.09537626057863235, Average Training Loss: 0.2114661116810406, Training Accuracy: 0.9485294117647058\n",
            "Epoch 10/10, Batch Loss: 0.23177507519721985, Average Training Loss: 0.21259438743193945, Training Accuracy: 0.9461805555555556\n",
            "Epoch 10/10, Batch Loss: 0.10805585235357285, Average Training Loss: 0.20709235926992015, Training Accuracy: 0.9490131578947368\n",
            "Epoch 10/10, Batch Loss: 0.26313623785972595, Average Training Loss: 0.20989455319941044, Training Accuracy: 0.9484375\n",
            "Epoch 10/10, Batch Loss: 0.08135714381933212, Average Training Loss: 0.20377372418131148, Training Accuracy: 0.9508928571428571\n",
            "Epoch 10/10, Batch Loss: 0.25103145837783813, Average Training Loss: 0.20592180300842633, Training Accuracy: 0.9502840909090909\n",
            "Epoch 10/10, Batch Loss: 0.1898033171892166, Average Training Loss: 0.20522099927715634, Training Accuracy: 0.9510869565217391\n",
            "Epoch 10/10, Batch Loss: 0.09328779578208923, Average Training Loss: 0.2005571157981952, Training Accuracy: 0.953125\n",
            "Epoch 10/10, Batch Loss: 0.10821223258972168, Average Training Loss: 0.19686332046985627, Training Accuracy: 0.955\n",
            "Epoch 10/10, Batch Loss: 0.13967934250831604, Average Training Loss: 0.19466393670210472, Training Accuracy: 0.9555288461538461\n",
            "Epoch 10/10, Batch Loss: 0.15191450715065002, Average Training Loss: 0.1930806244964953, Training Accuracy: 0.9560185185185185\n",
            "Epoch 10/10, Batch Loss: 0.14065051078796387, Average Training Loss: 0.1912081204354763, Training Accuracy: 0.9564732142857143\n",
            "Epoch 10/10, Batch Loss: 0.2915598750114441, Average Training Loss: 0.19466852576568208, Training Accuracy: 0.9558189655172413\n",
            "Epoch 10/10, Batch Loss: 0.3085438013076782, Average Training Loss: 0.19846436828374864, Training Accuracy: 0.9552083333333333\n",
            "Epoch 10/10, Batch Loss: 0.1415206640958786, Average Training Loss: 0.19662747460026894, Training Accuracy: 0.9556451612903226\n",
            "Epoch 10/10, Batch Loss: 0.20764178037643433, Average Training Loss: 0.19697167165577412, Training Accuracy: 0.955078125\n",
            "Epoch 10/10, Batch Loss: 0.28786709904670715, Average Training Loss: 0.19972607854640845, Training Accuracy: 0.9545454545454546\n",
            "Epoch 10/10, Batch Loss: 0.36663517355918884, Average Training Loss: 0.2046351695761961, Training Accuracy: 0.953125\n",
            "Epoch 10/10, Batch Loss: 0.3026452362537384, Average Training Loss: 0.20743545719555445, Training Accuracy: 0.9517857142857142\n",
            "Epoch 10/10, Batch Loss: 0.15097841620445251, Average Training Loss: 0.20586720605691275, Training Accuracy: 0.9522569444444444\n",
            "Epoch 10/10, Batch Loss: 0.11062520742416382, Average Training Loss: 0.20329309798575737, Training Accuracy: 0.9535472972972973\n",
            "Epoch 10/10, Batch Loss: 0.2896019518375397, Average Training Loss: 0.20556438361343585, Training Accuracy: 0.9523026315789473\n",
            "Epoch 10/10, Batch Loss: 0.18763887882232666, Average Training Loss: 0.20510475528545868, Training Accuracy: 0.9527243589743589\n",
            "Epoch 10/10, Batch Loss: 0.5315130949020386, Average Training Loss: 0.21326496377587317, Training Accuracy: 0.95078125\n",
            "Epoch 10/10, Batch Loss: 0.24150198698043823, Average Training Loss: 0.21395367165891135, Training Accuracy: 0.9504573170731707\n",
            "Epoch 10/10, Batch Loss: 0.1280587613582611, Average Training Loss: 0.2119085547469911, Training Accuracy: 0.9508928571428571\n",
            "Epoch 10/10, Batch Loss: 0.17673949897289276, Average Training Loss: 0.21109066972898882, Training Accuracy: 0.9513081395348837\n",
            "Epoch 10/10, Batch Loss: 0.26573342084884644, Average Training Loss: 0.21233255043625832, Training Accuracy: 0.9502840909090909\n",
            "Epoch 10/10, Batch Loss: 0.18186233937740326, Average Training Loss: 0.21165543463495043, Training Accuracy: 0.9506944444444444\n",
            "Epoch 10/10, Batch Loss: 0.27478674054145813, Average Training Loss: 0.21302785432857016, Training Accuracy: 0.9504076086956522\n",
            "Epoch 10/10, Batch Loss: 0.3616122007369995, Average Training Loss: 0.21618922340108992, Training Accuracy: 0.9488031914893617\n",
            "Epoch 10/10, Batch Loss: 0.23631101846694946, Average Training Loss: 0.216608427464962, Training Accuracy: 0.9479166666666666\n",
            "Epoch 10/10, Batch Loss: 0.15949924290180206, Average Training Loss: 0.21544293390244854, Training Accuracy: 0.9477040816326531\n",
            "Epoch 10/10, Batch Loss: 0.09825965762138367, Average Training Loss: 0.21309926837682724, Training Accuracy: 0.94875\n",
            "Epoch 10/10, Batch Loss: 0.1593542844057083, Average Training Loss: 0.21204544516170726, Training Accuracy: 0.9491421568627451\n",
            "Epoch 10/10, Batch Loss: 0.2927321791648865, Average Training Loss: 0.21359711312330687, Training Accuracy: 0.9489182692307693\n",
            "Epoch 10/10, Batch Loss: 0.09283538907766342, Average Training Loss: 0.21131859002810605, Training Accuracy: 0.9498820754716981\n",
            "Epoch 10/10, Batch Loss: 0.10131104290485382, Average Training Loss: 0.20928141322952729, Training Accuracy: 0.9508101851851852\n",
            "Epoch 10/10, Batch Loss: 0.30015891790390015, Average Training Loss: 0.21093373149633407, Training Accuracy: 0.9505681818181818\n",
            "Epoch 10/10, Batch Loss: 0.3095838129520416, Average Training Loss: 0.21269534009375743, Training Accuracy: 0.9508928571428571\n",
            "Epoch 10/10, Batch Loss: 0.18355078995227814, Average Training Loss: 0.2121840321965385, Training Accuracy: 0.9517543859649122\n",
            "Epoch 10/10, Batch Loss: 0.11830253154039383, Average Training Loss: 0.21056538563350152, Training Accuracy: 0.9520474137931034\n",
            "Epoch 10/10, Average Training Loss: 0.21056538563350152, Training Accuracy: 0.9520474137931034\n",
            "Epoch 10/10, Validation Loss: 15.667742431163788, Validation Accuracy: 0.665948275862069\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.60      0.64        99\n",
            "                Educational Opportunity       0.49      0.55      0.52        87\n",
            "                         Family Support       0.80      0.90      0.85        93\n",
            "                      Financial Support       0.66      0.66      0.66        89\n",
            "                 Program Implementation       0.69      0.61      0.65        96\n",
            "\n",
            "                               accuracy                           0.67       464\n",
            "                              macro avg       0.67      0.67      0.66       464\n",
            "                           weighted avg       0.67      0.67      0.66       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Test_Data.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_masks)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Calculate test accuracy and other metrics\n",
        "test_accuracy = accuracy_score(true_test_labels, test_predictions)\n",
        "test_classification_report = classification_report(true_test_labels, test_predictions, target_names=label_encoder.classes_)\n",
        "conf_matrix = confusion_matrix(true_test_labels, test_predictions)\n",
        "\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
        "print('Test Classification Report:')\n",
        "print(test_classification_report)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/Test_Data.csvv\"\n",
        "test_df['Predicted_Label'] = label_encoder.inverse_transform(test_predictions)\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels for the test set saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "wHVgriMFYfmq",
        "outputId": "3bbfbb4c-a4c9-41a1-86b4-58850148dcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1c32c2919d9e>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true_test_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3bbacc241585>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Calculate test accuracy and other metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mtest_classification_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true_test_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Testing-Dataset.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted Labels'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_labels = label_encoder.transform(test_df['True Labels'])\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Display test accuracy\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Calculate other metrics (precision, recall, F1 score, confusion matrix)\n",
        "test_classification_report = classification_report(test_labels, test_predictions, target_names=label_encoder.classes_)\n",
        "test_confusion_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Display other metrics\n",
        "print('Test Classification Report:')\n",
        "print(test_classification_report)\n",
        "print('Test Confusion Matrix:')\n",
        "print(test_confusion_matrix)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2isI5cWg9Xx",
        "outputId": "da167379-a3be-4e6b-956d-be9bf23bbc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b46c4898d9bf>:34: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5759075907590759\n",
            "Test Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.52      0.60      0.56       108\n",
            "                Educational Opportunity       0.41      0.48      0.44       116\n",
            "                         Family Support       0.72      0.90      0.80        90\n",
            "                      Financial Support       0.56      0.64      0.60       106\n",
            "                 Program Implementation       0.72      0.42      0.54       186\n",
            "\n",
            "                               accuracy                           0.58       606\n",
            "                              macro avg       0.59      0.61      0.59       606\n",
            "                           weighted avg       0.60      0.58      0.57       606\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[65 15  7  8 13]\n",
            " [29 56  8 13 10]\n",
            " [ 2  1 81  4  2]\n",
            " [ 3 21  9 68  5]\n",
            " [26 45  8 28 79]]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Testing-Dataset.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted Labels'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_labels = label_encoder.transform(test_df['True Labels'])\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Display test accuracy\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Calculate other metrics (precision, recall, F1 score, confusion matrix)\n",
        "test_classification_report = classification_report(test_labels, test_predictions, target_names=label_encoder.classes_)\n",
        "test_confusion_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Display other metrics\n",
        "print('Test Classification Report:')\n",
        "print(test_classification_report)\n",
        "print('Test Confusion Matrix:')\n",
        "print(test_confusion_matrix)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-vHLyTVoWIb",
        "outputId": "a30231bc-1efe-42b9-835c-f551640f1d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f04af53c2927>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6567656765676567\n",
            "Test Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.68      0.66       108\n",
            "                Educational Opportunity       0.45      0.71      0.55       116\n",
            "                         Family Support       0.92      0.87      0.89        90\n",
            "                      Financial Support       0.63      0.69      0.66       106\n",
            "                 Program Implementation       0.84      0.49      0.62       186\n",
            "\n",
            "                               accuracy                           0.66       606\n",
            "                              macro avg       0.70      0.69      0.68       606\n",
            "                           weighted avg       0.70      0.66      0.66       606\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[73 19  1 10  5]\n",
            " [18 82  2  6  8]\n",
            " [ 3  4 78  5  0]\n",
            " [ 4 22  2 73  5]\n",
            " [16 54  2 22 92]]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction with No True Label\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Test_Data_Experience.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted_Label'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(test_df[['Responses', 'Predicted_Label']])\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-DGKi6NkAIh",
        "outputId": "ac35ccf4-f71c-4ed2-bfe3-6d4bf9929414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-37758020bac2>:32: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Responses  \\\n",
            "0    \"We were able to save more money because of th...   \n",
            "1              \"It gives access to quality education.\"   \n",
            "2    \"It was honestly a big help since the budget f...   \n",
            "3    \"The UAQTE gave students the opportunity to en...   \n",
            "4    \"It has given my college experience a good one...   \n",
            "..                                                 ...   \n",
            "596  \"The UAQTE provides free access to education w...   \n",
            "597  \"Despite being free, quality education was sti...   \n",
            "598  \"I also like the fact that the selection proce...   \n",
            "599  \"The UAQTE Act made a significant difference i...   \n",
            "600  \"It opened doors to higher education that were...   \n",
            "\n",
            "             Predicted_Label  \n",
            "0          Financial Support  \n",
            "1    Educational Opportunity  \n",
            "2          Financial Support  \n",
            "3    Educational Opportunity  \n",
            "4    Educational Opportunity  \n",
            "..                       ...  \n",
            "596  Educational Opportunity  \n",
            "597  Educational Opportunity  \n",
            "598   Program Implementation  \n",
            "599   Program Implementation  \n",
            "600  Educational Opportunity  \n",
            "\n",
            "[601 rows x 2 columns]\n",
            "Predicted labels saved to /content/drive/MyDrive/Dissertation_UC/predicted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous code)\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_file_path = \"/content/drive/MyDrive/Dissertation_UC/Test_Data.csv\"\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "test_df['Processed_Response'] = test_df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize test data\n",
        "test_inputs, test_masks = tokenize_text(test_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "for batch in DataLoader(TensorDataset(test_inputs, test_masks), batch_size=batch_size):\n",
        "    inputs, masks = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "    logits = outputs.logits\n",
        "    preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Map predictions back to labels\n",
        "test_df['Predicted_Label'] = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "predicted_csv_path = \"/content/drive/MyDrive/Dissertation_UC/predicted.csv\"\n",
        "test_df.to_csv(predicted_csv_path, index=False)\n",
        "\n",
        "# Display a message indicating that the file has been saved\n",
        "print(f'Predicted labels saved to {predicted_csv_path}')\n",
        "\n",
        "# Assuming you have a CSV file with validated labels, load it\n",
        "validated_labels_path = \"/path/to/validated_labels.csv\"\n",
        "validated_df = pd.read_csv(validated_labels_path)\n",
        "\n",
        "# Ensure that the order of responses in test_df matches the order in validated_df\n",
        "# Assuming that 'Responses' is the common column between test_df and validated_df\n",
        "test_df = test_df.merge(validated_df[['Responses', 'Validated_Label']], on='Responses', how='left')\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "true_labels = label_encoder.transform(test_df['Validated_Label'])\n",
        "predicted_labels = label_encoder.transform(test_df['Predicted_Label'])\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "classification_report = classification_report(true_labels, predicted_labels, target_names=label_encoder.classes_)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "print('Test Classification Report:')\n",
        "print(classification_report)\n"
      ],
      "metadata": {
        "id": "ALlJxhuKn3C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7257e4f3d51843309f8a73c1b4434822",
            "9b758357636c4c5f9413e8b9d38b6cff",
            "09da9858bf5447f8893ad56f401dacd5",
            "d1867f9b9bcd4a0b887e2c8272b5e3ce",
            "60a6dcb138ec4a7c81043aa9b826610d",
            "f8e79c19c623423bbd61826740038c3c",
            "6a1ca34602384c84a345ad0ae33889a7",
            "7eb1d0a3f216410c9bb01c51532c7965",
            "8b2df60f04c84d76a6d65ac82807ada0",
            "d4bc25d6e0774855aaa61e87b4c385db",
            "6629d806ed0c421c968b4ab2b9c61ad6",
            "5ed2190dc4f443528c2b715543c93fd9",
            "07531ee610a046be9d9306331823cd9a",
            "02fa65ecca9b4e36b6d514cd54e78cf5",
            "62be74c8627b4f32a849e778c3a42d5c",
            "9ea3a79f512e4d46bd6204b047d089dd",
            "04c0bd12108c4380a65646537f8717fb",
            "6d6e0acdc5e14e9498880e1de55c57dc",
            "00b4a5cd2e4240b98a164b708944b7f8",
            "c2bd9d45cb8c49289d0334ace5419300",
            "57095181912949689e209b0e8529faf6",
            "5af42680915c4d00a4035de6af198965",
            "d5777a45b0e3457cba9486587cb8acfb",
            "f348ddb5a9ad4c38a8908f777a422fcb",
            "b25de63419904bcc97d1e355fd02958e",
            "d1583dad5a1a42c18bbf4ea8186a2c77",
            "532d7e41a65a4006b5d4980bfa7f54fd",
            "4fd860928cfd408e85d6e64048c0310f",
            "de1e592ce6fc4dc5b9121c169b080efd",
            "18eb58adeab7469c932662eeacafd203",
            "4fc6518aa1bf4f9c9e7a422b1f0ef217",
            "dbd3042e557d46e0b27a9195eecfcf1b",
            "f5b314ef52974613bc4886d1faf6f633",
            "886d1bf66e7343d78f5223e6d269c23e",
            "feebaf3082644270810a33cb3cd8f7ac",
            "c29942236e3b41128ca3f9dc139427ef",
            "c7c7c517a57b4a8e83143dd229843a8c",
            "e7647ec20dc8451bb24d7a1822ce22ca",
            "927f31f0f3ae4e09950e7b16743f4676",
            "925946e641e147379010cc97a90e5749",
            "808ad27558b3451a9d981e6d6b7458fb",
            "666cb4109a3647ccae25e36002e8dd9b",
            "4c46b109d8d24354854565ec96baf847",
            "3c90b8887fd54d8795ce86ad076e410c",
            "1811b8fee39f4b3188cbb8869a3a13af",
            "fcdb0fd9e7064ccb88e7f0a0754dc340",
            "3826c490fa56421eb67434d983796c9f",
            "8137629d5e294ee086902ec57bbab591",
            "fe157c1f4a5544c5859b30acf4e93a91",
            "0f81e4c965164a798609aa7ae704b8e3",
            "cc007374fcad4c19b2f25ce0f23ccff3",
            "7d32c255303b411180ebe6fdb1a18fad",
            "6e2b029042054cc9b71cb178cd573a2c",
            "870993d9d4c44fe9afeb73dc491d4b7e",
            "46b336be77df469196b40f9a02107d1a"
          ]
        },
        "id": "Z1LVq77R6C9t",
        "outputId": "c2342843-27fb-46c7-90fe-7a0dc001e92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<ipython-input-2-bb3b6dde8e82>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7257e4f3d51843309f8a73c1b4434822"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ed2190dc4f443528c2b715543c93fd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5777a45b0e3457cba9486587cb8acfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "886d1bf66e7343d78f5223e6d269c23e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1811b8fee39f4b3188cbb8869a3a13af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.6605498790740967, Average Training Loss: 1.6605498790740967, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.7241383790969849, Average Training Loss: 1.6923441290855408, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.5882024765014648, Average Training Loss: 1.6576302448908489, Training Accuracy: 0.14583333333333334\n",
            "Epoch 1/1, Batch Loss: 1.5249766111373901, Average Training Loss: 1.6244668364524841, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.5881320238113403, Average Training Loss: 1.6171998739242555, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.599433183670044, Average Training Loss: 1.6142387588818867, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.6526724100112915, Average Training Loss: 1.6197292804718018, Training Accuracy: 0.17857142857142858\n",
            "Epoch 1/1, Batch Loss: 1.6471292972564697, Average Training Loss: 1.6231542825698853, Training Accuracy: 0.1640625\n",
            "Epoch 1/1, Batch Loss: 1.5935280323028564, Average Training Loss: 1.61986247698466, Training Accuracy: 0.1597222222222222\n",
            "Epoch 1/1, Batch Loss: 1.6029268503189087, Average Training Loss: 1.6181689143180846, Training Accuracy: 0.15\n",
            "Epoch 1/1, Batch Loss: 1.590663194656372, Average Training Loss: 1.6156683943488381, Training Accuracy: 0.16477272727272727\n",
            "Epoch 1/1, Batch Loss: 1.5455620288848877, Average Training Loss: 1.6098261972268422, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.5366101264953613, Average Training Loss: 1.604194191785959, Training Accuracy: 0.19230769230769232\n",
            "Epoch 1/1, Batch Loss: 1.501333475112915, Average Training Loss: 1.5968469977378845, Training Accuracy: 0.20089285714285715\n",
            "Epoch 1/1, Batch Loss: 1.4811244010925293, Average Training Loss: 1.5891321579615274, Training Accuracy: 0.2125\n",
            "Epoch 1/1, Batch Loss: 1.5093259811401367, Average Training Loss: 1.5841442719101906, Training Accuracy: 0.22265625\n",
            "Epoch 1/1, Batch Loss: 1.6136857271194458, Average Training Loss: 1.5858820045695585, Training Accuracy: 0.22794117647058823\n",
            "Epoch 1/1, Batch Loss: 1.5993385314941406, Average Training Loss: 1.586629589398702, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/1, Batch Loss: 1.6429424285888672, Average Training Loss: 1.5895934230402897, Training Accuracy: 0.23026315789473684\n",
            "Epoch 1/1, Batch Loss: 1.510711908340454, Average Training Loss: 1.585649347305298, Training Accuracy: 0.2375\n",
            "Epoch 1/1, Batch Loss: 1.5160682201385498, Average Training Loss: 1.5823359602973575, Training Accuracy: 0.24702380952380953\n",
            "Epoch 1/1, Batch Loss: 1.363473653793335, Average Training Loss: 1.5723876736380837, Training Accuracy: 0.2585227272727273\n",
            "Epoch 1/1, Batch Loss: 1.5302958488464355, Average Training Loss: 1.5705575942993164, Training Accuracy: 0.26358695652173914\n",
            "Epoch 1/1, Batch Loss: 1.4780160188674927, Average Training Loss: 1.5667016953229904, Training Accuracy: 0.265625\n",
            "Epoch 1/1, Batch Loss: 1.6165046691894531, Average Training Loss: 1.568693814277649, Training Accuracy: 0.2625\n",
            "Epoch 1/1, Batch Loss: 1.5359995365142822, Average Training Loss: 1.567436342055981, Training Accuracy: 0.2620192307692308\n",
            "Epoch 1/1, Batch Loss: 1.4864493608474731, Average Training Loss: 1.5644368242334437, Training Accuracy: 0.26157407407407407\n",
            "Epoch 1/1, Batch Loss: 1.54682195186615, Average Training Loss: 1.5638077216488975, Training Accuracy: 0.26785714285714285\n",
            "Epoch 1/1, Batch Loss: 1.478190541267395, Average Training Loss: 1.560855405084018, Training Accuracy: 0.27155172413793105\n",
            "Epoch 1/1, Batch Loss: 1.5098367929458618, Average Training Loss: 1.559154784679413, Training Accuracy: 0.2791666666666667\n",
            "Epoch 1/1, Batch Loss: 1.4147799015045166, Average Training Loss: 1.5544975303834485, Training Accuracy: 0.28830645161290325\n",
            "Epoch 1/1, Batch Loss: 1.4099160432815552, Average Training Loss: 1.5499793589115143, Training Accuracy: 0.298828125\n",
            "Epoch 1/1, Batch Loss: 1.4775108098983765, Average Training Loss: 1.5477833422747524, Training Accuracy: 0.30113636363636365\n",
            "Epoch 1/1, Batch Loss: 1.4928126335144043, Average Training Loss: 1.5461665567229776, Training Accuracy: 0.29963235294117646\n",
            "Epoch 1/1, Batch Loss: 1.3440831899642944, Average Training Loss: 1.540392746244158, Training Accuracy: 0.30714285714285716\n",
            "Epoch 1/1, Batch Loss: 1.3938038349151611, Average Training Loss: 1.5363208320405748, Training Accuracy: 0.3125\n",
            "Epoch 1/1, Batch Loss: 1.3957815170288086, Average Training Loss: 1.5325224721753918, Training Accuracy: 0.31925675675675674\n",
            "Epoch 1/1, Batch Loss: 1.4708548784255981, Average Training Loss: 1.5308996407609237, Training Accuracy: 0.3223684210526316\n",
            "Epoch 1/1, Batch Loss: 1.50428307056427, Average Training Loss: 1.530217164602035, Training Accuracy: 0.32051282051282054\n",
            "Epoch 1/1, Batch Loss: 1.3212026357650757, Average Training Loss: 1.5249918013811112, Training Accuracy: 0.328125\n",
            "Epoch 1/1, Batch Loss: 1.3707623481750488, Average Training Loss: 1.5212301074004755, Training Accuracy: 0.3323170731707317\n",
            "Epoch 1/1, Batch Loss: 1.2111949920654297, Average Training Loss: 1.5138483189401173, Training Accuracy: 0.33630952380952384\n",
            "Epoch 1/1, Batch Loss: 1.4567731618881226, Average Training Loss: 1.5125209897063498, Training Accuracy: 0.33575581395348836\n",
            "Epoch 1/1, Batch Loss: 1.401345133781433, Average Training Loss: 1.5099942657080563, Training Accuracy: 0.3366477272727273\n",
            "Epoch 1/1, Batch Loss: 1.5623408555984497, Average Training Loss: 1.5111575232611762, Training Accuracy: 0.3347222222222222\n",
            "Epoch 1/1, Batch Loss: 1.13680899143219, Average Training Loss: 1.5030195116996765, Training Accuracy: 0.34375\n",
            "Epoch 1/1, Batch Loss: 1.2382861375808716, Average Training Loss: 1.4973868867184252, Training Accuracy: 0.35106382978723405\n",
            "Epoch 1/1, Batch Loss: 1.056762456893921, Average Training Loss: 1.4882072110970814, Training Accuracy: 0.359375\n",
            "Epoch 1/1, Batch Loss: 1.2426087856292725, Average Training Loss: 1.4831949983324324, Training Accuracy: 0.3635204081632653\n",
            "Epoch 1/1, Batch Loss: 1.298876404762268, Average Training Loss: 1.479508626461029, Training Accuracy: 0.36375\n",
            "Epoch 1/1, Batch Loss: 1.2540497779846191, Average Training Loss: 1.4750878647261976, Training Accuracy: 0.36642156862745096\n",
            "Epoch 1/1, Batch Loss: 1.007707953453064, Average Training Loss: 1.4660997895094066, Training Accuracy: 0.37259615384615385\n",
            "Epoch 1/1, Batch Loss: 1.0096464157104492, Average Training Loss: 1.457487461701879, Training Accuracy: 0.37971698113207547\n",
            "Epoch 1/1, Batch Loss: 1.1013734340667725, Average Training Loss: 1.450892757486414, Training Accuracy: 0.3854166666666667\n",
            "Epoch 1/1, Batch Loss: 1.1120940446853638, Average Training Loss: 1.4447327808900312, Training Accuracy: 0.38977272727272727\n",
            "Epoch 1/1, Batch Loss: 1.0521942377090454, Average Training Loss: 1.4377231640475137, Training Accuracy: 0.39620535714285715\n",
            "Epoch 1/1, Batch Loss: 0.9169661402702332, Average Training Loss: 1.4285870759110701, Training Accuracy: 0.40350877192982454\n",
            "Epoch 1/1, Batch Loss: 0.933477520942688, Average Training Loss: 1.4200507042736843, Training Accuracy: 0.40948275862068967\n",
            "Epoch 1/1, Batch Loss: 1.2704479694366455, Average Training Loss: 1.417515064700175, Training Accuracy: 0.4088983050847458\n",
            "Epoch 1/1, Batch Loss: 0.8785728812217712, Average Training Loss: 1.408532694975535, Training Accuracy: 0.4125\n",
            "Epoch 1/1, Batch Loss: 1.098055124282837, Average Training Loss: 1.4034428987346712, Training Accuracy: 0.41598360655737704\n",
            "Epoch 1/1, Batch Loss: 1.1648480892181396, Average Training Loss: 1.3995945953553723, Training Accuracy: 0.4173387096774194\n",
            "Epoch 1/1, Batch Loss: 0.9925330281257629, Average Training Loss: 1.393133300637442, Training Accuracy: 0.42162698412698413\n",
            "Epoch 1/1, Batch Loss: 0.9079859852790833, Average Training Loss: 1.3855528738349676, Training Accuracy: 0.4248046875\n",
            "Epoch 1/1, Batch Loss: 1.0778381824493408, Average Training Loss: 1.3808188016598042, Training Accuracy: 0.42788461538461536\n",
            "Epoch 1/1, Batch Loss: 1.007521390914917, Average Training Loss: 1.3751627802848816, Training Accuracy: 0.4318181818181818\n",
            "Epoch 1/1, Batch Loss: 0.6301610469818115, Average Training Loss: 1.364043351429612, Training Accuracy: 0.4375\n",
            "Epoch 1/1, Batch Loss: 0.9535994529724121, Average Training Loss: 1.3580074117464178, Training Accuracy: 0.4420955882352941\n",
            "Epoch 1/1, Batch Loss: 0.9374808669090271, Average Training Loss: 1.3519128241400789, Training Accuracy: 0.4447463768115942\n",
            "Epoch 1/1, Batch Loss: 0.8926626443862915, Average Training Loss: 1.3453521072864532, Training Accuracy: 0.44910714285714287\n",
            "Epoch 1/1, Batch Loss: 0.6414642333984375, Average Training Loss: 1.3354381935697206, Training Accuracy: 0.4533450704225352\n",
            "Epoch 1/1, Batch Loss: 0.9915016293525696, Average Training Loss: 1.3306612968444824, Training Accuracy: 0.4565972222222222\n",
            "Epoch 1/1, Batch Loss: 0.9855858683586121, Average Training Loss: 1.3259342361802924, Training Accuracy: 0.4589041095890411\n",
            "Epoch 1/1, Batch Loss: 0.8344532251358032, Average Training Loss: 1.3192926008959074, Training Accuracy: 0.46283783783783783\n",
            "Epoch 1/1, Batch Loss: 0.884951651096344, Average Training Loss: 1.3135013882319133, Training Accuracy: 0.465\n",
            "Epoch 1/1, Batch Loss: 0.869873583316803, Average Training Loss: 1.307664180272504, Training Accuracy: 0.46710526315789475\n",
            "Epoch 1/1, Batch Loss: 0.7434819340705872, Average Training Loss: 1.3003371381140374, Training Accuracy: 0.4699675324675325\n",
            "Epoch 1/1, Batch Loss: 1.140252947807312, Average Training Loss: 1.2982847766998487, Training Accuracy: 0.47275641025641024\n",
            "Epoch 1/1, Batch Loss: 0.8322615623474121, Average Training Loss: 1.292385748670071, Training Accuracy: 0.47468354430379744\n",
            "Epoch 1/1, Batch Loss: 0.9904747009277344, Average Training Loss: 1.2886118605732917, Training Accuracy: 0.4765625\n",
            "Epoch 1/1, Batch Loss: 0.9169049859046936, Average Training Loss: 1.284022886811951, Training Accuracy: 0.4799382716049383\n",
            "Epoch 1/1, Batch Loss: 1.2711081504821777, Average Training Loss: 1.2838653900274417, Training Accuracy: 0.4801829268292683\n",
            "Epoch 1/1, Batch Loss: 0.8825138807296753, Average Training Loss: 1.2790298296744564, Training Accuracy: 0.48343373493975905\n",
            "Epoch 1/1, Batch Loss: 0.7594276666641235, Average Training Loss: 1.2728440896386193, Training Accuracy: 0.48735119047619047\n",
            "Epoch 1/1, Batch Loss: 0.7519571185112, Average Training Loss: 1.2667160076253554, Training Accuracy: 0.49117647058823527\n",
            "Epoch 1/1, Batch Loss: 0.777187168598175, Average Training Loss: 1.2610238118227137, Training Accuracy: 0.4934593023255814\n",
            "Epoch 1/1, Batch Loss: 0.8855969905853271, Average Training Loss: 1.2567085610038933, Training Accuracy: 0.4949712643678161\n",
            "Epoch 1/1, Batch Loss: 0.8089173436164856, Average Training Loss: 1.2516200244426727, Training Accuracy: 0.4978693181818182\n",
            "Epoch 1/1, Batch Loss: 0.7652817368507385, Average Training Loss: 1.2461555493011902, Training Accuracy: 0.49929775280898875\n",
            "Epoch 1/1, Batch Loss: 0.6618160009384155, Average Training Loss: 1.2396628876527152, Training Accuracy: 0.5027777777777778\n",
            "Epoch 1/1, Batch Loss: 0.9509841799736023, Average Training Loss: 1.2364905941617357, Training Accuracy: 0.5054945054945055\n",
            "Epoch 1/1, Batch Loss: 0.7039876580238342, Average Training Loss: 1.2307025187689324, Training Accuracy: 0.5088315217391305\n",
            "Epoch 1/1, Batch Loss: 0.9062643647193909, Average Training Loss: 1.2272139364673245, Training Accuracy: 0.5100806451612904\n",
            "Epoch 1/1, Batch Loss: 1.1090037822723389, Average Training Loss: 1.225956381635463, Training Accuracy: 0.5113031914893617\n",
            "Epoch 1/1, Batch Loss: 0.7984984517097473, Average Training Loss: 1.2214568244783501, Training Accuracy: 0.5125\n",
            "Epoch 1/1, Batch Loss: 0.7986406683921814, Average Training Loss: 1.2170524895191193, Training Accuracy: 0.5143229166666666\n",
            "Epoch 1/1, Batch Loss: 1.0077862739562988, Average Training Loss: 1.2148951058535231, Training Accuracy: 0.5148195876288659\n",
            "Epoch 1/1, Batch Loss: 0.5798625946044922, Average Training Loss: 1.2084151822693494, Training Accuracy: 0.5178571428571429\n",
            "Epoch 1/1, Batch Loss: 0.5514622330665588, Average Training Loss: 1.2017792938935636, Training Accuracy: 0.5208333333333334\n",
            "Epoch 1/1, Batch Loss: 0.9864987730979919, Average Training Loss: 1.1996264886856078, Training Accuracy: 0.523125\n",
            "Epoch 1/1, Batch Loss: 0.7255070209503174, Average Training Loss: 1.194932236529813, Training Accuracy: 0.5247524752475248\n",
            "Epoch 1/1, Batch Loss: 0.791053295135498, Average Training Loss: 1.1909726390651627, Training Accuracy: 0.5263480392156863\n",
            "Epoch 1/1, Batch Loss: 0.7673088908195496, Average Training Loss: 1.1868593987909335, Training Accuracy: 0.5285194174757282\n",
            "Epoch 1/1, Batch Loss: 0.8595393300056458, Average Training Loss: 1.183712090437229, Training Accuracy: 0.5300480769230769\n",
            "Epoch 1/1, Batch Loss: 0.8079114556312561, Average Training Loss: 1.18013303677241, Training Accuracy: 0.531547619047619\n",
            "Epoch 1/1, Batch Loss: 0.6942976713180542, Average Training Loss: 1.1755496842681237, Training Accuracy: 0.5341981132075472\n",
            "Epoch 1/1, Batch Loss: 1.1930097341537476, Average Training Loss: 1.175712862304438, Training Accuracy: 0.5332943925233645\n",
            "Epoch 1/1, Batch Loss: 0.858848512172699, Average Training Loss: 1.1727789331365515, Training Accuracy: 0.5341435185185185\n",
            "Epoch 1/1, Batch Loss: 0.8512032628059387, Average Training Loss: 1.1698286976289312, Training Accuracy: 0.5361238532110092\n",
            "Epoch 1/1, Batch Loss: 0.44508615136146545, Average Training Loss: 1.1632401290264998, Training Accuracy: 0.5397727272727273\n",
            "Epoch 1/1, Batch Loss: 0.886543869972229, Average Training Loss: 1.1607473699359205, Training Accuracy: 0.5405405405405406\n",
            "Epoch 1/1, Batch Loss: 0.7506048679351807, Average Training Loss: 1.157085383310914, Training Accuracy: 0.5412946428571429\n",
            "Epoch 1/1, Batch Loss: 0.8600980639457703, Average Training Loss: 1.1544571769448508, Training Accuracy: 0.543141592920354\n",
            "Epoch 1/1, Batch Loss: 0.9639317989349365, Average Training Loss: 1.1527859016991497, Training Accuracy: 0.543859649122807\n",
            "Epoch 1/1, Batch Loss: 0.5810725092887878, Average Training Loss: 1.1478144808955815, Training Accuracy: 0.5456521739130434\n",
            "Epoch 1/1, Batch Loss: 0.5929650068283081, Average Training Loss: 1.1430312957743118, Training Accuracy: 0.5479525862068966\n",
            "Epoch 1/1, Batch Loss: 0.7144505977630615, Average Training Loss: 1.1393682128853269, Training Accuracy: 0.5496794871794872\n",
            "Epoch 1/1, Batch Loss: 1.0414679050445557, Average Training Loss: 1.1385385492595577, Training Accuracy: 0.5497881355932204\n",
            "Epoch 1/1, Batch Loss: 0.6574370861053467, Average Training Loss: 1.1344956798212869, Training Accuracy: 0.5519957983193278\n",
            "Epoch 1/1, Batch Loss: 0.9284952282905579, Average Training Loss: 1.1327790093918642, Training Accuracy: 0.5520833333333334\n",
            "Epoch 1/1, Batch Loss: 0.6559351682662964, Average Training Loss: 1.1288381512007437, Training Accuracy: 0.5542355371900827\n",
            "Epoch 1/1, Batch Loss: 0.7387378811836243, Average Training Loss: 1.125640608003882, Training Accuracy: 0.555327868852459\n",
            "Epoch 1/1, Batch Loss: 1.0653916597366333, Average Training Loss: 1.125150779156181, Training Accuracy: 0.5558943089430894\n",
            "Epoch 1/1, Batch Loss: 0.5944679975509644, Average Training Loss: 1.120871079304526, Training Accuracy: 0.5584677419354839\n",
            "Epoch 1/1, Batch Loss: 0.891430675983429, Average Training Loss: 1.1190355560779572, Training Accuracy: 0.5595\n",
            "Epoch 1/1, Batch Loss: 0.45487019419670105, Average Training Loss: 1.1137644024122328, Training Accuracy: 0.5620039682539683\n",
            "Epoch 1/1, Batch Loss: 0.6714603304862976, Average Training Loss: 1.1102816931844697, Training Accuracy: 0.5634842519685039\n",
            "Epoch 1/1, Batch Loss: 0.7444241046905518, Average Training Loss: 1.107423430774361, Training Accuracy: 0.5654296875\n",
            "Epoch 1/1, Batch Loss: 1.0604362487792969, Average Training Loss: 1.107059189053469, Training Accuracy: 0.565406976744186\n",
            "Epoch 1/1, Batch Loss: 0.5671828389167786, Average Training Loss: 1.1029062940524175, Training Accuracy: 0.5677884615384615\n",
            "Epoch 1/1, Batch Loss: 1.0170176029205322, Average Training Loss: 1.1022506551888154, Training Accuracy: 0.5682251908396947\n",
            "Epoch 1/1, Batch Loss: 0.6561487913131714, Average Training Loss: 1.0988710956139998, Training Accuracy: 0.5691287878787878\n",
            "Epoch 1/1, Batch Loss: 0.5031396150588989, Average Training Loss: 1.1016395401029848, Training Accuracy: 0.5695364238410596\n",
            "Epoch 1/1, Average Training Loss: 1.0943919115496756, Training Accuracy: 0.5695364238410596\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.55      0.50      0.52       427\n",
            "                Educational Opportunity       0.43      0.55      0.48       451\n",
            "                         Family Support       0.63      0.76      0.69       396\n",
            "                      Financial Support       0.65      0.55      0.60       404\n",
            "                 Program Implementation       0.66      0.50      0.57       436\n",
            "\n",
            "                               accuracy                           0.57      2114\n",
            "                              macro avg       0.58      0.57      0.57      2114\n",
            "                           weighted avg       0.58      0.57      0.57      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 26.45139765739441, Validation Accuracy: 0.7051039697542533\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.62      0.64      0.63       113\n",
            "                Educational Opportunity       0.53      0.56      0.55       100\n",
            "                         Family Support       0.89      0.96      0.93       105\n",
            "                      Financial Support       0.68      0.81      0.74        97\n",
            "                 Program Implementation       0.83      0.57      0.68       114\n",
            "\n",
            "                               accuracy                           0.71       529\n",
            "                              macro avg       0.71      0.71      0.70       529\n",
            "                           weighted avg       0.71      0.71      0.70       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2BhWwV37bdo",
        "outputId": "b5f871da-1e84-465c-ed44-60f0a0b0130c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-3-93dd1b0995c5>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.642849326133728, Average Training Loss: 1.642849326133728, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.6452349424362183, Average Training Loss: 1.6440421342849731, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.6601519584655762, Average Training Loss: 1.6494120756785076, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.7175464630126953, Average Training Loss: 1.6664456725120544, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.5867669582366943, Average Training Loss: 1.6505099296569825, Training Accuracy: 0.1375\n",
            "Epoch 1/1, Batch Loss: 1.5878355503082275, Average Training Loss: 1.6400641997655232, Training Accuracy: 0.16666666666666666\n",
            "Epoch 1/1, Batch Loss: 1.5517346858978271, Average Training Loss: 1.6274456977844238, Training Accuracy: 0.20535714285714285\n",
            "Epoch 1/1, Batch Loss: 1.5813757181167603, Average Training Loss: 1.6216869503259659, Training Accuracy: 0.2265625\n",
            "Epoch 1/1, Batch Loss: 1.5881948471069336, Average Training Loss: 1.6179656055238512, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/1, Batch Loss: 1.5392487049102783, Average Training Loss: 1.6100939154624938, Training Accuracy: 0.23125\n",
            "Epoch 1/1, Batch Loss: 1.4846901893615723, Average Training Loss: 1.5986935767260464, Training Accuracy: 0.24431818181818182\n",
            "Epoch 1/1, Batch Loss: 1.5501437187194824, Average Training Loss: 1.5946477552254994, Training Accuracy: 0.24479166666666666\n",
            "Epoch 1/1, Batch Loss: 1.5732789039611816, Average Training Loss: 1.5930039974359365, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.4879597425460815, Average Training Loss: 1.5855008363723755, Training Accuracy: 0.26785714285714285\n",
            "Epoch 1/1, Batch Loss: 1.4569897651672363, Average Training Loss: 1.5769334316253663, Training Accuracy: 0.2791666666666667\n",
            "Epoch 1/1, Batch Loss: 1.5218288898468018, Average Training Loss: 1.573489397764206, Training Accuracy: 0.28125\n",
            "Epoch 1/1, Batch Loss: 1.5333091020584106, Average Training Loss: 1.5711258509579826, Training Accuracy: 0.29044117647058826\n",
            "Epoch 1/1, Batch Loss: 1.4867093563079834, Average Training Loss: 1.5664360456996493, Training Accuracy: 0.2881944444444444\n",
            "Epoch 1/1, Batch Loss: 1.5074213743209839, Average Training Loss: 1.56333001036393, Training Accuracy: 0.2894736842105263\n",
            "Epoch 1/1, Batch Loss: 1.6269949674606323, Average Training Loss: 1.5665132582187653, Training Accuracy: 0.28125\n",
            "Epoch 1/1, Batch Loss: 1.6636210680007935, Average Training Loss: 1.571137439636957, Training Accuracy: 0.2767857142857143\n",
            "Epoch 1/1, Batch Loss: 1.6354726552963257, Average Training Loss: 1.5740617676214739, Training Accuracy: 0.2784090909090909\n",
            "Epoch 1/1, Batch Loss: 1.6411075592041016, Average Training Loss: 1.5769768020381099, Training Accuracy: 0.27717391304347827\n",
            "Epoch 1/1, Batch Loss: 1.6330541372299194, Average Training Loss: 1.5793133576711018, Training Accuracy: 0.2786458333333333\n",
            "Epoch 1/1, Batch Loss: 1.5547919273376465, Average Training Loss: 1.5783325004577637, Training Accuracy: 0.2775\n",
            "Epoch 1/1, Batch Loss: 1.60221266746521, Average Training Loss: 1.5792509684195886, Training Accuracy: 0.27884615384615385\n",
            "Epoch 1/1, Batch Loss: 1.5351135730743408, Average Training Loss: 1.5776162500734683, Training Accuracy: 0.2777777777777778\n",
            "Epoch 1/1, Batch Loss: 1.5512819290161133, Average Training Loss: 1.5766757386071342, Training Accuracy: 0.2767857142857143\n",
            "Epoch 1/1, Batch Loss: 1.3948462009429932, Average Training Loss: 1.57040575454975, Training Accuracy: 0.28448275862068967\n",
            "Epoch 1/1, Batch Loss: 1.3898626565933228, Average Training Loss: 1.5643876512845358, Training Accuracy: 0.28958333333333336\n",
            "Epoch 1/1, Batch Loss: 1.43915593624115, Average Training Loss: 1.5603479185412008, Training Accuracy: 0.2923387096774194\n",
            "Epoch 1/1, Batch Loss: 1.5112143754959106, Average Training Loss: 1.5588124953210354, Training Accuracy: 0.29296875\n",
            "Epoch 1/1, Batch Loss: 1.4176852703094482, Average Training Loss: 1.5545359127449268, Training Accuracy: 0.29924242424242425\n",
            "Epoch 1/1, Batch Loss: 1.5209285020828247, Average Training Loss: 1.553547459490159, Training Accuracy: 0.2959558823529412\n",
            "Epoch 1/1, Batch Loss: 1.5418789386749268, Average Training Loss: 1.5532140731811523, Training Accuracy: 0.2982142857142857\n",
            "Epoch 1/1, Batch Loss: 1.4095814228057861, Average Training Loss: 1.549224277337392, Training Accuracy: 0.3055555555555556\n",
            "Epoch 1/1, Batch Loss: 1.3429758548736572, Average Training Loss: 1.5436499956491831, Training Accuracy: 0.3091216216216216\n",
            "Epoch 1/1, Batch Loss: 1.3796749114990234, Average Training Loss: 1.5393348618557579, Training Accuracy: 0.31414473684210525\n",
            "Epoch 1/1, Batch Loss: 1.3186763525009155, Average Training Loss: 1.53367695135948, Training Accuracy: 0.3189102564102564\n",
            "Epoch 1/1, Batch Loss: 1.2782729864120483, Average Training Loss: 1.5272918522357941, Training Accuracy: 0.3296875\n",
            "Epoch 1/1, Batch Loss: 1.4614887237548828, Average Training Loss: 1.525686897882601, Training Accuracy: 0.3323170731707317\n",
            "Epoch 1/1, Batch Loss: 1.3238046169281006, Average Training Loss: 1.520880176907494, Training Accuracy: 0.3333333333333333\n",
            "Epoch 1/1, Batch Loss: 1.2401436567306519, Average Training Loss: 1.5143514206243116, Training Accuracy: 0.34011627906976744\n",
            "Epoch 1/1, Batch Loss: 1.3256094455718994, Average Training Loss: 1.5100618302822113, Training Accuracy: 0.34375\n",
            "Epoch 1/1, Batch Loss: 1.5044831037521362, Average Training Loss: 1.509937858581543, Training Accuracy: 0.3416666666666667\n",
            "Epoch 1/1, Batch Loss: 1.3075180053710938, Average Training Loss: 1.5055374269900115, Training Accuracy: 0.34375\n",
            "Epoch 1/1, Batch Loss: 1.248597264289856, Average Training Loss: 1.5000706150176677, Training Accuracy: 0.3484042553191489\n",
            "Epoch 1/1, Batch Loss: 1.2989435195922852, Average Training Loss: 1.4958804671963055, Training Accuracy: 0.35546875\n",
            "Epoch 1/1, Batch Loss: 1.161578893661499, Average Training Loss: 1.4890579861037585, Training Accuracy: 0.35841836734693877\n",
            "Epoch 1/1, Batch Loss: 1.2756030559539795, Average Training Loss: 1.4847888875007629, Training Accuracy: 0.35875\n",
            "Epoch 1/1, Batch Loss: 1.317553997039795, Average Training Loss: 1.4815097720015282, Training Accuracy: 0.3590686274509804\n",
            "Epoch 1/1, Batch Loss: 1.4147499799728394, Average Training Loss: 1.4802259298471303, Training Accuracy: 0.3581730769230769\n",
            "Epoch 1/1, Batch Loss: 1.1756421327590942, Average Training Loss: 1.4744790657511297, Training Accuracy: 0.3643867924528302\n",
            "Epoch 1/1, Batch Loss: 1.2136422395706177, Average Training Loss: 1.4696487541551944, Training Accuracy: 0.36689814814814814\n",
            "Epoch 1/1, Batch Loss: 0.9947633147239685, Average Training Loss: 1.4610144734382629, Training Accuracy: 0.37386363636363634\n",
            "Epoch 1/1, Batch Loss: 1.1421780586242676, Average Training Loss: 1.4553209660308701, Training Accuracy: 0.3794642857142857\n",
            "Epoch 1/1, Batch Loss: 1.407625675201416, Average Training Loss: 1.4544842065426342, Training Accuracy: 0.3793859649122807\n",
            "Epoch 1/1, Batch Loss: 0.8864057660102844, Average Training Loss: 1.4446897506713867, Training Accuracy: 0.3857758620689655\n",
            "Epoch 1/1, Batch Loss: 1.5569632053375244, Average Training Loss: 1.4465926905809823, Training Accuracy: 0.3845338983050847\n",
            "Epoch 1/1, Batch Loss: 1.1049312353134155, Average Training Loss: 1.4408983329931895, Training Accuracy: 0.38958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.1623613834381104, Average Training Loss: 1.4363321534922866, Training Accuracy: 0.39344262295081966\n",
            "Epoch 1/1, Batch Loss: 1.2687406539916992, Average Training Loss: 1.4336290647906642, Training Accuracy: 0.39314516129032256\n",
            "Epoch 1/1, Batch Loss: 0.9997543096542358, Average Training Loss: 1.4267421639154827, Training Accuracy: 0.39880952380952384\n",
            "Epoch 1/1, Batch Loss: 0.9598238468170166, Average Training Loss: 1.4194465652108192, Training Accuracy: 0.4033203125\n",
            "Epoch 1/1, Batch Loss: 1.105920672416687, Average Training Loss: 1.4146230899370633, Training Accuracy: 0.40384615384615385\n",
            "Epoch 1/1, Batch Loss: 0.931127667427063, Average Training Loss: 1.4072974017172148, Training Accuracy: 0.4119318181818182\n",
            "Epoch 1/1, Batch Loss: 1.1665534973144531, Average Training Loss: 1.4037042091141885, Training Accuracy: 0.41511194029850745\n",
            "Epoch 1/1, Batch Loss: 1.0197335481643677, Average Training Loss: 1.3980575817472793, Training Accuracy: 0.4181985294117647\n",
            "Epoch 1/1, Batch Loss: 1.1019095182418823, Average Training Loss: 1.3937655808269114, Training Accuracy: 0.42028985507246375\n",
            "Epoch 1/1, Batch Loss: 1.0467240810394287, Average Training Loss: 1.3888078451156616, Training Accuracy: 0.4232142857142857\n",
            "Epoch 1/1, Batch Loss: 0.8825891017913818, Average Training Loss: 1.3816780036603902, Training Accuracy: 0.426056338028169\n",
            "Epoch 1/1, Batch Loss: 0.9159708023071289, Average Training Loss: 1.3752098480860393, Training Accuracy: 0.4314236111111111\n",
            "Epoch 1/1, Batch Loss: 0.7669053077697754, Average Training Loss: 1.3668769091775972, Training Accuracy: 0.4357876712328767\n",
            "Epoch 1/1, Batch Loss: 1.074784755706787, Average Training Loss: 1.3629297179144781, Training Accuracy: 0.4391891891891892\n",
            "Epoch 1/1, Batch Loss: 1.009655237197876, Average Training Loss: 1.3582193915049234, Training Accuracy: 0.4425\n",
            "Epoch 1/1, Batch Loss: 1.0074228048324585, Average Training Loss: 1.3536036469434436, Training Accuracy: 0.4449013157894737\n",
            "Epoch 1/1, Batch Loss: 1.0641016960144043, Average Training Loss: 1.3498438813469626, Training Accuracy: 0.44805194805194803\n",
            "Epoch 1/1, Batch Loss: 0.8365274667739868, Average Training Loss: 1.3432629016729503, Training Accuracy: 0.4511217948717949\n",
            "Epoch 1/1, Batch Loss: 0.8301095366477966, Average Training Loss: 1.3367672894574418, Training Accuracy: 0.45569620253164556\n",
            "Epoch 1/1, Batch Loss: 1.1203389167785645, Average Training Loss: 1.334061934798956, Training Accuracy: 0.4578125\n",
            "Epoch 1/1, Batch Loss: 0.9890077710151672, Average Training Loss: 1.329802006851008, Training Accuracy: 0.4591049382716049\n",
            "Epoch 1/1, Batch Loss: 0.9735291004180908, Average Training Loss: 1.325457215309143, Training Accuracy: 0.4611280487804878\n",
            "Epoch 1/1, Batch Loss: 1.1260805130004883, Average Training Loss: 1.3230550863656654, Training Accuracy: 0.4631024096385542\n",
            "Epoch 1/1, Batch Loss: 0.5150632262229919, Average Training Loss: 1.313436135649681, Training Accuracy: 0.4680059523809524\n",
            "Epoch 1/1, Batch Loss: 0.6921690106391907, Average Training Loss: 1.3061271106495578, Training Accuracy: 0.47205882352941175\n",
            "Epoch 1/1, Batch Loss: 0.7856177091598511, Average Training Loss: 1.3000746757485147, Training Accuracy: 0.47601744186046513\n",
            "Epoch 1/1, Batch Loss: 0.8710889220237732, Average Training Loss: 1.2951438050160462, Training Accuracy: 0.47772988505747127\n",
            "Epoch 1/1, Batch Loss: 1.060767650604248, Average Training Loss: 1.2924804396250031, Training Accuracy: 0.48011363636363635\n",
            "Epoch 1/1, Batch Loss: 0.7590422630310059, Average Training Loss: 1.2864867522475425, Training Accuracy: 0.48314606741573035\n",
            "Epoch 1/1, Batch Loss: 0.8258916139602661, Average Training Loss: 1.2813690284887949, Training Accuracy: 0.4847222222222222\n",
            "Epoch 1/1, Batch Loss: 1.0111533403396606, Average Training Loss: 1.2783996253223209, Training Accuracy: 0.48626373626373626\n",
            "Epoch 1/1, Batch Loss: 0.8256480693817139, Average Training Loss: 1.2734784127577492, Training Accuracy: 0.48845108695652173\n",
            "Epoch 1/1, Batch Loss: 0.9679136276245117, Average Training Loss: 1.270192769906854, Training Accuracy: 0.489247311827957\n",
            "Epoch 1/1, Batch Loss: 0.8728649616241455, Average Training Loss: 1.2659658783293786, Training Accuracy: 0.4933510638297872\n",
            "Epoch 1/1, Batch Loss: 0.8798508048057556, Average Training Loss: 1.261901509134393, Training Accuracy: 0.49473684210526314\n",
            "Epoch 1/1, Batch Loss: 0.6945441961288452, Average Training Loss: 1.2559915371239185, Training Accuracy: 0.4967447916666667\n",
            "Epoch 1/1, Batch Loss: 0.9440551400184631, Average Training Loss: 1.2527756979785014, Training Accuracy: 0.4961340206185567\n",
            "Epoch 1/1, Batch Loss: 0.823512852191925, Average Training Loss: 1.2483954648582303, Training Accuracy: 0.49808673469387754\n",
            "Epoch 1/1, Batch Loss: 0.9946826100349426, Average Training Loss: 1.245832708748904, Training Accuracy: 0.49936868686868685\n",
            "Epoch 1/1, Batch Loss: 0.6084328889846802, Average Training Loss: 1.239458710551262, Training Accuracy: 0.503125\n",
            "Epoch 1/1, Batch Loss: 0.6537288427352905, Average Training Loss: 1.2336594049293217, Training Accuracy: 0.5068069306930693\n",
            "Epoch 1/1, Batch Loss: 0.6532191038131714, Average Training Loss: 1.2279688137419082, Training Accuracy: 0.5098039215686274\n",
            "Epoch 1/1, Batch Loss: 1.0929832458496094, Average Training Loss: 1.2266582742478083, Training Accuracy: 0.5103155339805825\n",
            "Epoch 1/1, Batch Loss: 0.8762081265449524, Average Training Loss: 1.223288561289127, Training Accuracy: 0.5120192307692307\n",
            "Epoch 1/1, Batch Loss: 0.7766681909561157, Average Training Loss: 1.2190350339526221, Training Accuracy: 0.5136904761904761\n",
            "Epoch 1/1, Batch Loss: 0.636131227016449, Average Training Loss: 1.2135359414343565, Training Accuracy: 0.5159198113207547\n",
            "Epoch 1/1, Batch Loss: 1.2571440935134888, Average Training Loss: 1.2139434942575258, Training Accuracy: 0.5163551401869159\n",
            "Epoch 1/1, Batch Loss: 1.2179551124572754, Average Training Loss: 1.2139806388704866, Training Accuracy: 0.5162037037037037\n",
            "Epoch 1/1, Batch Loss: 0.6524657011032104, Average Training Loss: 1.208829125679961, Training Accuracy: 0.5189220183486238\n",
            "Epoch 1/1, Batch Loss: 0.7238126993179321, Average Training Loss: 1.2044198854403063, Training Accuracy: 0.5204545454545455\n",
            "Epoch 1/1, Batch Loss: 0.8997316956520081, Average Training Loss: 1.2016749467935648, Training Accuracy: 0.5219594594594594\n",
            "Epoch 1/1, Batch Loss: 0.7737119197845459, Average Training Loss: 1.1978538483381271, Training Accuracy: 0.5234375\n",
            "Epoch 1/1, Batch Loss: 0.8694865107536316, Average Training Loss: 1.1949479426957865, Training Accuracy: 0.5248893805309734\n",
            "Epoch 1/1, Batch Loss: 0.8373028039932251, Average Training Loss: 1.1918107046369921, Training Accuracy: 0.5268640350877193\n",
            "Epoch 1/1, Batch Loss: 0.5571327209472656, Average Training Loss: 1.1862917656483858, Training Accuracy: 0.529891304347826\n",
            "Epoch 1/1, Batch Loss: 0.627748966217041, Average Training Loss: 1.1814767415153569, Training Accuracy: 0.53125\n",
            "Epoch 1/1, Batch Loss: 1.0506950616836548, Average Training Loss: 1.1803589493800433, Training Accuracy: 0.531517094017094\n",
            "Epoch 1/1, Batch Loss: 0.9626957774162292, Average Training Loss: 1.1785143462278076, Training Accuracy: 0.5328389830508474\n",
            "Epoch 1/1, Batch Loss: 0.55129075050354, Average Training Loss: 1.1732435597091162, Training Accuracy: 0.5351890756302521\n",
            "Epoch 1/1, Batch Loss: 0.797195315361023, Average Training Loss: 1.1701098243395487, Training Accuracy: 0.5364583333333334\n",
            "Epoch 1/1, Batch Loss: 0.7462260723114014, Average Training Loss: 1.166606652835184, Training Accuracy: 0.5382231404958677\n",
            "Epoch 1/1, Batch Loss: 0.7401408553123474, Average Training Loss: 1.1631110315440132, Training Accuracy: 0.5409836065573771\n",
            "Epoch 1/1, Batch Loss: 1.0106313228607178, Average Training Loss: 1.1618713591156937, Training Accuracy: 0.5411585365853658\n",
            "Epoch 1/1, Batch Loss: 0.7566328644752502, Average Training Loss: 1.158603306739561, Training Accuracy: 0.5428427419354839\n",
            "Epoch 1/1, Batch Loss: 0.8830661773681641, Average Training Loss: 1.1563990097045898, Training Accuracy: 0.5435\n",
            "Epoch 1/1, Batch Loss: 0.5841229557991028, Average Training Loss: 1.1518571362608956, Training Accuracy: 0.5456349206349206\n",
            "Epoch 1/1, Batch Loss: 0.7139918804168701, Average Training Loss: 1.1484093783408638, Training Accuracy: 0.547244094488189\n",
            "Epoch 1/1, Batch Loss: 0.9998465776443481, Average Training Loss: 1.1472487314604223, Training Accuracy: 0.5478515625\n",
            "Epoch 1/1, Batch Loss: 0.9471665024757385, Average Training Loss: 1.1456977064295333, Training Accuracy: 0.5489341085271318\n",
            "Epoch 1/1, Batch Loss: 0.45678722858428955, Average Training Loss: 1.1403983950614929, Training Accuracy: 0.5514423076923077\n",
            "Epoch 1/1, Batch Loss: 0.7478317618370056, Average Training Loss: 1.1374017032048174, Training Accuracy: 0.5534351145038168\n",
            "Epoch 1/1, Batch Loss: 1.0673201084136963, Average Training Loss: 1.1368707820321575, Training Accuracy: 0.5525568181818182\n",
            "Epoch 1/1, Batch Loss: 0.3730432987213135, Average Training Loss: 1.138618630289242, Training Accuracy: 0.5529801324503312\n",
            "Epoch 1/1, Average Training Loss: 1.1311277182478654, Training Accuracy: 0.5529801324503312\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.47      0.48      0.48       427\n",
            "                Educational Opportunity       0.43      0.42      0.43       451\n",
            "                         Family Support       0.82      0.64      0.72       396\n",
            "                      Financial Support       0.54      0.64      0.58       404\n",
            "                 Program Implementation       0.60      0.60      0.60       436\n",
            "\n",
            "                               accuracy                           0.55      2114\n",
            "                              macro avg       0.57      0.56      0.56      2114\n",
            "                           weighted avg       0.56      0.55      0.56      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 27.604343205690384, Validation Accuracy: 0.6994328922495274\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.62      0.67      0.64       113\n",
            "                Educational Opportunity       0.50      0.58      0.54       100\n",
            "                         Family Support       0.86      0.98      0.92       105\n",
            "                      Financial Support       0.75      0.70      0.72        97\n",
            "                 Program Implementation       0.81      0.57      0.67       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.71      0.70      0.70       529\n",
            "                           weighted avg       0.71      0.70      0.70       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDh5-SwQEj1X",
        "outputId": "b72a2dff-ca51-441e-a088-63da3aff0f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-5-669eb5b88e72>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.666519045829773, Average Training Loss: 1.666519045829773, Training Accuracy: 0.15625\n",
            "Epoch 1/1, Batch Loss: 1.6296865940093994, Average Training Loss: 1.6481028199195862, Training Accuracy: 0.171875\n",
            "Epoch 1/1, Batch Loss: 1.6017796993255615, Average Training Loss: 1.6326617797215779, Training Accuracy: 0.203125\n",
            "Epoch 1/1, Batch Loss: 1.5643727779388428, Average Training Loss: 1.6155895292758942, Training Accuracy: 0.22265625\n",
            "Epoch 1/1, Batch Loss: 1.5373390913009644, Average Training Loss: 1.5999394416809083, Training Accuracy: 0.24375\n",
            "Epoch 1/1, Batch Loss: 1.5280025005340576, Average Training Loss: 1.5879499514897664, Training Accuracy: 0.24739583333333334\n",
            "Epoch 1/1, Batch Loss: 1.5029752254486084, Average Training Loss: 1.5758107049124581, Training Accuracy: 0.27232142857142855\n",
            "Epoch 1/1, Batch Loss: 1.4641032218933105, Average Training Loss: 1.5618472695350647, Training Accuracy: 0.2890625\n",
            "Epoch 1/1, Batch Loss: 1.4384347200393677, Average Training Loss: 1.5481347640355427, Training Accuracy: 0.3055555555555556\n",
            "Epoch 1/1, Batch Loss: 1.4910086393356323, Average Training Loss: 1.5424221515655518, Training Accuracy: 0.309375\n",
            "Epoch 1/1, Batch Loss: 1.4538034200668335, Average Training Loss: 1.5343659032474866, Training Accuracy: 0.3125\n",
            "Epoch 1/1, Batch Loss: 1.4347246885299683, Average Training Loss: 1.5260624686876934, Training Accuracy: 0.3216145833333333\n",
            "Epoch 1/1, Batch Loss: 1.410080075263977, Average Training Loss: 1.5171407461166382, Training Accuracy: 0.3293269230769231\n",
            "Epoch 1/1, Batch Loss: 1.3497660160064697, Average Training Loss: 1.505185408251626, Training Accuracy: 0.3392857142857143\n",
            "Epoch 1/1, Batch Loss: 1.4483931064605713, Average Training Loss: 1.5013992547988892, Training Accuracy: 0.340625\n",
            "Epoch 1/1, Batch Loss: 1.365705966949463, Average Training Loss: 1.4929184243083, Training Accuracy: 0.3564453125\n",
            "Epoch 1/1, Batch Loss: 1.4891225099563599, Average Training Loss: 1.492695135228774, Training Accuracy: 0.3630514705882353\n",
            "Epoch 1/1, Batch Loss: 1.3446462154388428, Average Training Loss: 1.4844701952404447, Training Accuracy: 0.3697916666666667\n",
            "Epoch 1/1, Batch Loss: 1.2535412311553955, Average Training Loss: 1.4723160392359684, Training Accuracy: 0.3807565789473684\n",
            "Epoch 1/1, Batch Loss: 1.2817462682724, Average Training Loss: 1.4627875506877899, Training Accuracy: 0.384375\n",
            "Epoch 1/1, Batch Loss: 1.375628113746643, Average Training Loss: 1.45863710130964, Training Accuracy: 0.38839285714285715\n",
            "Epoch 1/1, Batch Loss: 1.2970999479293823, Average Training Loss: 1.4512945034287192, Training Accuracy: 0.3934659090909091\n",
            "Epoch 1/1, Batch Loss: 1.2868731021881104, Average Training Loss: 1.4441457468530405, Training Accuracy: 0.39945652173913043\n",
            "Epoch 1/1, Batch Loss: 1.3219646215438843, Average Training Loss: 1.4390548666318257, Training Accuracy: 0.40625\n",
            "Epoch 1/1, Batch Loss: 1.3169093132019043, Average Training Loss: 1.434169044494629, Training Accuracy: 0.4075\n",
            "Epoch 1/1, Batch Loss: 1.2359837293624878, Average Training Loss: 1.426546532374162, Training Accuracy: 0.4128605769230769\n",
            "Epoch 1/1, Batch Loss: 1.3633153438568115, Average Training Loss: 1.4242046365031489, Training Accuracy: 0.41782407407407407\n",
            "Epoch 1/1, Batch Loss: 1.18384850025177, Average Training Loss: 1.4156204887798853, Training Accuracy: 0.42410714285714285\n",
            "Epoch 1/1, Batch Loss: 1.3318158388137817, Average Training Loss: 1.412730673263813, Training Accuracy: 0.42510775862068967\n",
            "Epoch 1/1, Batch Loss: 1.296921730041504, Average Training Loss: 1.4088703751564027, Training Accuracy: 0.428125\n",
            "Epoch 1/1, Batch Loss: 1.2714364528656006, Average Training Loss: 1.4044370228244412, Training Accuracy: 0.42993951612903225\n",
            "Epoch 1/1, Batch Loss: 1.2503246068954468, Average Training Loss: 1.3996210098266602, Training Accuracy: 0.43359375\n",
            "Epoch 1/1, Batch Loss: 1.1872609853744507, Average Training Loss: 1.3931858575705327, Training Accuracy: 0.43892045454545453\n",
            "Epoch 1/1, Batch Loss: 1.325258731842041, Average Training Loss: 1.4319891627373962, Training Accuracy: 0.4389782403027436\n",
            "Epoch 1/1, Average Training Loss: 1.3911880009314592, Training Accuracy: 0.4389782403027436\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.37      0.62      0.46       427\n",
            "                Educational Opportunity       0.42      0.37      0.39       451\n",
            "                         Family Support       0.56      0.19      0.28       396\n",
            "                      Financial Support       0.45      0.48      0.46       404\n",
            "                 Program Implementation       0.53      0.53      0.53       436\n",
            "\n",
            "                               accuracy                           0.44      2114\n",
            "                              macro avg       0.46      0.44      0.43      2114\n",
            "                           weighted avg       0.46      0.44      0.43      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 11.029032945632935, Validation Accuracy: 0.5311909262759924\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.48      0.62      0.54       113\n",
            "                Educational Opportunity       0.41      0.46      0.43       100\n",
            "                         Family Support       0.73      0.30      0.43       105\n",
            "                      Financial Support       0.52      0.73      0.61        97\n",
            "                 Program Implementation       0.70      0.54      0.61       114\n",
            "\n",
            "                               accuracy                           0.53       529\n",
            "                              macro avg       0.57      0.53      0.52       529\n",
            "                           weighted avg       0.57      0.53      0.53       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZiG7JVtLxJ3",
        "outputId": "26a8c970-f46d-4404-cb84-ff842c46153e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-6-63b071806fe5>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.6754621267318726, Average Training Loss: 1.6754621267318726, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.6339415311813354, Average Training Loss: 1.654701828956604, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.6925803422927856, Average Training Loss: 1.6673280000686646, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.6836494207382202, Average Training Loss: 1.6714083552360535, Training Accuracy: 0.1953125\n",
            "Epoch 1/1, Batch Loss: 1.557828664779663, Average Training Loss: 1.6486924171447754, Training Accuracy: 0.2125\n",
            "Epoch 1/1, Batch Loss: 1.5971646308898926, Average Training Loss: 1.6401044527689617, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.5953556299209595, Average Training Loss: 1.6337117637906755, Training Accuracy: 0.21428571428571427\n",
            "Epoch 1/1, Batch Loss: 1.5597234964370728, Average Training Loss: 1.6244632303714752, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.6012053489685059, Average Training Loss: 1.621879021326701, Training Accuracy: 0.2152777777777778\n",
            "Epoch 1/1, Batch Loss: 1.6001087427139282, Average Training Loss: 1.6197019934654235, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.480225682258606, Average Training Loss: 1.6070223288102583, Training Accuracy: 0.24147727272727273\n",
            "Epoch 1/1, Batch Loss: 1.5526092052459717, Average Training Loss: 1.6024879018465679, Training Accuracy: 0.23958333333333334\n",
            "Epoch 1/1, Batch Loss: 1.5860031843185425, Average Training Loss: 1.6012198466521044, Training Accuracy: 0.24278846153846154\n",
            "Epoch 1/1, Batch Loss: 1.521673321723938, Average Training Loss: 1.5955379520143782, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.6087400913238525, Average Training Loss: 1.5964180946350097, Training Accuracy: 0.25416666666666665\n",
            "Epoch 1/1, Batch Loss: 1.4663830995559692, Average Training Loss: 1.5882909074425697, Training Accuracy: 0.26171875\n",
            "Epoch 1/1, Batch Loss: 1.4239379167556763, Average Training Loss: 1.5786230844609879, Training Accuracy: 0.27941176470588236\n",
            "Epoch 1/1, Batch Loss: 1.3854904174804688, Average Training Loss: 1.5678934918509588, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/1, Batch Loss: 1.5292972326278687, Average Training Loss: 1.5658621097865857, Training Accuracy: 0.2878289473684211\n",
            "Epoch 1/1, Batch Loss: 1.3754184246063232, Average Training Loss: 1.5563399255275727, Training Accuracy: 0.2890625\n",
            "Epoch 1/1, Batch Loss: 1.392842173576355, Average Training Loss: 1.5485543182918005, Training Accuracy: 0.2976190476190476\n",
            "Epoch 1/1, Batch Loss: 1.2841063737869263, Average Training Loss: 1.5365339571779424, Training Accuracy: 0.30823863636363635\n",
            "Epoch 1/1, Batch Loss: 1.285119652748108, Average Training Loss: 1.5256029004636018, Training Accuracy: 0.31929347826086957\n",
            "Epoch 1/1, Batch Loss: 1.2946220636367798, Average Training Loss: 1.5159786989291508, Training Accuracy: 0.3229166666666667\n",
            "Epoch 1/1, Batch Loss: 1.2398021221160889, Average Training Loss: 1.5049316358566285, Training Accuracy: 0.3325\n",
            "Epoch 1/1, Batch Loss: 1.1061484813690186, Average Training Loss: 1.4895938222224896, Training Accuracy: 0.34615384615384615\n",
            "Epoch 1/1, Batch Loss: 1.2475513219833374, Average Training Loss: 1.480629285176595, Training Accuracy: 0.35532407407407407\n",
            "Epoch 1/1, Batch Loss: 1.1966131925582886, Average Training Loss: 1.47048585329737, Training Accuracy: 0.3627232142857143\n",
            "Epoch 1/1, Batch Loss: 1.2247575521469116, Average Training Loss: 1.4620124636025265, Training Accuracy: 0.36530172413793105\n",
            "Epoch 1/1, Batch Loss: 1.181540608406067, Average Training Loss: 1.4526634017626445, Training Accuracy: 0.37083333333333335\n",
            "Epoch 1/1, Batch Loss: 1.117971420288086, Average Training Loss: 1.4418668862312072, Training Accuracy: 0.3800403225806452\n",
            "Epoch 1/1, Batch Loss: 1.2002462148666382, Average Training Loss: 1.4343162402510643, Training Accuracy: 0.384765625\n",
            "Epoch 1/1, Batch Loss: 1.0271110534667969, Average Training Loss: 1.4219766891363896, Training Accuracy: 0.39299242424242425\n",
            "Epoch 1/1, Batch Loss: 0.816883385181427, Average Training Loss: 1.4041798272553612, Training Accuracy: 0.40625\n",
            "Epoch 1/1, Batch Loss: 0.9922780394554138, Average Training Loss: 1.3924112047467914, Training Accuracy: 0.41160714285714284\n",
            "Epoch 1/1, Batch Loss: 0.962005078792572, Average Training Loss: 1.3804554790258408, Training Accuracy: 0.4184027777777778\n",
            "Epoch 1/1, Batch Loss: 1.3128886222839355, Average Training Loss: 1.378629347762546, Training Accuracy: 0.4197635135135135\n",
            "Epoch 1/1, Batch Loss: 1.0403218269348145, Average Training Loss: 1.3697265182670795, Training Accuracy: 0.4243421052631579\n",
            "Epoch 1/1, Batch Loss: 1.2545866966247559, Average Training Loss: 1.3667742151480455, Training Accuracy: 0.42628205128205127\n",
            "Epoch 1/1, Batch Loss: 0.99338698387146, Average Training Loss: 1.3574395343661307, Training Accuracy: 0.43125\n",
            "Epoch 1/1, Batch Loss: 1.0627126693725586, Average Training Loss: 1.3502510742443363, Training Accuracy: 0.4367378048780488\n",
            "Epoch 1/1, Batch Loss: 1.1514872312545776, Average Training Loss: 1.3455186017921992, Training Accuracy: 0.43898809523809523\n",
            "Epoch 1/1, Batch Loss: 1.2500900030136108, Average Training Loss: 1.3432993320531623, Training Accuracy: 0.44113372093023256\n",
            "Epoch 1/1, Batch Loss: 1.1584008932113647, Average Training Loss: 1.3390970948067578, Training Accuracy: 0.44176136363636365\n",
            "Epoch 1/1, Batch Loss: 1.1518816947937012, Average Training Loss: 1.3349367525842455, Training Accuracy: 0.44513888888888886\n",
            "Epoch 1/1, Batch Loss: 0.9455398917198181, Average Training Loss: 1.3264716034350188, Training Accuracy: 0.4517663043478261\n",
            "Epoch 1/1, Batch Loss: 1.1344298124313354, Average Training Loss: 1.3223856078817489, Training Accuracy: 0.45478723404255317\n",
            "Epoch 1/1, Batch Loss: 1.022737741470337, Average Training Loss: 1.3161429439981778, Training Accuracy: 0.45703125\n",
            "Epoch 1/1, Batch Loss: 1.1376172304153442, Average Training Loss: 1.3124995620883242, Training Accuracy: 0.45790816326530615\n",
            "Epoch 1/1, Batch Loss: 1.1085083484649658, Average Training Loss: 1.3084197378158569, Training Accuracy: 0.460625\n",
            "Epoch 1/1, Batch Loss: 0.8735030889511108, Average Training Loss: 1.2998919603871364, Training Accuracy: 0.46629901960784315\n",
            "Epoch 1/1, Batch Loss: 0.89809250831604, Average Training Loss: 1.2921650478473077, Training Accuracy: 0.46875\n",
            "Epoch 1/1, Batch Loss: 0.9029091000556946, Average Training Loss: 1.2848205960021828, Training Accuracy: 0.47287735849056606\n",
            "Epoch 1/1, Batch Loss: 1.0733834505081177, Average Training Loss: 1.2809050933078483, Training Accuracy: 0.47627314814814814\n",
            "Epoch 1/1, Batch Loss: 1.102359414100647, Average Training Loss: 1.2776588082313538, Training Accuracy: 0.4784090909090909\n",
            "Epoch 1/1, Batch Loss: 1.238736629486084, Average Training Loss: 1.2769637693251883, Training Accuracy: 0.47767857142857145\n",
            "Epoch 1/1, Batch Loss: 1.0225929021835327, Average Training Loss: 1.2725011225332294, Training Accuracy: 0.48026315789473684\n",
            "Epoch 1/1, Batch Loss: 0.7997236847877502, Average Training Loss: 1.2643497873996865, Training Accuracy: 0.4827586206896552\n",
            "Epoch 1/1, Batch Loss: 0.9360304474830627, Average Training Loss: 1.2587850528248286, Training Accuracy: 0.4846398305084746\n",
            "Epoch 1/1, Batch Loss: 1.0991322994232178, Average Training Loss: 1.2561241736014683, Training Accuracy: 0.48541666666666666\n",
            "Epoch 1/1, Batch Loss: 1.101853370666504, Average Training Loss: 1.2535951440451576, Training Accuracy: 0.48616803278688525\n",
            "Epoch 1/1, Batch Loss: 1.0793782472610474, Average Training Loss: 1.2507851940970267, Training Accuracy: 0.48588709677419356\n",
            "Epoch 1/1, Batch Loss: 1.0100984573364258, Average Training Loss: 1.2469647697040014, Training Accuracy: 0.4871031746031746\n",
            "Epoch 1/1, Batch Loss: 0.7693133354187012, Average Training Loss: 1.2395014660432935, Training Accuracy: 0.49267578125\n",
            "Epoch 1/1, Batch Loss: 1.0534754991531372, Average Training Loss: 1.2366395280911373, Training Accuracy: 0.4932692307692308\n",
            "Epoch 1/1, Batch Loss: 0.9237452745437622, Average Training Loss: 1.2318987060676923, Training Accuracy: 0.4971590909090909\n",
            "Epoch 1/1, Batch Loss: 1.1399047374725342, Average Training Loss: 1.2479881829773354, Training Accuracy: 0.4971617786187323\n",
            "Epoch 1/1, Average Training Loss: 1.2305256617603018, Training Accuracy: 0.4971617786187323\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.44      0.30      0.36       427\n",
            "                Educational Opportunity       0.43      0.31      0.36       451\n",
            "                         Family Support       0.55      0.76      0.64       396\n",
            "                      Financial Support       0.47      0.57      0.52       404\n",
            "                 Program Implementation       0.55      0.57      0.56       436\n",
            "\n",
            "                               accuracy                           0.50      2114\n",
            "                              macro avg       0.49      0.50      0.49      2114\n",
            "                           weighted avg       0.49      0.50      0.48      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 15.588127851486206, Validation Accuracy: 0.6446124763705104\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.54      0.54      0.54       113\n",
            "                Educational Opportunity       0.41      0.39      0.40       100\n",
            "                         Family Support       0.86      0.97      0.91       105\n",
            "                      Financial Support       0.72      0.70      0.71        97\n",
            "                 Program Implementation       0.66      0.62      0.64       114\n",
            "\n",
            "                               accuracy                           0.64       529\n",
            "                              macro avg       0.64      0.65      0.64       529\n",
            "                           weighted avg       0.64      0.64      0.64       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5mMTe-UQUy-",
        "outputId": "af1fda72-dd39-408c-88e2-a5304620a8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-7-b3a9047a53d5>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Batch Loss: 1.664396047592163, Average Training Loss: 1.664396047592163, Training Accuracy: 0.1875\n",
            "Epoch 1/1, Batch Loss: 1.668453335762024, Average Training Loss: 1.6664246916770935, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.5615029335021973, Average Training Loss: 1.6314507722854614, Training Accuracy: 0.2708333333333333\n",
            "Epoch 1/1, Batch Loss: 1.5911309719085693, Average Training Loss: 1.6213708221912384, Training Accuracy: 0.265625\n",
            "Epoch 1/1, Batch Loss: 1.6556731462478638, Average Training Loss: 1.6282312870025635, Training Accuracy: 0.23125\n",
            "Epoch 1/1, Batch Loss: 1.6124444007873535, Average Training Loss: 1.6256001393000286, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.612802505493164, Average Training Loss: 1.6237719058990479, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.632321834564209, Average Training Loss: 1.624840646982193, Training Accuracy: 0.22265625\n",
            "Epoch 1/1, Batch Loss: 1.6076148748397827, Average Training Loss: 1.6229266722997029, Training Accuracy: 0.2152777777777778\n",
            "Epoch 1/1, Batch Loss: 1.6327810287475586, Average Training Loss: 1.6239121079444885, Training Accuracy: 0.21875\n",
            "Epoch 1/1, Batch Loss: 1.5383168458938599, Average Training Loss: 1.6161307204853406, Training Accuracy: 0.23579545454545456\n",
            "Epoch 1/1, Batch Loss: 1.5728905200958252, Average Training Loss: 1.6125273704528809, Training Accuracy: 0.234375\n",
            "Epoch 1/1, Batch Loss: 1.5508824586868286, Average Training Loss: 1.6077854541631846, Training Accuracy: 0.24519230769230768\n",
            "Epoch 1/1, Batch Loss: 1.6352596282958984, Average Training Loss: 1.609747895172664, Training Accuracy: 0.24553571428571427\n",
            "Epoch 1/1, Batch Loss: 1.5676941871643066, Average Training Loss: 1.6069443146387736, Training Accuracy: 0.24375\n",
            "Epoch 1/1, Batch Loss: 1.56175696849823, Average Training Loss: 1.6041201055049896, Training Accuracy: 0.2421875\n",
            "Epoch 1/1, Batch Loss: 1.5085054636001587, Average Training Loss: 1.5984957148047054, Training Accuracy: 0.24632352941176472\n",
            "Epoch 1/1, Batch Loss: 1.5903648138046265, Average Training Loss: 1.5980439980824788, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.543997883796692, Average Training Loss: 1.595199465751648, Training Accuracy: 0.25\n",
            "Epoch 1/1, Batch Loss: 1.5460067987442017, Average Training Loss: 1.5927398324012756, Training Accuracy: 0.2515625\n",
            "Epoch 1/1, Batch Loss: 1.506385326385498, Average Training Loss: 1.588627713067191, Training Accuracy: 0.2544642857142857\n",
            "Epoch 1/1, Batch Loss: 1.4799696207046509, Average Training Loss: 1.5836887088688938, Training Accuracy: 0.2627840909090909\n",
            "Epoch 1/1, Batch Loss: 1.437892198562622, Average Training Loss: 1.5773497301599253, Training Accuracy: 0.2703804347826087\n",
            "Epoch 1/1, Batch Loss: 1.5241005420684814, Average Training Loss: 1.5751310139894485, Training Accuracy: 0.2747395833333333\n",
            "Epoch 1/1, Batch Loss: 1.426316499710083, Average Training Loss: 1.569178433418274, Training Accuracy: 0.28\n",
            "Epoch 1/1, Batch Loss: 1.4333080053329468, Average Training Loss: 1.5639526477226844, Training Accuracy: 0.2860576923076923\n",
            "Epoch 1/1, Batch Loss: 1.4329490661621094, Average Training Loss: 1.559100663220441, Training Accuracy: 0.28935185185185186\n",
            "Epoch 1/1, Batch Loss: 1.4983370304107666, Average Training Loss: 1.5569305334772383, Training Accuracy: 0.29129464285714285\n",
            "Epoch 1/1, Batch Loss: 1.4302873611450195, Average Training Loss: 1.552563527534748, Training Accuracy: 0.2952586206896552\n",
            "Epoch 1/1, Batch Loss: 1.464369535446167, Average Training Loss: 1.549623727798462, Training Accuracy: 0.29375\n",
            "Epoch 1/1, Batch Loss: 1.4140857458114624, Average Training Loss: 1.5452515348311393, Training Accuracy: 0.2973790322580645\n",
            "Epoch 1/1, Batch Loss: 1.4697153568267822, Average Training Loss: 1.5428910292685032, Training Accuracy: 0.30078125\n",
            "Epoch 1/1, Batch Loss: 1.3488184213638306, Average Training Loss: 1.5370100411501797, Training Accuracy: 0.3058712121212121\n",
            "Epoch 1/1, Batch Loss: 1.4932256937026978, Average Training Loss: 1.5357222662252539, Training Accuracy: 0.30422794117647056\n",
            "Epoch 1/1, Batch Loss: 1.2760649919509888, Average Training Loss: 1.5283034869602747, Training Accuracy: 0.3098214285714286\n",
            "Epoch 1/1, Batch Loss: 1.3476756811141968, Average Training Loss: 1.523286047908995, Training Accuracy: 0.3142361111111111\n",
            "Epoch 1/1, Batch Loss: 1.4816397428512573, Average Training Loss: 1.5221604720966235, Training Accuracy: 0.31503378378378377\n",
            "Epoch 1/1, Batch Loss: 1.5080662965774536, Average Training Loss: 1.521789572740856, Training Accuracy: 0.3149671052631579\n",
            "Epoch 1/1, Batch Loss: 1.3325059413909912, Average Training Loss: 1.5169361462959876, Training Accuracy: 0.31971153846153844\n",
            "Epoch 1/1, Batch Loss: 1.3304764032363892, Average Training Loss: 1.5122746527194977, Training Accuracy: 0.3234375\n",
            "Epoch 1/1, Batch Loss: 1.4960026741027832, Average Training Loss: 1.5118777751922607, Training Accuracy: 0.3231707317073171\n",
            "Epoch 1/1, Batch Loss: 1.3269150257110596, Average Training Loss: 1.5074739002046131, Training Accuracy: 0.328125\n",
            "Epoch 1/1, Batch Loss: 1.178798794746399, Average Training Loss: 1.4998302931009337, Training Accuracy: 0.33430232558139533\n",
            "Epoch 1/1, Batch Loss: 1.3473553657531738, Average Training Loss: 1.4963649538430301, Training Accuracy: 0.3380681818181818\n",
            "Epoch 1/1, Batch Loss: 1.1446962356567383, Average Training Loss: 1.4885500934388902, Training Accuracy: 0.3423611111111111\n",
            "Epoch 1/1, Batch Loss: 1.2759519815444946, Average Training Loss: 1.4839283953542295, Training Accuracy: 0.34578804347826086\n",
            "Epoch 1/1, Batch Loss: 1.2651139497756958, Average Training Loss: 1.4792727688525587, Training Accuracy: 0.35106382978723405\n",
            "Epoch 1/1, Batch Loss: 1.2931568622589111, Average Training Loss: 1.4753953541318576, Training Accuracy: 0.3528645833333333\n",
            "Epoch 1/1, Batch Loss: 1.3101353645324707, Average Training Loss: 1.4720227012828904, Training Accuracy: 0.35586734693877553\n",
            "Epoch 1/1, Batch Loss: 1.2753057479858398, Average Training Loss: 1.4680883622169494, Training Accuracy: 0.3575\n",
            "Epoch 1/1, Batch Loss: 1.22418212890625, Average Training Loss: 1.4633058870539946, Training Accuracy: 0.3584558823529412\n",
            "Epoch 1/1, Batch Loss: 1.447848916053772, Average Training Loss: 1.4630086376116826, Training Accuracy: 0.35877403846153844\n",
            "Epoch 1/1, Batch Loss: 1.1793879270553589, Average Training Loss: 1.4576573034502425, Training Accuracy: 0.3632075471698113\n",
            "Epoch 1/1, Batch Loss: 1.2663171291351318, Average Training Loss: 1.4541139668888516, Training Accuracy: 0.3645833333333333\n",
            "Epoch 1/1, Batch Loss: 1.2306979894638062, Average Training Loss: 1.4500518582083963, Training Accuracy: 0.3664772727272727\n",
            "Epoch 1/1, Batch Loss: 1.2045100927352905, Average Training Loss: 1.445667183824948, Training Accuracy: 0.36941964285714285\n",
            "Epoch 1/1, Batch Loss: 1.1130592823028564, Average Training Loss: 1.439831957482455, Training Accuracy: 0.3744517543859649\n",
            "Epoch 1/1, Batch Loss: 1.2335606813430786, Average Training Loss: 1.4362755561697071, Training Accuracy: 0.3793103448275862\n",
            "Epoch 1/1, Batch Loss: 1.2283669710159302, Average Training Loss: 1.432751681845067, Training Accuracy: 0.3824152542372881\n",
            "Epoch 1/1, Batch Loss: 1.0750828981399536, Average Training Loss: 1.4267905354499817, Training Accuracy: 0.38645833333333335\n",
            "Epoch 1/1, Batch Loss: 1.3014086484909058, Average Training Loss: 1.4247350946801607, Training Accuracy: 0.38831967213114754\n",
            "Epoch 1/1, Batch Loss: 1.0813846588134766, Average Training Loss: 1.4191971844242466, Training Accuracy: 0.39314516129032256\n",
            "Epoch 1/1, Batch Loss: 1.24280846118927, Average Training Loss: 1.4163973634205167, Training Accuracy: 0.3943452380952381\n",
            "Epoch 1/1, Batch Loss: 1.2684125900268555, Average Training Loss: 1.4140851013362408, Training Accuracy: 0.39697265625\n",
            "Epoch 1/1, Batch Loss: 1.227280855178833, Average Training Loss: 1.411211189856896, Training Accuracy: 0.3971153846153846\n",
            "Epoch 1/1, Batch Loss: 1.3484013080596924, Average Training Loss: 1.410259524981181, Training Accuracy: 0.3977272727272727\n",
            "Epoch 1/1, Batch Loss: 1.2171783447265625, Average Training Loss: 1.4273499639505696, Training Accuracy: 0.3978240302743614\n",
            "Epoch 1/1, Average Training Loss: 1.4073777163206642, Training Accuracy: 0.3978240302743614\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.33      0.35      0.34       427\n",
            "                Educational Opportunity       0.30      0.38      0.34       451\n",
            "                         Family Support       0.45      0.34      0.39       396\n",
            "                      Financial Support       0.43      0.34      0.38       404\n",
            "                 Program Implementation       0.53      0.57      0.55       436\n",
            "\n",
            "                               accuracy                           0.40      2114\n",
            "                              macro avg       0.41      0.40      0.40      2114\n",
            "                           weighted avg       0.41      0.40      0.40      2114\n",
            "\n",
            "Epoch 1/1, Validation Loss: 21.006471395492554, Validation Accuracy: 0.5141776937618148\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.54      0.31      0.39       113\n",
            "                Educational Opportunity       0.46      0.53      0.49       100\n",
            "                         Family Support       0.42      0.68      0.52       105\n",
            "                      Financial Support       0.61      0.48      0.54        97\n",
            "                 Program Implementation       0.65      0.58      0.61       114\n",
            "\n",
            "                               accuracy                           0.51       529\n",
            "                              macro avg       0.54      0.52      0.51       529\n",
            "                           weighted avg       0.54      0.51      0.51       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsXdRy4kUgnr",
        "outputId": "75005ad0-d103-49e1-f010-8bcc8e2c2442"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-8-0bfa20f2ad6a>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch Loss: 1.6228388547897339, Average Training Loss: 1.6228388547897339, Training Accuracy: 0.125\n",
            "Epoch 1/10, Batch Loss: 1.74497389793396, Average Training Loss: 1.683906376361847, Training Accuracy: 0.125\n",
            "Epoch 1/10, Batch Loss: 1.5916099548339844, Average Training Loss: 1.653140902519226, Training Accuracy: 0.14583333333333334\n",
            "Epoch 1/10, Batch Loss: 1.624433159828186, Average Training Loss: 1.645963966846466, Training Accuracy: 0.15625\n",
            "Epoch 1/10, Batch Loss: 1.578614592552185, Average Training Loss: 1.6324940919876099, Training Accuracy: 0.175\n",
            "Epoch 1/10, Batch Loss: 1.6372566223144531, Average Training Loss: 1.6332878470420837, Training Accuracy: 0.1875\n",
            "Epoch 1/10, Batch Loss: 1.6162292957305908, Average Training Loss: 1.630850911140442, Training Accuracy: 0.19642857142857142\n",
            "Epoch 1/10, Batch Loss: 1.6270800828933716, Average Training Loss: 1.630379557609558, Training Accuracy: 0.1796875\n",
            "Epoch 1/10, Batch Loss: 1.5234469175338745, Average Training Loss: 1.6184981531567044, Training Accuracy: 0.19444444444444445\n",
            "Epoch 1/10, Batch Loss: 1.6209803819656372, Average Training Loss: 1.6187463760375977, Training Accuracy: 0.2\n",
            "Epoch 1/10, Batch Loss: 1.610501766204834, Average Training Loss: 1.617996866052801, Training Accuracy: 0.19886363636363635\n",
            "Epoch 1/10, Batch Loss: 1.5130428075790405, Average Training Loss: 1.609250694513321, Training Accuracy: 0.21875\n",
            "Epoch 1/10, Batch Loss: 1.4196995496749878, Average Training Loss: 1.5946698372180645, Training Accuracy: 0.25\n",
            "Epoch 1/10, Batch Loss: 1.6130951642990112, Average Training Loss: 1.5959859320095606, Training Accuracy: 0.24553571428571427\n",
            "Epoch 1/10, Batch Loss: 1.5161787271499634, Average Training Loss: 1.5906654516855876, Training Accuracy: 0.25833333333333336\n",
            "Epoch 1/10, Batch Loss: 1.5698528289794922, Average Training Loss: 1.5893646627664566, Training Accuracy: 0.2578125\n",
            "Epoch 1/10, Batch Loss: 1.5554826259613037, Average Training Loss: 1.5873716017779183, Training Accuracy: 0.26838235294117646\n",
            "Epoch 1/10, Batch Loss: 1.470726728439331, Average Training Loss: 1.5808913310368855, Training Accuracy: 0.2777777777777778\n",
            "Epoch 1/10, Batch Loss: 1.4832983016967773, Average Training Loss: 1.5757548558084589, Training Accuracy: 0.27960526315789475\n",
            "Epoch 1/10, Batch Loss: 1.5491461753845215, Average Training Loss: 1.574424421787262, Training Accuracy: 0.284375\n",
            "Epoch 1/10, Batch Loss: 1.4503238201141357, Average Training Loss: 1.5685148693266369, Training Accuracy: 0.28869047619047616\n",
            "Epoch 1/10, Batch Loss: 1.5020923614501953, Average Training Loss: 1.5654956644231623, Training Accuracy: 0.2897727272727273\n",
            "Epoch 1/10, Batch Loss: 1.6237016916275024, Average Training Loss: 1.5680263612581335, Training Accuracy: 0.2907608695652174\n",
            "Epoch 1/10, Batch Loss: 1.5312458276748657, Average Training Loss: 1.5664938390254974, Training Accuracy: 0.2890625\n",
            "Epoch 1/10, Batch Loss: 1.3976397514343262, Average Training Loss: 1.5597396755218507, Training Accuracy: 0.2925\n",
            "Epoch 1/10, Batch Loss: 1.4216313362121582, Average Training Loss: 1.5544278163176317, Training Accuracy: 0.3004807692307692\n",
            "Epoch 1/10, Batch Loss: 1.5834345817565918, Average Training Loss: 1.555502140963519, Training Accuracy: 0.2986111111111111\n",
            "Epoch 1/10, Batch Loss: 1.4814589023590088, Average Training Loss: 1.5528577395847865, Training Accuracy: 0.30580357142857145\n",
            "Epoch 1/10, Batch Loss: 1.5102810859680176, Average Training Loss: 1.5513895791152428, Training Accuracy: 0.2995689655172414\n",
            "Epoch 1/10, Batch Loss: 1.5223779678344727, Average Training Loss: 1.5504225254058839, Training Accuracy: 0.3020833333333333\n",
            "Epoch 1/10, Batch Loss: 1.5215027332305908, Average Training Loss: 1.5494896288841002, Training Accuracy: 0.3004032258064516\n",
            "Epoch 1/10, Batch Loss: 1.3884460926055908, Average Training Loss: 1.5444570183753967, Training Accuracy: 0.30859375\n",
            "Epoch 1/10, Batch Loss: 1.360337495803833, Average Training Loss: 1.5388776389035312, Training Accuracy: 0.3125\n",
            "Epoch 1/10, Batch Loss: 1.388710379600525, Average Training Loss: 1.534460954806384, Training Accuracy: 0.3161764705882353\n",
            "Epoch 1/10, Batch Loss: 1.266543984413147, Average Training Loss: 1.52680618422372, Training Accuracy: 0.32321428571428573\n",
            "Epoch 1/10, Batch Loss: 1.2424509525299072, Average Training Loss: 1.5189074277877808, Training Accuracy: 0.3298611111111111\n",
            "Epoch 1/10, Batch Loss: 1.538467288017273, Average Training Loss: 1.519436072658848, Training Accuracy: 0.3277027027027027\n",
            "Epoch 1/10, Batch Loss: 1.536856770515442, Average Training Loss: 1.519894512076127, Training Accuracy: 0.32730263157894735\n",
            "Epoch 1/10, Batch Loss: 1.4622032642364502, Average Training Loss: 1.518415249311007, Training Accuracy: 0.3269230769230769\n",
            "Epoch 1/10, Batch Loss: 1.4111870527267456, Average Training Loss: 1.5157345443964005, Training Accuracy: 0.3328125\n",
            "Epoch 1/10, Batch Loss: 1.314292073249817, Average Training Loss: 1.5108213133928252, Training Accuracy: 0.3384146341463415\n",
            "Epoch 1/10, Batch Loss: 1.2740156650543213, Average Training Loss: 1.5051830836704798, Training Accuracy: 0.34375\n",
            "Epoch 1/10, Batch Loss: 1.3354806900024414, Average Training Loss: 1.5012365163758743, Training Accuracy: 0.34593023255813954\n",
            "Epoch 1/10, Batch Loss: 1.5094468593597412, Average Training Loss: 1.5014231150800532, Training Accuracy: 0.34375\n",
            "Epoch 1/10, Batch Loss: 1.3498427867889404, Average Training Loss: 1.4980546633402507, Training Accuracy: 0.3472222222222222\n",
            "Epoch 1/10, Batch Loss: 1.6345555782318115, Average Training Loss: 1.5010220745335454, Training Accuracy: 0.34646739130434784\n",
            "Epoch 1/10, Batch Loss: 1.1485077142715454, Average Training Loss: 1.493521768996056, Training Accuracy: 0.3537234042553192\n",
            "Epoch 1/10, Batch Loss: 1.394916296005249, Average Training Loss: 1.4914674883087475, Training Accuracy: 0.3541666666666667\n",
            "Epoch 1/10, Batch Loss: 1.3375062942504883, Average Training Loss: 1.4883254231238852, Training Accuracy: 0.35586734693877553\n",
            "Epoch 1/10, Batch Loss: 1.3912309408187866, Average Training Loss: 1.4863835334777833, Training Accuracy: 0.35375\n",
            "Epoch 1/10, Batch Loss: 1.2473726272583008, Average Training Loss: 1.4816970451205385, Training Accuracy: 0.35661764705882354\n",
            "Epoch 1/10, Batch Loss: 1.0377159118652344, Average Training Loss: 1.4731589464040904, Training Accuracy: 0.3605769230769231\n",
            "Epoch 1/10, Batch Loss: 0.9503048658370972, Average Training Loss: 1.4632937750726376, Training Accuracy: 0.36792452830188677\n",
            "Epoch 1/10, Batch Loss: 1.281301498413086, Average Training Loss: 1.4599235477270904, Training Accuracy: 0.37037037037037035\n",
            "Epoch 1/10, Batch Loss: 1.1124546527862549, Average Training Loss: 1.4536059314554388, Training Accuracy: 0.37613636363636366\n",
            "Epoch 1/10, Batch Loss: 1.0667669773101807, Average Training Loss: 1.4466980929885591, Training Accuracy: 0.3828125\n",
            "Epoch 1/10, Batch Loss: 1.1975529193878174, Average Training Loss: 1.4423271250306515, Training Accuracy: 0.3892543859649123\n",
            "Epoch 1/10, Batch Loss: 0.8830975294113159, Average Training Loss: 1.4326852354510078, Training Accuracy: 0.3954741379310345\n",
            "Epoch 1/10, Batch Loss: 1.3786686658859253, Average Training Loss: 1.4317697003736334, Training Accuracy: 0.3951271186440678\n",
            "Epoch 1/10, Batch Loss: 1.1774286031723022, Average Training Loss: 1.4275306820869447, Training Accuracy: 0.396875\n",
            "Epoch 1/10, Batch Loss: 1.1473180055618286, Average Training Loss: 1.4229370316521066, Training Accuracy: 0.39959016393442626\n",
            "Epoch 1/10, Batch Loss: 1.1124686002731323, Average Training Loss: 1.4179294763072845, Training Accuracy: 0.4032258064516129\n",
            "Epoch 1/10, Batch Loss: 1.1565520763397217, Average Training Loss: 1.4137806286887518, Training Accuracy: 0.40476190476190477\n",
            "Epoch 1/10, Batch Loss: 0.9411761164665222, Average Training Loss: 1.4063961831852794, Training Accuracy: 0.408203125\n",
            "Epoch 1/10, Batch Loss: 0.9536199569702148, Average Training Loss: 1.399430395089663, Training Accuracy: 0.41442307692307695\n",
            "Epoch 1/10, Batch Loss: 1.042474627494812, Average Training Loss: 1.394021974368529, Training Accuracy: 0.41761363636363635\n",
            "Epoch 1/10, Batch Loss: 1.051079511642456, Average Training Loss: 1.3889034301487369, Training Accuracy: 0.4197761194029851\n",
            "Epoch 1/10, Batch Loss: 1.0770277976989746, Average Training Loss: 1.3843170237891815, Training Accuracy: 0.4227941176470588\n",
            "Epoch 1/10, Batch Loss: 1.126009464263916, Average Training Loss: 1.3805734359699746, Training Accuracy: 0.4230072463768116\n",
            "Epoch 1/10, Batch Loss: 0.7481446862220764, Average Training Loss: 1.3715387395450047, Training Accuracy: 0.42857142857142855\n",
            "Epoch 1/10, Batch Loss: 0.993670642375946, Average Training Loss: 1.3662166536693843, Training Accuracy: 0.43045774647887325\n",
            "Epoch 1/10, Batch Loss: 0.5816543698310852, Average Training Loss: 1.355319955282741, Training Accuracy: 0.4366319444444444\n",
            "Epoch 1/10, Batch Loss: 0.6656878590583801, Average Training Loss: 1.345872940265969, Training Accuracy: 0.4417808219178082\n",
            "Epoch 1/10, Batch Loss: 1.0208463668823242, Average Training Loss: 1.341480689274298, Training Accuracy: 0.44510135135135137\n",
            "Epoch 1/10, Batch Loss: 1.0861247777938843, Average Training Loss: 1.3380759437878926, Training Accuracy: 0.4483333333333333\n",
            "Epoch 1/10, Batch Loss: 0.8774693608283997, Average Training Loss: 1.332015330854215, Training Accuracy: 0.45230263157894735\n",
            "Epoch 1/10, Batch Loss: 0.6920462846755981, Average Training Loss: 1.323704044540207, Training Accuracy: 0.45616883116883117\n",
            "Epoch 1/10, Batch Loss: 1.1277331113815308, Average Training Loss: 1.3211915966791985, Training Accuracy: 0.45753205128205127\n",
            "Epoch 1/10, Batch Loss: 0.732220470905304, Average Training Loss: 1.3137362659731997, Training Accuracy: 0.4612341772151899\n",
            "Epoch 1/10, Batch Loss: 0.9693782925605774, Average Training Loss: 1.309431791305542, Training Accuracy: 0.46328125\n",
            "Epoch 1/10, Batch Loss: 0.894682765007019, Average Training Loss: 1.3043114329561776, Training Accuracy: 0.4652777777777778\n",
            "Epoch 1/10, Batch Loss: 0.9237430095672607, Average Training Loss: 1.2996703546221664, Training Accuracy: 0.4657012195121951\n",
            "Epoch 1/10, Batch Loss: 0.6233216524124146, Average Training Loss: 1.2915215750774705, Training Accuracy: 0.4691265060240964\n",
            "Epoch 1/10, Batch Loss: 1.0546399354934692, Average Training Loss: 1.2887015555586134, Training Accuracy: 0.47098214285714285\n",
            "Epoch 1/10, Batch Loss: 1.1211899518966675, Average Training Loss: 1.2867308308096492, Training Accuracy: 0.4742647058823529\n",
            "Epoch 1/10, Batch Loss: 0.717499852180481, Average Training Loss: 1.2801118659418682, Training Accuracy: 0.47819767441860467\n",
            "Epoch 1/10, Batch Loss: 0.9231001734733582, Average Training Loss: 1.2760082832698165, Training Accuracy: 0.47988505747126436\n",
            "Epoch 1/10, Batch Loss: 1.1930086612701416, Average Training Loss: 1.2750651057470928, Training Accuracy: 0.4815340909090909\n",
            "Epoch 1/10, Batch Loss: 0.7867476940155029, Average Training Loss: 1.2695783932557267, Training Accuracy: 0.4845505617977528\n",
            "Epoch 1/10, Batch Loss: 0.7859381437301636, Average Training Loss: 1.2642046127054427, Training Accuracy: 0.48680555555555555\n",
            "Epoch 1/10, Batch Loss: 0.6510298848152161, Average Training Loss: 1.257466428882473, Training Accuracy: 0.4896978021978022\n",
            "Epoch 1/10, Batch Loss: 0.6787124872207642, Average Training Loss: 1.251175625168759, Training Accuracy: 0.49320652173913043\n",
            "Epoch 1/10, Batch Loss: 1.0259073972702026, Average Training Loss: 1.248753386159097, Training Accuracy: 0.4939516129032258\n",
            "Epoch 1/10, Batch Loss: 0.7494739890098572, Average Training Loss: 1.243441903210701, Training Accuracy: 0.4966755319148936\n",
            "Epoch 1/10, Batch Loss: 0.8751825094223022, Average Training Loss: 1.239565488539244, Training Accuracy: 0.4986842105263158\n",
            "Epoch 1/10, Batch Loss: 0.68415766954422, Average Training Loss: 1.2337799904247124, Training Accuracy: 0.501953125\n",
            "Epoch 1/10, Batch Loss: 1.0108592510223389, Average Training Loss: 1.2314818384721107, Training Accuracy: 0.5032216494845361\n",
            "Epoch 1/10, Batch Loss: 1.4007474184036255, Average Training Loss: 1.2332090382673302, Training Accuracy: 0.5012755102040817\n",
            "Epoch 1/10, Batch Loss: 0.7221143841743469, Average Training Loss: 1.2280464660037647, Training Accuracy: 0.5031565656565656\n",
            "Epoch 1/10, Batch Loss: 0.7205175161361694, Average Training Loss: 1.2229711765050888, Training Accuracy: 0.50625\n",
            "Epoch 1/10, Batch Loss: 0.656189501285553, Average Training Loss: 1.2173594767504399, Training Accuracy: 0.5080445544554455\n",
            "Epoch 1/10, Batch Loss: 0.8387992978096008, Average Training Loss: 1.2136481024470984, Training Accuracy: 0.5110294117647058\n",
            "Epoch 1/10, Batch Loss: 1.1742241382598877, Average Training Loss: 1.213265345513242, Training Accuracy: 0.5103155339805825\n",
            "Epoch 1/10, Batch Loss: 0.6822400093078613, Average Training Loss: 1.2081593326651132, Training Accuracy: 0.5132211538461539\n",
            "Epoch 1/10, Batch Loss: 0.8278532028198242, Average Training Loss: 1.2045373695237296, Training Accuracy: 0.5148809523809523\n",
            "Epoch 1/10, Batch Loss: 0.8512099981307983, Average Training Loss: 1.201204092435117, Training Accuracy: 0.5176886792452831\n",
            "Epoch 1/10, Batch Loss: 0.6623562574386597, Average Training Loss: 1.1961681313603838, Training Accuracy: 0.5204439252336449\n",
            "Epoch 1/10, Batch Loss: 0.6504729986190796, Average Training Loss: 1.1911153986498162, Training Accuracy: 0.5225694444444444\n",
            "Epoch 1/10, Batch Loss: 0.6738131046295166, Average Training Loss: 1.1863695060441253, Training Accuracy: 0.5246559633027523\n",
            "Epoch 1/10, Batch Loss: 1.0321003198623657, Average Training Loss: 1.1849670588970185, Training Accuracy: 0.5261363636363636\n",
            "Epoch 1/10, Batch Loss: 0.8391831517219543, Average Training Loss: 1.1818518885621079, Training Accuracy: 0.5287162162162162\n",
            "Epoch 1/10, Batch Loss: 0.7882075309753418, Average Training Loss: 1.1783372067979403, Training Accuracy: 0.5306919642857143\n",
            "Epoch 1/10, Batch Loss: 0.5914626717567444, Average Training Loss: 1.1731436268418236, Training Accuracy: 0.5337389380530974\n",
            "Epoch 1/10, Batch Loss: 0.7012240290641785, Average Training Loss: 1.1690039812472828, Training Accuracy: 0.5350877192982456\n",
            "Epoch 1/10, Batch Loss: 0.9547314643859863, Average Training Loss: 1.1671407419702282, Training Accuracy: 0.5353260869565217\n",
            "Epoch 1/10, Batch Loss: 0.8744014501571655, Average Training Loss: 1.1646171273856327, Training Accuracy: 0.537176724137931\n",
            "Epoch 1/10, Batch Loss: 0.733447790145874, Average Training Loss: 1.1609319193750365, Training Accuracy: 0.5400641025641025\n",
            "Epoch 1/10, Batch Loss: 1.019454002380371, Average Training Loss: 1.1597329539767767, Training Accuracy: 0.5402542372881356\n",
            "Epoch 1/10, Batch Loss: 0.8145487308502197, Average Training Loss: 1.1568322462194107, Training Accuracy: 0.5414915966386554\n",
            "Epoch 1/10, Batch Loss: 1.2781423330307007, Average Training Loss: 1.1578431636095048, Training Accuracy: 0.5411458333333333\n",
            "Epoch 1/10, Batch Loss: 0.619785487651825, Average Training Loss: 1.153396405956962, Training Accuracy: 0.5433884297520661\n",
            "Epoch 1/10, Batch Loss: 0.8119876384735107, Average Training Loss: 1.1505979734366056, Training Accuracy: 0.5440573770491803\n",
            "Epoch 1/10, Batch Loss: 1.033980369567871, Average Training Loss: 1.149649862836047, Training Accuracy: 0.5457317073170732\n",
            "Epoch 1/10, Batch Loss: 0.7325035929679871, Average Training Loss: 1.1462857800145303, Training Accuracy: 0.5463709677419355\n",
            "Epoch 1/10, Batch Loss: 1.0104104280471802, Average Training Loss: 1.1451987771987915, Training Accuracy: 0.5475\n",
            "Epoch 1/10, Batch Loss: 0.5731338262557983, Average Training Loss: 1.1406585791754345, Training Accuracy: 0.5486111111111112\n",
            "Epoch 1/10, Batch Loss: 0.7333961725234985, Average Training Loss: 1.1374517885718758, Training Accuracy: 0.5497047244094488\n",
            "Epoch 1/10, Batch Loss: 0.6907347440719604, Average Training Loss: 1.1339618116617203, Training Accuracy: 0.5517578125\n",
            "Epoch 1/10, Batch Loss: 0.6960448026657104, Average Training Loss: 1.1305671061656273, Training Accuracy: 0.5537790697674418\n",
            "Epoch 1/10, Batch Loss: 0.9183415174484253, Average Training Loss: 1.1289346016370334, Training Accuracy: 0.5543269230769231\n",
            "Epoch 1/10, Batch Loss: 0.5957787036895752, Average Training Loss: 1.1248647092862893, Training Accuracy: 0.5567748091603053\n",
            "Epoch 1/10, Batch Loss: 0.5834569931030273, Average Training Loss: 1.1207631356788403, Training Accuracy: 0.5587121212121212\n",
            "Epoch 1/10, Batch Loss: 0.0860292911529541, Average Training Loss: 1.1203539315100086, Training Accuracy: 0.5591296121097445\n",
            "Epoch 1/10, Average Training Loss: 1.1129831819606006, Training Accuracy: 0.5591296121097445\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.51      0.49      0.50       427\n",
            "                Educational Opportunity       0.44      0.44      0.44       451\n",
            "                         Family Support       0.68      0.67      0.67       396\n",
            "                      Financial Support       0.59      0.66      0.62       404\n",
            "                 Program Implementation       0.59      0.56      0.58       436\n",
            "\n",
            "                               accuracy                           0.56      2114\n",
            "                              macro avg       0.56      0.56      0.56      2114\n",
            "                           weighted avg       0.56      0.56      0.56      2114\n",
            "\n",
            "Epoch 1/10, Validation Loss: 29.028923258185387, Validation Accuracy: 0.6899810964083176\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.53      0.74      0.62       113\n",
            "                Educational Opportunity       0.62      0.26      0.37       100\n",
            "                         Family Support       0.90      0.94      0.92       105\n",
            "                      Financial Support       0.65      0.84      0.73        97\n",
            "                 Program Implementation       0.82      0.66      0.73       114\n",
            "\n",
            "                               accuracy                           0.69       529\n",
            "                              macro avg       0.70      0.69      0.67       529\n",
            "                           weighted avg       0.70      0.69      0.67       529\n",
            "\n",
            "Epoch 2/10, Batch Loss: 0.8261029124259949, Average Training Loss: 0.8261029124259949, Training Accuracy: 0.6875\n",
            "Epoch 2/10, Batch Loss: 0.35837340354919434, Average Training Loss: 0.5922381579875946, Training Accuracy: 0.78125\n",
            "Epoch 2/10, Batch Loss: 0.6062738299369812, Average Training Loss: 0.5969167153040568, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/10, Batch Loss: 0.6267818808555603, Average Training Loss: 0.6043830066919327, Training Accuracy: 0.78125\n",
            "Epoch 2/10, Batch Loss: 0.4608432352542877, Average Training Loss: 0.5756750524044036, Training Accuracy: 0.8\n",
            "Epoch 2/10, Batch Loss: 0.7969902753829956, Average Training Loss: 0.6125609229008356, Training Accuracy: 0.78125\n",
            "Epoch 2/10, Batch Loss: 0.9096990823745728, Average Training Loss: 0.6550092313970838, Training Accuracy: 0.7589285714285714\n",
            "Epoch 2/10, Batch Loss: 0.3342688977718353, Average Training Loss: 0.6149166896939278, Training Accuracy: 0.78125\n",
            "Epoch 2/10, Batch Loss: 0.9051864147186279, Average Training Loss: 0.6471688813633389, Training Accuracy: 0.7638888888888888\n",
            "Epoch 2/10, Batch Loss: 0.5587154626846313, Average Training Loss: 0.6383235394954682, Training Accuracy: 0.76875\n",
            "Epoch 2/10, Batch Loss: 0.41546547412872314, Average Training Loss: 0.6180637153712186, Training Accuracy: 0.7840909090909091\n",
            "Epoch 2/10, Batch Loss: 0.9819002151489258, Average Training Loss: 0.6483834236860275, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/10, Batch Loss: 0.7982564568519592, Average Training Loss: 0.6599121185449454, Training Accuracy: 0.7596153846153846\n",
            "Epoch 2/10, Batch Loss: 0.6141418814659119, Average Training Loss: 0.6566428158964429, Training Accuracy: 0.7633928571428571\n",
            "Epoch 2/10, Batch Loss: 0.9192923903465271, Average Training Loss: 0.6741527875264486, Training Accuracy: 0.7541666666666667\n",
            "Epoch 2/10, Batch Loss: 0.6127289533615112, Average Training Loss: 0.67031379789114, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.9177256226539612, Average Training Loss: 0.6848674346418941, Training Accuracy: 0.7389705882352942\n",
            "Epoch 2/10, Batch Loss: 0.44043976068496704, Average Training Loss: 0.6712881194220649, Training Accuracy: 0.7465277777777778\n",
            "Epoch 2/10, Batch Loss: 0.7245294451713562, Average Training Loss: 0.6740902944615013, Training Accuracy: 0.7467105263157895\n",
            "Epoch 2/10, Batch Loss: 0.43119266629219055, Average Training Loss: 0.6619454130530358, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.6809831857681274, Average Training Loss: 0.6628519736585163, Training Accuracy: 0.7529761904761905\n",
            "Epoch 2/10, Batch Loss: 0.9418530464172363, Average Training Loss: 0.6755338406020944, Training Accuracy: 0.75\n",
            "Epoch 2/10, Batch Loss: 0.6419350504875183, Average Training Loss: 0.6740730236405912, Training Accuracy: 0.7472826086956522\n",
            "Epoch 2/10, Batch Loss: 0.6482419967651367, Average Training Loss: 0.6729967308541139, Training Accuracy: 0.7473958333333334\n",
            "Epoch 2/10, Batch Loss: 0.844114363193512, Average Training Loss: 0.6798414361476898, Training Accuracy: 0.745\n",
            "Epoch 2/10, Batch Loss: 0.7452629804611206, Average Training Loss: 0.6823576493905141, Training Accuracy: 0.7427884615384616\n",
            "Epoch 2/10, Batch Loss: 0.8180873990058899, Average Training Loss: 0.6873846771540465, Training Accuracy: 0.7430555555555556\n",
            "Epoch 2/10, Batch Loss: 0.7389215230941772, Average Training Loss: 0.6892252787947655, Training Accuracy: 0.7410714285714286\n",
            "Epoch 2/10, Batch Loss: 1.1234437227249146, Average Training Loss: 0.7041983285854603, Training Accuracy: 0.7370689655172413\n",
            "Epoch 2/10, Batch Loss: 0.7049194574356079, Average Training Loss: 0.7042223662137985, Training Accuracy: 0.7354166666666667\n",
            "Epoch 2/10, Batch Loss: 0.49548351764678955, Average Training Loss: 0.6974888549697015, Training Accuracy: 0.7399193548387096\n",
            "Epoch 2/10, Batch Loss: 0.5398231148719788, Average Training Loss: 0.6925618005916476, Training Accuracy: 0.7421875\n",
            "Epoch 2/10, Batch Loss: 0.6590481400489807, Average Training Loss: 0.6915462351206577, Training Accuracy: 0.7424242424242424\n",
            "Epoch 2/10, Batch Loss: 0.637718915939331, Average Training Loss: 0.6899630786741481, Training Accuracy: 0.7444852941176471\n",
            "Epoch 2/10, Batch Loss: 0.954663097858429, Average Training Loss: 0.6975259363651276, Training Accuracy: 0.7428571428571429\n",
            "Epoch 2/10, Batch Loss: 0.8590096235275269, Average Training Loss: 0.7020115943418609, Training Accuracy: 0.7413194444444444\n",
            "Epoch 2/10, Batch Loss: 0.4262421429157257, Average Training Loss: 0.6945583659249384, Training Accuracy: 0.7483108108108109\n",
            "Epoch 2/10, Batch Loss: 1.1133332252502441, Average Training Loss: 0.7055787569598148, Training Accuracy: 0.7467105263157895\n",
            "Epoch 2/10, Batch Loss: 0.8910626769065857, Average Training Loss: 0.7103347549071679, Training Accuracy: 0.7435897435897436\n",
            "Epoch 2/10, Batch Loss: 0.47236761450767517, Average Training Loss: 0.7043855763971806, Training Accuracy: 0.7453125\n",
            "Epoch 2/10, Batch Loss: 0.46359241008758545, Average Training Loss: 0.698512572340849, Training Accuracy: 0.7484756097560976\n",
            "Epoch 2/10, Batch Loss: 0.7311710715293884, Average Training Loss: 0.6992901556548619, Training Accuracy: 0.7455357142857143\n",
            "Epoch 2/10, Batch Loss: 0.6435710191726685, Average Training Loss: 0.6979943617831829, Training Accuracy: 0.747093023255814\n",
            "Epoch 2/10, Batch Loss: 0.39150670170783997, Average Training Loss: 0.6910287331451069, Training Accuracy: 0.7514204545454546\n",
            "Epoch 2/10, Batch Loss: 0.5022415518760681, Average Training Loss: 0.6868334624502394, Training Accuracy: 0.7541666666666667\n",
            "Epoch 2/10, Batch Loss: 0.7028146982192993, Average Training Loss: 0.687180880619132, Training Accuracy: 0.7527173913043478\n",
            "Epoch 2/10, Batch Loss: 0.5547632575035095, Average Training Loss: 0.6843634843826294, Training Accuracy: 0.7553191489361702\n",
            "Epoch 2/10, Batch Loss: 1.0432056188583374, Average Training Loss: 0.6918393621842066, Training Accuracy: 0.75390625\n",
            "Epoch 2/10, Batch Loss: 0.7419577836990356, Average Training Loss: 0.6928621871130807, Training Accuracy: 0.7551020408163265\n",
            "Epoch 2/10, Batch Loss: 1.0504425764083862, Average Training Loss: 0.7000137948989869, Training Accuracy: 0.7525\n",
            "Epoch 2/10, Batch Loss: 0.44739627838134766, Average Training Loss: 0.695060510261386, Training Accuracy: 0.7536764705882353\n",
            "Epoch 2/10, Batch Loss: 0.36659348011016846, Average Training Loss: 0.6887438366046319, Training Accuracy: 0.7560096153846154\n",
            "Epoch 2/10, Batch Loss: 0.6920026540756226, Average Training Loss: 0.688805323726726, Training Accuracy: 0.7558962264150944\n",
            "Epoch 2/10, Batch Loss: 0.6819521188735962, Average Training Loss: 0.6886784125257421, Training Accuracy: 0.7557870370370371\n",
            "Epoch 2/10, Batch Loss: 0.4866580665111542, Average Training Loss: 0.6850053153254769, Training Accuracy: 0.7579545454545454\n",
            "Epoch 2/10, Batch Loss: 0.5671238303184509, Average Training Loss: 0.6829002888074943, Training Accuracy: 0.7578125\n",
            "Epoch 2/10, Batch Loss: 0.8463502526283264, Average Training Loss: 0.6857678320324212, Training Accuracy: 0.756578947368421\n",
            "Epoch 2/10, Batch Loss: 0.5278517007827759, Average Training Loss: 0.6830451401143238, Training Accuracy: 0.7553879310344828\n",
            "Epoch 2/10, Batch Loss: 0.4910319745540619, Average Training Loss: 0.6797906796810991, Training Accuracy: 0.7563559322033898\n",
            "Epoch 2/10, Batch Loss: 0.938506007194519, Average Training Loss: 0.6841026018063228, Training Accuracy: 0.7541666666666667\n",
            "Epoch 2/10, Batch Loss: 0.524600625038147, Average Training Loss: 0.6814878153019264, Training Accuracy: 0.7551229508196722\n",
            "Epoch 2/10, Batch Loss: 0.47711676359176636, Average Training Loss: 0.6781915080162787, Training Accuracy: 0.7570564516129032\n",
            "Epoch 2/10, Batch Loss: 0.8814902901649475, Average Training Loss: 0.6814184728122893, Training Accuracy: 0.753968253968254\n",
            "Epoch 2/10, Batch Loss: 0.5462833046913147, Average Training Loss: 0.679306985810399, Training Accuracy: 0.755859375\n",
            "Epoch 2/10, Batch Loss: 0.41124317049980164, Average Training Loss: 0.675182927113313, Training Accuracy: 0.7576923076923077\n",
            "Epoch 2/10, Batch Loss: 0.5191308259963989, Average Training Loss: 0.6728185013388143, Training Accuracy: 0.7604166666666666\n",
            "Epoch 2/10, Batch Loss: 0.8480993509292603, Average Training Loss: 0.6754346334222537, Training Accuracy: 0.7593283582089553\n",
            "Epoch 2/10, Batch Loss: 0.7021791338920593, Average Training Loss: 0.6758279348997509, Training Accuracy: 0.7591911764705882\n",
            "Epoch 2/10, Batch Loss: 0.3620603084564209, Average Training Loss: 0.671280577994775, Training Accuracy: 0.759963768115942\n",
            "Epoch 2/10, Batch Loss: 1.0917905569076538, Average Training Loss: 0.6772878634078162, Training Accuracy: 0.7571428571428571\n",
            "Epoch 2/10, Batch Loss: 0.20290900766849518, Average Training Loss: 0.6706064710734596, Training Accuracy: 0.7605633802816901\n",
            "Epoch 2/10, Batch Loss: 0.4706202745437622, Average Training Loss: 0.6678288850105472, Training Accuracy: 0.7604166666666666\n",
            "Epoch 2/10, Batch Loss: 0.31242308020591736, Average Training Loss: 0.6629603123419905, Training Accuracy: 0.761986301369863\n",
            "Epoch 2/10, Batch Loss: 0.41905677318573, Average Training Loss: 0.6596643185696086, Training Accuracy: 0.7635135135135135\n",
            "Epoch 2/10, Batch Loss: 0.21121250092983246, Average Training Loss: 0.6536849610010783, Training Accuracy: 0.7658333333333334\n",
            "Epoch 2/10, Batch Loss: 0.6550264954566956, Average Training Loss: 0.6537026127702311, Training Accuracy: 0.7664473684210527\n",
            "Epoch 2/10, Batch Loss: 0.4236942231655121, Average Training Loss: 0.6507154908273127, Training Accuracy: 0.7678571428571429\n",
            "Epoch 2/10, Batch Loss: 0.9986856579780579, Average Training Loss: 0.6551766468164248, Training Accuracy: 0.7668269230769231\n",
            "Epoch 2/10, Batch Loss: 0.7010865211486816, Average Training Loss: 0.6557577844662003, Training Accuracy: 0.7674050632911392\n",
            "Epoch 2/10, Batch Loss: 0.6157357096672058, Average Training Loss: 0.6552575085312128, Training Accuracy: 0.7671875\n",
            "Epoch 2/10, Batch Loss: 0.6221818327903748, Average Training Loss: 0.6548491668554, Training Accuracy: 0.7669753086419753\n",
            "Epoch 2/10, Batch Loss: 0.6887136697769165, Average Training Loss: 0.6552621485983453, Training Accuracy: 0.7675304878048781\n",
            "Epoch 2/10, Batch Loss: 0.6467860341072083, Average Training Loss: 0.6551600267370064, Training Accuracy: 0.7673192771084337\n",
            "Epoch 2/10, Batch Loss: 0.5816081166267395, Average Training Loss: 0.6542844087595031, Training Accuracy: 0.7671130952380952\n",
            "Epoch 2/10, Batch Loss: 0.8712459206581116, Average Training Loss: 0.6568368971347809, Training Accuracy: 0.7654411764705882\n",
            "Epoch 2/10, Batch Loss: 0.5135342478752136, Average Training Loss: 0.6551705872596696, Training Accuracy: 0.7659883720930233\n",
            "Epoch 2/10, Batch Loss: 0.47879886627197266, Average Training Loss: 0.6531433260988915, Training Accuracy: 0.7665229885057471\n",
            "Epoch 2/10, Batch Loss: 0.5074681639671326, Average Training Loss: 0.6514879265292124, Training Accuracy: 0.7670454545454546\n",
            "Epoch 2/10, Batch Loss: 0.563398540019989, Average Training Loss: 0.6504981581414684, Training Accuracy: 0.7668539325842697\n",
            "Epoch 2/10, Batch Loss: 0.4418884515762329, Average Training Loss: 0.6481802725129657, Training Accuracy: 0.7673611111111112\n",
            "Epoch 2/10, Batch Loss: 0.5485184192657471, Average Training Loss: 0.6470850873124468, Training Accuracy: 0.7678571428571429\n",
            "Epoch 2/10, Batch Loss: 0.39235007762908936, Average Training Loss: 0.6443162285115408, Training Accuracy: 0.7683423913043478\n",
            "Epoch 2/10, Batch Loss: 0.6223145723342896, Average Training Loss: 0.6440796515633983, Training Accuracy: 0.7681451612903226\n",
            "Epoch 2/10, Batch Loss: 0.35131675004959106, Average Training Loss: 0.6409651526111237, Training Accuracy: 0.7699468085106383\n",
            "Epoch 2/10, Batch Loss: 0.929774820804596, Average Training Loss: 0.6440052543815814, Training Accuracy: 0.7684210526315789\n",
            "Epoch 2/10, Batch Loss: 0.5476394891738892, Average Training Loss: 0.6430014443273345, Training Accuracy: 0.7701822916666666\n",
            "Epoch 2/10, Batch Loss: 0.731896162033081, Average Training Loss: 0.6439178847160536, Training Accuracy: 0.7693298969072165\n",
            "Epoch 2/10, Batch Loss: 0.620072603225708, Average Training Loss: 0.6436745655171725, Training Accuracy: 0.7691326530612245\n",
            "Epoch 2/10, Batch Loss: 0.42761921882629395, Average Training Loss: 0.6414921882778707, Training Accuracy: 0.7702020202020202\n",
            "Epoch 2/10, Batch Loss: 0.7916626334190369, Average Training Loss: 0.6429938927292824, Training Accuracy: 0.77\n",
            "Epoch 2/10, Batch Loss: 0.5022923350334167, Average Training Loss: 0.6416008079996204, Training Accuracy: 0.7704207920792079\n",
            "Epoch 2/10, Batch Loss: 0.7018839120864868, Average Training Loss: 0.6421918188240013, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/10, Batch Loss: 0.9047763347625732, Average Training Loss: 0.6447411830564147, Training Accuracy: 0.7700242718446602\n",
            "Epoch 2/10, Batch Loss: 0.562431812286377, Average Training Loss: 0.6439497467990105, Training Accuracy: 0.7704326923076923\n",
            "Epoch 2/10, Batch Loss: 0.9068671464920044, Average Training Loss: 0.6464537220341818, Training Accuracy: 0.7690476190476191\n",
            "Epoch 2/10, Batch Loss: 0.41124963760375977, Average Training Loss: 0.6442348155772911, Training Accuracy: 0.7700471698113207\n",
            "Epoch 2/10, Batch Loss: 0.32985085248947144, Average Training Loss: 0.6412966476979657, Training Accuracy: 0.7710280373831776\n",
            "Epoch 2/10, Batch Loss: 0.5205126404762268, Average Training Loss: 0.6401782772607274, Training Accuracy: 0.7702546296296297\n",
            "Epoch 2/10, Batch Loss: 0.2338697612285614, Average Training Loss: 0.6364506761962121, Training Accuracy: 0.7717889908256881\n",
            "Epoch 2/10, Batch Loss: 1.1555960178375244, Average Training Loss: 0.6411701793020422, Training Accuracy: 0.7698863636363636\n",
            "Epoch 2/10, Batch Loss: 0.3444022834300995, Average Training Loss: 0.6384965946545472, Training Accuracy: 0.7708333333333334\n",
            "Epoch 2/10, Batch Loss: 0.41308632493019104, Average Training Loss: 0.6364840029605797, Training Accuracy: 0.7717633928571429\n",
            "Epoch 2/10, Batch Loss: 0.4574109613895416, Average Training Loss: 0.6348992857785352, Training Accuracy: 0.7721238938053098\n",
            "Epoch 2/10, Batch Loss: 0.813372015953064, Average Training Loss: 0.636464836043224, Training Accuracy: 0.7719298245614035\n",
            "Epoch 2/10, Batch Loss: 0.8635767102241516, Average Training Loss: 0.6384397219056669, Training Accuracy: 0.7711956521739131\n",
            "Epoch 2/10, Batch Loss: 0.3914596438407898, Average Training Loss: 0.6363105833016592, Training Accuracy: 0.7720905172413793\n",
            "Epoch 2/10, Batch Loss: 0.5792229175567627, Average Training Loss: 0.6358226545346088, Training Accuracy: 0.7724358974358975\n",
            "Epoch 2/10, Batch Loss: 0.655017614364624, Average Training Loss: 0.6359853236857107, Training Accuracy: 0.7733050847457628\n",
            "Epoch 2/10, Batch Loss: 0.44784268736839294, Average Training Loss: 0.6344042931284223, Training Accuracy: 0.7736344537815126\n",
            "Epoch 2/10, Batch Loss: 0.9207159280776978, Average Training Loss: 0.6367902234196663, Training Accuracy: 0.7729166666666667\n",
            "Epoch 2/10, Batch Loss: 0.8355154991149902, Average Training Loss: 0.6384325810700409, Training Accuracy: 0.7722107438016529\n",
            "Epoch 2/10, Batch Loss: 0.6811537146568298, Average Training Loss: 0.638782754296162, Training Accuracy: 0.7725409836065574\n",
            "Epoch 2/10, Batch Loss: 0.5795902013778687, Average Training Loss: 0.6383015140285336, Training Accuracy: 0.7723577235772358\n",
            "Epoch 2/10, Batch Loss: 1.015161395072937, Average Training Loss: 0.6413407066176015, Training Accuracy: 0.7711693548387096\n",
            "Epoch 2/10, Batch Loss: 0.4080308675765991, Average Training Loss: 0.6394742279052734, Training Accuracy: 0.772\n",
            "Epoch 2/10, Batch Loss: 0.26492640376091003, Average Training Loss: 0.63650162612635, Training Accuracy: 0.7733134920634921\n",
            "Epoch 2/10, Batch Loss: 0.38461947441101074, Average Training Loss: 0.6345183020970953, Training Accuracy: 0.7731299212598425\n",
            "Epoch 2/10, Batch Loss: 0.2521454989910126, Average Training Loss: 0.631531014572829, Training Accuracy: 0.77490234375\n",
            "Epoch 2/10, Batch Loss: 0.47949206829071045, Average Training Loss: 0.6303524180900218, Training Accuracy: 0.7756782945736435\n",
            "Epoch 2/10, Batch Loss: 0.8113267421722412, Average Training Loss: 0.6317445282752697, Training Accuracy: 0.7745192307692308\n",
            "Epoch 2/10, Batch Loss: 0.6680384278297424, Average Training Loss: 0.6320215809436245, Training Accuracy: 0.7743320610687023\n",
            "Epoch 2/10, Batch Loss: 0.8290146589279175, Average Training Loss: 0.6335139527465358, Training Accuracy: 0.7732007575757576\n",
            "Epoch 2/10, Batch Loss: 1.2487380504608154, Average Training Loss: 0.6423657885563182, Training Accuracy: 0.7729422894985809\n",
            "Epoch 2/10, Average Training Loss: 0.6381396978421319, Training Accuracy: 0.7729422894985809\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.74      0.76      0.75       427\n",
            "                Educational Opportunity       0.65      0.65      0.65       451\n",
            "                         Family Support       0.91      0.97      0.94       396\n",
            "                      Financial Support       0.78      0.85      0.81       404\n",
            "                 Program Implementation       0.79      0.67      0.72       436\n",
            "\n",
            "                               accuracy                           0.77      2114\n",
            "                              macro avg       0.78      0.78      0.78      2114\n",
            "                           weighted avg       0.77      0.77      0.77      2114\n",
            "\n",
            "Epoch 2/10, Validation Loss: 25.02183298766613, Validation Accuracy: 0.7296786389413988\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.79      0.59      0.68       113\n",
            "                Educational Opportunity       0.55      0.64      0.59       100\n",
            "                         Family Support       0.91      0.96      0.94       105\n",
            "                      Financial Support       0.64      0.84      0.72        97\n",
            "                 Program Implementation       0.81      0.64      0.72       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.74      0.73      0.73       529\n",
            "                           weighted avg       0.75      0.73      0.73       529\n",
            "\n",
            "Epoch 3/10, Batch Loss: 0.3812596797943115, Average Training Loss: 0.3812596797943115, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.5637287497520447, Average Training Loss: 0.4724942147731781, Training Accuracy: 0.84375\n",
            "Epoch 3/10, Batch Loss: 0.5525888800621033, Average Training Loss: 0.49919243653615314, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.3214646875858307, Average Training Loss: 0.45476049929857254, Training Accuracy: 0.859375\n",
            "Epoch 3/10, Batch Loss: 0.27505388855934143, Average Training Loss: 0.4188191771507263, Training Accuracy: 0.8625\n",
            "Epoch 3/10, Batch Loss: 0.35772714018821716, Average Training Loss: 0.4086371709903081, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.2889012396335602, Average Training Loss: 0.39153203793934416, Training Accuracy: 0.8839285714285714\n",
            "Epoch 3/10, Batch Loss: 0.33353281021118164, Average Training Loss: 0.3842821344733238, Training Accuracy: 0.890625\n",
            "Epoch 3/10, Batch Loss: 0.3011155128479004, Average Training Loss: 0.3750413987371657, Training Accuracy: 0.8958333333333334\n",
            "Epoch 3/10, Batch Loss: 0.6370096206665039, Average Training Loss: 0.4012382209300995, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.34509822726249695, Average Training Loss: 0.3961345851421356, Training Accuracy: 0.8806818181818182\n",
            "Epoch 3/10, Batch Loss: 0.37692397832870483, Average Training Loss: 0.3945337012410164, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.3298323452472687, Average Training Loss: 0.389556673856882, Training Accuracy: 0.8701923076923077\n",
            "Epoch 3/10, Batch Loss: 0.25490543246269226, Average Training Loss: 0.37993872804301126, Training Accuracy: 0.8705357142857143\n",
            "Epoch 3/10, Batch Loss: 0.3499986529350281, Average Training Loss: 0.3779427230358124, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.363209068775177, Average Training Loss: 0.37702186964452267, Training Accuracy: 0.875\n",
            "Epoch 3/10, Batch Loss: 0.09384483844041824, Average Training Loss: 0.3603643972207518, Training Accuracy: 0.8823529411764706\n",
            "Epoch 3/10, Batch Loss: 0.6182762384414673, Average Training Loss: 0.3746928328441249, Training Accuracy: 0.8715277777777778\n",
            "Epoch 3/10, Batch Loss: 0.3035120964050293, Average Training Loss: 0.3709464782946988, Training Accuracy: 0.8717105263157895\n",
            "Epoch 3/10, Batch Loss: 0.38952645659446716, Average Training Loss: 0.3718754772096872, Training Accuracy: 0.871875\n",
            "Epoch 3/10, Batch Loss: 0.9018673300743103, Average Training Loss: 0.397113184488955, Training Accuracy: 0.8630952380952381\n",
            "Epoch 3/10, Batch Loss: 0.47655749320983887, Average Training Loss: 0.40072428943081334, Training Accuracy: 0.8579545454545454\n",
            "Epoch 3/10, Batch Loss: 0.2600431442260742, Average Training Loss: 0.3946077179001725, Training Accuracy: 0.8614130434782609\n",
            "Epoch 3/10, Batch Loss: 0.3326391577720642, Average Training Loss: 0.3920256945615013, Training Accuracy: 0.8619791666666666\n",
            "Epoch 3/10, Batch Loss: 0.8270702362060547, Average Training Loss: 0.4094274762272835, Training Accuracy: 0.855\n",
            "Epoch 3/10, Batch Loss: 0.12072166800498962, Average Training Loss: 0.39832340668027216, Training Accuracy: 0.8605769230769231\n",
            "Epoch 3/10, Batch Loss: 0.5825498104095459, Average Training Loss: 0.40514660681839343, Training Accuracy: 0.8587962962962963\n",
            "Epoch 3/10, Batch Loss: 0.45215266942977905, Average Training Loss: 0.40682539476880003, Training Accuracy: 0.8571428571428571\n",
            "Epoch 3/10, Batch Loss: 0.15296877920627594, Average Training Loss: 0.3980717183700923, Training Accuracy: 0.8620689655172413\n",
            "Epoch 3/10, Batch Loss: 0.7540491819381714, Average Training Loss: 0.40993763382236165, Training Accuracy: 0.8583333333333333\n",
            "Epoch 3/10, Batch Loss: 0.4714009165763855, Average Training Loss: 0.411920320362814, Training Accuracy: 0.8568548387096774\n",
            "Epoch 3/10, Batch Loss: 0.5250353813171387, Average Training Loss: 0.41545516601763666, Training Accuracy: 0.857421875\n",
            "Epoch 3/10, Batch Loss: 0.4968990981578827, Average Training Loss: 0.4179231639612805, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.5009399056434631, Average Training Loss: 0.42036483283428583, Training Accuracy: 0.8547794117647058\n",
            "Epoch 3/10, Batch Loss: 0.34207573533058167, Average Training Loss: 0.41812800147703716, Training Accuracy: 0.8553571428571428\n",
            "Epoch 3/10, Batch Loss: 0.5644711256027222, Average Training Loss: 0.4221930882583062, Training Accuracy: 0.8524305555555556\n",
            "Epoch 3/10, Batch Loss: 0.26294633746147156, Average Training Loss: 0.4178891220205539, Training Accuracy: 0.8547297297297297\n",
            "Epoch 3/10, Batch Loss: 0.1986788511276245, Average Training Loss: 0.4121204306812663, Training Accuracy: 0.8569078947368421\n",
            "Epoch 3/10, Batch Loss: 0.4066910743713379, Average Training Loss: 0.41198121641690916, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.17114636301994324, Average Training Loss: 0.405960345081985, Training Accuracy: 0.8578125\n",
            "Epoch 3/10, Batch Loss: 0.31533098220825195, Average Training Loss: 0.403749872816772, Training Accuracy: 0.8582317073170732\n",
            "Epoch 3/10, Batch Loss: 0.2593659460544586, Average Training Loss: 0.40031216027481215, Training Accuracy: 0.8601190476190477\n",
            "Epoch 3/10, Batch Loss: 0.4283699691295624, Average Training Loss: 0.4009646674574808, Training Accuracy: 0.8590116279069767\n",
            "Epoch 3/10, Batch Loss: 0.2524378001689911, Average Training Loss: 0.3975890568372878, Training Accuracy: 0.8607954545454546\n",
            "Epoch 3/10, Batch Loss: 0.6964329481124878, Average Training Loss: 0.4042300321989589, Training Accuracy: 0.8611111111111112\n",
            "Epoch 3/10, Batch Loss: 0.4918173849582672, Average Training Loss: 0.40613410508503084, Training Accuracy: 0.8559782608695652\n",
            "Epoch 3/10, Batch Loss: 0.36860254406929016, Average Training Loss: 0.4053355612336321, Training Accuracy: 0.8563829787234043\n",
            "Epoch 3/10, Batch Loss: 0.2034178525209427, Average Training Loss: 0.40112894230211776, Training Accuracy: 0.8580729166666666\n",
            "Epoch 3/10, Batch Loss: 0.3539296090602875, Average Training Loss: 0.40016569060330487, Training Accuracy: 0.8558673469387755\n",
            "Epoch 3/10, Batch Loss: 0.14991235733032227, Average Training Loss: 0.39516062393784523, Training Accuracy: 0.8575\n",
            "Epoch 3/10, Batch Loss: 0.29861152172088623, Average Training Loss: 0.3932675042865323, Training Accuracy: 0.8578431372549019\n",
            "Epoch 3/10, Batch Loss: 0.20924162864685059, Average Training Loss: 0.38972854513961536, Training Accuracy: 0.8605769230769231\n",
            "Epoch 3/10, Batch Loss: 0.5301287174224854, Average Training Loss: 0.39237760499400914, Training Accuracy: 0.8596698113207547\n",
            "Epoch 3/10, Batch Loss: 0.3348906636238098, Average Training Loss: 0.3913130320056721, Training Accuracy: 0.8611111111111112\n",
            "Epoch 3/10, Batch Loss: 0.29530975222587585, Average Training Loss: 0.38956751782785765, Training Accuracy: 0.8613636363636363\n",
            "Epoch 3/10, Batch Loss: 0.6137663722038269, Average Training Loss: 0.39357106879885706, Training Accuracy: 0.8582589285714286\n",
            "Epoch 3/10, Batch Loss: 0.6506823301315308, Average Training Loss: 0.3980817926818864, Training Accuracy: 0.8552631578947368\n",
            "Epoch 3/10, Batch Loss: 0.25459420680999756, Average Training Loss: 0.3956078687875435, Training Accuracy: 0.8566810344827587\n",
            "Epoch 3/10, Batch Loss: 0.658220112323761, Average Training Loss: 0.40005892376273366, Training Accuracy: 0.8559322033898306\n",
            "Epoch 3/10, Batch Loss: 0.29056206345558167, Average Training Loss: 0.3982339760909478, Training Accuracy: 0.85625\n",
            "Epoch 3/10, Batch Loss: 0.22950495779514313, Average Training Loss: 0.3954679266106887, Training Accuracy: 0.8565573770491803\n",
            "Epoch 3/10, Batch Loss: 0.695944607257843, Average Training Loss: 0.4003143246856428, Training Accuracy: 0.8548387096774194\n",
            "Epoch 3/10, Batch Loss: 0.6860193014144897, Average Training Loss: 0.4048493243162594, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.29990994930267334, Average Training Loss: 0.40320964658167213, Training Accuracy: 0.85546875\n",
            "Epoch 3/10, Batch Loss: 0.5070137977600098, Average Training Loss: 0.4048066335228773, Training Accuracy: 0.8557692307692307\n",
            "Epoch 3/10, Batch Loss: 0.5838987231254578, Average Training Loss: 0.4075201500320073, Training Accuracy: 0.8560606060606061\n",
            "Epoch 3/10, Batch Loss: 0.7435060143470764, Average Training Loss: 0.41253486442476955, Training Accuracy: 0.855410447761194\n",
            "Epoch 3/10, Batch Loss: 0.36984795331954956, Average Training Loss: 0.41190711573204575, Training Accuracy: 0.8556985294117647\n",
            "Epoch 3/10, Batch Loss: 0.6341981291770935, Average Training Loss: 0.4151287246225537, Training Accuracy: 0.855072463768116\n",
            "Epoch 3/10, Batch Loss: 0.5830839276313782, Average Training Loss: 0.41752808466553687, Training Accuracy: 0.8535714285714285\n",
            "Epoch 3/10, Batch Loss: 0.18123815953731537, Average Training Loss: 0.4142000575510549, Training Accuracy: 0.8547535211267606\n",
            "Epoch 3/10, Batch Loss: 0.0850505530834198, Average Training Loss: 0.40962853665567106, Training Accuracy: 0.8567708333333334\n",
            "Epoch 3/10, Batch Loss: 0.2590111494064331, Average Training Loss: 0.40756528477554455, Training Accuracy: 0.8578767123287672\n",
            "Epoch 3/10, Batch Loss: 0.5458370447158813, Average Training Loss: 0.40943382207203555, Training Accuracy: 0.8581081081081081\n",
            "Epoch 3/10, Batch Loss: 0.5583828091621399, Average Training Loss: 0.4114198085665703, Training Accuracy: 0.8575\n",
            "Epoch 3/10, Batch Loss: 0.5430833697319031, Average Training Loss: 0.4131522238450615, Training Accuracy: 0.8560855263157895\n",
            "Epoch 3/10, Batch Loss: 0.4832337200641632, Average Training Loss: 0.41406237314660826, Training Accuracy: 0.8563311688311688\n",
            "Epoch 3/10, Batch Loss: 0.6123292446136475, Average Training Loss: 0.41660425611413443, Training Accuracy: 0.8549679487179487\n",
            "Epoch 3/10, Batch Loss: 0.2013135403394699, Average Training Loss: 0.4138790571802779, Training Accuracy: 0.8568037974683544\n",
            "Epoch 3/10, Batch Loss: 0.6503165364265442, Average Training Loss: 0.4168345256708562, Training Accuracy: 0.85625\n",
            "Epoch 3/10, Batch Loss: 0.4323875308036804, Average Training Loss: 0.4170265380799035, Training Accuracy: 0.8557098765432098\n",
            "Epoch 3/10, Batch Loss: 0.6211881637573242, Average Training Loss: 0.4195163140027988, Training Accuracy: 0.854420731707317\n",
            "Epoch 3/10, Batch Loss: 0.09137267619371414, Average Training Loss: 0.4155627761978701, Training Accuracy: 0.8561746987951807\n",
            "Epoch 3/10, Batch Loss: 0.32202503085136414, Average Training Loss: 0.4144492316104117, Training Accuracy: 0.8563988095238095\n",
            "Epoch 3/10, Batch Loss: 0.6633245348930359, Average Training Loss: 0.41737717635491317, Training Accuracy: 0.8544117647058823\n",
            "Epoch 3/10, Batch Loss: 0.4588603973388672, Average Training Loss: 0.4178595393896103, Training Accuracy: 0.8546511627906976\n",
            "Epoch 3/10, Batch Loss: 0.8535565137863159, Average Training Loss: 0.4228675505895724, Training Accuracy: 0.853448275862069\n",
            "Epoch 3/10, Batch Loss: 0.2241726517677307, Average Training Loss: 0.42060965401205147, Training Accuracy: 0.8536931818181818\n",
            "Epoch 3/10, Batch Loss: 0.40759772062301636, Average Training Loss: 0.4204634525132983, Training Accuracy: 0.8532303370786517\n",
            "Epoch 3/10, Batch Loss: 0.1848224401473999, Average Training Loss: 0.4178452190425661, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/10, Batch Loss: 0.44681477546691895, Average Training Loss: 0.4181635658164601, Training Accuracy: 0.8537087912087912\n",
            "Epoch 3/10, Batch Loss: 0.4282494783401489, Average Training Loss: 0.41827319530041324, Training Accuracy: 0.8539402173913043\n",
            "Epoch 3/10, Batch Loss: 0.20956680178642273, Average Training Loss: 0.41602904053144557, Training Accuracy: 0.855510752688172\n",
            "Epoch 3/10, Batch Loss: 0.16323988139629364, Average Training Loss: 0.41333979415766736, Training Accuracy: 0.8570478723404256\n",
            "Epoch 3/10, Batch Loss: 0.19619357585906982, Average Training Loss: 0.41105404449136634, Training Accuracy: 0.8578947368421053\n",
            "Epoch 3/10, Batch Loss: 0.28927263617515564, Average Training Loss: 0.40978548815473914, Training Accuracy: 0.8587239583333334\n",
            "Epoch 3/10, Batch Loss: 0.5020337104797363, Average Training Loss: 0.41073650075602774, Training Accuracy: 0.8576030927835051\n",
            "Epoch 3/10, Batch Loss: 0.35890743136405945, Average Training Loss: 0.4102076327010077, Training Accuracy: 0.8584183673469388\n",
            "Epoch 3/10, Batch Loss: 0.4818669557571411, Average Training Loss: 0.41093146424702925, Training Accuracy: 0.8573232323232324\n",
            "Epoch 3/10, Batch Loss: 0.3029276728630066, Average Training Loss: 0.409851426333189, Training Accuracy: 0.8575\n",
            "Epoch 3/10, Batch Loss: 0.49950188398361206, Average Training Loss: 0.4107390546267576, Training Accuracy: 0.8570544554455446\n",
            "Epoch 3/10, Batch Loss: 0.5007688999176025, Average Training Loss: 0.41162170016882466, Training Accuracy: 0.8566176470588235\n",
            "Epoch 3/10, Batch Loss: 0.20002521574497223, Average Training Loss: 0.40956736536859306, Training Accuracy: 0.8574029126213593\n",
            "Epoch 3/10, Batch Loss: 0.19664427638053894, Average Training Loss: 0.4075200279744772, Training Accuracy: 0.8587740384615384\n",
            "Epoch 3/10, Batch Loss: 0.218917116522789, Average Training Loss: 0.4057238097701754, Training Accuracy: 0.8595238095238096\n",
            "Epoch 3/10, Batch Loss: 0.16950201988220215, Average Training Loss: 0.4034953023184021, Training Accuracy: 0.8602594339622641\n",
            "Epoch 3/10, Batch Loss: 0.08210308849811554, Average Training Loss: 0.40049163676867977, Training Accuracy: 0.8615654205607477\n",
            "Epoch 3/10, Batch Loss: 0.47189944982528687, Average Training Loss: 0.4011528202229076, Training Accuracy: 0.8611111111111112\n",
            "Epoch 3/10, Batch Loss: 0.15090033411979675, Average Training Loss: 0.39885692585498916, Training Accuracy: 0.8623853211009175\n",
            "Epoch 3/10, Batch Loss: 0.5811038613319397, Average Training Loss: 0.40051371617750686, Training Accuracy: 0.8613636363636363\n",
            "Epoch 3/10, Batch Loss: 0.2004805952310562, Average Training Loss: 0.3987116159888001, Training Accuracy: 0.8614864864864865\n",
            "Epoch 3/10, Batch Loss: 0.7198866605758667, Average Training Loss: 0.40157925031547037, Training Accuracy: 0.8610491071428571\n",
            "Epoch 3/10, Batch Loss: 0.3801664412021637, Average Training Loss: 0.4013897564295119, Training Accuracy: 0.8606194690265486\n",
            "Epoch 3/10, Batch Loss: 0.393176406621933, Average Training Loss: 0.40131770950137524, Training Accuracy: 0.8601973684210527\n",
            "Epoch 3/10, Batch Loss: 0.5341206789016724, Average Training Loss: 0.402472517930943, Training Accuracy: 0.8592391304347826\n",
            "Epoch 3/10, Batch Loss: 0.3277607858181, Average Training Loss: 0.4018284512747978, Training Accuracy: 0.8588362068965517\n",
            "Epoch 3/10, Batch Loss: 0.7131696939468384, Average Training Loss: 0.404489487536952, Training Accuracy: 0.8584401709401709\n",
            "Epoch 3/10, Batch Loss: 0.21494776010513306, Average Training Loss: 0.40288320171125863, Training Accuracy: 0.8591101694915254\n",
            "Epoch 3/10, Batch Loss: 0.4470129907131195, Average Training Loss: 0.4032540402742995, Training Accuracy: 0.8587184873949579\n",
            "Epoch 3/10, Batch Loss: 0.2577453851699829, Average Training Loss: 0.40204146814843017, Training Accuracy: 0.859375\n",
            "Epoch 3/10, Batch Loss: 0.2706716060638428, Average Training Loss: 0.40095576680888817, Training Accuracy: 0.859504132231405\n",
            "Epoch 3/10, Batch Loss: 0.5993191599845886, Average Training Loss: 0.402581696261148, Training Accuracy: 0.8591188524590164\n",
            "Epoch 3/10, Batch Loss: 0.6954490542411804, Average Training Loss: 0.40496273169187996, Training Accuracy: 0.8577235772357723\n",
            "Epoch 3/10, Batch Loss: 0.09206882864236832, Average Training Loss: 0.4024393937640613, Training Accuracy: 0.8588709677419355\n",
            "Epoch 3/10, Batch Loss: 0.17739206552505493, Average Training Loss: 0.40063901513814926, Training Accuracy: 0.8595\n",
            "Epoch 3/10, Batch Loss: 0.33776938915252686, Average Training Loss: 0.4001400498525491, Training Accuracy: 0.8591269841269841\n",
            "Epoch 3/10, Batch Loss: 0.0978965014219284, Average Training Loss: 0.39776017939246544, Training Accuracy: 0.860236220472441\n",
            "Epoch 3/10, Batch Loss: 0.18614819645881653, Average Training Loss: 0.3961069607757963, Training Accuracy: 0.86083984375\n",
            "Epoch 3/10, Batch Loss: 0.3227776885032654, Average Training Loss: 0.39553851680469143, Training Accuracy: 0.8609496124031008\n",
            "Epoch 3/10, Batch Loss: 0.6226948499679565, Average Training Loss: 0.3972858732136396, Training Accuracy: 0.8600961538461539\n",
            "Epoch 3/10, Batch Loss: 0.2166745960712433, Average Training Loss: 0.3959071611743847, Training Accuracy: 0.8602099236641222\n",
            "Epoch 3/10, Batch Loss: 0.3359013795852661, Average Training Loss: 0.39545257191992167, Training Accuracy: 0.8603219696969697\n",
            "Epoch 3/10, Batch Loss: 0.7155151963233948, Average Training Loss: 0.4004938860151603, Training Accuracy: 0.8599810785241249\n",
            "Epoch 3/10, Average Training Loss: 0.39785905781769215, Training Accuracy: 0.8599810785241249\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.86      0.87      0.87       427\n",
            "                Educational Opportunity       0.76      0.78      0.77       451\n",
            "                         Family Support       0.94      0.97      0.96       396\n",
            "                      Financial Support       0.87      0.90      0.88       404\n",
            "                 Program Implementation       0.88      0.80      0.84       436\n",
            "\n",
            "                               accuracy                           0.86      2114\n",
            "                              macro avg       0.86      0.86      0.86      2114\n",
            "                           weighted avg       0.86      0.86      0.86      2114\n",
            "\n",
            "Epoch 3/10, Validation Loss: 29.627555146813393, Validation Accuracy: 0.7013232514177694\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.64      0.73      0.68       113\n",
            "                Educational Opportunity       0.48      0.70      0.57       100\n",
            "                         Family Support       0.92      0.90      0.91       105\n",
            "                      Financial Support       0.74      0.69      0.71        97\n",
            "                 Program Implementation       0.95      0.49      0.65       114\n",
            "\n",
            "                               accuracy                           0.70       529\n",
            "                              macro avg       0.75      0.70      0.71       529\n",
            "                           weighted avg       0.75      0.70      0.71       529\n",
            "\n",
            "Epoch 4/10, Batch Loss: 0.1951970010995865, Average Training Loss: 0.1951970010995865, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.09538305550813675, Average Training Loss: 0.14529002830386162, Training Accuracy: 0.96875\n",
            "Epoch 4/10, Batch Loss: 0.3297426700592041, Average Training Loss: 0.2067742422223091, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.48862266540527344, Average Training Loss: 0.2772363480180502, Training Accuracy: 0.921875\n",
            "Epoch 4/10, Batch Loss: 0.18099531531333923, Average Training Loss: 0.257988141477108, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.2244035303592682, Average Training Loss: 0.25239070629080135, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.30253759026527405, Average Training Loss: 0.2595545468585832, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.34720104932785034, Average Training Loss: 0.2705103596672416, Training Accuracy: 0.921875\n",
            "Epoch 4/10, Batch Loss: 0.062131620943546295, Average Training Loss: 0.24735716647571987, Training Accuracy: 0.9305555555555556\n",
            "Epoch 4/10, Batch Loss: 0.09392870217561722, Average Training Loss: 0.2320143200457096, Training Accuracy: 0.93125\n",
            "Epoch 4/10, Batch Loss: 0.07604654133319855, Average Training Loss: 0.21783543107184497, Training Accuracy: 0.9375\n",
            "Epoch 4/10, Batch Loss: 0.35050904750823975, Average Training Loss: 0.22889156577487788, Training Accuracy: 0.9270833333333334\n",
            "Epoch 4/10, Batch Loss: 0.1236991435289383, Average Training Loss: 0.22079984098672867, Training Accuracy: 0.9326923076923077\n",
            "Epoch 4/10, Batch Loss: 0.22127607464790344, Average Training Loss: 0.22083385767681257, Training Accuracy: 0.9285714285714286\n",
            "Epoch 4/10, Batch Loss: 0.16194887459278107, Average Training Loss: 0.21690819213787715, Training Accuracy: 0.9291666666666667\n",
            "Epoch 4/10, Batch Loss: 0.15622802078723907, Average Training Loss: 0.21311568142846227, Training Accuracy: 0.92578125\n",
            "Epoch 4/10, Batch Loss: 0.5642876029014587, Average Training Loss: 0.233772853279815, Training Accuracy: 0.9227941176470589\n",
            "Epoch 4/10, Batch Loss: 0.19837619364261627, Average Training Loss: 0.23180637218885952, Training Accuracy: 0.9236111111111112\n",
            "Epoch 4/10, Batch Loss: 0.2587176561355591, Average Training Loss: 0.23322275555447528, Training Accuracy: 0.9243421052631579\n",
            "Epoch 4/10, Batch Loss: 0.3340444564819336, Average Training Loss: 0.2382638406008482, Training Accuracy: 0.91875\n",
            "Epoch 4/10, Batch Loss: 0.5968213677406311, Average Training Loss: 0.2553380085598855, Training Accuracy: 0.9136904761904762\n",
            "Epoch 4/10, Batch Loss: 0.3933090567588806, Average Training Loss: 0.261609419841658, Training Accuracy: 0.9119318181818182\n",
            "Epoch 4/10, Batch Loss: 0.09368115663528442, Average Training Loss: 0.25430819100659824, Training Accuracy: 0.9157608695652174\n",
            "Epoch 4/10, Batch Loss: 0.5106826424598694, Average Training Loss: 0.26499045981715125, Training Accuracy: 0.9114583333333334\n",
            "Epoch 4/10, Batch Loss: 0.3155346214771271, Average Training Loss: 0.26701222628355026, Training Accuracy: 0.91\n",
            "Epoch 4/10, Batch Loss: 0.21751146018505096, Average Training Loss: 0.2651083506643772, Training Accuracy: 0.9110576923076923\n",
            "Epoch 4/10, Batch Loss: 0.15231803059577942, Average Training Loss: 0.2609309314025773, Training Accuracy: 0.9120370370370371\n",
            "Epoch 4/10, Batch Loss: 0.11992494761943817, Average Training Loss: 0.25589500341032234, Training Accuracy: 0.9151785714285714\n",
            "Epoch 4/10, Batch Loss: 0.044613003730773926, Average Training Loss: 0.24860941721447583, Training Accuracy: 0.9181034482758621\n",
            "Epoch 4/10, Batch Loss: 0.13679704070091248, Average Training Loss: 0.24488233799735706, Training Accuracy: 0.91875\n",
            "Epoch 4/10, Batch Loss: 0.07088588923215866, Average Training Loss: 0.23926954932751193, Training Accuracy: 0.9213709677419355\n",
            "Epoch 4/10, Batch Loss: 0.06600821763277054, Average Training Loss: 0.23385513271205127, Training Accuracy: 0.923828125\n",
            "Epoch 4/10, Batch Loss: 0.18417561054229736, Average Training Loss: 0.23234969264630115, Training Accuracy: 0.9242424242424242\n",
            "Epoch 4/10, Batch Loss: 0.2660335600376129, Average Training Loss: 0.23334039462839856, Training Accuracy: 0.9246323529411765\n",
            "Epoch 4/10, Batch Loss: 0.3343428671360016, Average Training Loss: 0.23622617955718722, Training Accuracy: 0.925\n",
            "Epoch 4/10, Batch Loss: 0.118507519364357, Average Training Loss: 0.23295621677405304, Training Accuracy: 0.9253472222222222\n",
            "Epoch 4/10, Batch Loss: 0.11735590547323227, Average Training Loss: 0.22983188403619303, Training Accuracy: 0.9256756756756757\n",
            "Epoch 4/10, Batch Loss: 0.10777939110994339, Average Training Loss: 0.2266199763276075, Training Accuracy: 0.9276315789473685\n",
            "Epoch 4/10, Batch Loss: 0.27536553144454956, Average Training Loss: 0.22786986235624704, Training Accuracy: 0.9262820512820513\n",
            "Epoch 4/10, Batch Loss: 0.17999398708343506, Average Training Loss: 0.22667296547442675, Training Accuracy: 0.9265625\n",
            "Epoch 4/10, Batch Loss: 0.09078966826200485, Average Training Loss: 0.22335873871314815, Training Accuracy: 0.926829268292683\n",
            "Epoch 4/10, Batch Loss: 0.06028924137353897, Average Training Loss: 0.21947613163363366, Training Accuracy: 0.9285714285714286\n",
            "Epoch 4/10, Batch Loss: 0.3279678523540497, Average Training Loss: 0.22199919490620149, Training Accuracy: 0.9273255813953488\n",
            "Epoch 4/10, Batch Loss: 0.33593302965164185, Average Training Loss: 0.22458860024132513, Training Accuracy: 0.9261363636363636\n",
            "Epoch 4/10, Batch Loss: 0.05556609854102135, Average Training Loss: 0.22083254464798505, Training Accuracy: 0.9277777777777778\n",
            "Epoch 4/10, Batch Loss: 0.054468121379613876, Average Training Loss: 0.21721592675084653, Training Accuracy: 0.9293478260869565\n",
            "Epoch 4/10, Batch Loss: 0.29480552673339844, Average Training Loss: 0.21886676930366677, Training Accuracy: 0.9281914893617021\n",
            "Epoch 4/10, Batch Loss: 0.07925450801849365, Average Training Loss: 0.21595818052689233, Training Accuracy: 0.9296875\n",
            "Epoch 4/10, Batch Loss: 0.2584155201911926, Average Training Loss: 0.21682465684657193, Training Accuracy: 0.9285714285714286\n",
            "Epoch 4/10, Batch Loss: 0.2684476971626282, Average Training Loss: 0.21785711765289306, Training Accuracy: 0.9275\n",
            "Epoch 4/10, Batch Loss: 0.27062711119651794, Average Training Loss: 0.2188918234086504, Training Accuracy: 0.9276960784313726\n",
            "Epoch 4/10, Batch Loss: 0.12867099046707153, Average Training Loss: 0.21715680739054313, Training Accuracy: 0.9290865384615384\n",
            "Epoch 4/10, Batch Loss: 0.6931862235069275, Average Training Loss: 0.22613849448707868, Training Accuracy: 0.9257075471698113\n",
            "Epoch 4/10, Batch Loss: 0.08336402475833893, Average Training Loss: 0.22349452282543536, Training Accuracy: 0.9270833333333334\n",
            "Epoch 4/10, Batch Loss: 0.14467179775238037, Average Training Loss: 0.22206138236956163, Training Accuracy: 0.9272727272727272\n",
            "Epoch 4/10, Batch Loss: 0.1966884583234787, Average Training Loss: 0.2216082944401673, Training Accuracy: 0.9274553571428571\n",
            "Epoch 4/10, Batch Loss: 0.15279582142829895, Average Training Loss: 0.220401058071538, Training Accuracy: 0.9276315789473685\n",
            "Epoch 4/10, Batch Loss: 0.375140517950058, Average Training Loss: 0.22306897979358148, Training Accuracy: 0.927801724137931\n",
            "Epoch 4/10, Batch Loss: 0.09583193063735962, Average Training Loss: 0.22091241963839126, Training Accuracy: 0.9290254237288136\n",
            "Epoch 4/10, Batch Loss: 0.06693507730960846, Average Training Loss: 0.21834613059957822, Training Accuracy: 0.9302083333333333\n",
            "Epoch 4/10, Batch Loss: 0.06008213758468628, Average Training Loss: 0.2157516389108095, Training Accuracy: 0.9313524590163934\n",
            "Epoch 4/10, Batch Loss: 0.023158259689807892, Average Training Loss: 0.21264529408466432, Training Accuracy: 0.9324596774193549\n",
            "Epoch 4/10, Batch Loss: 0.09804750233888626, Average Training Loss: 0.210826281517271, Training Accuracy: 0.9325396825396826\n",
            "Epoch 4/10, Batch Loss: 0.24087022244930267, Average Training Loss: 0.211295718094334, Training Accuracy: 0.9326171875\n",
            "Epoch 4/10, Batch Loss: 0.12670542299747467, Average Training Loss: 0.20999432893899772, Training Accuracy: 0.9326923076923077\n",
            "Epoch 4/10, Batch Loss: 0.2649277150630951, Average Training Loss: 0.210826652971181, Training Accuracy: 0.9318181818181818\n",
            "Epoch 4/10, Batch Loss: 0.4540148973464966, Average Training Loss: 0.21445632826036481, Training Accuracy: 0.9319029850746269\n",
            "Epoch 4/10, Batch Loss: 0.23678433895111084, Average Training Loss: 0.21478468135875814, Training Accuracy: 0.9310661764705882\n",
            "Epoch 4/10, Batch Loss: 0.4463934302330017, Average Training Loss: 0.21814132989316748, Training Accuracy: 0.9284420289855072\n",
            "Epoch 4/10, Batch Loss: 0.7368573546409607, Average Training Loss: 0.22555155881813593, Training Accuracy: 0.925\n",
            "Epoch 4/10, Batch Loss: 0.5933167934417725, Average Training Loss: 0.23073135085508856, Training Accuracy: 0.9234154929577465\n",
            "Epoch 4/10, Batch Loss: 0.05757441744208336, Average Training Loss: 0.2283263934465746, Training Accuracy: 0.9244791666666666\n",
            "Epoch 4/10, Batch Loss: 0.0481162890791893, Average Training Loss: 0.2258577618798981, Training Accuracy: 0.925513698630137\n",
            "Epoch 4/10, Batch Loss: 0.22498172521591187, Average Training Loss: 0.225845923546601, Training Accuracy: 0.924831081081081\n",
            "Epoch 4/10, Batch Loss: 0.1890684962272644, Average Training Loss: 0.22535555784900982, Training Accuracy: 0.925\n",
            "Epoch 4/10, Batch Loss: 0.8011969327926636, Average Training Loss: 0.23293241804563686, Training Accuracy: 0.9226973684210527\n",
            "Epoch 4/10, Batch Loss: 0.14076507091522217, Average Training Loss: 0.23173543951147563, Training Accuracy: 0.9228896103896104\n",
            "Epoch 4/10, Batch Loss: 0.3679259419441223, Average Training Loss: 0.23348147159394544, Training Accuracy: 0.9222756410256411\n",
            "Epoch 4/10, Batch Loss: 0.10141076147556305, Average Training Loss: 0.23180969045320643, Training Accuracy: 0.9232594936708861\n",
            "Epoch 4/10, Batch Loss: 0.15451736748218536, Average Training Loss: 0.23084353641606867, Training Accuracy: 0.9234375\n",
            "Epoch 4/10, Batch Loss: 0.37447071075439453, Average Training Loss: 0.23261671140789986, Training Accuracy: 0.9228395061728395\n",
            "Epoch 4/10, Batch Loss: 0.4394674301147461, Average Training Loss: 0.23513928114822724, Training Accuracy: 0.9207317073170732\n",
            "Epoch 4/10, Batch Loss: 0.054313547909259796, Average Training Loss: 0.2329606578561915, Training Accuracy: 0.9216867469879518\n",
            "Epoch 4/10, Batch Loss: 0.06410595029592514, Average Training Loss: 0.23095048276618832, Training Accuracy: 0.9226190476190477\n",
            "Epoch 4/10, Batch Loss: 0.24508677423000336, Average Training Loss: 0.23111679207752733, Training Accuracy: 0.9213235294117647\n",
            "Epoch 4/10, Batch Loss: 0.14557912945747375, Average Training Loss: 0.23012216809357322, Training Accuracy: 0.9215116279069767\n",
            "Epoch 4/10, Batch Loss: 0.1283794641494751, Average Training Loss: 0.22895271172639967, Training Accuracy: 0.9224137931034483\n",
            "Epoch 4/10, Batch Loss: 0.233269602060318, Average Training Loss: 0.229001767298376, Training Accuracy: 0.9225852272727273\n",
            "Epoch 4/10, Batch Loss: 0.2648836374282837, Average Training Loss: 0.22940493437848733, Training Accuracy: 0.9220505617977528\n",
            "Epoch 4/10, Batch Loss: 0.28646427392959595, Average Training Loss: 0.23003892704016632, Training Accuracy: 0.9222222222222223\n",
            "Epoch 4/10, Batch Loss: 0.18060408532619476, Average Training Loss: 0.22949568702133147, Training Accuracy: 0.9217032967032966\n",
            "Epoch 4/10, Batch Loss: 0.04812447726726532, Average Training Loss: 0.2275242608283525, Training Accuracy: 0.9225543478260869\n",
            "Epoch 4/10, Batch Loss: 0.15952180325984955, Average Training Loss: 0.2267930516071858, Training Accuracy: 0.9233870967741935\n",
            "Epoch 4/10, Batch Loss: 0.24375690519809723, Average Training Loss: 0.22697351813474867, Training Accuracy: 0.9235372340425532\n",
            "Epoch 4/10, Batch Loss: 0.3675374686717987, Average Training Loss: 0.22845313866671763, Training Accuracy: 0.9230263157894737\n",
            "Epoch 4/10, Batch Loss: 0.14405865967273712, Average Training Loss: 0.22757402951053032, Training Accuracy: 0.9231770833333334\n",
            "Epoch 4/10, Batch Loss: 0.3326720893383026, Average Training Loss: 0.22865751466339396, Training Accuracy: 0.9226804123711341\n",
            "Epoch 4/10, Batch Loss: 0.133949875831604, Average Training Loss: 0.22769111018551855, Training Accuracy: 0.9228316326530612\n",
            "Epoch 4/10, Batch Loss: 0.18008093535900116, Average Training Loss: 0.22721019932868505, Training Accuracy: 0.922979797979798\n",
            "Epoch 4/10, Batch Loss: 0.1875368058681488, Average Training Loss: 0.22681346539407968, Training Accuracy: 0.923125\n",
            "Epoch 4/10, Batch Loss: 0.04670431464910507, Average Training Loss: 0.22503020647581262, Training Accuracy: 0.9238861386138614\n",
            "Epoch 4/10, Batch Loss: 0.22637490928173065, Average Training Loss: 0.22504338983665495, Training Accuracy: 0.9240196078431373\n",
            "Epoch 4/10, Batch Loss: 0.8289865255355835, Average Training Loss: 0.23090691542596492, Training Accuracy: 0.9223300970873787\n",
            "Epoch 4/10, Batch Loss: 0.29163891077041626, Average Training Loss: 0.23149087691966158, Training Accuracy: 0.9224759615384616\n",
            "Epoch 4/10, Batch Loss: 0.5419352650642395, Average Training Loss: 0.23444749014008612, Training Accuracy: 0.9208333333333333\n",
            "Epoch 4/10, Batch Loss: 0.5498442649841309, Average Training Loss: 0.23742293141219975, Training Accuracy: 0.9204009433962265\n",
            "Epoch 4/10, Batch Loss: 0.3216303288936615, Average Training Loss: 0.238209916435391, Training Accuracy: 0.919392523364486\n",
            "Epoch 4/10, Batch Loss: 0.3786442279815674, Average Training Loss: 0.2395102341348926, Training Accuracy: 0.9189814814814815\n",
            "Epoch 4/10, Batch Loss: 0.08934661000967026, Average Training Loss: 0.23813258620713829, Training Accuracy: 0.9197247706422018\n",
            "Epoch 4/10, Batch Loss: 0.28590548038482666, Average Training Loss: 0.23856688524511727, Training Accuracy: 0.9193181818181818\n",
            "Epoch 4/10, Batch Loss: 0.325818806886673, Average Training Loss: 0.2393529385932394, Training Accuracy: 0.918918918918919\n",
            "Epoch 4/10, Batch Loss: 0.29254695773124695, Average Training Loss: 0.23982788519268589, Training Accuracy: 0.9190848214285714\n",
            "Epoch 4/10, Batch Loss: 0.28204643726348877, Average Training Loss: 0.24020150069773724, Training Accuracy: 0.9186946902654868\n",
            "Epoch 4/10, Batch Loss: 0.07304544746875763, Average Training Loss: 0.238735219529062, Training Accuracy: 0.9194078947368421\n",
            "Epoch 4/10, Batch Loss: 0.05919083207845688, Average Training Loss: 0.23717396398601326, Training Accuracy: 0.9201086956521739\n",
            "Epoch 4/10, Batch Loss: 0.2688503563404083, Average Training Loss: 0.23744703633389597, Training Accuracy: 0.9202586206896551\n",
            "Epoch 4/10, Batch Loss: 0.3382457494735718, Average Training Loss: 0.23830856379662824, Training Accuracy: 0.9204059829059829\n",
            "Epoch 4/10, Batch Loss: 0.08180268853902817, Average Training Loss: 0.2369822428198689, Training Accuracy: 0.9210805084745762\n",
            "Epoch 4/10, Batch Loss: 0.09902534633874893, Average Training Loss: 0.23582294116876706, Training Accuracy: 0.9217436974789915\n",
            "Epoch 4/10, Batch Loss: 0.06362753361463547, Average Training Loss: 0.2343879794391493, Training Accuracy: 0.9223958333333333\n",
            "Epoch 4/10, Batch Loss: 0.04052681475877762, Average Training Loss: 0.2327858210533611, Training Accuracy: 0.9230371900826446\n",
            "Epoch 4/10, Batch Loss: 0.03217819705605507, Average Training Loss: 0.23114149626649794, Training Accuracy: 0.9236680327868853\n",
            "Epoch 4/10, Batch Loss: 0.0882439836859703, Average Training Loss: 0.2299797278715343, Training Accuracy: 0.9242886178861789\n",
            "Epoch 4/10, Batch Loss: 0.33694788813591003, Average Training Loss: 0.23084237432527926, Training Accuracy: 0.9238911290322581\n",
            "Epoch 4/10, Batch Loss: 0.1261538565158844, Average Training Loss: 0.2300048661828041, Training Accuracy: 0.924\n",
            "Epoch 4/10, Batch Loss: 0.03998492285609245, Average Training Loss: 0.22849677139449687, Training Accuracy: 0.9246031746031746\n",
            "Epoch 4/10, Batch Loss: 0.3727104663848877, Average Training Loss: 0.22963231229993303, Training Accuracy: 0.9242125984251969\n",
            "Epoch 4/10, Batch Loss: 0.09039904922246933, Average Training Loss: 0.22854455243214034, Training Accuracy: 0.9248046875\n",
            "Epoch 4/10, Batch Loss: 0.30776819586753845, Average Training Loss: 0.22915868920295737, Training Accuracy: 0.9244186046511628\n",
            "Epoch 4/10, Batch Loss: 0.048582784831523895, Average Training Loss: 0.2277696437847156, Training Accuracy: 0.925\n",
            "Epoch 4/10, Batch Loss: 0.11697036027908325, Average Training Loss: 0.22692384772742066, Training Accuracy: 0.9255725190839694\n",
            "Epoch 4/10, Batch Loss: 0.09431677311658859, Average Training Loss: 0.22591924867733862, Training Accuracy: 0.9261363636363636\n",
            "Epoch 4/10, Batch Loss: 0.02541353926062584, Average Training Loss: 0.22589785706466847, Training Accuracy: 0.9262062440870388\n",
            "Epoch 4/10, Average Training Loss: 0.22441168695240094, Training Accuracy: 0.9262062440870388\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.93      0.94      0.93       427\n",
            "                Educational Opportunity       0.85      0.89      0.87       451\n",
            "                         Family Support       0.98      0.99      0.98       396\n",
            "                      Financial Support       0.95      0.94      0.95       404\n",
            "                 Program Implementation       0.93      0.88      0.91       436\n",
            "\n",
            "                               accuracy                           0.93      2114\n",
            "                              macro avg       0.93      0.93      0.93      2114\n",
            "                           weighted avg       0.93      0.93      0.93      2114\n",
            "\n",
            "Epoch 4/10, Validation Loss: 30.50740167684853, Validation Accuracy: 0.7126654064272212\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.66      0.68       113\n",
            "                Educational Opportunity       0.49      0.66      0.56       100\n",
            "                         Family Support       0.92      0.92      0.92       105\n",
            "                      Financial Support       0.72      0.65      0.68        97\n",
            "                 Program Implementation       0.82      0.67      0.73       114\n",
            "\n",
            "                               accuracy                           0.71       529\n",
            "                              macro avg       0.73      0.71      0.72       529\n",
            "                           weighted avg       0.73      0.71      0.72       529\n",
            "\n",
            "Epoch 5/10, Batch Loss: 0.03726484254002571, Average Training Loss: 0.03726484254002571, Training Accuracy: 1.0\n",
            "Epoch 5/10, Batch Loss: 0.09305835515260696, Average Training Loss: 0.06516159884631634, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.06910911202430725, Average Training Loss: 0.06647743657231331, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/10, Batch Loss: 0.036484479904174805, Average Training Loss: 0.05897919740527868, Training Accuracy: 0.984375\n",
            "Epoch 5/10, Batch Loss: 0.04978432506322861, Average Training Loss: 0.05714022293686867, Training Accuracy: 0.9875\n",
            "Epoch 5/10, Batch Loss: 0.38170838356018066, Average Training Loss: 0.11123491637408733, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/10, Batch Loss: 0.09183661639690399, Average Training Loss: 0.10846373066306114, Training Accuracy: 0.9821428571428571\n",
            "Epoch 5/10, Batch Loss: 0.1342909336090088, Average Training Loss: 0.1116921310313046, Training Accuracy: 0.984375\n",
            "Epoch 5/10, Batch Loss: 0.1986522078514099, Average Training Loss: 0.12135436178909408, Training Accuracy: 0.9791666666666666\n",
            "Epoch 5/10, Batch Loss: 0.03783199563622475, Average Training Loss: 0.11300212517380714, Training Accuracy: 0.98125\n",
            "Epoch 5/10, Batch Loss: 0.0671880692243576, Average Training Loss: 0.10883721099658446, Training Accuracy: 0.9829545454545454\n",
            "Epoch 5/10, Batch Loss: 0.3512052893638611, Average Training Loss: 0.12903455086052418, Training Accuracy: 0.9739583333333334\n",
            "Epoch 5/10, Batch Loss: 0.04486062005162239, Average Training Loss: 0.12255963310599327, Training Accuracy: 0.9759615384615384\n",
            "Epoch 5/10, Batch Loss: 0.06752541661262512, Average Training Loss: 0.11862861764218126, Training Accuracy: 0.9776785714285714\n",
            "Epoch 5/10, Batch Loss: 0.23952420055866241, Average Training Loss: 0.12668832316994666, Training Accuracy: 0.9708333333333333\n",
            "Epoch 5/10, Batch Loss: 0.07035176455974579, Average Training Loss: 0.12316728825680912, Training Accuracy: 0.97265625\n",
            "Epoch 5/10, Batch Loss: 0.04074430093169212, Average Training Loss: 0.11831887723768458, Training Accuracy: 0.9742647058823529\n",
            "Epoch 5/10, Batch Loss: 0.19401118159294128, Average Training Loss: 0.12252400525742108, Training Accuracy: 0.9722222222222222\n",
            "Epoch 5/10, Batch Loss: 0.09900069236755371, Average Training Loss: 0.12128593615795437, Training Accuracy: 0.9736842105263158\n",
            "Epoch 5/10, Batch Loss: 0.2100294828414917, Average Training Loss: 0.12572311349213122, Training Accuracy: 0.971875\n",
            "Epoch 5/10, Batch Loss: 0.11316990852355957, Average Training Loss: 0.12512534182696117, Training Accuracy: 0.9702380952380952\n",
            "Epoch 5/10, Batch Loss: 0.06925157457590103, Average Training Loss: 0.12258562513373115, Training Accuracy: 0.9715909090909091\n",
            "Epoch 5/10, Batch Loss: 0.019740190356969833, Average Training Loss: 0.11811408449126326, Training Accuracy: 0.9728260869565217\n",
            "Epoch 5/10, Batch Loss: 0.04096117615699768, Average Training Loss: 0.11489937997733553, Training Accuracy: 0.9739583333333334\n",
            "Epoch 5/10, Batch Loss: 0.07141858339309692, Average Training Loss: 0.11316014811396599, Training Accuracy: 0.975\n",
            "Epoch 5/10, Batch Loss: 0.8100830316543579, Average Training Loss: 0.13996487440398106, Training Accuracy: 0.9663461538461539\n",
            "Epoch 5/10, Batch Loss: 0.08440031111240387, Average Training Loss: 0.13790692761540413, Training Accuracy: 0.9675925925925926\n",
            "Epoch 5/10, Batch Loss: 0.42774948477745056, Average Training Loss: 0.14825844751404865, Training Accuracy: 0.9665178571428571\n",
            "Epoch 5/10, Batch Loss: 0.02768031321465969, Average Training Loss: 0.1441005808140697, Training Accuracy: 0.9676724137931034\n",
            "Epoch 5/10, Batch Loss: 0.0926295816898346, Average Training Loss: 0.14238488084326187, Training Accuracy: 0.9666666666666667\n",
            "Epoch 5/10, Batch Loss: 0.15211230516433716, Average Training Loss: 0.1426986687245869, Training Accuracy: 0.9657258064516129\n",
            "Epoch 5/10, Batch Loss: 0.048162590712308884, Average Training Loss: 0.1397444162867032, Training Accuracy: 0.966796875\n",
            "Epoch 5/10, Batch Loss: 0.15611110627651215, Average Training Loss: 0.14024037658942468, Training Accuracy: 0.9659090909090909\n",
            "Epoch 5/10, Batch Loss: 0.12979952991008759, Average Training Loss: 0.13993329286356182, Training Accuracy: 0.9650735294117647\n",
            "Epoch 5/10, Batch Loss: 0.11079146713018417, Average Training Loss: 0.13910066927117962, Training Accuracy: 0.9660714285714286\n",
            "Epoch 5/10, Batch Loss: 0.03755345195531845, Average Training Loss: 0.1362799132346279, Training Accuracy: 0.9670138888888888\n",
            "Epoch 5/10, Batch Loss: 0.05014599487185478, Average Training Loss: 0.1339519694950935, Training Accuracy: 0.9679054054054054\n",
            "Epoch 5/10, Batch Loss: 0.07243538647890091, Average Training Loss: 0.13233311204729895, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.022252783179283142, Average Training Loss: 0.12951053951222163, Training Accuracy: 0.969551282051282\n",
            "Epoch 5/10, Batch Loss: 0.11059442907571793, Average Training Loss: 0.12903763675130903, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.1466917246580124, Average Training Loss: 0.12946822426122864, Training Accuracy: 0.9679878048780488\n",
            "Epoch 5/10, Batch Loss: 0.3622671067714691, Average Training Loss: 0.13501105479718672, Training Accuracy: 0.9672619047619048\n",
            "Epoch 5/10, Batch Loss: 0.027880743145942688, Average Training Loss: 0.13251965220064618, Training Accuracy: 0.9680232558139535\n",
            "Epoch 5/10, Batch Loss: 0.2036464512348175, Average Training Loss: 0.1341361703605137, Training Accuracy: 0.9673295454545454\n",
            "Epoch 5/10, Batch Loss: 0.06701822578907013, Average Training Loss: 0.13264466048114829, Training Accuracy: 0.9680555555555556\n",
            "Epoch 5/10, Batch Loss: 0.07416079193353653, Average Training Loss: 0.13137327203446109, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.023563966155052185, Average Training Loss: 0.12907945701575024, Training Accuracy: 0.9694148936170213\n",
            "Epoch 5/10, Batch Loss: 0.018328895792365074, Average Training Loss: 0.12677215365692973, Training Accuracy: 0.9700520833333334\n",
            "Epoch 5/10, Batch Loss: 0.060908813029527664, Average Training Loss: 0.12542800384820724, Training Accuracy: 0.9706632653061225\n",
            "Epoch 5/10, Batch Loss: 0.4235033690929413, Average Training Loss: 0.13138951115310193, Training Accuracy: 0.97\n",
            "Epoch 5/10, Batch Loss: 0.025566954165697098, Average Training Loss: 0.12931455905530967, Training Accuracy: 0.9705882352941176\n",
            "Epoch 5/10, Batch Loss: 0.10174722969532013, Average Training Loss: 0.1287844181060791, Training Accuracy: 0.9699519230769231\n",
            "Epoch 5/10, Batch Loss: 0.02252911776304245, Average Training Loss: 0.12677960111847464, Training Accuracy: 0.9705188679245284\n",
            "Epoch 5/10, Batch Loss: 0.1568232625722885, Average Training Loss: 0.1273359652194712, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.11146453768014908, Average Training Loss: 0.12704739380966534, Training Accuracy: 0.9681818181818181\n",
            "Epoch 5/10, Batch Loss: 0.024383801966905594, Average Training Loss: 0.12521411538390176, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.15352122485637665, Average Training Loss: 0.12571073133955923, Training Accuracy: 0.9682017543859649\n",
            "Epoch 5/10, Batch Loss: 0.464942067861557, Average Training Loss: 0.1315595474864902, Training Accuracy: 0.9655172413793104\n",
            "Epoch 5/10, Batch Loss: 0.27177321910858154, Average Training Loss: 0.13393605039533923, Training Accuracy: 0.965042372881356\n",
            "Epoch 5/10, Batch Loss: 0.29296842217445374, Average Training Loss: 0.13658658992499112, Training Accuracy: 0.9645833333333333\n",
            "Epoch 5/10, Batch Loss: 0.015198797918856144, Average Training Loss: 0.13459662612161186, Training Accuracy: 0.9651639344262295\n",
            "Epoch 5/10, Batch Loss: 0.011687763035297394, Average Training Loss: 0.13261422510409066, Training Accuracy: 0.9657258064516129\n",
            "Epoch 5/10, Batch Loss: 0.016893787309527397, Average Training Loss: 0.1307773927581452, Training Accuracy: 0.9662698412698413\n",
            "Epoch 5/10, Batch Loss: 0.036313220858573914, Average Training Loss: 0.12930139007221442, Training Accuracy: 0.966796875\n",
            "Epoch 5/10, Batch Loss: 0.047405023127794266, Average Training Loss: 0.12804144596537717, Training Accuracy: 0.9673076923076923\n",
            "Epoch 5/10, Batch Loss: 0.10431043058633804, Average Training Loss: 0.12768188512630083, Training Accuracy: 0.9678030303030303\n",
            "Epoch 5/10, Batch Loss: 0.06328150629997253, Average Training Loss: 0.1267206854423258, Training Accuracy: 0.9682835820895522\n",
            "Epoch 5/10, Batch Loss: 0.036275677382946014, Average Training Loss: 0.12539061179439373, Training Accuracy: 0.96875\n",
            "Epoch 5/10, Batch Loss: 0.2934212386608124, Average Training Loss: 0.12782583827071864, Training Accuracy: 0.9682971014492754\n",
            "Epoch 5/10, Batch Loss: 0.14269256591796875, Average Training Loss: 0.12803822009425078, Training Accuracy: 0.9678571428571429\n",
            "Epoch 5/10, Batch Loss: 0.286085844039917, Average Training Loss: 0.13026424296672495, Training Accuracy: 0.9665492957746479\n",
            "Epoch 5/10, Batch Loss: 0.02420034259557724, Average Training Loss: 0.1287911332393479, Training Accuracy: 0.9670138888888888\n",
            "Epoch 5/10, Batch Loss: 0.013009213842451572, Average Training Loss: 0.12720507954897947, Training Accuracy: 0.9674657534246576\n",
            "Epoch 5/10, Batch Loss: 0.057155221700668335, Average Training Loss: 0.1262584598483266, Training Accuracy: 0.9679054054054054\n",
            "Epoch 5/10, Batch Loss: 0.21242773532867432, Average Training Loss: 0.1274073835213979, Training Accuracy: 0.9675\n",
            "Epoch 5/10, Batch Loss: 0.07167104631662369, Average Training Loss: 0.12667401066344036, Training Accuracy: 0.9671052631578947\n",
            "Epoch 5/10, Batch Loss: 0.10966526716947556, Average Training Loss: 0.12645311789079147, Training Accuracy: 0.9667207792207793\n",
            "Epoch 5/10, Batch Loss: 0.014205079525709152, Average Training Loss: 0.12501404047585452, Training Accuracy: 0.9671474358974359\n",
            "Epoch 5/10, Batch Loss: 0.2623818814754486, Average Training Loss: 0.1267528739062291, Training Accuracy: 0.9659810126582279\n",
            "Epoch 5/10, Batch Loss: 0.10093586891889572, Average Training Loss: 0.12643016134388746, Training Accuracy: 0.965625\n",
            "Epoch 5/10, Batch Loss: 0.05529838427901268, Average Training Loss: 0.12555199125666677, Training Accuracy: 0.9660493827160493\n",
            "Epoch 5/10, Batch Loss: 0.12203755229711533, Average Training Loss: 0.12550913224496493, Training Accuracy: 0.9657012195121951\n",
            "Epoch 5/10, Batch Loss: 0.0698843002319336, Average Training Loss: 0.12483895354601274, Training Accuracy: 0.9661144578313253\n",
            "Epoch 5/10, Batch Loss: 0.03612971678376198, Average Training Loss: 0.123782891203605, Training Accuracy: 0.9665178571428571\n",
            "Epoch 5/10, Batch Loss: 0.03498414531350136, Average Training Loss: 0.12273820007548612, Training Accuracy: 0.9669117647058824\n",
            "Epoch 5/10, Batch Loss: 0.16630803048610687, Average Training Loss: 0.12324482601049334, Training Accuracy: 0.9665697674418605\n",
            "Epoch 5/10, Batch Loss: 0.10795775055885315, Average Training Loss: 0.12306911249955495, Training Accuracy: 0.9662356321839081\n",
            "Epoch 5/10, Batch Loss: 0.2728455066680908, Average Training Loss: 0.12477111697874287, Training Accuracy: 0.9651988636363636\n",
            "Epoch 5/10, Batch Loss: 0.06496114283800125, Average Training Loss: 0.1240990947973862, Training Accuracy: 0.9655898876404494\n",
            "Epoch 5/10, Batch Loss: 0.09499428421258926, Average Training Loss: 0.12377570801311069, Training Accuracy: 0.9652777777777778\n",
            "Epoch 5/10, Batch Loss: 0.16839881241321564, Average Training Loss: 0.12426607179772722, Training Accuracy: 0.9649725274725275\n",
            "Epoch 5/10, Batch Loss: 0.11013012379407883, Average Training Loss: 0.12411242018899192, Training Accuracy: 0.9646739130434783\n",
            "Epoch 5/10, Batch Loss: 0.03562471270561218, Average Training Loss: 0.12316093946336418, Training Accuracy: 0.9650537634408602\n",
            "Epoch 5/10, Batch Loss: 0.31543493270874023, Average Training Loss: 0.12520640747661285, Training Accuracy: 0.9647606382978723\n",
            "Epoch 5/10, Batch Loss: 0.026943888515233994, Average Training Loss: 0.12417206517175625, Training Accuracy: 0.9651315789473685\n",
            "Epoch 5/10, Batch Loss: 0.061213418841362, Average Training Loss: 0.12351624593914796, Training Accuracy: 0.96484375\n",
            "Epoch 5/10, Batch Loss: 0.20314691960811615, Average Training Loss: 0.12433718071924042, Training Accuracy: 0.9639175257731959\n",
            "Epoch 5/10, Batch Loss: 0.05832306295633316, Average Training Loss: 0.12366356727268014, Training Accuracy: 0.9642857142857143\n",
            "Epoch 5/10, Batch Loss: 0.26596468687057495, Average Training Loss: 0.12510095231912352, Training Accuracy: 0.9633838383838383\n",
            "Epoch 5/10, Batch Loss: 0.10857541114091873, Average Training Loss: 0.12493569690734148, Training Accuracy: 0.963125\n",
            "Epoch 5/10, Batch Loss: 0.054335303604602814, Average Training Loss: 0.12423668311226486, Training Accuracy: 0.963490099009901\n",
            "Epoch 5/10, Batch Loss: 0.08706890791654587, Average Training Loss: 0.12387229315936565, Training Accuracy: 0.9632352941176471\n",
            "Epoch 5/10, Batch Loss: 0.13013125956058502, Average Training Loss: 0.12393305982345516, Training Accuracy: 0.9629854368932039\n",
            "Epoch 5/10, Batch Loss: 0.04632718488574028, Average Training Loss: 0.1231868494875156, Training Accuracy: 0.9633413461538461\n",
            "Epoch 5/10, Batch Loss: 0.11911128461360931, Average Training Loss: 0.12314803458395458, Training Accuracy: 0.9630952380952381\n",
            "Epoch 5/10, Batch Loss: 0.08958035707473755, Average Training Loss: 0.12283135838103744, Training Accuracy: 0.9634433962264151\n",
            "Epoch 5/10, Batch Loss: 0.060955677181482315, Average Training Loss: 0.12225308098664908, Training Accuracy: 0.9637850467289719\n",
            "Epoch 5/10, Batch Loss: 0.07238547503948212, Average Training Loss: 0.12179134389454568, Training Accuracy: 0.9635416666666666\n",
            "Epoch 5/10, Batch Loss: 0.22212015092372894, Average Training Loss: 0.12271179166545562, Training Accuracy: 0.963302752293578\n",
            "Epoch 5/10, Batch Loss: 0.023720121011137962, Average Training Loss: 0.12181186738678, Training Accuracy: 0.9636363636363636\n",
            "Epoch 5/10, Batch Loss: 0.019588278606534004, Average Training Loss: 0.12089093415452554, Training Accuracy: 0.963963963963964\n",
            "Epoch 5/10, Batch Loss: 0.16690799593925476, Average Training Loss: 0.12130180077760347, Training Accuracy: 0.9631696428571429\n",
            "Epoch 5/10, Batch Loss: 0.0660085678100586, Average Training Loss: 0.12081248013187298, Training Accuracy: 0.963495575221239\n",
            "Epoch 5/10, Batch Loss: 0.12446438521146774, Average Training Loss: 0.12084451438695715, Training Accuracy: 0.9632675438596491\n",
            "Epoch 5/10, Batch Loss: 0.17741899192333221, Average Training Loss: 0.12133646636553433, Training Accuracy: 0.9630434782608696\n",
            "Epoch 5/10, Batch Loss: 0.044373519718647, Average Training Loss: 0.12067299268754392, Training Accuracy: 0.9633620689655172\n",
            "Epoch 5/10, Batch Loss: 0.07671694457530975, Average Training Loss: 0.12029729996863593, Training Accuracy: 0.9631410256410257\n",
            "Epoch 5/10, Batch Loss: 0.02950708568096161, Average Training Loss: 0.11952789137297767, Training Accuracy: 0.9634533898305084\n",
            "Epoch 5/10, Batch Loss: 0.2176385223865509, Average Training Loss: 0.12035235045712535, Training Accuracy: 0.9627100840336135\n",
            "Epoch 5/10, Batch Loss: 0.04781243950128555, Average Training Loss: 0.11974785119916002, Training Accuracy: 0.9630208333333333\n",
            "Epoch 5/10, Batch Loss: 0.02896960824728012, Average Training Loss: 0.11899761778633457, Training Accuracy: 0.9633264462809917\n",
            "Epoch 5/10, Batch Loss: 0.11237434297800064, Average Training Loss: 0.11894332864856133, Training Accuracy: 0.9631147540983607\n",
            "Epoch 5/10, Batch Loss: 0.017973605543375015, Average Training Loss: 0.11812243659079559, Training Accuracy: 0.9634146341463414\n",
            "Epoch 5/10, Batch Loss: 0.023231111466884613, Average Training Loss: 0.11735718396882858, Training Accuracy: 0.9637096774193549\n",
            "Epoch 5/10, Batch Loss: 0.16999955475330353, Average Training Loss: 0.11777832293510437, Training Accuracy: 0.9635\n",
            "Epoch 5/10, Batch Loss: 0.0895298644900322, Average Training Loss: 0.11755412882046094, Training Accuracy: 0.9632936507936508\n",
            "Epoch 5/10, Batch Loss: 0.03419734537601471, Average Training Loss: 0.11689777619491412, Training Accuracy: 0.9635826771653543\n",
            "Epoch 5/10, Batch Loss: 0.6516058444976807, Average Training Loss: 0.12107518297852948, Training Accuracy: 0.96240234375\n",
            "Epoch 5/10, Batch Loss: 0.036478184163570404, Average Training Loss: 0.12041939229004142, Training Accuracy: 0.9626937984496124\n",
            "Epoch 5/10, Batch Loss: 0.08566570281982422, Average Training Loss: 0.1201520562171936, Training Accuracy: 0.9625\n",
            "Epoch 5/10, Batch Loss: 0.010183781385421753, Average Training Loss: 0.11931260373756175, Training Accuracy: 0.9627862595419847\n",
            "Epoch 5/10, Batch Loss: 0.024108808487653732, Average Training Loss: 0.11859136286445639, Training Accuracy: 0.9630681818181818\n",
            "Epoch 5/10, Batch Loss: 0.008341029286384583, Average Training Loss: 0.11854229651765093, Training Accuracy: 0.9631031220435194\n",
            "Epoch 5/10, Average Training Loss: 0.11776241298792954, Training Accuracy: 0.9631031220435194\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.97      0.97      0.97       427\n",
            "                Educational Opportunity       0.93      0.94      0.94       451\n",
            "                         Family Support       0.98      0.99      0.98       396\n",
            "                      Financial Support       0.98      0.98      0.98       404\n",
            "                 Program Implementation       0.96      0.94      0.95       436\n",
            "\n",
            "                               accuracy                           0.96      2114\n",
            "                              macro avg       0.96      0.96      0.96      2114\n",
            "                           weighted avg       0.96      0.96      0.96      2114\n",
            "\n",
            "Epoch 5/10, Validation Loss: 33.893454130738974, Validation Accuracy: 0.7334593572778828\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.69      0.65      0.67       113\n",
            "                Educational Opportunity       0.59      0.55      0.57       100\n",
            "                         Family Support       0.92      0.93      0.92       105\n",
            "                      Financial Support       0.70      0.80      0.75        97\n",
            "                 Program Implementation       0.75      0.73      0.74       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.73      0.73      0.73       529\n",
            "                           weighted avg       0.73      0.73      0.73       529\n",
            "\n",
            "Epoch 6/10, Batch Loss: 0.018516626209020615, Average Training Loss: 0.018516626209020615, Training Accuracy: 1.0\n",
            "Epoch 6/10, Batch Loss: 0.09533396363258362, Average Training Loss: 0.056925294920802116, Training Accuracy: 0.96875\n",
            "Epoch 6/10, Batch Loss: 0.09032008051872253, Average Training Loss: 0.06805689012010892, Training Accuracy: 0.9583333333333334\n",
            "Epoch 6/10, Batch Loss: 0.04924185201525688, Average Training Loss: 0.06335313059389591, Training Accuracy: 0.96875\n",
            "Epoch 6/10, Batch Loss: 0.016461975872516632, Average Training Loss: 0.05397489964962006, Training Accuracy: 0.975\n",
            "Epoch 6/10, Batch Loss: 0.01659923978149891, Average Training Loss: 0.0477456230049332, Training Accuracy: 0.9791666666666666\n",
            "Epoch 6/10, Batch Loss: 0.03452828899025917, Average Training Loss: 0.045857432431408336, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.017221646383404732, Average Training Loss: 0.042277959175407887, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.10437175631523132, Average Training Loss: 0.0491772699687216, Training Accuracy: 0.9791666666666666\n",
            "Epoch 6/10, Batch Loss: 0.018091488629579544, Average Training Loss: 0.0460686918348074, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.024815702810883522, Average Training Loss: 0.04413660192354159, Training Accuracy: 0.9829545454545454\n",
            "Epoch 6/10, Batch Loss: 0.01059639547020197, Average Training Loss: 0.04134158471909662, Training Accuracy: 0.984375\n",
            "Epoch 6/10, Batch Loss: 0.016361461952328682, Average Training Loss: 0.03942003681396063, Training Accuracy: 0.9855769230769231\n",
            "Epoch 6/10, Batch Loss: 0.2778799831867218, Average Training Loss: 0.05645289012630071, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.23139925301074982, Average Training Loss: 0.06811598098526399, Training Accuracy: 0.975\n",
            "Epoch 6/10, Batch Loss: 0.014101061969995499, Average Training Loss: 0.0647400485468097, Training Accuracy: 0.9765625\n",
            "Epoch 6/10, Batch Loss: 0.21305380761623383, Average Training Loss: 0.07346438731559936, Training Accuracy: 0.9742647058823529\n",
            "Epoch 6/10, Batch Loss: 0.024283139035105705, Average Training Loss: 0.07073209574446082, Training Accuracy: 0.9756944444444444\n",
            "Epoch 6/10, Batch Loss: 0.029750071465969086, Average Training Loss: 0.06857514709822442, Training Accuracy: 0.9769736842105263\n",
            "Epoch 6/10, Batch Loss: 0.027530699968338013, Average Training Loss: 0.06652292474173009, Training Accuracy: 0.978125\n",
            "Epoch 6/10, Batch Loss: 0.03675626963376999, Average Training Loss: 0.06510546497468438, Training Accuracy: 0.9791666666666666\n",
            "Epoch 6/10, Batch Loss: 0.01991976611316204, Average Training Loss: 0.0630515695718879, Training Accuracy: 0.9801136363636364\n",
            "Epoch 6/10, Batch Loss: 0.01951904408633709, Average Training Loss: 0.06115885107251613, Training Accuracy: 0.9809782608695652\n",
            "Epoch 6/10, Batch Loss: 0.3289908170700073, Average Training Loss: 0.0723185163224116, Training Accuracy: 0.9791666666666666\n",
            "Epoch 6/10, Batch Loss: 0.06672368198633194, Average Training Loss: 0.0720947229489684, Training Accuracy: 0.9775\n",
            "Epoch 6/10, Batch Loss: 0.276461124420166, Average Training Loss: 0.07995496915939909, Training Accuracy: 0.9759615384615384\n",
            "Epoch 6/10, Batch Loss: 0.01184176467359066, Average Training Loss: 0.07743225788214693, Training Accuracy: 0.9768518518518519\n",
            "Epoch 6/10, Batch Loss: 0.027835629880428314, Average Training Loss: 0.0756609497392284, Training Accuracy: 0.9776785714285714\n",
            "Epoch 6/10, Batch Loss: 0.15135233104228973, Average Training Loss: 0.07827099737036845, Training Accuracy: 0.9762931034482759\n",
            "Epoch 6/10, Batch Loss: 0.020838918164372444, Average Training Loss: 0.07635659473016858, Training Accuracy: 0.9770833333333333\n",
            "Epoch 6/10, Batch Loss: 0.025521475821733475, Average Training Loss: 0.0747167521847352, Training Accuracy: 0.9778225806451613\n",
            "Epoch 6/10, Batch Loss: 0.033274926245212555, Average Training Loss: 0.07342169512412511, Training Accuracy: 0.978515625\n",
            "Epoch 6/10, Batch Loss: 0.19147230684757233, Average Training Loss: 0.076998986388472, Training Accuracy: 0.9772727272727273\n",
            "Epoch 6/10, Batch Loss: 0.30384859442710876, Average Training Loss: 0.08367103368372601, Training Accuracy: 0.9761029411764706\n",
            "Epoch 6/10, Batch Loss: 0.015879107639193535, Average Training Loss: 0.08173412151102509, Training Accuracy: 0.9767857142857143\n",
            "Epoch 6/10, Batch Loss: 0.04094640910625458, Average Training Loss: 0.08060112949978146, Training Accuracy: 0.9774305555555556\n",
            "Epoch 6/10, Batch Loss: 0.0607735700905323, Average Training Loss: 0.0800652495157477, Training Accuracy: 0.9780405405405406\n",
            "Epoch 6/10, Batch Loss: 0.010113600641489029, Average Training Loss: 0.07822441665063563, Training Accuracy: 0.9786184210526315\n",
            "Epoch 6/10, Batch Loss: 0.02529204450547695, Average Training Loss: 0.07686717633922131, Training Accuracy: 0.9791666666666666\n",
            "Epoch 6/10, Batch Loss: 0.026964083313941956, Average Training Loss: 0.07561959901358932, Training Accuracy: 0.9796875\n",
            "Epoch 6/10, Batch Loss: 0.020738599821925163, Average Training Loss: 0.07428103805769508, Training Accuracy: 0.9801829268292683\n",
            "Epoch 6/10, Batch Loss: 0.036894429475069046, Average Training Loss: 0.07339088071048969, Training Accuracy: 0.9806547619047619\n",
            "Epoch 6/10, Batch Loss: 0.018552465364336967, Average Training Loss: 0.07211556872569544, Training Accuracy: 0.9811046511627907\n",
            "Epoch 6/10, Batch Loss: 0.013693207874894142, Average Training Loss: 0.07078778779726815, Training Accuracy: 0.9815340909090909\n",
            "Epoch 6/10, Batch Loss: 0.17875458300113678, Average Training Loss: 0.07318704991290967, Training Accuracy: 0.9805555555555555\n",
            "Epoch 6/10, Batch Loss: 0.022227393463253975, Average Training Loss: 0.0720792312944389, Training Accuracy: 0.9809782608695652\n",
            "Epoch 6/10, Batch Loss: 0.018346048891544342, Average Training Loss: 0.07093597209437731, Training Accuracy: 0.9813829787234043\n",
            "Epoch 6/10, Batch Loss: 0.012449050322175026, Average Training Loss: 0.06971749455745642, Training Accuracy: 0.9817708333333334\n",
            "Epoch 6/10, Batch Loss: 0.09351201355457306, Average Training Loss: 0.07020309698596901, Training Accuracy: 0.9808673469387755\n",
            "Epoch 6/10, Batch Loss: 0.016232844442129135, Average Training Loss: 0.06912369193509221, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.0104758832603693, Average Training Loss: 0.0679737349022545, Training Accuracy: 0.9816176470588235\n",
            "Epoch 6/10, Batch Loss: 0.01530307624489069, Average Training Loss: 0.06696083762038213, Training Accuracy: 0.9819711538461539\n",
            "Epoch 6/10, Batch Loss: 0.032554470002651215, Average Training Loss: 0.06631166087287776, Training Accuracy: 0.9823113207547169\n",
            "Epoch 6/10, Batch Loss: 0.13165825605392456, Average Training Loss: 0.06752178300586012, Training Accuracy: 0.9814814814814815\n",
            "Epoch 6/10, Batch Loss: 0.1225629597902298, Average Training Loss: 0.06852253167466683, Training Accuracy: 0.9806818181818182\n",
            "Epoch 6/10, Batch Loss: 0.10825525224208832, Average Training Loss: 0.06923204454194222, Training Accuracy: 0.9799107142857143\n",
            "Epoch 6/10, Batch Loss: 0.017549024894833565, Average Training Loss: 0.0683253248990105, Training Accuracy: 0.9802631578947368\n",
            "Epoch 6/10, Batch Loss: 0.03793049603700638, Average Training Loss: 0.06780127612552767, Training Accuracy: 0.9806034482758621\n",
            "Epoch 6/10, Batch Loss: 0.027662428095936775, Average Training Loss: 0.067120956667399, Training Accuracy: 0.9809322033898306\n",
            "Epoch 6/10, Batch Loss: 0.03360358625650406, Average Training Loss: 0.06656233382721742, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.05864737182855606, Average Training Loss: 0.06643258035182953, Training Accuracy: 0.9815573770491803\n",
            "Epoch 6/10, Batch Loss: 0.12293333560228348, Average Training Loss: 0.0673438828558691, Training Accuracy: 0.9808467741935484\n",
            "Epoch 6/10, Batch Loss: 0.028477275744080544, Average Training Loss: 0.06672695258425342, Training Accuracy: 0.9811507936507936\n",
            "Epoch 6/10, Batch Loss: 0.02139914408326149, Average Training Loss: 0.06601870557642542, Training Accuracy: 0.9814453125\n",
            "Epoch 6/10, Batch Loss: 0.02031794935464859, Average Training Loss: 0.06531561701916731, Training Accuracy: 0.9817307692307692\n",
            "Epoch 6/10, Batch Loss: 0.12343242019414902, Average Training Loss: 0.06619617464303067, Training Accuracy: 0.9810606060606061\n",
            "Epoch 6/10, Batch Loss: 0.026339195668697357, Average Training Loss: 0.06560129435983167, Training Accuracy: 0.9813432835820896\n",
            "Epoch 6/10, Batch Loss: 0.015060696750879288, Average Training Loss: 0.06485805027734708, Training Accuracy: 0.9816176470588235\n",
            "Epoch 6/10, Batch Loss: 0.011352024972438812, Average Training Loss: 0.06408260063524696, Training Accuracy: 0.9818840579710145\n",
            "Epoch 6/10, Batch Loss: 0.012029738165438175, Average Training Loss: 0.06333898831424968, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.10695900022983551, Average Training Loss: 0.06395335467925793, Training Accuracy: 0.9815140845070423\n",
            "Epoch 6/10, Batch Loss: 0.0598638653755188, Average Training Loss: 0.06389655621670601, Training Accuracy: 0.9817708333333334\n",
            "Epoch 6/10, Batch Loss: 0.09731091558933258, Average Training Loss: 0.06435428716701595, Training Accuracy: 0.9811643835616438\n",
            "Epoch 6/10, Batch Loss: 0.010490359738469124, Average Training Loss: 0.06362639625581938, Training Accuracy: 0.981418918918919\n",
            "Epoch 6/10, Batch Loss: 0.04269883781671524, Average Training Loss: 0.06334736214329799, Training Accuracy: 0.9816666666666667\n",
            "Epoch 6/10, Batch Loss: 0.05182882398366928, Average Training Loss: 0.0631958024306713, Training Accuracy: 0.9819078947368421\n",
            "Epoch 6/10, Batch Loss: 0.0638410747051239, Average Training Loss: 0.06320418259007977, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.1724717617034912, Average Training Loss: 0.06460504898896967, Training Accuracy: 0.9815705128205128\n",
            "Epoch 6/10, Batch Loss: 0.2874610126018524, Average Training Loss: 0.0674260105536897, Training Accuracy: 0.9810126582278481\n",
            "Epoch 6/10, Batch Loss: 0.010735654272139072, Average Training Loss: 0.06671738110017031, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.022296234965324402, Average Training Loss: 0.06616897188862901, Training Accuracy: 0.9814814814814815\n",
            "Epoch 6/10, Batch Loss: 0.013724535703659058, Average Training Loss: 0.06552940559369035, Training Accuracy: 0.9817073170731707\n",
            "Epoch 6/10, Batch Loss: 0.06352075934410095, Average Training Loss: 0.06550520503646638, Training Accuracy: 0.9811746987951807\n",
            "Epoch 6/10, Batch Loss: 0.011674837209284306, Average Training Loss: 0.06486436732423802, Training Accuracy: 0.9813988095238095\n",
            "Epoch 6/10, Batch Loss: 0.013002967461943626, Average Training Loss: 0.06425423320821103, Training Accuracy: 0.9816176470588235\n",
            "Epoch 6/10, Batch Loss: 0.043507177382707596, Average Training Loss: 0.06401298837303075, Training Accuracy: 0.9818313953488372\n",
            "Epoch 6/10, Batch Loss: 0.016029998660087585, Average Training Loss: 0.0634614597556406, Training Accuracy: 0.9820402298850575\n",
            "Epoch 6/10, Batch Loss: 0.06384021043777466, Average Training Loss: 0.06346576374066486, Training Accuracy: 0.9822443181818182\n",
            "Epoch 6/10, Batch Loss: 0.053275562822818756, Average Training Loss: 0.06335126710113849, Training Accuracy: 0.9824438202247191\n",
            "Epoch 6/10, Batch Loss: 0.012951696291565895, Average Training Loss: 0.06279127186992102, Training Accuracy: 0.9826388888888888\n",
            "Epoch 6/10, Batch Loss: 0.06633765250444412, Average Training Loss: 0.06283024308568501, Training Accuracy: 0.9828296703296703\n",
            "Epoch 6/10, Batch Loss: 0.02771184593439102, Average Training Loss: 0.06244852137751877, Training Accuracy: 0.983016304347826\n",
            "Epoch 6/10, Batch Loss: 0.015488549135625362, Average Training Loss: 0.0619435754394339, Training Accuracy: 0.9831989247311828\n",
            "Epoch 6/10, Batch Loss: 0.1524764597415924, Average Training Loss: 0.06290669122988239, Training Accuracy: 0.9820478723404256\n",
            "Epoch 6/10, Batch Loss: 0.010380260646343231, Average Training Loss: 0.06235378143426619, Training Accuracy: 0.9822368421052632\n",
            "Epoch 6/10, Batch Loss: 0.04141111299395561, Average Training Loss: 0.06213562863801295, Training Accuracy: 0.982421875\n",
            "Epoch 6/10, Batch Loss: 0.0197360310703516, Average Training Loss: 0.061698519384738096, Training Accuracy: 0.9826030927835051\n",
            "Epoch 6/10, Batch Loss: 0.06055934354662895, Average Training Loss: 0.06168689514149209, Training Accuracy: 0.982780612244898\n",
            "Epoch 6/10, Batch Loss: 0.01685585267841816, Average Training Loss: 0.061234056328733764, Training Accuracy: 0.9829545454545454\n",
            "Epoch 6/10, Batch Loss: 0.044983092695474625, Average Training Loss: 0.06107154669240117, Training Accuracy: 0.983125\n",
            "Epoch 6/10, Batch Loss: 0.31054049730300903, Average Training Loss: 0.06354153630240719, Training Accuracy: 0.9826732673267327\n",
            "Epoch 6/10, Batch Loss: 0.0467941053211689, Average Training Loss: 0.06337734580259113, Training Accuracy: 0.9828431372549019\n",
            "Epoch 6/10, Batch Loss: 0.011323781684041023, Average Training Loss: 0.06287197139367316, Training Accuracy: 0.9830097087378641\n",
            "Epoch 6/10, Batch Loss: 0.037349678575992584, Average Training Loss: 0.06262656473196469, Training Accuracy: 0.9831730769230769\n",
            "Epoch 6/10, Batch Loss: 0.013765770941972733, Average Training Loss: 0.06216122383872668, Training Accuracy: 0.9833333333333333\n",
            "Epoch 6/10, Batch Loss: 0.16853350400924683, Average Training Loss: 0.06316473591580705, Training Accuracy: 0.9829009433962265\n",
            "Epoch 6/10, Batch Loss: 0.014536969363689423, Average Training Loss: 0.06271027080784335, Training Accuracy: 0.9830607476635514\n",
            "Epoch 6/10, Batch Loss: 0.10447309166193008, Average Training Loss: 0.06309696359352933, Training Accuracy: 0.9826388888888888\n",
            "Epoch 6/10, Batch Loss: 0.014827185310423374, Average Training Loss: 0.06265412159093203, Training Accuracy: 0.9827981651376146\n",
            "Epoch 6/10, Batch Loss: 0.34962648153305054, Average Training Loss: 0.06526296122676947, Training Accuracy: 0.9818181818181818\n",
            "Epoch 6/10, Batch Loss: 0.021952548995614052, Average Training Loss: 0.06487277733279509, Training Accuracy: 0.9819819819819819\n",
            "Epoch 6/10, Batch Loss: 0.031977392733097076, Average Training Loss: 0.06457906854172636, Training Accuracy: 0.9821428571428571\n",
            "Epoch 6/10, Batch Loss: 0.010228803381323814, Average Training Loss: 0.0640980927438467, Training Accuracy: 0.9823008849557522\n",
            "Epoch 6/10, Batch Loss: 0.01628178171813488, Average Training Loss: 0.06367865141905975, Training Accuracy: 0.9824561403508771\n",
            "Epoch 6/10, Batch Loss: 0.04264441877603531, Average Training Loss: 0.06349574504825084, Training Accuracy: 0.9826086956521739\n",
            "Epoch 6/10, Batch Loss: 0.014177536591887474, Average Training Loss: 0.06307058807879944, Training Accuracy: 0.9827586206896551\n",
            "Epoch 6/10, Batch Loss: 0.37922748923301697, Average Training Loss: 0.06577278381516026, Training Accuracy: 0.9823717948717948\n",
            "Epoch 6/10, Batch Loss: 0.08170875906944275, Average Training Loss: 0.06590783445290842, Training Accuracy: 0.9819915254237288\n",
            "Epoch 6/10, Batch Loss: 0.32732313871383667, Average Training Loss: 0.0681046017156053, Training Accuracy: 0.9810924369747899\n",
            "Epoch 6/10, Batch Loss: 0.04284347593784332, Average Training Loss: 0.06789409233412395, Training Accuracy: 0.98125\n",
            "Epoch 6/10, Batch Loss: 0.0201047882437706, Average Training Loss: 0.0674991394077574, Training Accuracy: 0.981404958677686\n",
            "Epoch 6/10, Batch Loss: 0.02070174366235733, Average Training Loss: 0.06711555419672953, Training Accuracy: 0.9815573770491803\n",
            "Epoch 6/10, Batch Loss: 0.008486030623316765, Average Training Loss: 0.06663889140344975, Training Accuracy: 0.9817073170731707\n",
            "Epoch 6/10, Batch Loss: 0.06224120035767555, Average Training Loss: 0.0666034261530806, Training Accuracy: 0.9818548387096774\n",
            "Epoch 6/10, Batch Loss: 0.039894264191389084, Average Training Loss: 0.06638975285738706, Training Accuracy: 0.982\n",
            "Epoch 6/10, Batch Loss: 0.6344412565231323, Average Training Loss: 0.07089809812457552, Training Accuracy: 0.9811507936507936\n",
            "Epoch 6/10, Batch Loss: 0.37436842918395996, Average Training Loss: 0.07328762829039745, Training Accuracy: 0.9808070866141733\n",
            "Epoch 6/10, Batch Loss: 0.02022332139313221, Average Training Loss: 0.07287306339276256, Training Accuracy: 0.98095703125\n",
            "Epoch 6/10, Batch Loss: 0.08837434649467468, Average Training Loss: 0.0729932283780487, Training Accuracy: 0.9806201550387597\n",
            "Epoch 6/10, Batch Loss: 0.015028846450150013, Average Training Loss: 0.07254734851706486, Training Accuracy: 0.9807692307692307\n",
            "Epoch 6/10, Batch Loss: 0.03364145755767822, Average Training Loss: 0.07225035698302375, Training Accuracy: 0.9809160305343512\n",
            "Epoch 6/10, Batch Loss: 0.006582762114703655, Average Training Loss: 0.07175287520371829, Training Accuracy: 0.9810606060606061\n",
            "Epoch 6/10, Batch Loss: 0.011435036547482014, Average Training Loss: 0.07177153879612712, Training Accuracy: 0.9810785241248817\n",
            "Epoch 6/10, Average Training Loss: 0.07129935761983681, Training Accuracy: 0.9810785241248817\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.98      0.99      0.99       427\n",
            "                Educational Opportunity       0.97      0.97      0.97       451\n",
            "                         Family Support       0.99      0.99      0.99       396\n",
            "                      Financial Support       0.98      0.98      0.98       404\n",
            "                 Program Implementation       0.99      0.97      0.98       436\n",
            "\n",
            "                               accuracy                           0.98      2114\n",
            "                              macro avg       0.98      0.98      0.98      2114\n",
            "                           weighted avg       0.98      0.98      0.98      2114\n",
            "\n",
            "Epoch 6/10, Validation Loss: 36.958937510848045, Validation Accuracy: 0.7353497164461248\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.68      0.68       113\n",
            "                Educational Opportunity       0.61      0.54      0.57       100\n",
            "                         Family Support       0.89      0.98      0.93       105\n",
            "                      Financial Support       0.67      0.84      0.74        97\n",
            "                 Program Implementation       0.83      0.65      0.73       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.73      0.74      0.73       529\n",
            "                           weighted avg       0.74      0.74      0.73       529\n",
            "\n",
            "Epoch 7/10, Batch Loss: 0.019281484186649323, Average Training Loss: 0.019281484186649323, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.008167057298123837, Average Training Loss: 0.01372427074238658, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.011016860604286194, Average Training Loss: 0.012821800696353117, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.045689649879932404, Average Training Loss: 0.02103876299224794, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.03638163581490517, Average Training Loss: 0.024107337556779386, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.009781451895833015, Average Training Loss: 0.021719689946621656, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.020405367016792297, Average Training Loss: 0.021531929528074607, Training Accuracy: 1.0\n",
            "Epoch 7/10, Batch Loss: 0.098356232047081, Average Training Loss: 0.031134967342950404, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.04213962331414223, Average Training Loss: 0.03235770689530505, Training Accuracy: 0.9930555555555556\n",
            "Epoch 7/10, Batch Loss: 0.006538520101457834, Average Training Loss: 0.029775788215920328, Training Accuracy: 0.99375\n",
            "Epoch 7/10, Batch Loss: 0.035093482583761215, Average Training Loss: 0.03025921497663314, Training Accuracy: 0.9943181818181818\n",
            "Epoch 7/10, Batch Loss: 0.03860781341791153, Average Training Loss: 0.030954931513406336, Training Accuracy: 0.9947916666666666\n",
            "Epoch 7/10, Batch Loss: 0.013008583337068558, Average Training Loss: 0.029574443192149583, Training Accuracy: 0.9951923076923077\n",
            "Epoch 7/10, Batch Loss: 0.01788713037967682, Average Training Loss: 0.028739635134115815, Training Accuracy: 0.9955357142857143\n",
            "Epoch 7/10, Batch Loss: 0.014098268933594227, Average Training Loss: 0.027763544054081043, Training Accuracy: 0.9958333333333333\n",
            "Epoch 7/10, Batch Loss: 0.058586955070495605, Average Training Loss: 0.029690007242606953, Training Accuracy: 0.99609375\n",
            "Epoch 7/10, Batch Loss: 0.015151138417422771, Average Training Loss: 0.028834779664654944, Training Accuracy: 0.9963235294117647\n",
            "Epoch 7/10, Batch Loss: 0.046155527234077454, Average Training Loss: 0.02979704341851175, Training Accuracy: 0.9965277777777778\n",
            "Epoch 7/10, Batch Loss: 0.027652202174067497, Average Training Loss: 0.029684157037225208, Training Accuracy: 0.9967105263157895\n",
            "Epoch 7/10, Batch Loss: 0.02120046876370907, Average Training Loss: 0.029259972623549402, Training Accuracy: 0.996875\n",
            "Epoch 7/10, Batch Loss: 0.0147207947447896, Average Training Loss: 0.028567630819798934, Training Accuracy: 0.9970238095238095\n",
            "Epoch 7/10, Batch Loss: 0.011830572038888931, Average Training Loss: 0.027806855420666663, Training Accuracy: 0.9971590909090909\n",
            "Epoch 7/10, Batch Loss: 0.009813266806304455, Average Training Loss: 0.027024525480911783, Training Accuracy: 0.9972826086956522\n",
            "Epoch 7/10, Batch Loss: 0.02400844730436802, Average Training Loss: 0.026898855556889128, Training Accuracy: 0.9973958333333334\n",
            "Epoch 7/10, Batch Loss: 0.009027625434100628, Average Training Loss: 0.026184006351977585, Training Accuracy: 0.9975\n",
            "Epoch 7/10, Batch Loss: 0.016880113631486893, Average Training Loss: 0.025826164324266408, Training Accuracy: 0.9975961538461539\n",
            "Epoch 7/10, Batch Loss: 0.0996919646859169, Average Training Loss: 0.02856193470803124, Training Accuracy: 0.9953703703703703\n",
            "Epoch 7/10, Batch Loss: 0.048556338995695114, Average Training Loss: 0.029276020575447807, Training Accuracy: 0.9955357142857143\n",
            "Epoch 7/10, Batch Loss: 0.023386018350720406, Average Training Loss: 0.029072917050457205, Training Accuracy: 0.9956896551724138\n",
            "Epoch 7/10, Batch Loss: 0.02806153893470764, Average Training Loss: 0.02903920444659889, Training Accuracy: 0.9958333333333333\n",
            "Epoch 7/10, Batch Loss: 0.08971299231052399, Average Training Loss: 0.03099642340995131, Training Accuracy: 0.9939516129032258\n",
            "Epoch 7/10, Batch Loss: 0.01363232173025608, Average Training Loss: 0.030453795232460834, Training Accuracy: 0.994140625\n",
            "Epoch 7/10, Batch Loss: 0.02958708442747593, Average Training Loss: 0.030427531268673414, Training Accuracy: 0.9943181818181818\n",
            "Epoch 7/10, Batch Loss: 0.020450133830308914, Average Training Loss: 0.030134078402839163, Training Accuracy: 0.9944852941176471\n",
            "Epoch 7/10, Batch Loss: 0.007733846083283424, Average Training Loss: 0.02949407176513757, Training Accuracy: 0.9946428571428572\n",
            "Epoch 7/10, Batch Loss: 0.010552790015935898, Average Training Loss: 0.02896792504988197, Training Accuracy: 0.9947916666666666\n",
            "Epoch 7/10, Batch Loss: 0.01489226333796978, Average Training Loss: 0.028587501760370827, Training Accuracy: 0.9949324324324325\n",
            "Epoch 7/10, Batch Loss: 0.026353903114795685, Average Training Loss: 0.028528722848645167, Training Accuracy: 0.9950657894736842\n",
            "Epoch 7/10, Batch Loss: 0.00834028422832489, Average Training Loss: 0.02801107057632926, Training Accuracy: 0.9951923076923077\n",
            "Epoch 7/10, Batch Loss: 0.028653718531131744, Average Training Loss: 0.028027136775199323, Training Accuracy: 0.9953125\n",
            "Epoch 7/10, Batch Loss: 0.1687546968460083, Average Training Loss: 0.0314595162891215, Training Accuracy: 0.9939024390243902\n",
            "Epoch 7/10, Batch Loss: 0.011584514752030373, Average Training Loss: 0.0309863019668098, Training Accuracy: 0.9940476190476191\n",
            "Epoch 7/10, Batch Loss: 0.02201474830508232, Average Training Loss: 0.03077766118397893, Training Accuracy: 0.9941860465116279\n",
            "Epoch 7/10, Batch Loss: 0.13801084458827972, Average Training Loss: 0.03321477898862213, Training Accuracy: 0.9928977272727273\n",
            "Epoch 7/10, Batch Loss: 0.008185034617781639, Average Training Loss: 0.032658562447047894, Training Accuracy: 0.9930555555555556\n",
            "Epoch 7/10, Batch Loss: 0.021997394040226936, Average Training Loss: 0.032426797916464835, Training Accuracy: 0.9932065217391305\n",
            "Epoch 7/10, Batch Loss: 0.010339267551898956, Average Training Loss: 0.0319568504618996, Training Accuracy: 0.9933510638297872\n",
            "Epoch 7/10, Batch Loss: 0.010616084560751915, Average Training Loss: 0.03151225117229236, Training Accuracy: 0.9934895833333334\n",
            "Epoch 7/10, Batch Loss: 0.013110163621604443, Average Training Loss: 0.03113669836513546, Training Accuracy: 0.9936224489795918\n",
            "Epoch 7/10, Batch Loss: 0.014911027625203133, Average Training Loss: 0.030812184950336816, Training Accuracy: 0.99375\n",
            "Epoch 7/10, Batch Loss: 0.20914418995380402, Average Training Loss: 0.034308890930796955, Training Accuracy: 0.9926470588235294\n",
            "Epoch 7/10, Batch Loss: 0.006510196719318628, Average Training Loss: 0.0337743006574993, Training Accuracy: 0.9927884615384616\n",
            "Epoch 7/10, Batch Loss: 0.007159254513680935, Average Training Loss: 0.03327212997554046, Training Accuracy: 0.9929245283018868\n",
            "Epoch 7/10, Batch Loss: 0.009391997009515762, Average Training Loss: 0.032829905290984444, Training Accuracy: 0.9930555555555556\n",
            "Epoch 7/10, Batch Loss: 0.011102809570729733, Average Training Loss: 0.03243486718697981, Training Accuracy: 0.9931818181818182\n",
            "Epoch 7/10, Batch Loss: 0.016856273636221886, Average Training Loss: 0.032156678016430566, Training Accuracy: 0.9933035714285714\n",
            "Epoch 7/10, Batch Loss: 0.006683152634650469, Average Training Loss: 0.03170977406236425, Training Accuracy: 0.993421052631579\n",
            "Epoch 7/10, Batch Loss: 0.04135839641094208, Average Training Loss: 0.03187612962009835, Training Accuracy: 0.9935344827586207\n",
            "Epoch 7/10, Batch Loss: 0.009026167914271355, Average Training Loss: 0.03148884213355891, Training Accuracy: 0.9936440677966102\n",
            "Epoch 7/10, Batch Loss: 0.007673237938433886, Average Training Loss: 0.03109191539697349, Training Accuracy: 0.99375\n",
            "Epoch 7/10, Batch Loss: 0.027702055871486664, Average Training Loss: 0.03103634392934256, Training Accuracy: 0.9938524590163934\n",
            "Epoch 7/10, Batch Loss: 0.005940127186477184, Average Training Loss: 0.030631566239941503, Training Accuracy: 0.9939516129032258\n",
            "Epoch 7/10, Batch Loss: 0.016309810802340508, Average Training Loss: 0.030404236788551014, Training Accuracy: 0.9940476190476191\n",
            "Epoch 7/10, Batch Loss: 0.008612347766757011, Average Training Loss: 0.03006373852258548, Training Accuracy: 0.994140625\n",
            "Epoch 7/10, Batch Loss: 0.006749511696398258, Average Training Loss: 0.029705058109874907, Training Accuracy: 0.9942307692307693\n",
            "Epoch 7/10, Batch Loss: 0.11441695690155029, Average Training Loss: 0.030988571727930597, Training Accuracy: 0.9933712121212122\n",
            "Epoch 7/10, Batch Loss: 0.01479264348745346, Average Training Loss: 0.030746841455684668, Training Accuracy: 0.9934701492537313\n",
            "Epoch 7/10, Batch Loss: 0.005084038246423006, Average Training Loss: 0.030369447290842587, Training Accuracy: 0.9935661764705882\n",
            "Epoch 7/10, Batch Loss: 0.0067131612449884415, Average Training Loss: 0.03002660256554035, Training Accuracy: 0.9936594202898551\n",
            "Epoch 7/10, Batch Loss: 0.010165500454604626, Average Training Loss: 0.029742872535384126, Training Accuracy: 0.99375\n",
            "Epoch 7/10, Batch Loss: 0.04196564108133316, Average Training Loss: 0.029915024205045382, Training Accuracy: 0.9938380281690141\n",
            "Epoch 7/10, Batch Loss: 0.018134549260139465, Average Training Loss: 0.029751406497477245, Training Accuracy: 0.9939236111111112\n",
            "Epoch 7/10, Batch Loss: 0.007854200899600983, Average Training Loss: 0.02945144477695839, Training Accuracy: 0.9940068493150684\n",
            "Epoch 7/10, Batch Loss: 0.012358310632407665, Average Training Loss: 0.029220456477707706, Training Accuracy: 0.9940878378378378\n",
            "Epoch 7/10, Batch Loss: 0.2412615716457367, Average Training Loss: 0.03204767134661476, Training Accuracy: 0.9933333333333333\n",
            "Epoch 7/10, Batch Loss: 0.03158879280090332, Average Training Loss: 0.03204163347101329, Training Accuracy: 0.993421052631579\n",
            "Epoch 7/10, Batch Loss: 0.005941696465015411, Average Training Loss: 0.031702673250156174, Training Accuracy: 0.9935064935064936\n",
            "Epoch 7/10, Batch Loss: 0.2883245646953583, Average Training Loss: 0.03499269749945364, Training Accuracy: 0.9927884615384616\n",
            "Epoch 7/10, Batch Loss: 0.01129128597676754, Average Training Loss: 0.034692679632077866, Training Accuracy: 0.992879746835443\n",
            "Epoch 7/10, Batch Loss: 0.1853162944316864, Average Training Loss: 0.036575474817072975, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.009325053542852402, Average Training Loss: 0.03623904986307025, Training Accuracy: 0.9922839506172839\n",
            "Epoch 7/10, Batch Loss: 0.00786238070577383, Average Training Loss: 0.03589299292212761, Training Accuracy: 0.9923780487804879\n",
            "Epoch 7/10, Batch Loss: 0.01946813054382801, Average Training Loss: 0.03569510301395533, Training Accuracy: 0.9924698795180723\n",
            "Epoch 7/10, Batch Loss: 0.008364691399037838, Average Training Loss: 0.03536974097092059, Training Accuracy: 0.9925595238095238\n",
            "Epoch 7/10, Batch Loss: 0.007933629676699638, Average Training Loss: 0.03504696319098858, Training Accuracy: 0.9926470588235294\n",
            "Epoch 7/10, Batch Loss: 0.015823904424905777, Average Training Loss: 0.03482343925184808, Training Accuracy: 0.9927325581395349\n",
            "Epoch 7/10, Batch Loss: 0.18970544636249542, Average Training Loss: 0.03660369220714288, Training Accuracy: 0.9920977011494253\n",
            "Epoch 7/10, Batch Loss: 0.014443817548453808, Average Training Loss: 0.03635187544965778, Training Accuracy: 0.9921875\n",
            "Epoch 7/10, Batch Loss: 0.020364519208669662, Average Training Loss: 0.0361722422334669, Training Accuracy: 0.9922752808988764\n",
            "Epoch 7/10, Batch Loss: 0.02000017836689949, Average Training Loss: 0.035992552634949486, Training Accuracy: 0.9923611111111111\n",
            "Epoch 7/10, Batch Loss: 0.007936587557196617, Average Training Loss: 0.03568424532640275, Training Accuracy: 0.992445054945055\n",
            "Epoch 7/10, Batch Loss: 0.008293481543660164, Average Training Loss: 0.03538651963311207, Training Accuracy: 0.9925271739130435\n",
            "Epoch 7/10, Batch Loss: 0.17703789472579956, Average Training Loss: 0.03690965269862484, Training Accuracy: 0.991263440860215\n",
            "Epoch 7/10, Batch Loss: 0.03222028538584709, Average Training Loss: 0.036859765812318694, Training Accuracy: 0.9913563829787234\n",
            "Epoch 7/10, Batch Loss: 0.014558007940649986, Average Training Loss: 0.03662501046630113, Training Accuracy: 0.9914473684210526\n",
            "Epoch 7/10, Batch Loss: 0.00830021221190691, Average Training Loss: 0.03632996048448452, Training Accuracy: 0.9915364583333334\n",
            "Epoch 7/10, Batch Loss: 0.280756413936615, Average Training Loss: 0.038849820829351844, Training Accuracy: 0.990979381443299\n",
            "Epoch 7/10, Batch Loss: 0.01074005477130413, Average Training Loss: 0.038562986481820744, Training Accuracy: 0.9910714285714286\n",
            "Epoch 7/10, Batch Loss: 0.010204305872321129, Average Training Loss: 0.03827653516253287, Training Accuracy: 0.9911616161616161\n",
            "Epoch 7/10, Batch Loss: 0.16342255473136902, Average Training Loss: 0.039527995358221234, Training Accuracy: 0.99\n",
            "Epoch 7/10, Batch Loss: 0.02136640064418316, Average Training Loss: 0.03934817758877531, Training Accuracy: 0.9900990099009901\n",
            "Epoch 7/10, Batch Loss: 0.24740198254585266, Average Training Loss: 0.04138792077462901, Training Accuracy: 0.9895833333333334\n",
            "Epoch 7/10, Batch Loss: 0.016663331538438797, Average Training Loss: 0.04114787621893785, Training Accuracy: 0.9896844660194175\n",
            "Epoch 7/10, Batch Loss: 0.18007169663906097, Average Training Loss: 0.04248368218451595, Training Accuracy: 0.9891826923076923\n",
            "Epoch 7/10, Batch Loss: 0.009427919052541256, Average Training Loss: 0.04216886539278286, Training Accuracy: 0.9892857142857143\n",
            "Epoch 7/10, Batch Loss: 0.016270693391561508, Average Training Loss: 0.041924543015412846, Training Accuracy: 0.9893867924528302\n",
            "Epoch 7/10, Batch Loss: 0.030726155266165733, Average Training Loss: 0.04181988518598063, Training Accuracy: 0.9894859813084113\n",
            "Epoch 7/10, Batch Loss: 0.12996214628219604, Average Training Loss: 0.04263601723316781, Training Accuracy: 0.9890046296296297\n",
            "Epoch 7/10, Batch Loss: 0.021591292694211006, Average Training Loss: 0.04244294636583793, Training Accuracy: 0.989105504587156\n",
            "Epoch 7/10, Batch Loss: 0.09764894098043442, Average Training Loss: 0.04294481904415244, Training Accuracy: 0.9886363636363636\n",
            "Epoch 7/10, Batch Loss: 0.20446182787418365, Average Training Loss: 0.04439992723181038, Training Accuracy: 0.9881756756756757\n",
            "Epoch 7/10, Batch Loss: 0.023017195984721184, Average Training Loss: 0.0442090099885328, Training Accuracy: 0.98828125\n",
            "Epoch 7/10, Batch Loss: 0.009699986316263676, Average Training Loss: 0.04390362039851272, Training Accuracy: 0.9883849557522124\n",
            "Epoch 7/10, Batch Loss: 0.009082971140742302, Average Training Loss: 0.043598176106777894, Training Accuracy: 0.9884868421052632\n",
            "Epoch 7/10, Batch Loss: 0.01257996167987585, Average Training Loss: 0.0433284525030657, Training Accuracy: 0.9885869565217391\n",
            "Epoch 7/10, Batch Loss: 0.07816574722528458, Average Training Loss: 0.04362877400929172, Training Accuracy: 0.9881465517241379\n",
            "Epoch 7/10, Batch Loss: 0.007716393563896418, Average Training Loss: 0.04332183058668151, Training Accuracy: 0.9882478632478633\n",
            "Epoch 7/10, Batch Loss: 0.016772853210568428, Average Training Loss: 0.04309683925298564, Training Accuracy: 0.9883474576271186\n",
            "Epoch 7/10, Batch Loss: 0.012510711327195168, Average Training Loss: 0.04283981296789496, Training Accuracy: 0.9884453781512605\n",
            "Epoch 7/10, Batch Loss: 0.023284992203116417, Average Training Loss: 0.04267685612818847, Training Accuracy: 0.9885416666666667\n",
            "Epoch 7/10, Batch Loss: 0.23163393139839172, Average Training Loss: 0.04423848484942982, Training Accuracy: 0.9881198347107438\n",
            "Epoch 7/10, Batch Loss: 0.233662948012352, Average Training Loss: 0.04579114438355213, Training Accuracy: 0.9877049180327869\n",
            "Epoch 7/10, Batch Loss: 0.013197188265621662, Average Training Loss: 0.045526152870398226, Training Accuracy: 0.9878048780487805\n",
            "Epoch 7/10, Batch Loss: 0.022640088573098183, Average Training Loss: 0.04534158783574258, Training Accuracy: 0.9879032258064516\n",
            "Epoch 7/10, Batch Loss: 0.019773399457335472, Average Training Loss: 0.04513704232871532, Training Accuracy: 0.988\n",
            "Epoch 7/10, Batch Loss: 0.016621330752968788, Average Training Loss: 0.04491072715747924, Training Accuracy: 0.9880952380952381\n",
            "Epoch 7/10, Batch Loss: 0.012920757755637169, Average Training Loss: 0.04465883763463009, Training Accuracy: 0.9881889763779528\n",
            "Epoch 7/10, Batch Loss: 0.2674524188041687, Average Training Loss: 0.04639941248751711, Training Accuracy: 0.98779296875\n",
            "Epoch 7/10, Batch Loss: 0.01544339768588543, Average Training Loss: 0.046159443380527715, Training Accuracy: 0.9878875968992248\n",
            "Epoch 7/10, Batch Loss: 0.07337038218975067, Average Training Loss: 0.04636875829444482, Training Accuracy: 0.9875\n",
            "Epoch 7/10, Batch Loss: 0.02137269824743271, Average Training Loss: 0.046177948675765336, Training Accuracy: 0.9875954198473282\n",
            "Epoch 7/10, Batch Loss: 0.008232977241277695, Average Training Loss: 0.04589048677095861, Training Accuracy: 0.9876893939393939\n",
            "Epoch 7/10, Batch Loss: 0.010555327869951725, Average Training Loss: 0.045926959936700006, Training Accuracy: 0.9877010406811731\n",
            "Epoch 7/10, Average Training Loss: 0.04562480888448488, Training Accuracy: 0.9877010406811731\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.99      0.99      0.99       427\n",
            "                Educational Opportunity       0.98      0.98      0.98       451\n",
            "                         Family Support       0.99      0.99      0.99       396\n",
            "                      Financial Support       0.99      0.99      0.99       404\n",
            "                 Program Implementation       0.99      0.98      0.98       436\n",
            "\n",
            "                               accuracy                           0.99      2114\n",
            "                              macro avg       0.99      0.99      0.99      2114\n",
            "                           weighted avg       0.99      0.99      0.99      2114\n",
            "\n",
            "Epoch 7/10, Validation Loss: 39.22424845583737, Validation Accuracy: 0.7296786389413988\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.71      0.66      0.68       113\n",
            "                Educational Opportunity       0.52      0.66      0.58       100\n",
            "                         Family Support       0.91      0.95      0.93       105\n",
            "                      Financial Support       0.71      0.77      0.74        97\n",
            "                 Program Implementation       0.86      0.61      0.72       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.74      0.73      0.73       529\n",
            "                           weighted avg       0.75      0.73      0.73       529\n",
            "\n",
            "Epoch 8/10, Batch Loss: 0.11035650223493576, Average Training Loss: 0.11035650223493576, Training Accuracy: 0.9375\n",
            "Epoch 8/10, Batch Loss: 0.027460459619760513, Average Training Loss: 0.06890848092734814, Training Accuracy: 0.96875\n",
            "Epoch 8/10, Batch Loss: 0.0095908734947443, Average Training Loss: 0.049135945116480194, Training Accuracy: 0.9791666666666666\n",
            "Epoch 8/10, Batch Loss: 0.012174008414149284, Average Training Loss: 0.039895460940897465, Training Accuracy: 0.984375\n",
            "Epoch 8/10, Batch Loss: 0.10256969183683395, Average Training Loss: 0.052430307120084764, Training Accuracy: 0.975\n",
            "Epoch 8/10, Batch Loss: 0.0078116185031831264, Average Training Loss: 0.04499385901726782, Training Accuracy: 0.9791666666666666\n",
            "Epoch 8/10, Batch Loss: 0.008460931479930878, Average Training Loss: 0.03977486936907683, Training Accuracy: 0.9821428571428571\n",
            "Epoch 8/10, Batch Loss: 0.052594248205423355, Average Training Loss: 0.041377291723620147, Training Accuracy: 0.984375\n",
            "Epoch 8/10, Batch Loss: 0.02131788805127144, Average Training Loss: 0.03914846909335918, Training Accuracy: 0.9861111111111112\n",
            "Epoch 8/10, Batch Loss: 0.0104011669754982, Average Training Loss: 0.03627373888157308, Training Accuracy: 0.9875\n",
            "Epoch 8/10, Batch Loss: 0.013662251643836498, Average Training Loss: 0.03421814913268794, Training Accuracy: 0.9886363636363636\n",
            "Epoch 8/10, Batch Loss: 0.021565357223153114, Average Training Loss: 0.03316374980689337, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.023777494207024574, Average Training Loss: 0.032441730145365, Training Accuracy: 0.9903846153846154\n",
            "Epoch 8/10, Batch Loss: 0.01083640567958355, Average Training Loss: 0.030898492683523467, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.028725745156407356, Average Training Loss: 0.030753642848382393, Training Accuracy: 0.9916666666666667\n",
            "Epoch 8/10, Batch Loss: 0.009594548493623734, Average Training Loss: 0.029431199451209977, Training Accuracy: 0.9921875\n",
            "Epoch 8/10, Batch Loss: 0.014818000607192516, Average Training Loss: 0.02857159951920895, Training Accuracy: 0.9926470588235294\n",
            "Epoch 8/10, Batch Loss: 0.0086026880890131, Average Training Loss: 0.027462215550864737, Training Accuracy: 0.9930555555555556\n",
            "Epoch 8/10, Batch Loss: 0.017366893589496613, Average Training Loss: 0.02693088281605589, Training Accuracy: 0.993421052631579\n",
            "Epoch 8/10, Batch Loss: 0.008522214367985725, Average Training Loss: 0.02601044939365238, Training Accuracy: 0.99375\n",
            "Epoch 8/10, Batch Loss: 0.00963109266012907, Average Training Loss: 0.025230480025389364, Training Accuracy: 0.9940476190476191\n",
            "Epoch 8/10, Batch Loss: 0.008587612770497799, Average Training Loss: 0.02447398605925793, Training Accuracy: 0.9943181818181818\n",
            "Epoch 8/10, Batch Loss: 0.010761048644781113, Average Training Loss: 0.023877771389063284, Training Accuracy: 0.9945652173913043\n",
            "Epoch 8/10, Batch Loss: 0.01646704412996769, Average Training Loss: 0.02356899108660097, Training Accuracy: 0.9947916666666666\n",
            "Epoch 8/10, Batch Loss: 0.005506579298526049, Average Training Loss: 0.022846494615077973, Training Accuracy: 0.995\n",
            "Epoch 8/10, Batch Loss: 0.05277257785201073, Average Training Loss: 0.023997497816498462, Training Accuracy: 0.9927884615384616\n",
            "Epoch 8/10, Batch Loss: 0.005735292099416256, Average Training Loss: 0.0233211198269769, Training Accuracy: 0.9930555555555556\n",
            "Epoch 8/10, Batch Loss: 0.021399231627583504, Average Training Loss: 0.02325248096271285, Training Accuracy: 0.9933035714285714\n",
            "Epoch 8/10, Batch Loss: 0.07058319449424744, Average Training Loss: 0.024884574532765765, Training Accuracy: 0.9913793103448276\n",
            "Epoch 8/10, Batch Loss: 0.007093883119523525, Average Training Loss: 0.024291551485657693, Training Accuracy: 0.9916666666666667\n",
            "Epoch 8/10, Batch Loss: 0.0068236906081438065, Average Training Loss: 0.02372807210251208, Training Accuracy: 0.9919354838709677\n",
            "Epoch 8/10, Batch Loss: 0.18886049091815948, Average Training Loss: 0.028888460190501064, Training Accuracy: 0.990234375\n",
            "Epoch 8/10, Batch Loss: 0.03419850021600723, Average Training Loss: 0.029049370494304283, Training Accuracy: 0.990530303030303\n",
            "Epoch 8/10, Batch Loss: 0.013381462544202805, Average Training Loss: 0.028588549672242475, Training Accuracy: 0.9908088235294118\n",
            "Epoch 8/10, Batch Loss: 0.011398672126233578, Average Training Loss: 0.028097410313785078, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.0066209109500050545, Average Training Loss: 0.02750084088701341, Training Accuracy: 0.9913194444444444\n",
            "Epoch 8/10, Batch Loss: 0.01208543125540018, Average Training Loss: 0.027084208194267104, Training Accuracy: 0.9915540540540541\n",
            "Epoch 8/10, Batch Loss: 0.009050213731825352, Average Training Loss: 0.0266096293926239, Training Accuracy: 0.9917763157894737\n",
            "Epoch 8/10, Batch Loss: 0.011702976189553738, Average Training Loss: 0.026227407515622102, Training Accuracy: 0.9919871794871795\n",
            "Epoch 8/10, Batch Loss: 0.011478371918201447, Average Training Loss: 0.025858681625686587, Training Accuracy: 0.9921875\n",
            "Epoch 8/10, Batch Loss: 0.007513083051890135, Average Training Loss: 0.025411228001935453, Training Accuracy: 0.9923780487804879\n",
            "Epoch 8/10, Batch Loss: 0.13340476155281067, Average Training Loss: 0.027982502610289624, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.011928921565413475, Average Training Loss: 0.027609163516222737, Training Accuracy: 0.9912790697674418\n",
            "Epoch 8/10, Batch Loss: 0.007118780165910721, Average Training Loss: 0.027143472985533827, Training Accuracy: 0.9914772727272727\n",
            "Epoch 8/10, Batch Loss: 0.00655084103345871, Average Training Loss: 0.026685858942154382, Training Accuracy: 0.9916666666666667\n",
            "Epoch 8/10, Batch Loss: 0.06745154410600662, Average Training Loss: 0.027572069489194648, Training Accuracy: 0.9904891304347826\n",
            "Epoch 8/10, Batch Loss: 0.006542322691529989, Average Training Loss: 0.02712462806796774, Training Accuracy: 0.9906914893617021\n",
            "Epoch 8/10, Batch Loss: 0.006484923418611288, Average Training Loss: 0.026694634221106146, Training Accuracy: 0.9908854166666666\n",
            "Epoch 8/10, Batch Loss: 0.00917034037411213, Average Training Loss: 0.026336995571167494, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.005808699876070023, Average Training Loss: 0.025926429657265545, Training Accuracy: 0.99125\n",
            "Epoch 8/10, Batch Loss: 0.020628945901989937, Average Training Loss: 0.025822557426769945, Training Accuracy: 0.991421568627451\n",
            "Epoch 8/10, Batch Loss: 0.011438891291618347, Average Training Loss: 0.025545948462632414, Training Accuracy: 0.9915865384615384\n",
            "Epoch 8/10, Batch Loss: 0.11738359183073044, Average Training Loss: 0.02727873418655879, Training Accuracy: 0.9905660377358491\n",
            "Epoch 8/10, Batch Loss: 0.005602057557553053, Average Training Loss: 0.02687731424898461, Training Accuracy: 0.9907407407407407\n",
            "Epoch 8/10, Batch Loss: 0.011212224140763283, Average Training Loss: 0.026592494428835132, Training Accuracy: 0.990909090909091\n",
            "Epoch 8/10, Batch Loss: 0.012428902089595795, Average Training Loss: 0.026339573137063, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.004602490458637476, Average Training Loss: 0.025958220809371324, Training Accuracy: 0.9912280701754386\n",
            "Epoch 8/10, Batch Loss: 0.014575126580893993, Average Training Loss: 0.02576196056405275, Training Accuracy: 0.9913793103448276\n",
            "Epoch 8/10, Batch Loss: 0.015675237402319908, Average Training Loss: 0.025590999154531856, Training Accuracy: 0.9915254237288136\n",
            "Epoch 8/10, Batch Loss: 0.0055802627466619015, Average Training Loss: 0.025257486881067357, Training Accuracy: 0.9916666666666667\n",
            "Epoch 8/10, Batch Loss: 0.009009749628603458, Average Training Loss: 0.024991130532666307, Training Accuracy: 0.9918032786885246\n",
            "Epoch 8/10, Batch Loss: 0.017868749797344208, Average Training Loss: 0.02487625342403208, Training Accuracy: 0.9919354838709677\n",
            "Epoch 8/10, Batch Loss: 0.01606724224984646, Average Training Loss: 0.02473642784983866, Training Accuracy: 0.9920634920634921\n",
            "Epoch 8/10, Batch Loss: 0.00687013752758503, Average Training Loss: 0.024457267063553445, Training Accuracy: 0.9921875\n",
            "Epoch 8/10, Batch Loss: 0.03878273814916611, Average Training Loss: 0.024677658926409024, Training Accuracy: 0.9923076923076923\n",
            "Epoch 8/10, Batch Loss: 0.005989218130707741, Average Training Loss: 0.02439450073253476, Training Accuracy: 0.9924242424242424\n",
            "Epoch 8/10, Batch Loss: 0.0055124182254076, Average Training Loss: 0.024112678605562717, Training Accuracy: 0.9925373134328358\n",
            "Epoch 8/10, Batch Loss: 0.008533711545169353, Average Training Loss: 0.023883576148792225, Training Accuracy: 0.9926470588235294\n",
            "Epoch 8/10, Batch Loss: 0.007929816842079163, Average Training Loss: 0.023652362245796383, Training Accuracy: 0.9927536231884058\n",
            "Epoch 8/10, Batch Loss: 0.009082782082259655, Average Training Loss: 0.023444225386317286, Training Accuracy: 0.9928571428571429\n",
            "Epoch 8/10, Batch Loss: 0.1479560285806656, Average Training Loss: 0.02519791275525177, Training Accuracy: 0.9920774647887324\n",
            "Epoch 8/10, Batch Loss: 0.07851286232471466, Average Training Loss: 0.025938398165938754, Training Accuracy: 0.9913194444444444\n",
            "Epoch 8/10, Batch Loss: 0.14874424040317535, Average Training Loss: 0.02762066997740775, Training Accuracy: 0.990582191780822\n",
            "Epoch 8/10, Batch Loss: 0.11485732346773148, Average Training Loss: 0.028799543673222936, Training Accuracy: 0.9898648648648649\n",
            "Epoch 8/10, Batch Loss: 0.0049423533491790295, Average Training Loss: 0.028481447802235684, Training Accuracy: 0.99\n",
            "Epoch 8/10, Batch Loss: 0.0204863753169775, Average Training Loss: 0.028376249480061233, Training Accuracy: 0.9901315789473685\n",
            "Epoch 8/10, Batch Loss: 0.046361569315195084, Average Training Loss: 0.028609825062335698, Training Accuracy: 0.9902597402597403\n",
            "Epoch 8/10, Batch Loss: 0.0906003788113594, Average Training Loss: 0.029404575751425747, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.016261640936136246, Average Training Loss: 0.02923820948794107, Training Accuracy: 0.9897151898734177\n",
            "Epoch 8/10, Batch Loss: 0.015570104122161865, Average Training Loss: 0.029067358170868828, Training Accuracy: 0.98984375\n",
            "Epoch 8/10, Batch Loss: 0.14465561509132385, Average Training Loss: 0.03049437368840531, Training Accuracy: 0.9891975308641975\n",
            "Epoch 8/10, Batch Loss: 0.0065970574505627155, Average Training Loss: 0.03020294300257796, Training Accuracy: 0.989329268292683\n",
            "Epoch 8/10, Batch Loss: 0.005679940804839134, Average Training Loss: 0.02990748514477388, Training Accuracy: 0.9894578313253012\n",
            "Epoch 8/10, Batch Loss: 0.010262534022331238, Average Training Loss: 0.029673616679030516, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.005804768297821283, Average Training Loss: 0.029392806698075112, Training Accuracy: 0.9897058823529412\n",
            "Epoch 8/10, Batch Loss: 0.005692722275853157, Average Training Loss: 0.02911722432107253, Training Accuracy: 0.9898255813953488\n",
            "Epoch 8/10, Batch Loss: 0.015149538405239582, Average Training Loss: 0.02895667620709744, Training Accuracy: 0.9899425287356322\n",
            "Epoch 8/10, Batch Loss: 0.01742047443985939, Average Training Loss: 0.028825583005197008, Training Accuracy: 0.9900568181818182\n",
            "Epoch 8/10, Batch Loss: 0.017048537731170654, Average Training Loss: 0.028693256653803453, Training Accuracy: 0.9901685393258427\n",
            "Epoch 8/10, Batch Loss: 0.3609079420566559, Average Training Loss: 0.03238453093605737, Training Accuracy: 0.9895833333333334\n",
            "Epoch 8/10, Batch Loss: 0.016540678218007088, Average Training Loss: 0.032210422664430444, Training Accuracy: 0.9896978021978022\n",
            "Epoch 8/10, Batch Loss: 0.00924185011535883, Average Training Loss: 0.03196076426715792, Training Accuracy: 0.9898097826086957\n",
            "Epoch 8/10, Batch Loss: 0.02016470953822136, Average Training Loss: 0.03183392496899732, Training Accuracy: 0.9899193548387096\n",
            "Epoch 8/10, Batch Loss: 0.007382152136415243, Average Training Loss: 0.03157379972609751, Training Accuracy: 0.9900265957446809\n",
            "Epoch 8/10, Batch Loss: 0.04043559357523918, Average Training Loss: 0.031667081766614785, Training Accuracy: 0.9901315789473685\n",
            "Epoch 8/10, Batch Loss: 0.017639057710766792, Average Training Loss: 0.03152095651603304, Training Accuracy: 0.990234375\n",
            "Epoch 8/10, Batch Loss: 0.01049167662858963, Average Training Loss: 0.03130415981616249, Training Accuracy: 0.9903350515463918\n",
            "Epoch 8/10, Batch Loss: 0.009318917989730835, Average Training Loss: 0.03107982061385196, Training Accuracy: 0.9904336734693877\n",
            "Epoch 8/10, Batch Loss: 0.014076960273087025, Average Training Loss: 0.03090807454980383, Training Accuracy: 0.990530303030303\n",
            "Epoch 8/10, Batch Loss: 0.012297065928578377, Average Training Loss: 0.030721964463591576, Training Accuracy: 0.990625\n",
            "Epoch 8/10, Batch Loss: 0.008261525072157383, Average Training Loss: 0.030499583875557575, Training Accuracy: 0.9907178217821783\n",
            "Epoch 8/10, Batch Loss: 0.004365390166640282, Average Training Loss: 0.030243366290176033, Training Accuracy: 0.9908088235294118\n",
            "Epoch 8/10, Batch Loss: 0.028364581987261772, Average Training Loss: 0.030225125665875895, Training Accuracy: 0.9908980582524272\n",
            "Epoch 8/10, Batch Loss: 0.004542618058621883, Average Training Loss: 0.029978178477344606, Training Accuracy: 0.9909855769230769\n",
            "Epoch 8/10, Batch Loss: 0.028141096234321594, Average Training Loss: 0.02996068245598248, Training Accuracy: 0.9910714285714286\n",
            "Epoch 8/10, Batch Loss: 0.01951085589826107, Average Training Loss: 0.029862099186570016, Training Accuracy: 0.9911556603773585\n",
            "Epoch 8/10, Batch Loss: 0.008810150437057018, Average Training Loss: 0.029665352001995125, Training Accuracy: 0.9912383177570093\n",
            "Epoch 8/10, Batch Loss: 0.006356528960168362, Average Training Loss: 0.029449529566422657, Training Accuracy: 0.9913194444444444\n",
            "Epoch 8/10, Batch Loss: 0.025557368993759155, Average Training Loss: 0.029413821671260606, Training Accuracy: 0.9913990825688074\n",
            "Epoch 8/10, Batch Loss: 0.005841876845806837, Average Training Loss: 0.029199531263756483, Training Accuracy: 0.9914772727272727\n",
            "Epoch 8/10, Batch Loss: 0.007251522969454527, Average Training Loss: 0.02900180145930331, Training Accuracy: 0.9915540540540541\n",
            "Epoch 8/10, Batch Loss: 0.02184307761490345, Average Training Loss: 0.028937884282121167, Training Accuracy: 0.9916294642857143\n",
            "Epoch 8/10, Batch Loss: 0.008712105453014374, Average Training Loss: 0.02875889508894323, Training Accuracy: 0.9917035398230089\n",
            "Epoch 8/10, Batch Loss: 0.06807028502225876, Average Training Loss: 0.029103731842744247, Training Accuracy: 0.9912280701754386\n",
            "Epoch 8/10, Batch Loss: 0.008288328535854816, Average Training Loss: 0.028922728335727815, Training Accuracy: 0.991304347826087\n",
            "Epoch 8/10, Batch Loss: 0.025922367349267006, Average Training Loss: 0.028896863154810052, Training Accuracy: 0.9913793103448276\n",
            "Epoch 8/10, Batch Loss: 0.0072088479064404964, Average Training Loss: 0.028711495503114585, Training Accuracy: 0.9914529914529915\n",
            "Epoch 8/10, Batch Loss: 0.010296636261045933, Average Training Loss: 0.02855543737394451, Training Accuracy: 0.9915254237288136\n",
            "Epoch 8/10, Batch Loss: 0.03039027936756611, Average Training Loss: 0.028570856214227044, Training Accuracy: 0.9915966386554622\n",
            "Epoch 8/10, Batch Loss: 0.24986794590950012, Average Training Loss: 0.030414998628354322, Training Accuracy: 0.9911458333333333\n",
            "Epoch 8/10, Batch Loss: 0.004799640271812677, Average Training Loss: 0.030203301451853976, Training Accuracy: 0.9912190082644629\n",
            "Epoch 8/10, Batch Loss: 0.045444659888744354, Average Training Loss: 0.03032823061936947, Training Accuracy: 0.9912909836065574\n",
            "Epoch 8/10, Batch Loss: 0.005558570381253958, Average Training Loss: 0.030126851267840076, Training Accuracy: 0.9913617886178862\n",
            "Epoch 8/10, Batch Loss: 0.016371024772524834, Average Training Loss: 0.030015917183200437, Training Accuracy: 0.9914314516129032\n",
            "Epoch 8/10, Batch Loss: 0.008447853848338127, Average Training Loss: 0.02984337267652154, Training Accuracy: 0.9915\n",
            "Epoch 8/10, Batch Loss: 0.019031064584851265, Average Training Loss: 0.02975756070754003, Training Accuracy: 0.9915674603174603\n",
            "Epoch 8/10, Batch Loss: 0.006403842940926552, Average Training Loss: 0.02957367316607063, Training Accuracy: 0.9916338582677166\n",
            "Epoch 8/10, Batch Loss: 0.01816343516111374, Average Training Loss: 0.029484530681656906, Training Accuracy: 0.99169921875\n",
            "Epoch 8/10, Batch Loss: 0.17569099366664886, Average Training Loss: 0.03061791411564909, Training Accuracy: 0.9912790697674418\n",
            "Epoch 8/10, Batch Loss: 0.010572309605777264, Average Training Loss: 0.03046371715788085, Training Accuracy: 0.9913461538461539\n",
            "Epoch 8/10, Batch Loss: 0.009303276427090168, Average Training Loss: 0.030302187075966415, Training Accuracy: 0.9914122137404581\n",
            "Epoch 8/10, Batch Loss: 0.007708188146352768, Average Training Loss: 0.030131020417408734, Training Accuracy: 0.9914772727272727\n",
            "Epoch 8/10, Batch Loss: 0.0027247145771980286, Average Training Loss: 0.030123136497068315, Training Accuracy: 0.9914853358561968\n",
            "Epoch 8/10, Average Training Loss: 0.02992495796748234, Training Accuracy: 0.9914853358561968\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      0.99      0.99       427\n",
            "                Educational Opportunity       0.98      0.99      0.99       451\n",
            "                         Family Support       1.00      0.99      1.00       396\n",
            "                      Financial Support       1.00      1.00      1.00       404\n",
            "                 Program Implementation       0.99      0.98      0.99       436\n",
            "\n",
            "                               accuracy                           0.99      2114\n",
            "                              macro avg       0.99      0.99      0.99      2114\n",
            "                           weighted avg       0.99      0.99      0.99      2114\n",
            "\n",
            "Epoch 8/10, Validation Loss: 40.29100004490465, Validation Accuracy: 0.7315689981096408\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.67      0.68       113\n",
            "                Educational Opportunity       0.53      0.63      0.57       100\n",
            "                         Family Support       0.91      0.95      0.93       105\n",
            "                      Financial Support       0.73      0.76      0.75        97\n",
            "                 Program Implementation       0.83      0.65      0.73       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.74      0.73      0.73       529\n",
            "                           weighted avg       0.74      0.73      0.73       529\n",
            "\n",
            "Epoch 9/10, Batch Loss: 0.008343765512108803, Average Training Loss: 0.008343765512108803, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.011739668436348438, Average Training Loss: 0.01004171697422862, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.011935095302760601, Average Training Loss: 0.01067284308373928, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.008311023004353046, Average Training Loss: 0.010082388063892722, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.00999443419277668, Average Training Loss: 0.010064797289669514, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.008663422428071499, Average Training Loss: 0.009831234812736511, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.010546703822910786, Average Training Loss: 0.009933444671332836, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.005331252235919237, Average Training Loss: 0.009358170616906136, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.008267506957054138, Average Training Loss: 0.00923698576581147, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.007289000321179628, Average Training Loss: 0.009042187221348285, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.006910333875566721, Average Training Loss: 0.00884838237173178, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.007474824320524931, Average Training Loss: 0.008733919200797876, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.008920853026211262, Average Training Loss: 0.008748298725829674, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.029738225042819977, Average Training Loss: 0.010247579177043267, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.01139057893306017, Average Training Loss: 0.010323779160777728, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.010290402919054031, Average Training Loss: 0.010321693145669997, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.009107601828873158, Average Training Loss: 0.01025027600938783, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.013762264512479305, Average Training Loss: 0.010445386481781801, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.005972538609057665, Average Training Loss: 0.010209973435848951, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.008759471587836742, Average Training Loss: 0.010137448343448341, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.012132427655160427, Average Training Loss: 0.010232447358291773, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.005411998368799686, Average Training Loss: 0.010013336040587588, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.019977284595370293, Average Training Loss: 0.010446551195143358, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.01062813587486744, Average Training Loss: 0.010454117223465195, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.004166655708104372, Average Training Loss: 0.010202618762850762, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.005605210550129414, Average Training Loss: 0.010025795370053787, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.006198067683726549, Average Training Loss: 0.009884027677967592, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.01064162515103817, Average Training Loss: 0.009911084730577256, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.006021395791321993, Average Training Loss: 0.00977695752577535, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.006371838506311178, Average Training Loss: 0.009663453558459878, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.03557119891047478, Average Training Loss: 0.010499187279492617, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.004671560134738684, Average Training Loss: 0.010317073931219056, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.006486239843070507, Average Training Loss: 0.01020098804976001, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.009221037849783897, Average Training Loss: 0.01017216598505483, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.009265496395528316, Average Training Loss: 0.010146261139639786, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.011197500862181187, Average Training Loss: 0.010175462243043713, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.007752619683742523, Average Training Loss: 0.01010998001171125, Training Accuracy: 1.0\n",
            "Epoch 9/10, Batch Loss: 0.07467466592788696, Average Training Loss: 0.011809050693715873, Training Accuracy: 0.9983552631578947\n",
            "Epoch 9/10, Batch Loss: 0.01840931363403797, Average Training Loss: 0.011978288205006184, Training Accuracy: 0.9983974358974359\n",
            "Epoch 9/10, Batch Loss: 0.005538810510188341, Average Training Loss: 0.011817301262635738, Training Accuracy: 0.9984375\n",
            "Epoch 9/10, Batch Loss: 0.005453369580209255, Average Training Loss: 0.011662083416722896, Training Accuracy: 0.9984756097560976\n",
            "Epoch 9/10, Batch Loss: 0.008205416612327099, Average Training Loss: 0.011579781826142044, Training Accuracy: 0.9985119047619048\n",
            "Epoch 9/10, Batch Loss: 0.010307368822395802, Average Training Loss: 0.011550190826054922, Training Accuracy: 0.998546511627907\n",
            "Epoch 9/10, Batch Loss: 0.005669360980391502, Average Training Loss: 0.011416535602289845, Training Accuracy: 0.9985795454545454\n",
            "Epoch 9/10, Batch Loss: 0.048589400947093964, Average Training Loss: 0.012242599276618825, Training Accuracy: 0.9986111111111111\n",
            "Epoch 9/10, Batch Loss: 0.02758166193962097, Average Training Loss: 0.012576057160597133, Training Accuracy: 0.998641304347826\n",
            "Epoch 9/10, Batch Loss: 0.01109579112380743, Average Training Loss: 0.012544562138537777, Training Accuracy: 0.9986702127659575\n",
            "Epoch 9/10, Batch Loss: 0.004736786708235741, Average Training Loss: 0.012381900150406485, Training Accuracy: 0.9986979166666666\n",
            "Epoch 9/10, Batch Loss: 0.004336698912084103, Average Training Loss: 0.012217712370032559, Training Accuracy: 0.9987244897959183\n",
            "Epoch 9/10, Batch Loss: 0.012422077357769012, Average Training Loss: 0.012221799669787288, Training Accuracy: 0.99875\n",
            "Epoch 9/10, Batch Loss: 0.13829569518566132, Average Training Loss: 0.01469383683676521, Training Accuracy: 0.9975490196078431\n",
            "Epoch 9/10, Batch Loss: 0.015180652029812336, Average Training Loss: 0.01470319866740073, Training Accuracy: 0.9975961538461539\n",
            "Epoch 9/10, Batch Loss: 0.007482823450118303, Average Training Loss: 0.014566965172735025, Training Accuracy: 0.9976415094339622\n",
            "Epoch 9/10, Batch Loss: 0.008292602375149727, Average Training Loss: 0.014450773269076038, Training Accuracy: 0.9976851851851852\n",
            "Epoch 9/10, Batch Loss: 0.0067718434147536755, Average Training Loss: 0.014311156362633814, Training Accuracy: 0.9977272727272727\n",
            "Epoch 9/10, Batch Loss: 0.028285173699259758, Average Training Loss: 0.014560692386502134, Training Accuracy: 0.9977678571428571\n",
            "Epoch 9/10, Batch Loss: 0.06556728482246399, Average Training Loss: 0.015455544885378657, Training Accuracy: 0.9978070175438597\n",
            "Epoch 9/10, Batch Loss: 0.018472891300916672, Average Training Loss: 0.015507568099439657, Training Accuracy: 0.9978448275862069\n",
            "Epoch 9/10, Batch Loss: 0.009337971918284893, Average Training Loss: 0.015402998672640425, Training Accuracy: 0.9978813559322034\n",
            "Epoch 9/10, Batch Loss: 0.010823391377925873, Average Training Loss: 0.015326671884395182, Training Accuracy: 0.9979166666666667\n",
            "Epoch 9/10, Batch Loss: 0.009882659651339054, Average Training Loss: 0.015237425782213935, Training Accuracy: 0.9979508196721312\n",
            "Epoch 9/10, Batch Loss: 0.005034800618886948, Average Training Loss: 0.015072867311837693, Training Accuracy: 0.9979838709677419\n",
            "Epoch 9/10, Batch Loss: 0.009243238717317581, Average Training Loss: 0.014980333524623088, Training Accuracy: 0.998015873015873\n",
            "Epoch 9/10, Batch Loss: 0.011594799347221851, Average Training Loss: 0.014927434553101193, Training Accuracy: 0.998046875\n",
            "Epoch 9/10, Batch Loss: 0.005594287998974323, Average Training Loss: 0.014783847683037702, Training Accuracy: 0.9980769230769231\n",
            "Epoch 9/10, Batch Loss: 0.004974864888936281, Average Training Loss: 0.014635226731611923, Training Accuracy: 0.9981060606060606\n",
            "Epoch 9/10, Batch Loss: 0.009473934769630432, Average Training Loss: 0.01455819252322414, Training Accuracy: 0.9981343283582089\n",
            "Epoch 9/10, Batch Loss: 0.009658833965659142, Average Training Loss: 0.014486143132671714, Training Accuracy: 0.9981617647058824\n",
            "Epoch 9/10, Batch Loss: 0.005638992413878441, Average Training Loss: 0.01435792355703703, Training Accuracy: 0.9981884057971014\n",
            "Epoch 9/10, Batch Loss: 0.007203903514891863, Average Training Loss: 0.01425572327072067, Training Accuracy: 0.9982142857142857\n",
            "Epoch 9/10, Batch Loss: 0.008480768650770187, Average Training Loss: 0.014174385881707283, Training Accuracy: 0.9982394366197183\n",
            "Epoch 9/10, Batch Loss: 0.008080866187810898, Average Training Loss: 0.0140897536637365, Training Accuracy: 0.9982638888888888\n",
            "Epoch 9/10, Batch Loss: 0.021236581727862358, Average Training Loss: 0.014187655418039593, Training Accuracy: 0.9982876712328768\n",
            "Epoch 9/10, Batch Loss: 0.0053359223529696465, Average Training Loss: 0.014068037403646755, Training Accuracy: 0.9983108108108109\n",
            "Epoch 9/10, Batch Loss: 0.0094915721565485, Average Training Loss: 0.01400701786701878, Training Accuracy: 0.9983333333333333\n",
            "Epoch 9/10, Batch Loss: 0.013293265365064144, Average Training Loss: 0.013997626386729902, Training Accuracy: 0.9983552631578947\n",
            "Epoch 9/10, Batch Loss: 0.007657282520085573, Average Training Loss: 0.013915284258591664, Training Accuracy: 0.9983766233766234\n",
            "Epoch 9/10, Batch Loss: 0.004793633706867695, Average Training Loss: 0.01379834002074905, Training Accuracy: 0.9983974358974359\n",
            "Epoch 9/10, Batch Loss: 0.01158098503947258, Average Training Loss: 0.01377027223617593, Training Accuracy: 0.9984177215189873\n",
            "Epoch 9/10, Batch Loss: 0.004684149753302336, Average Training Loss: 0.013656695705140009, Training Accuracy: 0.9984375\n",
            "Epoch 9/10, Batch Loss: 0.006272504106163979, Average Training Loss: 0.013565532845893392, Training Accuracy: 0.9984567901234568\n",
            "Epoch 9/10, Batch Loss: 0.009156164713203907, Average Training Loss: 0.013511760063787423, Training Accuracy: 0.9984756097560976\n",
            "Epoch 9/10, Batch Loss: 0.005684128496795893, Average Training Loss: 0.013417451249727284, Training Accuracy: 0.9984939759036144\n",
            "Epoch 9/10, Batch Loss: 0.08863621205091476, Average Training Loss: 0.014312912687836658, Training Accuracy: 0.9977678571428571\n",
            "Epoch 9/10, Batch Loss: 0.007829675450921059, Average Training Loss: 0.014236639308578828, Training Accuracy: 0.9977941176470588\n",
            "Epoch 9/10, Batch Loss: 0.006368601694703102, Average Training Loss: 0.014145150499115156, Training Accuracy: 0.9978197674418605\n",
            "Epoch 9/10, Batch Loss: 0.0085225198417902, Average Training Loss: 0.014080522560525215, Training Accuracy: 0.9978448275862069\n",
            "Epoch 9/10, Batch Loss: 0.007630054838955402, Average Training Loss: 0.014007221790961921, Training Accuracy: 0.9978693181818182\n",
            "Epoch 9/10, Batch Loss: 0.06468305736780167, Average Training Loss: 0.01457661320193765, Training Accuracy: 0.9971910112359551\n",
            "Epoch 9/10, Batch Loss: 0.006610268726944923, Average Training Loss: 0.014488098263326619, Training Accuracy: 0.9972222222222222\n",
            "Epoch 9/10, Batch Loss: 0.005625641904771328, Average Training Loss: 0.014390708633012825, Training Accuracy: 0.9972527472527473\n",
            "Epoch 9/10, Batch Loss: 0.006757611408829689, Average Training Loss: 0.014307740184923878, Training Accuracy: 0.9972826086956522\n",
            "Epoch 9/10, Batch Loss: 0.006823062896728516, Average Training Loss: 0.01422725978397554, Training Accuracy: 0.9973118279569892\n",
            "Epoch 9/10, Batch Loss: 0.006572069134563208, Average Training Loss: 0.014145821585577536, Training Accuracy: 0.9973404255319149\n",
            "Epoch 9/10, Batch Loss: 0.0037247634027153254, Average Training Loss: 0.01403612623628425, Training Accuracy: 0.9973684210526316\n",
            "Epoch 9/10, Batch Loss: 0.0050826105289161205, Average Training Loss: 0.013942860447665831, Training Accuracy: 0.9973958333333334\n",
            "Epoch 9/10, Batch Loss: 0.003745186608284712, Average Training Loss: 0.013837729789527882, Training Accuracy: 0.9974226804123711\n",
            "Epoch 9/10, Batch Loss: 0.005317015573382378, Average Training Loss: 0.013750783726097825, Training Accuracy: 0.9974489795918368\n",
            "Epoch 9/10, Batch Loss: 0.004619212355464697, Average Training Loss: 0.013658545631444965, Training Accuracy: 0.9974747474747475\n",
            "Epoch 9/10, Batch Loss: 0.00693872757256031, Average Training Loss: 0.01359134745085612, Training Accuracy: 0.9975\n",
            "Epoch 9/10, Batch Loss: 0.06779180467128754, Average Training Loss: 0.01412798564115742, Training Accuracy: 0.9969059405940595\n",
            "Epoch 9/10, Batch Loss: 0.004643769469112158, Average Training Loss: 0.014035003129666782, Training Accuracy: 0.9969362745098039\n",
            "Epoch 9/10, Batch Loss: 0.007209757808595896, Average Training Loss: 0.01396873861198648, Training Accuracy: 0.9969660194174758\n",
            "Epoch 9/10, Batch Loss: 0.005641118157655001, Average Training Loss: 0.01388866533838714, Training Accuracy: 0.9969951923076923\n",
            "Epoch 9/10, Batch Loss: 0.009716394357383251, Average Training Loss: 0.013848929424282341, Training Accuracy: 0.9970238095238095\n",
            "Epoch 9/10, Batch Loss: 0.004230420105159283, Average Training Loss: 0.013758188770328349, Training Accuracy: 0.9970518867924528\n",
            "Epoch 9/10, Batch Loss: 0.01960720680654049, Average Training Loss: 0.013812852490292949, Training Accuracy: 0.9970794392523364\n",
            "Epoch 9/10, Batch Loss: 0.013744551688432693, Average Training Loss: 0.01381222007546091, Training Accuracy: 0.9971064814814815\n",
            "Epoch 9/10, Batch Loss: 0.005144966766238213, Average Training Loss: 0.013732703990055196, Training Accuracy: 0.9971330275229358\n",
            "Epoch 9/10, Batch Loss: 0.005004991311579943, Average Training Loss: 0.013653361147523604, Training Accuracy: 0.9971590909090909\n",
            "Epoch 9/10, Batch Loss: 0.010022133588790894, Average Training Loss: 0.01362064738573322, Training Accuracy: 0.9971846846846847\n",
            "Epoch 9/10, Batch Loss: 0.007152589038014412, Average Training Loss: 0.013562896864771443, Training Accuracy: 0.9972098214285714\n",
            "Epoch 9/10, Batch Loss: 0.06607760488986969, Average Training Loss: 0.014027628794197092, Training Accuracy: 0.9966814159292036\n",
            "Epoch 9/10, Batch Loss: 0.005306863691657782, Average Training Loss: 0.013951130854701134, Training Accuracy: 0.9967105263157895\n",
            "Epoch 9/10, Batch Loss: 0.005309833213686943, Average Training Loss: 0.013875989136083618, Training Accuracy: 0.9967391304347826\n",
            "Epoch 9/10, Batch Loss: 0.0070266397669911385, Average Training Loss: 0.013816943020832822, Training Accuracy: 0.9967672413793104\n",
            "Epoch 9/10, Batch Loss: 0.01682211644947529, Average Training Loss: 0.01384262826381267, Training Accuracy: 0.9967948717948718\n",
            "Epoch 9/10, Batch Loss: 0.012384584173560143, Average Training Loss: 0.013830271957963073, Training Accuracy: 0.996822033898305\n",
            "Epoch 9/10, Batch Loss: 0.004967711865901947, Average Training Loss: 0.013755796663071803, Training Accuracy: 0.9968487394957983\n",
            "Epoch 9/10, Batch Loss: 0.005794032942503691, Average Training Loss: 0.013689448632067069, Training Accuracy: 0.996875\n",
            "Epoch 9/10, Batch Loss: 0.20821398496627808, Average Training Loss: 0.015297089428217574, Training Accuracy: 0.9963842975206612\n",
            "Epoch 9/10, Batch Loss: 0.03008360043168068, Average Training Loss: 0.015418290338082025, Training Accuracy: 0.9964139344262295\n",
            "Epoch 9/10, Batch Loss: 0.0045868284069001675, Average Training Loss: 0.015330229671974855, Training Accuracy: 0.9964430894308943\n",
            "Epoch 9/10, Batch Loss: 0.005788099952042103, Average Training Loss: 0.01525327701294314, Training Accuracy: 0.9964717741935484\n",
            "Epoch 9/10, Batch Loss: 0.004456560593098402, Average Training Loss: 0.015166903281584381, Training Accuracy: 0.9965\n",
            "Epoch 9/10, Batch Loss: 0.17219209671020508, Average Training Loss: 0.016413134975462325, Training Accuracy: 0.996031746031746\n",
            "Epoch 9/10, Batch Loss: 0.3156452476978302, Average Training Loss: 0.018769293343354986, Training Accuracy: 0.9955708661417323\n",
            "Epoch 9/10, Batch Loss: 0.006958306767046452, Average Training Loss: 0.018677020010727574, Training Accuracy: 0.99560546875\n",
            "Epoch 9/10, Batch Loss: 0.004723057150840759, Average Training Loss: 0.018568849755999768, Training Accuracy: 0.9956395348837209\n",
            "Epoch 9/10, Batch Loss: 0.005032776389271021, Average Training Loss: 0.01846472611471724, Training Accuracy: 0.9956730769230769\n",
            "Epoch 9/10, Batch Loss: 0.015996210277080536, Average Training Loss: 0.018445882482368867, Training Accuracy: 0.995706106870229\n",
            "Epoch 9/10, Batch Loss: 0.006099647842347622, Average Training Loss: 0.018352350401762647, Training Accuracy: 0.9957386363636364\n",
            "Epoch 9/10, Batch Loss: 0.003252987749874592, Average Training Loss: 0.018359608255686236, Training Accuracy: 0.9957426679280984\n",
            "Epoch 9/10, Average Training Loss: 0.018238821359267247, Training Accuracy: 0.9957426679280984\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.99      0.99      0.99       451\n",
            "                         Family Support       1.00      1.00      1.00       396\n",
            "                      Financial Support       1.00      1.00      1.00       404\n",
            "                 Program Implementation       1.00      0.99      1.00       436\n",
            "\n",
            "                               accuracy                           1.00      2114\n",
            "                              macro avg       1.00      1.00      1.00      2114\n",
            "                           weighted avg       1.00      1.00      1.00      2114\n",
            "\n",
            "Epoch 9/10, Validation Loss: 42.687455356586725, Validation Accuracy: 0.7277882797731569\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.65      0.67       113\n",
            "                Educational Opportunity       0.52      0.67      0.58       100\n",
            "                         Family Support       0.91      0.95      0.93       105\n",
            "                      Financial Support       0.72      0.76      0.74        97\n",
            "                 Program Implementation       0.87      0.62      0.72       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.74      0.73      0.73       529\n",
            "                           weighted avg       0.75      0.73      0.73       529\n",
            "\n",
            "Epoch 10/10, Batch Loss: 0.010892676189541817, Average Training Loss: 0.010892676189541817, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.007998847402632236, Average Training Loss: 0.009445761796087027, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.006768343038856983, Average Training Loss: 0.008553288877010345, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.006969692651182413, Average Training Loss: 0.008157389820553362, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.005171590484678745, Average Training Loss: 0.007560229953378439, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.005917116068303585, Average Training Loss: 0.007286377639199297, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.008126124739646912, Average Training Loss: 0.007406341510691813, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.004450736567378044, Average Training Loss: 0.007036890892777592, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.0046718125231564045, Average Training Loss: 0.0067741044072641265, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.006613305304199457, Average Training Loss: 0.0067580244969576595, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.00366515526548028, Average Training Loss: 0.006476854566823353, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.00507387425750494, Average Training Loss: 0.006359939541046818, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.0065569146536290646, Average Training Loss: 0.006375091472783914, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.004386143758893013, Average Training Loss: 0.006233023778934564, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.010514145717024803, Average Training Loss: 0.00651843190814058, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.015150832012295723, Average Training Loss: 0.007057956914650276, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.008635107427835464, Average Training Loss: 0.007150730474249405, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.016011470928788185, Average Training Loss: 0.007642993832834893, Training Accuracy: 1.0\n",
            "Epoch 10/10, Batch Loss: 0.09141870588064194, Average Training Loss: 0.012052241835351052, Training Accuracy: 0.9967105263157895\n",
            "Epoch 10/10, Batch Loss: 0.018413832411170006, Average Training Loss: 0.012370321364142001, Training Accuracy: 0.996875\n",
            "Epoch 10/10, Batch Loss: 0.0056891185231506824, Average Training Loss: 0.012052168847904318, Training Accuracy: 0.9970238095238095\n",
            "Epoch 10/10, Batch Loss: 0.004228195175528526, Average Training Loss: 0.011696533680978146, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.005559240467846394, Average Training Loss: 0.011429694845624592, Training Accuracy: 0.9972826086956522\n",
            "Epoch 10/10, Batch Loss: 0.010676141828298569, Average Training Loss: 0.011398296803236008, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.006880331318825483, Average Training Loss: 0.011217578183859586, Training Accuracy: 0.9975\n",
            "Epoch 10/10, Batch Loss: 0.005292906425893307, Average Training Loss: 0.010989706193168577, Training Accuracy: 0.9975961538461539\n",
            "Epoch 10/10, Batch Loss: 0.0100712263956666, Average Training Loss: 0.010955688422890726, Training Accuracy: 0.9976851851851852\n",
            "Epoch 10/10, Batch Loss: 0.011971437372267246, Average Training Loss: 0.010991965171082743, Training Accuracy: 0.9977678571428571\n",
            "Epoch 10/10, Batch Loss: 0.007935771718621254, Average Training Loss: 0.010886579189963382, Training Accuracy: 0.9978448275862069\n",
            "Epoch 10/10, Batch Loss: 0.0054626548662781715, Average Training Loss: 0.010705781712507209, Training Accuracy: 0.9979166666666667\n",
            "Epoch 10/10, Batch Loss: 0.005688593722879887, Average Training Loss: 0.010543936938648262, Training Accuracy: 0.9979838709677419\n",
            "Epoch 10/10, Batch Loss: 0.00742183905094862, Average Training Loss: 0.010446371379657649, Training Accuracy: 0.998046875\n",
            "Epoch 10/10, Batch Loss: 0.005121482536196709, Average Training Loss: 0.010285011111673984, Training Accuracy: 0.9981060606060606\n",
            "Epoch 10/10, Batch Loss: 0.006609031930565834, Average Training Loss: 0.010176894076935509, Training Accuracy: 0.9981617647058824\n",
            "Epoch 10/10, Batch Loss: 0.004433462396264076, Average Training Loss: 0.010012796028916325, Training Accuracy: 0.9982142857142857\n",
            "Epoch 10/10, Batch Loss: 0.07358435541391373, Average Training Loss: 0.011778672678499587, Training Accuracy: 0.9965277777777778\n",
            "Epoch 10/10, Batch Loss: 0.006177852395921946, Average Training Loss: 0.01162729915734884, Training Accuracy: 0.9966216216216216\n",
            "Epoch 10/10, Batch Loss: 0.007402012124657631, Average Training Loss: 0.011516107393330649, Training Accuracy: 0.9967105263157895\n",
            "Epoch 10/10, Batch Loss: 0.004987718071788549, Average Training Loss: 0.01134871279534239, Training Accuracy: 0.9967948717948718\n",
            "Epoch 10/10, Batch Loss: 0.00555372191593051, Average Training Loss: 0.011203838023357093, Training Accuracy: 0.996875\n",
            "Epoch 10/10, Batch Loss: 0.004668279085308313, Average Training Loss: 0.011044434146819318, Training Accuracy: 0.9969512195121951\n",
            "Epoch 10/10, Batch Loss: 0.0050682625733315945, Average Training Loss: 0.010902144347450562, Training Accuracy: 0.9970238095238095\n",
            "Epoch 10/10, Batch Loss: 0.06489850580692291, Average Training Loss: 0.012157873683717362, Training Accuracy: 0.997093023255814\n",
            "Epoch 10/10, Batch Loss: 0.006728816777467728, Average Training Loss: 0.012034486026757142, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.004114687442779541, Average Training Loss: 0.011858490502668751, Training Accuracy: 0.9972222222222222\n",
            "Epoch 10/10, Batch Loss: 0.003767900401726365, Average Training Loss: 0.011682608109170003, Training Accuracy: 0.9972826086956522\n",
            "Epoch 10/10, Batch Loss: 0.004796793684363365, Average Training Loss: 0.011536101419280501, Training Accuracy: 0.9973404255319149\n",
            "Epoch 10/10, Batch Loss: 0.004309314768761396, Average Training Loss: 0.011385543364061354, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.005553548224270344, Average Training Loss: 0.011266523055086027, Training Accuracy: 0.9974489795918368\n",
            "Epoch 10/10, Batch Loss: 0.010322614572942257, Average Training Loss: 0.01124764488544315, Training Accuracy: 0.9975\n",
            "Epoch 10/10, Batch Loss: 0.00717633543536067, Average Training Loss: 0.01116781528838271, Training Accuracy: 0.9975490196078431\n",
            "Epoch 10/10, Batch Loss: 0.005418139509856701, Average Training Loss: 0.011057244600334134, Training Accuracy: 0.9975961538461539\n",
            "Epoch 10/10, Batch Loss: 0.006360348779708147, Average Training Loss: 0.010968623924473266, Training Accuracy: 0.9976415094339622\n",
            "Epoch 10/10, Batch Loss: 0.007904880680143833, Average Training Loss: 0.010911887938467165, Training Accuracy: 0.9976851851851852\n",
            "Epoch 10/10, Batch Loss: 0.008573858998715878, Average Training Loss: 0.010869378321380779, Training Accuracy: 0.9977272727272727\n",
            "Epoch 10/10, Batch Loss: 0.0132987629622221, Average Training Loss: 0.01091276018996723, Training Accuracy: 0.9977678571428571\n",
            "Epoch 10/10, Batch Loss: 0.06360574066638947, Average Training Loss: 0.01183719844393955, Training Accuracy: 0.9967105263157895\n",
            "Epoch 10/10, Batch Loss: 0.005694192368537188, Average Training Loss: 0.011731284546087784, Training Accuracy: 0.9967672413793104\n",
            "Epoch 10/10, Batch Loss: 0.006040961481630802, Average Training Loss: 0.01163483839245292, Training Accuracy: 0.996822033898305\n",
            "Epoch 10/10, Batch Loss: 0.013357153162360191, Average Training Loss: 0.011663543638618042, Training Accuracy: 0.996875\n",
            "Epoch 10/10, Batch Loss: 0.007581664714962244, Average Training Loss: 0.011596627590689258, Training Accuracy: 0.9969262295081968\n",
            "Epoch 10/10, Batch Loss: 0.0075681558810174465, Average Training Loss: 0.011531652240533262, Training Accuracy: 0.9969758064516129\n",
            "Epoch 10/10, Batch Loss: 0.005857172887772322, Average Training Loss: 0.011441581139695785, Training Accuracy: 0.9970238095238095\n",
            "Epoch 10/10, Batch Loss: 0.008530893363058567, Average Training Loss: 0.01139610164318583, Training Accuracy: 0.9970703125\n",
            "Epoch 10/10, Batch Loss: 0.008072936907410622, Average Training Loss: 0.01134497603186621, Training Accuracy: 0.9971153846153846\n",
            "Epoch 10/10, Batch Loss: 0.00962675642222166, Average Training Loss: 0.011318942401417051, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.004122218117117882, Average Training Loss: 0.011211528606129005, Training Accuracy: 0.9972014925373134\n",
            "Epoch 10/10, Batch Loss: 0.02356215938925743, Average Training Loss: 0.011393155529410304, Training Accuracy: 0.9972426470588235\n",
            "Epoch 10/10, Batch Loss: 0.006430608686059713, Average Training Loss: 0.011321234560666093, Training Accuracy: 0.9972826086956522\n",
            "Epoch 10/10, Batch Loss: 0.004421699326485395, Average Training Loss: 0.011222669771606368, Training Accuracy: 0.9973214285714286\n",
            "Epoch 10/10, Batch Loss: 0.003982439637184143, Average Training Loss: 0.011120694699290563, Training Accuracy: 0.9973591549295775\n",
            "Epoch 10/10, Batch Loss: 0.003995264880359173, Average Training Loss: 0.01102173039624985, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.005693579092621803, Average Training Loss: 0.010948742022227547, Training Accuracy: 0.997431506849315\n",
            "Epoch 10/10, Batch Loss: 0.010314621962606907, Average Training Loss: 0.010940172832232673, Training Accuracy: 0.9974662162162162\n",
            "Epoch 10/10, Batch Loss: 0.006255357526242733, Average Training Loss: 0.010877708628152807, Training Accuracy: 0.9975\n",
            "Epoch 10/10, Batch Loss: 0.006872829515486956, Average Training Loss: 0.010825012850354573, Training Accuracy: 0.9975328947368421\n",
            "Epoch 10/10, Batch Loss: 0.044395796954631805, Average Training Loss: 0.01126099705950103, Training Accuracy: 0.997564935064935\n",
            "Epoch 10/10, Batch Loss: 0.004224319476634264, Average Training Loss: 0.011170783244336072, Training Accuracy: 0.9975961538461539\n",
            "Epoch 10/10, Batch Loss: 0.006456612143665552, Average Training Loss: 0.01111111019242885, Training Accuracy: 0.997626582278481\n",
            "Epoch 10/10, Batch Loss: 0.005432593170553446, Average Training Loss: 0.011040128729655407, Training Accuracy: 0.99765625\n",
            "Epoch 10/10, Batch Loss: 0.0056393020786345005, Average Training Loss: 0.010973451857420581, Training Accuracy: 0.9976851851851852\n",
            "Epoch 10/10, Batch Loss: 0.003591802204027772, Average Training Loss: 0.010883431739696279, Training Accuracy: 0.9977134146341463\n",
            "Epoch 10/10, Batch Loss: 0.006210797931998968, Average Training Loss: 0.010827134946832457, Training Accuracy: 0.9977409638554217\n",
            "Epoch 10/10, Batch Loss: 0.003984556067734957, Average Training Loss: 0.010745675674462248, Training Accuracy: 0.9977678571428571\n",
            "Epoch 10/10, Batch Loss: 0.005293790716677904, Average Training Loss: 0.01068153585142949, Training Accuracy: 0.9977941176470588\n",
            "Epoch 10/10, Batch Loss: 0.008195103146135807, Average Training Loss: 0.010652623843228402, Training Accuracy: 0.9978197674418605\n",
            "Epoch 10/10, Batch Loss: 0.08170284330844879, Average Training Loss: 0.011469293032483808, Training Accuracy: 0.9971264367816092\n",
            "Epoch 10/10, Batch Loss: 0.0063177659176290035, Average Training Loss: 0.011410752951633185, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.010932404547929764, Average Training Loss: 0.011405378250467979, Training Accuracy: 0.9971910112359551\n",
            "Epoch 10/10, Batch Loss: 0.011386475525796413, Average Training Loss: 0.01140516822019385, Training Accuracy: 0.9972222222222222\n",
            "Epoch 10/10, Batch Loss: 0.0167333222925663, Average Training Loss: 0.011463719363846294, Training Accuracy: 0.9972527472527473\n",
            "Epoch 10/10, Batch Loss: 0.0045367456041276455, Average Training Loss: 0.011388426170805875, Training Accuracy: 0.9972826086956522\n",
            "Epoch 10/10, Batch Loss: 0.006090593058615923, Average Training Loss: 0.011331460223362972, Training Accuracy: 0.9973118279569892\n",
            "Epoch 10/10, Batch Loss: 0.0047820983454585075, Average Training Loss: 0.011261786160832073, Training Accuracy: 0.9973404255319149\n",
            "Epoch 10/10, Batch Loss: 0.047812774777412415, Average Training Loss: 0.011646533409427656, Training Accuracy: 0.9973684210526316\n",
            "Epoch 10/10, Batch Loss: 0.0049751815386116505, Average Training Loss: 0.011577040160773322, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.00404444569721818, Average Training Loss: 0.011499384547746981, Training Accuracy: 0.9974226804123711\n",
            "Epoch 10/10, Batch Loss: 0.00708451634272933, Average Training Loss: 0.011454334872185576, Training Accuracy: 0.9974489795918368\n",
            "Epoch 10/10, Batch Loss: 0.005895634647458792, Average Training Loss: 0.011398186385067123, Training Accuracy: 0.9974747474747475\n",
            "Epoch 10/10, Batch Loss: 0.009886367246508598, Average Training Loss: 0.011383068193681537, Training Accuracy: 0.9975\n",
            "Epoch 10/10, Batch Loss: 0.08942186832427979, Average Training Loss: 0.012155729581113203, Training Accuracy: 0.9969059405940595\n",
            "Epoch 10/10, Batch Loss: 0.005725712049752474, Average Training Loss: 0.012092690193550843, Training Accuracy: 0.9969362745098039\n",
            "Epoch 10/10, Batch Loss: 0.004331821575760841, Average Training Loss: 0.012017341954543174, Training Accuracy: 0.9969660194174758\n",
            "Epoch 10/10, Batch Loss: 0.006439741235226393, Average Training Loss: 0.011963711178395897, Training Accuracy: 0.9969951923076923\n",
            "Epoch 10/10, Batch Loss: 0.015932660549879074, Average Training Loss: 0.012001510696219547, Training Accuracy: 0.9970238095238095\n",
            "Epoch 10/10, Batch Loss: 0.004946079570800066, Average Training Loss: 0.011934950025225023, Training Accuracy: 0.9970518867924528\n",
            "Epoch 10/10, Batch Loss: 0.008066143840551376, Average Training Loss: 0.01189879295807854, Training Accuracy: 0.9970794392523364\n",
            "Epoch 10/10, Batch Loss: 0.006784697994589806, Average Training Loss: 0.011851440226935126, Training Accuracy: 0.9971064814814815\n",
            "Epoch 10/10, Batch Loss: 0.01083117164671421, Average Training Loss: 0.011842079964731264, Training Accuracy: 0.9971330275229358\n",
            "Epoch 10/10, Batch Loss: 0.004933890886604786, Average Training Loss: 0.011779278245839206, Training Accuracy: 0.9971590909090909\n",
            "Epoch 10/10, Batch Loss: 0.004770226776599884, Average Training Loss: 0.011716133638008221, Training Accuracy: 0.9971846846846847\n",
            "Epoch 10/10, Batch Loss: 0.004679870326071978, Average Training Loss: 0.011653309858437362, Training Accuracy: 0.9972098214285714\n",
            "Epoch 10/10, Batch Loss: 0.004093729890882969, Average Training Loss: 0.011586410920671393, Training Accuracy: 0.9972345132743363\n",
            "Epoch 10/10, Batch Loss: 0.006453102920204401, Average Training Loss: 0.011541381903123437, Training Accuracy: 0.9972587719298246\n",
            "Epoch 10/10, Batch Loss: 0.003291606903076172, Average Training Loss: 0.011469644729209983, Training Accuracy: 0.9972826086956522\n",
            "Epoch 10/10, Batch Loss: 0.0047961133532226086, Average Training Loss: 0.01141211428631354, Training Accuracy: 0.9973060344827587\n",
            "Epoch 10/10, Batch Loss: 0.00828593410551548, Average Training Loss: 0.01138539479758877, Training Accuracy: 0.9973290598290598\n",
            "Epoch 10/10, Batch Loss: 0.004690812900662422, Average Training Loss: 0.011328661052699564, Training Accuracy: 0.9973516949152542\n",
            "Epoch 10/10, Batch Loss: 0.004745814483612776, Average Training Loss: 0.011273343014303877, Training Accuracy: 0.9973739495798319\n",
            "Epoch 10/10, Batch Loss: 0.004906619433313608, Average Training Loss: 0.01122028698446229, Training Accuracy: 0.9973958333333334\n",
            "Epoch 10/10, Batch Loss: 0.12392221391201019, Average Training Loss: 0.012151707868161034, Training Accuracy: 0.996900826446281\n",
            "Epoch 10/10, Batch Loss: 0.005140400491654873, Average Training Loss: 0.012094238135566721, Training Accuracy: 0.9969262295081968\n",
            "Epoch 10/10, Batch Loss: 0.008249599486589432, Average Training Loss: 0.012062980910778289, Training Accuracy: 0.9969512195121951\n",
            "Epoch 10/10, Batch Loss: 0.008178501389920712, Average Training Loss: 0.012031654463029437, Training Accuracy: 0.9969758064516129\n",
            "Epoch 10/10, Batch Loss: 0.008126260712742805, Average Training Loss: 0.012000411313027143, Training Accuracy: 0.997\n",
            "Epoch 10/10, Batch Loss: 0.055847663432359695, Average Training Loss: 0.01234840537746629, Training Accuracy: 0.9965277777777778\n",
            "Epoch 10/10, Batch Loss: 0.004467299673706293, Average Training Loss: 0.012286349427042983, Training Accuracy: 0.9965551181102362\n",
            "Epoch 10/10, Batch Loss: 0.006033896002918482, Average Training Loss: 0.012237502134667011, Training Accuracy: 0.99658203125\n",
            "Epoch 10/10, Batch Loss: 0.008089100942015648, Average Training Loss: 0.012205343985886768, Training Accuracy: 0.9966085271317829\n",
            "Epoch 10/10, Batch Loss: 0.005598324816673994, Average Training Loss: 0.012154520761508207, Training Accuracy: 0.9966346153846154\n",
            "Epoch 10/10, Batch Loss: 0.006598387844860554, Average Training Loss: 0.012112107533136851, Training Accuracy: 0.9966603053435115\n",
            "Epoch 10/10, Batch Loss: 0.0061471303924918175, Average Training Loss: 0.01206691831237439, Training Accuracy: 0.9966856060606061\n",
            "Epoch 10/10, Batch Loss: 0.005231087561696768, Average Training Loss: 0.012095094076027369, Training Accuracy: 0.9966887417218543\n",
            "Epoch 10/10, Average Training Loss: 0.012015521088685085, Training Accuracy: 0.9966887417218543\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       1.00      1.00      1.00       427\n",
            "                Educational Opportunity       0.99      1.00      0.99       451\n",
            "                         Family Support       1.00      1.00      1.00       396\n",
            "                      Financial Support       1.00      1.00      1.00       404\n",
            "                 Program Implementation       1.00      0.99      0.99       436\n",
            "\n",
            "                               accuracy                           1.00      2114\n",
            "                              macro avg       1.00      1.00      1.00      2114\n",
            "                           weighted avg       1.00      1.00      1.00      2114\n",
            "\n",
            "Epoch 10/10, Validation Loss: 42.46034165751189, Validation Accuracy: 0.7315689981096408\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.67      0.68       113\n",
            "                Educational Opportunity       0.53      0.64      0.58       100\n",
            "                         Family Support       0.91      0.95      0.93       105\n",
            "                      Financial Support       0.73      0.76      0.74        97\n",
            "                 Program Implementation       0.84      0.64      0.73       114\n",
            "\n",
            "                               accuracy                           0.73       529\n",
            "                              macro avg       0.74      0.73      0.73       529\n",
            "                           weighted avg       0.74      0.73      0.73       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "80b14c3893844d63b3fb7e79a4b52232",
            "e8563ee373bd4adb80224ab5894db734",
            "15f72f37485d473a8c7e172fe832e961",
            "b1194b30424e471286aa0b16dc86344c",
            "100d2c6be03844538a9a2241cf66d803",
            "61234dd5ce614d5cb2e7811e3e532fb6",
            "aeb3087176724efab48c24b934ecd7b2",
            "0309b434dca64d768f2f4a1838211ef0",
            "1cf79b87820944069db05bbc84b852a7",
            "e7d955b3e67940e98dd7e5c54d7e6049",
            "3d386b4a2c814e71a9d0dda61eeba5ce",
            "26df0652170441bfa3ff1d5229e5f416",
            "f555c5aa053843699792b1b5dc90b706",
            "2aadfeacfab941f7b8fb98b650a91593",
            "a50df560ab154879a875387b6bf23499",
            "4724091d54254544b13f42da5e4e4b24",
            "903d2cb8556a49d5a4b35fd1464e1c67",
            "7bde73e794cf4cd99fa73faa1d8c5bf4",
            "d6b226e00e4f4b94a359e3fa2d11c0bb",
            "64cfd2fb4f604860b4324cad9bb2c23d",
            "bef14f25fd3e43268eb8a3975f76d966",
            "257082b92b324d208e65b6e1b5d4d2a2",
            "3e3e875114a54172bd4efe8560fc98df",
            "aa47dcda1ea746e88b72829f0d2e1a86",
            "8970b9ca2bf5461485ae6592e894b5a4",
            "de0ee40f014a45e0a9a86b6c49d44002",
            "ad81e0fa561045c1a65999d87d7216c3",
            "cf3c99055128424d9bc32675629d78c0",
            "dfb3e1ddbaa440a18cba40cd59f57a9d",
            "775d2254470f489791b0d637a47e5117",
            "99737f87dc00439d9032566a9ade20b6",
            "38d8dd7256434381857fd5167b15d83f",
            "0a025beb2f2a46348934013d769150b8",
            "66f6a22f8eb7419db887cea0a0f1391f",
            "3527b97f57794d6d908c8eda4fc51a70",
            "8ad331d275a24a2e9fbd3f445fd5d456",
            "3bea704c052348a3b1f76fb5a14e12da",
            "3750b995cb614cc28b863d8a229b5d41",
            "d01195e4e7654cb2a8e6aa6d03eecae8",
            "ccc13e8276ad4417a6dc86a12b3eb5a0",
            "c9cb41c3d2564b70a0d1e7abc3e2a13c",
            "363d668aea4040639fbd4ee6a806a7aa",
            "c48c837e557a4d02a73dda19b4f51ab5",
            "a498187372494308b841704db0474579",
            "515a29f87a5c4a059d54d7bf906024ef",
            "7000adcaa5d64a7297564202e96b35c8",
            "86045387c5eb49ed85729a279cedd5a7",
            "9a44bdedac564aea8521f41ed46cba97",
            "688db4b48e5144cf800225b7a8930f00",
            "5d468fa4d07f434a824a480eba2df571",
            "2adf73d8341648a58d5e663573ccea17",
            "af651e2cd58a4e1f85a2a78e5aed36fe",
            "5261a733b7f7490894329e631518a73e",
            "ba6368af9d684318b783ff657bf59c09",
            "ac2b19d3cc134a278004670144a54c88"
          ]
        },
        "id": "nSEliedfdQwr",
        "outputId": "1732d3fc-5eb6-475d-a194-a8623cc2ce20"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<ipython-input-2-41e28e8b649f>:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    focused studying much think could pay tuition fee\n",
            "1            also helped become responsible many thing\n",
            "2    every student help make thier dream become pos...\n",
            "3           became serious studying fail graduate time\n",
            "4    experience free funded material module make st...\n",
            "5      program made possible continue studying college\n",
            "6      scholarship serve stepping stone onward success\n",
            "7    help finish study without worrying tuition als...\n",
            "8    need worry financial expense allowance tuition...\n",
            "9    one beneficiary made lot enthusiastic came cla...\n",
            "Name: Processed_Response, dtype: object\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80b14c3893844d63b3fb7e79a4b52232",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26df0652170441bfa3ff1d5229e5f416",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e3e875114a54172bd4efe8560fc98df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66f6a22f8eb7419db887cea0a0f1391f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "515a29f87a5c4a059d54d7bf906024ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch Loss: 1.6391780376434326, Average Training Loss: 1.6391780376434326, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.7085189819335938, Average Training Loss: 1.6738485097885132, Training Accuracy: 0.125\n",
            "Epoch 1/5, Batch Loss: 1.610846996307373, Average Training Loss: 1.6528480052947998, Training Accuracy: 0.16666666666666666\n",
            "Epoch 1/5, Batch Loss: 1.6213816404342651, Average Training Loss: 1.6449814140796661, Training Accuracy: 0.171875\n",
            "Epoch 1/5, Batch Loss: 1.5468406677246094, Average Training Loss: 1.6253532648086548, Training Accuracy: 0.2125\n",
            "Epoch 1/5, Batch Loss: 1.5807524919509888, Average Training Loss: 1.6179198026657104, Training Accuracy: 0.21875\n",
            "Epoch 1/5, Batch Loss: 1.5779796838760376, Average Training Loss: 1.6122140714100428, Training Accuracy: 0.22321428571428573\n",
            "Epoch 1/5, Batch Loss: 1.5936646461486816, Average Training Loss: 1.6098953932523727, Training Accuracy: 0.2421875\n",
            "Epoch 1/5, Batch Loss: 1.6868716478347778, Average Training Loss: 1.6184483104281955, Training Accuracy: 0.22916666666666666\n",
            "Epoch 1/5, Batch Loss: 1.546642541885376, Average Training Loss: 1.6112677335739136, Training Accuracy: 0.23125\n",
            "Epoch 1/5, Batch Loss: 1.595007061958313, Average Training Loss: 1.609789490699768, Training Accuracy: 0.24431818181818182\n",
            "Epoch 1/5, Batch Loss: 1.5196707248687744, Average Training Loss: 1.6022795935471852, Training Accuracy: 0.2604166666666667\n",
            "Epoch 1/5, Batch Loss: 1.5676748752593994, Average Training Loss: 1.5996176921404326, Training Accuracy: 0.25961538461538464\n",
            "Epoch 1/5, Batch Loss: 1.5361255407333374, Average Training Loss: 1.5950825384684972, Training Accuracy: 0.26785714285714285\n",
            "Epoch 1/5, Batch Loss: 1.645650029182434, Average Training Loss: 1.598453704516093, Training Accuracy: 0.25833333333333336\n",
            "Epoch 1/5, Batch Loss: 1.483432412147522, Average Training Loss: 1.5912648737430573, Training Accuracy: 0.26953125\n",
            "Epoch 1/5, Batch Loss: 1.503739833831787, Average Training Loss: 1.5861163419835709, Training Accuracy: 0.2867647058823529\n",
            "Epoch 1/5, Batch Loss: 1.5699326992034912, Average Training Loss: 1.585217250718011, Training Accuracy: 0.2847222222222222\n",
            "Epoch 1/5, Batch Loss: 1.6785974502563477, Average Training Loss: 1.5901319980621338, Training Accuracy: 0.27631578947368424\n",
            "Epoch 1/5, Batch Loss: 1.5679636001586914, Average Training Loss: 1.5890235781669617, Training Accuracy: 0.271875\n",
            "Epoch 1/5, Batch Loss: 1.5739104747772217, Average Training Loss: 1.588303906576974, Training Accuracy: 0.26785714285714285\n",
            "Epoch 1/5, Batch Loss: 1.6411538124084473, Average Training Loss: 1.5907061750238591, Training Accuracy: 0.26420454545454547\n",
            "Epoch 1/5, Batch Loss: 1.4783207178115845, Average Training Loss: 1.5858198507972385, Training Accuracy: 0.27445652173913043\n",
            "Epoch 1/5, Batch Loss: 1.5476280450820923, Average Training Loss: 1.5842285255591075, Training Accuracy: 0.2786458333333333\n",
            "Epoch 1/5, Batch Loss: 1.5861185789108276, Average Training Loss: 1.5843041276931762, Training Accuracy: 0.2825\n",
            "Epoch 1/5, Batch Loss: 1.5448530912399292, Average Training Loss: 1.5827867801372821, Training Accuracy: 0.28365384615384615\n",
            "Epoch 1/5, Batch Loss: 1.553698182106018, Average Training Loss: 1.5817094246546428, Training Accuracy: 0.2777777777777778\n",
            "Epoch 1/5, Batch Loss: 1.4197291135787964, Average Training Loss: 1.5759244135447912, Training Accuracy: 0.28794642857142855\n",
            "Epoch 1/5, Batch Loss: 1.529461145401001, Average Training Loss: 1.5743222318846604, Training Accuracy: 0.28879310344827586\n",
            "Epoch 1/5, Batch Loss: 1.5787299871444702, Average Training Loss: 1.5744691570599874, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/5, Batch Loss: 1.6070427894592285, Average Training Loss: 1.5755199193954468, Training Accuracy: 0.28830645161290325\n",
            "Epoch 1/5, Batch Loss: 1.5952411890029907, Average Training Loss: 1.5761362090706825, Training Accuracy: 0.287109375\n",
            "Epoch 1/5, Batch Loss: 1.5766798257827759, Average Training Loss: 1.5761526823043823, Training Accuracy: 0.2916666666666667\n",
            "Epoch 1/5, Batch Loss: 1.3770420551300049, Average Training Loss: 1.570296487387489, Training Accuracy: 0.2959558823529412\n",
            "Epoch 1/5, Batch Loss: 1.5882951021194458, Average Training Loss: 1.5708107335226877, Training Accuracy: 0.29642857142857143\n",
            "Epoch 1/5, Batch Loss: 1.3899716138839722, Average Training Loss: 1.5657874246438344, Training Accuracy: 0.3055555555555556\n",
            "Epoch 1/5, Batch Loss: 1.424195647239685, Average Training Loss: 1.5619606198491276, Training Accuracy: 0.3091216216216216\n",
            "Epoch 1/5, Batch Loss: 1.4208178520202637, Average Training Loss: 1.5582463364852102, Training Accuracy: 0.31414473684210525\n",
            "Epoch 1/5, Batch Loss: 1.4364619255065918, Average Training Loss: 1.5551236592806303, Training Accuracy: 0.3173076923076923\n",
            "Epoch 1/5, Batch Loss: 1.3046373128890991, Average Training Loss: 1.548861500620842, Training Accuracy: 0.3265625\n",
            "Epoch 1/5, Batch Loss: 1.3730446100234985, Average Training Loss: 1.5445732837770043, Training Accuracy: 0.3307926829268293\n",
            "Epoch 1/5, Batch Loss: 1.6282681226730347, Average Training Loss: 1.5465660180364336, Training Accuracy: 0.3244047619047619\n",
            "Epoch 1/5, Batch Loss: 1.485528826713562, Average Training Loss: 1.5451465484707854, Training Accuracy: 0.32558139534883723\n",
            "Epoch 1/5, Batch Loss: 1.4613984823226929, Average Training Loss: 1.543243183331056, Training Accuracy: 0.328125\n",
            "Epoch 1/5, Batch Loss: 1.394742727279663, Average Training Loss: 1.5399431731965807, Training Accuracy: 0.33194444444444443\n",
            "Epoch 1/5, Batch Loss: 1.4946155548095703, Average Training Loss: 1.5389577901881675, Training Accuracy: 0.328804347826087\n",
            "Epoch 1/5, Batch Loss: 1.3814613819122314, Average Training Loss: 1.5356068027780412, Training Accuracy: 0.3337765957446808\n",
            "Epoch 1/5, Batch Loss: 1.4095163345336914, Average Training Loss: 1.5329799180229504, Training Accuracy: 0.3359375\n",
            "Epoch 1/5, Batch Loss: 1.3164235353469849, Average Training Loss: 1.5285604000091553, Training Accuracy: 0.34183673469387754\n",
            "Epoch 1/5, Batch Loss: 1.2432771921157837, Average Training Loss: 1.5228547358512878, Training Accuracy: 0.34625\n",
            "Epoch 1/5, Batch Loss: 1.3125405311584473, Average Training Loss: 1.518730927916134, Training Accuracy: 0.3480392156862745\n",
            "Epoch 1/5, Batch Loss: 1.5475050210952759, Average Training Loss: 1.5192842758618867, Training Accuracy: 0.3485576923076923\n",
            "Epoch 1/5, Batch Loss: 1.2006546258926392, Average Training Loss: 1.513272395673788, Training Accuracy: 0.35377358490566035\n",
            "Epoch 1/5, Batch Loss: 1.3585188388824463, Average Training Loss: 1.5104065890665408, Training Accuracy: 0.3576388888888889\n",
            "Epoch 1/5, Batch Loss: 1.4547951221466064, Average Training Loss: 1.5093954714861784, Training Accuracy: 0.3568181818181818\n",
            "Epoch 1/5, Batch Loss: 1.2869884967803955, Average Training Loss: 1.5054239183664322, Training Accuracy: 0.36049107142857145\n",
            "Epoch 1/5, Batch Loss: 1.141556978225708, Average Training Loss: 1.4990402878376476, Training Accuracy: 0.3651315789473684\n",
            "Epoch 1/5, Batch Loss: 1.22408926486969, Average Training Loss: 1.4942997529588897, Training Accuracy: 0.37176724137931033\n",
            "Epoch 1/5, Batch Loss: 1.224112868309021, Average Training Loss: 1.4897203142360105, Training Accuracy: 0.3771186440677966\n",
            "Epoch 1/5, Batch Loss: 1.1385905742645264, Average Training Loss: 1.4838681519031525, Training Accuracy: 0.38229166666666664\n",
            "Epoch 1/5, Batch Loss: 1.249780297279358, Average Training Loss: 1.4800306460896477, Training Accuracy: 0.3862704918032787\n",
            "Epoch 1/5, Batch Loss: 1.1797784566879272, Average Training Loss: 1.4751878688412328, Training Accuracy: 0.3911290322580645\n",
            "Epoch 1/5, Batch Loss: 1.130872130393982, Average Training Loss: 1.4697225396595304, Training Accuracy: 0.3968253968253968\n",
            "Epoch 1/5, Batch Loss: 1.0778687000274658, Average Training Loss: 1.4635998234152794, Training Accuracy: 0.4013671875\n",
            "Epoch 1/5, Batch Loss: 1.10972261428833, Average Training Loss: 1.45815555865948, Training Accuracy: 0.40384615384615385\n",
            "Epoch 1/5, Batch Loss: 1.211060643196106, Average Training Loss: 1.4544116963039746, Training Accuracy: 0.4053030303030303\n",
            "Epoch 1/5, Batch Loss: 1.1729991436004639, Average Training Loss: 1.4502115089501908, Training Accuracy: 0.40578358208955223\n",
            "Epoch 1/5, Batch Loss: 1.3749650716781616, Average Training Loss: 1.4491049436961903, Training Accuracy: 0.40625\n",
            "Epoch 1/5, Batch Loss: 1.0442724227905273, Average Training Loss: 1.4432378057120503, Training Accuracy: 0.41032608695652173\n",
            "Epoch 1/5, Batch Loss: 1.3301187753677368, Average Training Loss: 1.4416218195642745, Training Accuracy: 0.41160714285714284\n",
            "Epoch 1/5, Batch Loss: 0.9784195423126221, Average Training Loss: 1.4350978438283357, Training Accuracy: 0.4154929577464789\n",
            "Epoch 1/5, Batch Loss: 1.0932036638259888, Average Training Loss: 1.4303493135505252, Training Accuracy: 0.4166666666666667\n",
            "Epoch 1/5, Batch Loss: 0.7597807049751282, Average Training Loss: 1.4211634422001773, Training Accuracy: 0.4220890410958904\n",
            "Epoch 1/5, Batch Loss: 1.0863897800445557, Average Training Loss: 1.4166394737926689, Training Accuracy: 0.4248310810810811\n",
            "Epoch 1/5, Batch Loss: 1.0052680969238281, Average Training Loss: 1.4111545221010844, Training Accuracy: 0.4266666666666667\n",
            "Epoch 1/5, Batch Loss: 1.054038643836975, Average Training Loss: 1.4064556289660304, Training Accuracy: 0.4284539473684211\n",
            "Epoch 1/5, Batch Loss: 1.1828984022140503, Average Training Loss: 1.4035522883588618, Training Accuracy: 0.4301948051948052\n",
            "Epoch 1/5, Batch Loss: 1.0052682161331177, Average Training Loss: 1.3984460823046856, Training Accuracy: 0.4342948717948718\n",
            "Epoch 1/5, Batch Loss: 1.0250498056411743, Average Training Loss: 1.3937195471570463, Training Accuracy: 0.4375\n",
            "Epoch 1/5, Batch Loss: 1.2464547157287598, Average Training Loss: 1.3918787367641925, Training Accuracy: 0.4375\n",
            "Epoch 1/5, Batch Loss: 1.1380912065505981, Average Training Loss: 1.3887455573788396, Training Accuracy: 0.4382716049382716\n",
            "Epoch 1/5, Batch Loss: 1.116295576095581, Average Training Loss: 1.3854229966314828, Training Accuracy: 0.4413109756097561\n",
            "Epoch 1/5, Batch Loss: 1.2745636701583862, Average Training Loss: 1.3840873420956623, Training Accuracy: 0.44126506024096385\n",
            "Epoch 1/5, Batch Loss: 0.9161859154701233, Average Training Loss: 1.3785170870167869, Training Accuracy: 0.44419642857142855\n",
            "Epoch 1/5, Batch Loss: 1.2302378416061401, Average Training Loss: 1.3767726253060732, Training Accuracy: 0.44485294117647056\n",
            "Epoch 1/5, Batch Loss: 0.9558839797973633, Average Training Loss: 1.3718785712885302, Training Accuracy: 0.4476744186046512\n",
            "Epoch 1/5, Batch Loss: 1.0838888883590698, Average Training Loss: 1.3685683450479618, Training Accuracy: 0.4489942528735632\n",
            "Epoch 1/5, Batch Loss: 0.8220331072807312, Average Training Loss: 1.3623577173460613, Training Accuracy: 0.4509943181818182\n",
            "Epoch 1/5, Batch Loss: 1.1312623023986816, Average Training Loss: 1.3597611396500233, Training Accuracy: 0.45224719101123595\n",
            "Epoch 1/5, Batch Loss: 1.064902901649475, Average Training Loss: 1.356484937005573, Training Accuracy: 0.4527777777777778\n",
            "Epoch 1/5, Batch Loss: 0.9714738726615906, Average Training Loss: 1.3522540461886061, Training Accuracy: 0.45535714285714285\n",
            "Epoch 1/5, Batch Loss: 0.7781804203987122, Average Training Loss: 1.3460141154734984, Training Accuracy: 0.4592391304347826\n",
            "Epoch 1/5, Batch Loss: 0.7816942930221558, Average Training Loss: 1.3399461603933764, Training Accuracy: 0.46303763440860213\n",
            "Epoch 1/5, Batch Loss: 0.6518118381500244, Average Training Loss: 1.3326255824971707, Training Accuracy: 0.46675531914893614\n",
            "Epoch 1/5, Batch Loss: 0.7117952704429626, Average Training Loss: 1.3260905265808105, Training Accuracy: 0.4697368421052632\n",
            "Epoch 1/5, Batch Loss: 0.775140106678009, Average Training Loss: 1.320351459706823, Training Accuracy: 0.4733072916666667\n",
            "Epoch 1/5, Batch Loss: 0.8908792734146118, Average Training Loss: 1.3159239113945322, Training Accuracy: 0.47680412371134023\n",
            "Epoch 1/5, Batch Loss: 1.0394749641418457, Average Training Loss: 1.3131030037695048, Training Accuracy: 0.47831632653061223\n",
            "Epoch 1/5, Batch Loss: 1.132702112197876, Average Training Loss: 1.3112807725415085, Training Accuracy: 0.47853535353535354\n",
            "Epoch 1/5, Batch Loss: 0.7102010846138, Average Training Loss: 1.3052699756622315, Training Accuracy: 0.481875\n",
            "Epoch 1/5, Batch Loss: 0.7628665566444397, Average Training Loss: 1.2998996447808673, Training Accuracy: 0.4839108910891089\n",
            "Epoch 1/5, Batch Loss: 0.6444154977798462, Average Training Loss: 1.2934733296141905, Training Accuracy: 0.48713235294117646\n",
            "Epoch 1/5, Batch Loss: 0.8832407593727112, Average Training Loss: 1.2894904891264092, Training Accuracy: 0.4890776699029126\n",
            "Epoch 1/5, Batch Loss: 0.7750791311264038, Average Training Loss: 1.2845442260687168, Training Accuracy: 0.4909855769230769\n",
            "Epoch 1/5, Batch Loss: 0.9724483489990234, Average Training Loss: 1.2815718843823387, Training Accuracy: 0.4922619047619048\n",
            "Epoch 1/5, Batch Loss: 1.3320578336715698, Average Training Loss: 1.2820481669228032, Training Accuracy: 0.49174528301886794\n",
            "Epoch 1/5, Batch Loss: 1.0291248559951782, Average Training Loss: 1.2796843976617973, Training Accuracy: 0.49240654205607476\n",
            "Epoch 1/5, Batch Loss: 0.6928568482398987, Average Training Loss: 1.2742508092412241, Training Accuracy: 0.49594907407407407\n",
            "Epoch 1/5, Batch Loss: 0.9773457050323486, Average Training Loss: 1.2715269092026107, Training Accuracy: 0.49655963302752293\n",
            "Epoch 1/5, Batch Loss: 1.001563310623169, Average Training Loss: 1.2690726946700703, Training Accuracy: 0.4971590909090909\n",
            "Epoch 1/5, Batch Loss: 1.0486868619918823, Average Training Loss: 1.2670872367180146, Training Accuracy: 0.4988738738738739\n",
            "Epoch 1/5, Batch Loss: 0.8155484795570374, Average Training Loss: 1.2630556406719344, Training Accuracy: 0.5005580357142857\n",
            "Epoch 1/5, Batch Loss: 0.9671663641929626, Average Training Loss: 1.260437151499554, Training Accuracy: 0.5016592920353983\n",
            "Epoch 1/5, Batch Loss: 1.0366843938827515, Average Training Loss: 1.2584744080116874, Training Accuracy: 0.5027412280701754\n",
            "Epoch 1/5, Batch Loss: 0.9733591079711914, Average Training Loss: 1.2559951445330744, Training Accuracy: 0.503804347826087\n",
            "Epoch 1/5, Batch Loss: 1.108317255973816, Average Training Loss: 1.254722059286874, Training Accuracy: 0.5032327586206896\n",
            "Epoch 1/5, Batch Loss: 0.8741601705551147, Average Training Loss: 1.2514693935712178, Training Accuracy: 0.5053418803418803\n",
            "Epoch 1/5, Batch Loss: 1.0390682220458984, Average Training Loss: 1.2496693836430373, Training Accuracy: 0.5063559322033898\n",
            "Epoch 1/5, Batch Loss: 0.7589566111564636, Average Training Loss: 1.2455457468994526, Training Accuracy: 0.5084033613445378\n",
            "Epoch 1/5, Batch Loss: 0.686029314994812, Average Training Loss: 1.2408831099669138, Training Accuracy: 0.5109375\n",
            "Epoch 1/5, Batch Loss: 0.8326728940010071, Average Training Loss: 1.2375094718184352, Training Accuracy: 0.512396694214876\n",
            "Epoch 1/5, Batch Loss: 0.7514586448669434, Average Training Loss: 1.2335254486467018, Training Accuracy: 0.5138319672131147\n",
            "Epoch 1/5, Batch Loss: 1.0738775730133057, Average Training Loss: 1.2322274984383002, Training Accuracy: 0.5152439024390244\n",
            "Epoch 1/5, Batch Loss: 0.8707205653190613, Average Training Loss: 1.2293121199454031, Training Accuracy: 0.5171370967741935\n",
            "Epoch 1/5, Batch Loss: 0.6463053822517395, Average Training Loss: 1.2246480660438537, Training Accuracy: 0.5185\n",
            "Epoch 1/5, Batch Loss: 0.9643587470054626, Average Training Loss: 1.2225822777975173, Training Accuracy: 0.5193452380952381\n",
            "Epoch 1/5, Batch Loss: 0.7196129560470581, Average Training Loss: 1.2186218894372776, Training Accuracy: 0.5211614173228346\n",
            "Epoch 1/5, Batch Loss: 0.773517370223999, Average Training Loss: 1.2151445103809237, Training Accuracy: 0.5224609375\n",
            "Epoch 1/5, Batch Loss: 0.8712320327758789, Average Training Loss: 1.212478522182435, Training Accuracy: 0.5232558139534884\n",
            "Epoch 1/5, Batch Loss: 0.4867963194847107, Average Training Loss: 1.2068963513924524, Training Accuracy: 0.5259615384615385\n",
            "Epoch 1/5, Batch Loss: 0.7576510906219482, Average Training Loss: 1.2034669982567998, Training Accuracy: 0.5271946564885496\n",
            "Epoch 1/5, Batch Loss: 0.7706065773963928, Average Training Loss: 1.200187752644221, Training Accuracy: 0.5288825757575758\n",
            "Epoch 1/5, Batch Loss: 0.7069412469863892, Average Training Loss: 1.2044028351638492, Training Accuracy: 0.5288552507095553\n",
            "Epoch 1/5, Average Training Loss: 1.196479132300929, Training Accuracy: 0.5288552507095553\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.48      0.48      0.48       427\n",
            "                Educational Opportunity       0.49      0.36      0.42       451\n",
            "                         Family Support       0.60      0.69      0.65       396\n",
            "                      Financial Support       0.49      0.59      0.54       404\n",
            "                 Program Implementation       0.58      0.54      0.56       436\n",
            "\n",
            "                               accuracy                           0.53      2114\n",
            "                              macro avg       0.53      0.53      0.53      2114\n",
            "                           weighted avg       0.53      0.53      0.52      2114\n",
            "\n",
            "Epoch 1/5, Validation Loss: 31.299175798892975, Validation Accuracy: 0.6465028355387523\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.45      0.84      0.59       113\n",
            "                Educational Opportunity       0.48      0.42      0.45       100\n",
            "                         Family Support       0.90      0.97      0.94       105\n",
            "                      Financial Support       0.85      0.46      0.60        97\n",
            "                 Program Implementation       0.87      0.51      0.64       114\n",
            "\n",
            "                               accuracy                           0.65       529\n",
            "                              macro avg       0.71      0.64      0.64       529\n",
            "                           weighted avg       0.71      0.65      0.64       529\n",
            "\n",
            "Epoch 2/5, Batch Loss: 0.6622145771980286, Average Training Loss: 0.6622145771980286, Training Accuracy: 0.75\n",
            "Epoch 2/5, Batch Loss: 0.9768385291099548, Average Training Loss: 0.8195265531539917, Training Accuracy: 0.6875\n",
            "Epoch 2/5, Batch Loss: 1.2088325023651123, Average Training Loss: 0.9492952028910319, Training Accuracy: 0.6666666666666666\n",
            "Epoch 2/5, Batch Loss: 0.8054508566856384, Average Training Loss: 0.9133341163396835, Training Accuracy: 0.65625\n",
            "Epoch 2/5, Batch Loss: 0.45506995916366577, Average Training Loss: 0.82168128490448, Training Accuracy: 0.7\n",
            "Epoch 2/5, Batch Loss: 1.0160471200942993, Average Training Loss: 0.8540755907694498, Training Accuracy: 0.6875\n",
            "Epoch 2/5, Batch Loss: 0.848273754119873, Average Training Loss: 0.8532467569623675, Training Accuracy: 0.6875\n",
            "Epoch 2/5, Batch Loss: 0.8758208751678467, Average Training Loss: 0.8560685217380524, Training Accuracy: 0.6875\n",
            "Epoch 2/5, Batch Loss: 0.6889721751213074, Average Training Loss: 0.8375022610028585, Training Accuracy: 0.6805555555555556\n",
            "Epoch 2/5, Batch Loss: 0.8466946482658386, Average Training Loss: 0.8384214997291565, Training Accuracy: 0.68125\n",
            "Epoch 2/5, Batch Loss: 0.7148475646972656, Average Training Loss: 0.8271875056353483, Training Accuracy: 0.6988636363636364\n",
            "Epoch 2/5, Batch Loss: 0.6326540112495422, Average Training Loss: 0.8109763811031977, Training Accuracy: 0.7083333333333334\n",
            "Epoch 2/5, Batch Loss: 0.7564176321029663, Average Training Loss: 0.8067795542570261, Training Accuracy: 0.7019230769230769\n",
            "Epoch 2/5, Batch Loss: 0.4569147229194641, Average Training Loss: 0.781789209161486, Training Accuracy: 0.7142857142857143\n",
            "Epoch 2/5, Batch Loss: 0.6814858913421631, Average Training Loss: 0.7751023213068644, Training Accuracy: 0.7125\n",
            "Epoch 2/5, Batch Loss: 0.7250090837478638, Average Training Loss: 0.7719714939594269, Training Accuracy: 0.71484375\n",
            "Epoch 2/5, Batch Loss: 0.8997822999954224, Average Training Loss: 0.7794897766674266, Training Accuracy: 0.7058823529411765\n",
            "Epoch 2/5, Batch Loss: 0.9204870462417603, Average Training Loss: 0.7873229583104452, Training Accuracy: 0.6944444444444444\n",
            "Epoch 2/5, Batch Loss: 0.9482541680335999, Average Training Loss: 0.7957930219800848, Training Accuracy: 0.694078947368421\n",
            "Epoch 2/5, Batch Loss: 0.43849244713783264, Average Training Loss: 0.7779279932379722, Training Accuracy: 0.70625\n",
            "Epoch 2/5, Batch Loss: 0.8675297498703003, Average Training Loss: 0.7821947435537974, Training Accuracy: 0.7083333333333334\n",
            "Epoch 2/5, Batch Loss: 0.6976646184921265, Average Training Loss: 0.7783524651419033, Training Accuracy: 0.7045454545454546\n",
            "Epoch 2/5, Batch Loss: 0.7608792781829834, Average Training Loss: 0.7775927613610807, Training Accuracy: 0.7038043478260869\n",
            "Epoch 2/5, Batch Loss: 1.0379314422607422, Average Training Loss: 0.7884402063985666, Training Accuracy: 0.703125\n",
            "Epoch 2/5, Batch Loss: 0.6159710884094238, Average Training Loss: 0.7815414416790009, Training Accuracy: 0.71\n",
            "Epoch 2/5, Batch Loss: 0.7907631397247314, Average Training Loss: 0.7818961223730674, Training Accuracy: 0.7091346153846154\n",
            "Epoch 2/5, Batch Loss: 0.5646786689758301, Average Training Loss: 0.773851031506503, Training Accuracy: 0.7129629629629629\n",
            "Epoch 2/5, Batch Loss: 0.6765369176864624, Average Training Loss: 0.7703755274415016, Training Accuracy: 0.7120535714285714\n",
            "Epoch 2/5, Batch Loss: 0.5781133770942688, Average Training Loss: 0.7637457981191832, Training Accuracy: 0.7133620689655172\n",
            "Epoch 2/5, Batch Loss: 0.5717597007751465, Average Training Loss: 0.7573462615410487, Training Accuracy: 0.7166666666666667\n",
            "Epoch 2/5, Batch Loss: 0.8454363346099854, Average Training Loss: 0.7601878768013369, Training Accuracy: 0.7157258064516129\n",
            "Epoch 2/5, Batch Loss: 0.5052395462989807, Average Training Loss: 0.7522207414731383, Training Accuracy: 0.71875\n",
            "Epoch 2/5, Batch Loss: 0.7929415106773376, Average Training Loss: 0.7534547041762959, Training Accuracy: 0.7178030303030303\n",
            "Epoch 2/5, Batch Loss: 0.5482891798019409, Average Training Loss: 0.7474204240476384, Training Accuracy: 0.7242647058823529\n",
            "Epoch 2/5, Batch Loss: 0.3262067437171936, Average Training Loss: 0.7353857474667685, Training Accuracy: 0.7303571428571428\n",
            "Epoch 2/5, Batch Loss: 0.7531829476356506, Average Training Loss: 0.7358801141381264, Training Accuracy: 0.7309027777777778\n",
            "Epoch 2/5, Batch Loss: 0.6585069298744202, Average Training Loss: 0.733788946995864, Training Accuracy: 0.731418918918919\n",
            "Epoch 2/5, Batch Loss: 0.4108247756958008, Average Training Loss: 0.7252898898563886, Training Accuracy: 0.7368421052631579\n",
            "Epoch 2/5, Batch Loss: 0.8939266800880432, Average Training Loss: 0.7296139101187388, Training Accuracy: 0.7339743589743589\n",
            "Epoch 2/5, Batch Loss: 0.906895101070404, Average Training Loss: 0.7340459398925304, Training Accuracy: 0.73125\n",
            "Epoch 2/5, Batch Loss: 0.5904257297515869, Average Training Loss: 0.7305430079378733, Training Accuracy: 0.7332317073170732\n",
            "Epoch 2/5, Batch Loss: 0.8253530263900757, Average Training Loss: 0.7328003893295923, Training Accuracy: 0.7306547619047619\n",
            "Epoch 2/5, Batch Loss: 0.6662420034408569, Average Training Loss: 0.7312525198903195, Training Accuracy: 0.7340116279069767\n",
            "Epoch 2/5, Batch Loss: 0.5487075448036194, Average Training Loss: 0.7271037704565309, Training Accuracy: 0.734375\n",
            "Epoch 2/5, Batch Loss: 0.7367767691612244, Average Training Loss: 0.7273187259833018, Training Accuracy: 0.7333333333333333\n",
            "Epoch 2/5, Batch Loss: 0.8261348009109497, Average Training Loss: 0.7294669015252072, Training Accuracy: 0.7323369565217391\n",
            "Epoch 2/5, Batch Loss: 0.5283946990966797, Average Training Loss: 0.7251887695586428, Training Accuracy: 0.7340425531914894\n",
            "Epoch 2/5, Batch Loss: 0.7917430400848389, Average Training Loss: 0.7265753168612719, Training Accuracy: 0.73046875\n",
            "Epoch 2/5, Batch Loss: 0.836794376373291, Average Training Loss: 0.7288246854227416, Training Accuracy: 0.7283163265306123\n",
            "Epoch 2/5, Batch Loss: 0.6430477499961853, Average Training Loss: 0.7271091467142106, Training Accuracy: 0.72875\n",
            "Epoch 2/5, Batch Loss: 0.6558736562728882, Average Training Loss: 0.7257123723918316, Training Accuracy: 0.7291666666666666\n",
            "Epoch 2/5, Batch Loss: 0.5013652443885803, Average Training Loss: 0.7213980045456153, Training Accuracy: 0.7331730769230769\n",
            "Epoch 2/5, Batch Loss: 1.0014476776123047, Average Training Loss: 0.7266819606412132, Training Accuracy: 0.7311320754716981\n",
            "Epoch 2/5, Batch Loss: 0.8730965852737427, Average Training Loss: 0.7293933425788526, Training Accuracy: 0.7303240740740741\n",
            "Epoch 2/5, Batch Loss: 0.9020797610282898, Average Training Loss: 0.7325330956415697, Training Accuracy: 0.7284090909090909\n",
            "Epoch 2/5, Batch Loss: 0.43311840295791626, Average Training Loss: 0.7271864047007901, Training Accuracy: 0.7310267857142857\n",
            "Epoch 2/5, Batch Loss: 0.5558554530143738, Average Training Loss: 0.724180598530853, Training Accuracy: 0.7335526315789473\n",
            "Epoch 2/5, Batch Loss: 0.8953350782394409, Average Training Loss: 0.7271315378361735, Training Accuracy: 0.7306034482758621\n",
            "Epoch 2/5, Batch Loss: 0.6696875095367432, Average Training Loss: 0.726157910237878, Training Accuracy: 0.7298728813559322\n",
            "Epoch 2/5, Batch Loss: 0.5286882519721985, Average Training Loss: 0.7228667492667834, Training Accuracy: 0.7302083333333333\n",
            "Epoch 2/5, Batch Loss: 0.40130528807640076, Average Training Loss: 0.7175952499030066, Training Accuracy: 0.7325819672131147\n",
            "Epoch 2/5, Batch Loss: 0.41926664113998413, Average Training Loss: 0.7127834981487643, Training Accuracy: 0.7348790322580645\n",
            "Epoch 2/5, Batch Loss: 0.3830108940601349, Average Training Loss: 0.7075490123695798, Training Accuracy: 0.7380952380952381\n",
            "Epoch 2/5, Batch Loss: 0.5610732436180115, Average Training Loss: 0.7052603284828365, Training Accuracy: 0.7373046875\n",
            "Epoch 2/5, Batch Loss: 0.6962119340896606, Average Training Loss: 0.7051211224152492, Training Accuracy: 0.7365384615384616\n",
            "Epoch 2/5, Batch Loss: 0.920056164264679, Average Training Loss: 0.7083777139584223, Training Accuracy: 0.7348484848484849\n",
            "Epoch 2/5, Batch Loss: 0.581821858882904, Average Training Loss: 0.7064888205990862, Training Accuracy: 0.7360074626865671\n",
            "Epoch 2/5, Batch Loss: 0.9415676593780518, Average Training Loss: 0.7099458623458358, Training Accuracy: 0.7352941176470589\n",
            "Epoch 2/5, Batch Loss: 0.9792861342430115, Average Training Loss: 0.7138493445472441, Training Accuracy: 0.7327898550724637\n",
            "Epoch 2/5, Batch Loss: 0.6240556836128235, Average Training Loss: 0.7125665779624667, Training Accuracy: 0.7339285714285714\n",
            "Epoch 2/5, Batch Loss: 0.5318097472190857, Average Training Loss: 0.7100207071069261, Training Accuracy: 0.7341549295774648\n",
            "Epoch 2/5, Batch Loss: 1.2734861373901367, Average Training Loss: 0.7178466158608595, Training Accuracy: 0.7326388888888888\n",
            "Epoch 2/5, Batch Loss: 0.43138396739959717, Average Training Loss: 0.7139224699915272, Training Accuracy: 0.7337328767123288\n",
            "Epoch 2/5, Batch Loss: 0.7380009889602661, Average Training Loss: 0.7142478553829966, Training Accuracy: 0.7331081081081081\n",
            "Epoch 2/5, Batch Loss: 0.7044299244880676, Average Training Loss: 0.7141169496377309, Training Accuracy: 0.7341666666666666\n",
            "Epoch 2/5, Batch Loss: 0.5178634524345398, Average Training Loss: 0.7115346667797942, Training Accuracy: 0.7351973684210527\n",
            "Epoch 2/5, Batch Loss: 0.6010543704032898, Average Training Loss: 0.7100998577359435, Training Accuracy: 0.737012987012987\n",
            "Epoch 2/5, Batch Loss: 0.5915108323097229, Average Training Loss: 0.7085794856150945, Training Accuracy: 0.7371794871794872\n",
            "Epoch 2/5, Batch Loss: 0.26602792739868164, Average Training Loss: 0.7029775671566589, Training Accuracy: 0.740506329113924\n",
            "Epoch 2/5, Batch Loss: 0.5846803188323975, Average Training Loss: 0.7014988515526056, Training Accuracy: 0.740625\n",
            "Epoch 2/5, Batch Loss: 0.7331036329269409, Average Training Loss: 0.7018890340387085, Training Accuracy: 0.7407407407407407\n",
            "Epoch 2/5, Batch Loss: 0.5328773260116577, Average Training Loss: 0.6998279156481347, Training Accuracy: 0.743140243902439\n",
            "Epoch 2/5, Batch Loss: 0.6223584413528442, Average Training Loss: 0.6988945484879505, Training Accuracy: 0.7432228915662651\n",
            "Epoch 2/5, Batch Loss: 0.446790874004364, Average Training Loss: 0.6958933142679078, Training Accuracy: 0.7447916666666666\n",
            "Epoch 2/5, Batch Loss: 0.25926825404167175, Average Training Loss: 0.6907565488534815, Training Accuracy: 0.7477941176470588\n",
            "Epoch 2/5, Batch Loss: 0.6531952619552612, Average Training Loss: 0.6903197897035022, Training Accuracy: 0.747093023255814\n",
            "Epoch 2/5, Batch Loss: 0.7965486645698547, Average Training Loss: 0.6915408112536902, Training Accuracy: 0.7471264367816092\n",
            "Epoch 2/5, Batch Loss: 0.7135043144226074, Average Training Loss: 0.6917903965169733, Training Accuracy: 0.7464488636363636\n",
            "Epoch 2/5, Batch Loss: 0.6239924430847168, Average Training Loss: 0.6910286217593076, Training Accuracy: 0.7464887640449438\n",
            "Epoch 2/5, Batch Loss: 0.594007134437561, Average Training Loss: 0.6899506052335104, Training Accuracy: 0.7479166666666667\n",
            "Epoch 2/5, Batch Loss: 0.5320864915847778, Average Training Loss: 0.688215834753854, Training Accuracy: 0.7479395604395604\n",
            "Epoch 2/5, Batch Loss: 0.5277234315872192, Average Training Loss: 0.6864713521107383, Training Accuracy: 0.7493206521739131\n",
            "Epoch 2/5, Batch Loss: 0.8365156054496765, Average Training Loss: 0.688084731178899, Training Accuracy: 0.7473118279569892\n",
            "Epoch 2/5, Batch Loss: 0.7972257733345032, Average Training Loss: 0.6892458060954479, Training Accuracy: 0.7473404255319149\n",
            "Epoch 2/5, Batch Loss: 0.5765674114227295, Average Training Loss: 0.6880597177304719, Training Accuracy: 0.7473684210526316\n",
            "Epoch 2/5, Batch Loss: 0.5059385895729065, Average Training Loss: 0.6861626226454973, Training Accuracy: 0.748046875\n",
            "Epoch 2/5, Batch Loss: 0.639628529548645, Average Training Loss: 0.6856828897269731, Training Accuracy: 0.7487113402061856\n",
            "Epoch 2/5, Batch Loss: 0.640332043170929, Average Training Loss: 0.6852201259866053, Training Accuracy: 0.7493622448979592\n",
            "Epoch 2/5, Batch Loss: 0.7816524505615234, Average Training Loss: 0.6861941898712004, Training Accuracy: 0.75\n",
            "Epoch 2/5, Batch Loss: 0.4538350999355316, Average Training Loss: 0.6838705989718438, Training Accuracy: 0.75125\n",
            "Epoch 2/5, Batch Loss: 0.7064183354377747, Average Training Loss: 0.684093843887348, Training Accuracy: 0.7512376237623762\n",
            "Epoch 2/5, Batch Loss: 0.8761894702911377, Average Training Loss: 0.6859771343422871, Training Accuracy: 0.7506127450980392\n",
            "Epoch 2/5, Batch Loss: 0.9962037205696106, Average Training Loss: 0.6889890429464359, Training Accuracy: 0.7487864077669902\n",
            "Epoch 2/5, Batch Loss: 0.5412395000457764, Average Training Loss: 0.6875683742646987, Training Accuracy: 0.7493990384615384\n",
            "Epoch 2/5, Batch Loss: 0.6843284964561462, Average Training Loss: 0.6875375182855696, Training Accuracy: 0.7488095238095238\n",
            "Epoch 2/5, Batch Loss: 0.3652580678462982, Average Training Loss: 0.6844971461116143, Training Accuracy: 0.7505896226415094\n",
            "Epoch 2/5, Batch Loss: 0.44412732124328613, Average Training Loss: 0.6822506991502281, Training Accuracy: 0.7517523364485982\n",
            "Epoch 2/5, Batch Loss: 0.3628256022930145, Average Training Loss: 0.6792930593645131, Training Accuracy: 0.7528935185185185\n",
            "Epoch 2/5, Batch Loss: 0.4312264621257782, Average Training Loss: 0.6770172190228734, Training Accuracy: 0.7540137614678899\n",
            "Epoch 2/5, Batch Loss: 0.6679062247276306, Average Training Loss: 0.6769343918020075, Training Accuracy: 0.7539772727272728\n",
            "Epoch 2/5, Batch Loss: 0.6691001653671265, Average Training Loss: 0.6768638131854771, Training Accuracy: 0.7533783783783784\n",
            "Epoch 2/5, Batch Loss: 1.0820105075836182, Average Training Loss: 0.6804811943854604, Training Accuracy: 0.7522321428571429\n",
            "Epoch 2/5, Batch Loss: 0.5834953784942627, Average Training Loss: 0.6796229128289012, Training Accuracy: 0.7516592920353983\n",
            "Epoch 2/5, Batch Loss: 0.4980366826057434, Average Training Loss: 0.678030051160277, Training Accuracy: 0.7521929824561403\n",
            "Epoch 2/5, Batch Loss: 0.9570192694664001, Average Training Loss: 0.6804560443629389, Training Accuracy: 0.75\n",
            "Epoch 2/5, Batch Loss: 0.6559818387031555, Average Training Loss: 0.680245059831389, Training Accuracy: 0.75\n",
            "Epoch 2/5, Batch Loss: 0.522843062877655, Average Training Loss: 0.6788997436181093, Training Accuracy: 0.7510683760683761\n",
            "Epoch 2/5, Batch Loss: 0.6672818660736084, Average Training Loss: 0.6788012870287491, Training Accuracy: 0.7515889830508474\n",
            "Epoch 2/5, Batch Loss: 0.5153388381004333, Average Training Loss: 0.6774276530041414, Training Accuracy: 0.7521008403361344\n",
            "Epoch 2/5, Batch Loss: 0.604444146156311, Average Training Loss: 0.6768194571137428, Training Accuracy: 0.7526041666666666\n",
            "Epoch 2/5, Batch Loss: 0.3230631947517395, Average Training Loss: 0.6738958516396767, Training Accuracy: 0.7541322314049587\n",
            "Epoch 2/5, Batch Loss: 0.3232036828994751, Average Training Loss: 0.6710213256663964, Training Accuracy: 0.7561475409836066\n",
            "Epoch 2/5, Batch Loss: 0.730343759059906, Average Training Loss: 0.6715036218728476, Training Accuracy: 0.7566056910569106\n",
            "Epoch 2/5, Batch Loss: 0.6757031679153442, Average Training Loss: 0.671537489179642, Training Accuracy: 0.7565524193548387\n",
            "Epoch 2/5, Batch Loss: 0.4141230285167694, Average Training Loss: 0.669478173494339, Training Accuracy: 0.7575\n",
            "Epoch 2/5, Batch Loss: 0.428241103887558, Average Training Loss: 0.6675635935768248, Training Accuracy: 0.7579365079365079\n",
            "Epoch 2/5, Batch Loss: 0.42959529161453247, Average Training Loss: 0.6656898274196414, Training Accuracy: 0.7583661417322834\n",
            "Epoch 2/5, Batch Loss: 0.6128683090209961, Average Training Loss: 0.665277159307152, Training Accuracy: 0.75830078125\n",
            "Epoch 2/5, Batch Loss: 0.6619029641151428, Average Training Loss: 0.665251002755276, Training Accuracy: 0.7582364341085271\n",
            "Epoch 2/5, Batch Loss: 0.6728492379188538, Average Training Loss: 0.6653094507180728, Training Accuracy: 0.7591346153846154\n",
            "Epoch 2/5, Batch Loss: 0.47048419713974, Average Training Loss: 0.6638222350419023, Training Accuracy: 0.7600190839694656\n",
            "Epoch 2/5, Batch Loss: 0.5669942498207092, Average Training Loss: 0.6630886896993174, Training Accuracy: 0.7599431818181818\n",
            "Epoch 2/5, Batch Loss: 1.3492871522903442, Average Training Loss: 0.6726735605873245, Training Accuracy: 0.759697256385998\n",
            "Epoch 2/5, Average Training Loss: 0.6682480766360921, Training Accuracy: 0.759697256385998\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.68      0.74      0.71       427\n",
            "                Educational Opportunity       0.64      0.61      0.62       451\n",
            "                         Family Support       0.92      0.97      0.94       396\n",
            "                      Financial Support       0.79      0.82      0.81       404\n",
            "                 Program Implementation       0.79      0.69      0.74       436\n",
            "\n",
            "                               accuracy                           0.76      2114\n",
            "                              macro avg       0.76      0.77      0.76      2114\n",
            "                           weighted avg       0.76      0.76      0.76      2114\n",
            "\n",
            "Epoch 2/5, Validation Loss: 26.436398714780807, Validation Accuracy: 0.7069943289224953\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.73      0.55      0.63       113\n",
            "                Educational Opportunity       0.47      0.75      0.58       100\n",
            "                         Family Support       0.92      0.93      0.92       105\n",
            "                      Financial Support       0.71      0.77      0.74        97\n",
            "                 Program Implementation       0.86      0.56      0.68       114\n",
            "\n",
            "                               accuracy                           0.71       529\n",
            "                              macro avg       0.74      0.71      0.71       529\n",
            "                           weighted avg       0.74      0.71      0.71       529\n",
            "\n",
            "Epoch 3/5, Batch Loss: 0.6980061531066895, Average Training Loss: 0.6980061531066895, Training Accuracy: 0.75\n",
            "Epoch 3/5, Batch Loss: 0.3392913341522217, Average Training Loss: 0.5186487436294556, Training Accuracy: 0.8125\n",
            "Epoch 3/5, Batch Loss: 0.9909228682518005, Average Training Loss: 0.6760734518369039, Training Accuracy: 0.7291666666666666\n",
            "Epoch 3/5, Batch Loss: 0.39976340532302856, Average Training Loss: 0.6069959402084351, Training Accuracy: 0.765625\n",
            "Epoch 3/5, Batch Loss: 0.34572404623031616, Average Training Loss: 0.5547415614128113, Training Accuracy: 0.7875\n",
            "Epoch 3/5, Batch Loss: 0.2728191614151001, Average Training Loss: 0.5077544947465261, Training Accuracy: 0.8229166666666666\n",
            "Epoch 3/5, Batch Loss: 0.8234121799468994, Average Training Loss: 0.5528484497751508, Training Accuracy: 0.7946428571428571\n",
            "Epoch 3/5, Batch Loss: 0.2956237494945526, Average Training Loss: 0.5206953622400761, Training Accuracy: 0.8046875\n",
            "Epoch 3/5, Batch Loss: 0.6644622087478638, Average Training Loss: 0.5366694562964969, Training Accuracy: 0.7916666666666666\n",
            "Epoch 3/5, Batch Loss: 0.6352142095565796, Average Training Loss: 0.5465239316225052, Training Accuracy: 0.7875\n",
            "Epoch 3/5, Batch Loss: 0.29367661476135254, Average Training Loss: 0.523537811907855, Training Accuracy: 0.7954545454545454\n",
            "Epoch 3/5, Batch Loss: 0.4803442656993866, Average Training Loss: 0.5199383497238159, Training Accuracy: 0.8020833333333334\n",
            "Epoch 3/5, Batch Loss: 0.22818411886692047, Average Training Loss: 0.4974957165809778, Training Accuracy: 0.8125\n",
            "Epoch 3/5, Batch Loss: 0.39074528217315674, Average Training Loss: 0.4898706855518477, Training Accuracy: 0.8125\n",
            "Epoch 3/5, Batch Loss: 0.5040560364723206, Average Training Loss: 0.49081637561321256, Training Accuracy: 0.8166666666666667\n",
            "Epoch 3/5, Batch Loss: 0.3596211075782776, Average Training Loss: 0.48261667136102915, Training Accuracy: 0.82421875\n",
            "Epoch 3/5, Batch Loss: 0.5311266183853149, Average Training Loss: 0.4854701976565754, Training Accuracy: 0.8198529411764706\n",
            "Epoch 3/5, Batch Loss: 0.24437104165554047, Average Training Loss: 0.47207580010096234, Training Accuracy: 0.8298611111111112\n",
            "Epoch 3/5, Batch Loss: 0.3704199194908142, Average Training Loss: 0.46672549059516505, Training Accuracy: 0.8322368421052632\n",
            "Epoch 3/5, Batch Loss: 0.26909732818603516, Average Training Loss: 0.45684408247470853, Training Accuracy: 0.8375\n",
            "Epoch 3/5, Batch Loss: 0.16566075384616852, Average Training Loss: 0.4429782096828733, Training Accuracy: 0.8452380952380952\n",
            "Epoch 3/5, Batch Loss: 0.33248254656791687, Average Training Loss: 0.4379556795412844, Training Accuracy: 0.8465909090909091\n",
            "Epoch 3/5, Batch Loss: 0.6259929537773132, Average Training Loss: 0.4461312132037204, Training Accuracy: 0.845108695652174\n",
            "Epoch 3/5, Batch Loss: 0.2870132029056549, Average Training Loss: 0.4395012961079677, Training Accuracy: 0.8463541666666666\n",
            "Epoch 3/5, Batch Loss: 0.278972864151001, Average Training Loss: 0.43308015882968903, Training Accuracy: 0.85\n",
            "Epoch 3/5, Batch Loss: 0.4616565704345703, Average Training Loss: 0.43417925158372295, Training Accuracy: 0.8509615384615384\n",
            "Epoch 3/5, Batch Loss: 0.3451232314109802, Average Training Loss: 0.4308808804662139, Training Accuracy: 0.8541666666666666\n",
            "Epoch 3/5, Batch Loss: 0.6617631316184998, Average Training Loss: 0.43912667515022413, Training Accuracy: 0.8482142857142857\n",
            "Epoch 3/5, Batch Loss: 0.2188086360692978, Average Training Loss: 0.4315295013888129, Training Accuracy: 0.8491379310344828\n",
            "Epoch 3/5, Batch Loss: 0.24088862538337708, Average Training Loss: 0.425174805521965, Training Accuracy: 0.8520833333333333\n",
            "Epoch 3/5, Batch Loss: 0.8240953683853149, Average Training Loss: 0.43804321077562147, Training Accuracy: 0.8487903225806451\n",
            "Epoch 3/5, Batch Loss: 0.36783090233802795, Average Training Loss: 0.4358490761369467, Training Accuracy: 0.84765625\n",
            "Epoch 3/5, Batch Loss: 0.7651135325431824, Average Training Loss: 0.4458267869371356, Training Accuracy: 0.8446969696969697\n",
            "Epoch 3/5, Batch Loss: 0.46223944425582886, Average Training Loss: 0.44630951215239134, Training Accuracy: 0.84375\n",
            "Epoch 3/5, Batch Loss: 0.4524052143096924, Average Training Loss: 0.44648367507117137, Training Accuracy: 0.8410714285714286\n",
            "Epoch 3/5, Batch Loss: 0.8522282242774963, Average Training Loss: 0.45775435699356926, Training Accuracy: 0.8368055555555556\n",
            "Epoch 3/5, Batch Loss: 0.70530766248703, Average Training Loss: 0.46444498687177094, Training Accuracy: 0.8361486486486487\n",
            "Epoch 3/5, Batch Loss: 0.5248519778251648, Average Training Loss: 0.4660346445284392, Training Accuracy: 0.837171052631579\n",
            "Epoch 3/5, Batch Loss: 0.4729653298854828, Average Training Loss: 0.466212354409389, Training Accuracy: 0.8381410256410257\n",
            "Epoch 3/5, Batch Loss: 0.8753155469894409, Average Training Loss: 0.4764399342238903, Training Accuracy: 0.834375\n",
            "Epoch 3/5, Batch Loss: 0.38557085394859314, Average Training Loss: 0.4742236151927855, Training Accuracy: 0.8353658536585366\n",
            "Epoch 3/5, Batch Loss: 0.7854436039924622, Average Training Loss: 0.4816336149261111, Training Accuracy: 0.8318452380952381\n",
            "Epoch 3/5, Batch Loss: 0.5620139241218567, Average Training Loss: 0.48350292444229126, Training Accuracy: 0.8313953488372093\n",
            "Epoch 3/5, Batch Loss: 0.4636441767215729, Average Training Loss: 0.4830515892668204, Training Accuracy: 0.8323863636363636\n",
            "Epoch 3/5, Batch Loss: 0.40521103143692017, Average Training Loss: 0.4813217990928226, Training Accuracy: 0.8333333333333334\n",
            "Epoch 3/5, Batch Loss: 0.6565940976142883, Average Training Loss: 0.4851320664519849, Training Accuracy: 0.8315217391304348\n",
            "Epoch 3/5, Batch Loss: 0.42279213666915894, Average Training Loss: 0.4838056849672439, Training Accuracy: 0.8324468085106383\n",
            "Epoch 3/5, Batch Loss: 0.45519089698791504, Average Training Loss: 0.4832095435510079, Training Accuracy: 0.83203125\n",
            "Epoch 3/5, Batch Loss: 0.46691879630088806, Average Training Loss: 0.4828770793214136, Training Accuracy: 0.8341836734693877\n",
            "Epoch 3/5, Batch Loss: 0.5015814900398254, Average Training Loss: 0.48325116753578184, Training Accuracy: 0.835\n",
            "Epoch 3/5, Batch Loss: 0.26832032203674316, Average Training Loss: 0.4790368372318791, Training Accuracy: 0.8370098039215687\n",
            "Epoch 3/5, Batch Loss: 0.44864019751548767, Average Training Loss: 0.4784522864681024, Training Accuracy: 0.8365384615384616\n",
            "Epoch 3/5, Batch Loss: 0.21184216439723969, Average Training Loss: 0.473421906806388, Training Accuracy: 0.839622641509434\n",
            "Epoch 3/5, Batch Loss: 0.3317878246307373, Average Training Loss: 0.47079905343276485, Training Accuracy: 0.8402777777777778\n",
            "Epoch 3/5, Batch Loss: 0.5881133675575256, Average Training Loss: 0.47293204096230596, Training Accuracy: 0.8397727272727272\n",
            "Epoch 3/5, Batch Loss: 0.5220848917961121, Average Training Loss: 0.47380977044148104, Training Accuracy: 0.8392857142857143\n",
            "Epoch 3/5, Batch Loss: 0.6325703263282776, Average Training Loss: 0.4765950433517757, Training Accuracy: 0.8377192982456141\n",
            "Epoch 3/5, Batch Loss: 0.5873456001281738, Average Training Loss: 0.47850453570998946, Training Accuracy: 0.8362068965517241\n",
            "Epoch 3/5, Batch Loss: 0.356747031211853, Average Training Loss: 0.4764408491930719, Training Accuracy: 0.836864406779661\n",
            "Epoch 3/5, Batch Loss: 0.28664520382881165, Average Training Loss: 0.4732775884370009, Training Accuracy: 0.8375\n",
            "Epoch 3/5, Batch Loss: 0.6919006705284119, Average Training Loss: 0.4768615733893191, Training Accuracy: 0.8350409836065574\n",
            "Epoch 3/5, Batch Loss: 0.29516199231147766, Average Training Loss: 0.4739309349848378, Training Accuracy: 0.8346774193548387\n",
            "Epoch 3/5, Batch Loss: 0.41935110092163086, Average Training Loss: 0.47306458841240595, Training Accuracy: 0.8363095238095238\n",
            "Epoch 3/5, Batch Loss: 0.24209293723106384, Average Training Loss: 0.4694556563626975, Training Accuracy: 0.837890625\n",
            "Epoch 3/5, Batch Loss: 0.5752593278884888, Average Training Loss: 0.471083405155402, Training Accuracy: 0.8375\n",
            "Epoch 3/5, Batch Loss: 0.5549423098564148, Average Training Loss: 0.4723539946205688, Training Accuracy: 0.8371212121212122\n",
            "Epoch 3/5, Batch Loss: 0.27673375606536865, Average Training Loss: 0.46943428956750616, Training Accuracy: 0.8386194029850746\n",
            "Epoch 3/5, Batch Loss: 0.34788158535957336, Average Training Loss: 0.4676467497997424, Training Accuracy: 0.8400735294117647\n",
            "Epoch 3/5, Batch Loss: 0.3704245090484619, Average Training Loss: 0.4662377318178398, Training Accuracy: 0.8405797101449275\n",
            "Epoch 3/5, Batch Loss: 0.5441781282424927, Average Training Loss: 0.4673511660524777, Training Accuracy: 0.8410714285714286\n",
            "Epoch 3/5, Batch Loss: 0.6128528714179993, Average Training Loss: 0.4694004858463583, Training Accuracy: 0.8397887323943662\n",
            "Epoch 3/5, Batch Loss: 0.16877411305904388, Average Training Loss: 0.46522511955764556, Training Accuracy: 0.8420138888888888\n",
            "Epoch 3/5, Batch Loss: 0.586184561252594, Average Training Loss: 0.466882098211001, Training Accuracy: 0.8407534246575342\n",
            "Epoch 3/5, Batch Loss: 0.37947359681129456, Average Training Loss: 0.46570090224614014, Training Accuracy: 0.8420608108108109\n",
            "Epoch 3/5, Batch Loss: 0.27018070220947266, Average Training Loss: 0.46309396624565125, Training Accuracy: 0.8433333333333334\n",
            "Epoch 3/5, Batch Loss: 0.4149174392223358, Average Training Loss: 0.46246006457429184, Training Accuracy: 0.84375\n",
            "Epoch 3/5, Batch Loss: 0.5460007786750793, Average Training Loss: 0.4635450089132631, Training Accuracy: 0.8433441558441559\n",
            "Epoch 3/5, Batch Loss: 0.5878360867500305, Average Training Loss: 0.46513848427014476, Training Accuracy: 0.8413461538461539\n",
            "Epoch 3/5, Batch Loss: 0.3938651382923126, Average Training Loss: 0.4642362900172608, Training Accuracy: 0.8409810126582279\n",
            "Epoch 3/5, Batch Loss: 0.5504177212715149, Average Training Loss: 0.46531355790793894, Training Accuracy: 0.83984375\n",
            "Epoch 3/5, Batch Loss: 0.2948889136314392, Average Training Loss: 0.4632095499539081, Training Accuracy: 0.8402777777777778\n",
            "Epoch 3/5, Batch Loss: 0.6298857927322388, Average Training Loss: 0.46524218706096093, Training Accuracy: 0.8391768292682927\n",
            "Epoch 3/5, Batch Loss: 0.33755239844322205, Average Training Loss: 0.4637037558727954, Training Accuracy: 0.8396084337349398\n",
            "Epoch 3/5, Batch Loss: 0.4808122515678406, Average Training Loss: 0.4639074284405935, Training Accuracy: 0.8392857142857143\n",
            "Epoch 3/5, Batch Loss: 0.2328748255968094, Average Training Loss: 0.46118939781890195, Training Accuracy: 0.8404411764705882\n",
            "Epoch 3/5, Batch Loss: 0.29096126556396484, Average Training Loss: 0.45921000093221664, Training Accuracy: 0.8415697674418605\n",
            "Epoch 3/5, Batch Loss: 0.4592857360839844, Average Training Loss: 0.4592108714512025, Training Accuracy: 0.8412356321839081\n",
            "Epoch 3/5, Batch Loss: 0.9332073926925659, Average Training Loss: 0.464597195556218, Training Accuracy: 0.8387784090909091\n",
            "Epoch 3/5, Batch Loss: 0.4431403577327728, Average Training Loss: 0.464356107490786, Training Accuracy: 0.8398876404494382\n",
            "Epoch 3/5, Batch Loss: 0.47912222146987915, Average Training Loss: 0.464520175423887, Training Accuracy: 0.8388888888888889\n",
            "Epoch 3/5, Batch Loss: 0.5272510051727295, Average Training Loss: 0.46520952520134684, Training Accuracy: 0.8379120879120879\n",
            "Epoch 3/5, Batch Loss: 0.5413002371788025, Average Training Loss: 0.46603659815762355, Training Accuracy: 0.8383152173913043\n",
            "Epoch 3/5, Batch Loss: 0.5881081819534302, Average Training Loss: 0.4673491958328473, Training Accuracy: 0.8380376344086021\n",
            "Epoch 3/5, Batch Loss: 0.591423749923706, Average Training Loss: 0.46866913789764364, Training Accuracy: 0.8377659574468085\n",
            "Epoch 3/5, Batch Loss: 0.48225629329681396, Average Training Loss: 0.46881216058605596, Training Accuracy: 0.8375\n",
            "Epoch 3/5, Batch Loss: 0.36070433259010315, Average Training Loss: 0.46768603737776476, Training Accuracy: 0.837890625\n",
            "Epoch 3/5, Batch Loss: 0.4472447633743286, Average Training Loss: 0.4674753025942242, Training Accuracy: 0.8376288659793815\n",
            "Epoch 3/5, Batch Loss: 0.2392517626285553, Average Training Loss: 0.46514649096192145, Training Accuracy: 0.8386479591836735\n",
            "Epoch 3/5, Batch Loss: 0.40428677201271057, Average Training Loss: 0.46453174632607086, Training Accuracy: 0.8383838383838383\n",
            "Epoch 3/5, Batch Loss: 0.24387681484222412, Average Training Loss: 0.46232519701123237, Training Accuracy: 0.839375\n",
            "Epoch 3/5, Batch Loss: 0.6073511242866516, Average Training Loss: 0.463761097281286, Training Accuracy: 0.8391089108910891\n",
            "Epoch 3/5, Batch Loss: 0.4079524576663971, Average Training Loss: 0.4632139537556499, Training Accuracy: 0.8394607843137255\n",
            "Epoch 3/5, Batch Loss: 0.3488702178001404, Average Training Loss: 0.4621038203968585, Training Accuracy: 0.8398058252427184\n",
            "Epoch 3/5, Batch Loss: 0.18998223543167114, Average Training Loss: 0.4594872666952702, Training Accuracy: 0.8413461538461539\n",
            "Epoch 3/5, Batch Loss: 0.6671014428138733, Average Training Loss: 0.4614645445630664, Training Accuracy: 0.8404761904761905\n",
            "Epoch 3/5, Batch Loss: 0.13622261583805084, Average Training Loss: 0.4583962244807549, Training Accuracy: 0.8419811320754716\n",
            "Epoch 3/5, Batch Loss: 0.3384372889995575, Average Training Loss: 0.4572751129342017, Training Accuracy: 0.8422897196261683\n",
            "Epoch 3/5, Batch Loss: 0.6951431632041931, Average Training Loss: 0.45947759488114603, Training Accuracy: 0.8414351851851852\n",
            "Epoch 3/5, Batch Loss: 0.534569501876831, Average Training Loss: 0.4601665114590881, Training Accuracy: 0.841743119266055\n",
            "Epoch 3/5, Batch Loss: 0.5555689334869385, Average Training Loss: 0.46103380620479584, Training Accuracy: 0.8414772727272727\n",
            "Epoch 3/5, Batch Loss: 0.5498768091201782, Average Training Loss: 0.4618341936184479, Training Accuracy: 0.8412162162162162\n",
            "Epoch 3/5, Batch Loss: 0.8046456575393677, Average Training Loss: 0.464895010260599, Training Accuracy: 0.83984375\n",
            "Epoch 3/5, Batch Loss: 0.8558558821678162, Average Training Loss: 0.4683548409854416, Training Accuracy: 0.838495575221239\n",
            "Epoch 3/5, Batch Loss: 0.4263991713523865, Average Training Loss: 0.467986808795678, Training Accuracy: 0.8388157894736842\n",
            "Epoch 3/5, Batch Loss: 0.8422491550445557, Average Training Loss: 0.47124126398045085, Training Accuracy: 0.8375\n",
            "Epoch 3/5, Batch Loss: 0.31849369406700134, Average Training Loss: 0.46992447458464526, Training Accuracy: 0.8383620689655172\n",
            "Epoch 3/5, Batch Loss: 0.2584737539291382, Average Training Loss: 0.4681172034679315, Training Accuracy: 0.8392094017094017\n",
            "Epoch 3/5, Batch Loss: 0.346284955739975, Average Training Loss: 0.46708472679227087, Training Accuracy: 0.840042372881356\n",
            "Epoch 3/5, Batch Loss: 0.2807982861995697, Average Training Loss: 0.4655192945183826, Training Accuracy: 0.8403361344537815\n",
            "Epoch 3/5, Batch Loss: 0.4627816081047058, Average Training Loss: 0.4654964804649353, Training Accuracy: 0.8395833333333333\n",
            "Epoch 3/5, Batch Loss: 0.9430422782897949, Average Training Loss: 0.46944313995109116, Training Accuracy: 0.8378099173553719\n",
            "Epoch 3/5, Batch Loss: 0.36014440655708313, Average Training Loss: 0.46854724869376324, Training Accuracy: 0.8386270491803278\n",
            "Epoch 3/5, Batch Loss: 0.19907167553901672, Average Training Loss: 0.466356390375432, Training Accuracy: 0.8394308943089431\n",
            "Epoch 3/5, Batch Loss: 0.4022314250469208, Average Training Loss: 0.46583925355826655, Training Accuracy: 0.8397177419354839\n",
            "Epoch 3/5, Batch Loss: 0.4543353319168091, Average Training Loss: 0.46574722218513487, Training Accuracy: 0.839\n",
            "Epoch 3/5, Batch Loss: 0.38995760679244995, Average Training Loss: 0.46514571730106596, Training Accuracy: 0.8392857142857143\n",
            "Epoch 3/5, Batch Loss: 0.8303471803665161, Average Training Loss: 0.46802131937244745, Training Accuracy: 0.8385826771653543\n",
            "Epoch 3/5, Batch Loss: 0.23096850514411926, Average Training Loss: 0.46616934426128864, Training Accuracy: 0.83935546875\n",
            "Epoch 3/5, Batch Loss: 0.38172951340675354, Average Training Loss: 0.46551477192908297, Training Accuracy: 0.8396317829457365\n",
            "Epoch 3/5, Batch Loss: 0.2360745519399643, Average Training Loss: 0.4637498471599359, Training Accuracy: 0.8403846153846154\n",
            "Epoch 3/5, Batch Loss: 0.3021957576274872, Average Training Loss: 0.4625166098352607, Training Accuracy: 0.8406488549618321\n",
            "Epoch 3/5, Batch Loss: 0.266084223985672, Average Training Loss: 0.4610284857000365, Training Accuracy: 0.8413825757575758\n",
            "Epoch 3/5, Batch Loss: 0.3650268316268921, Average Training Loss: 0.4633550572869004, Training Accuracy: 0.8415326395458845\n",
            "Epoch 3/5, Average Training Loss: 0.4603066687521182, Training Accuracy: 0.8415326395458845\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.84      0.85      0.85       427\n",
            "                Educational Opportunity       0.73      0.75      0.74       451\n",
            "                         Family Support       0.96      0.97      0.96       396\n",
            "                      Financial Support       0.85      0.88      0.86       404\n",
            "                 Program Implementation       0.84      0.77      0.80       436\n",
            "\n",
            "                               accuracy                           0.84      2114\n",
            "                              macro avg       0.84      0.85      0.84      2114\n",
            "                           weighted avg       0.84      0.84      0.84      2114\n",
            "\n",
            "Epoch 3/5, Validation Loss: 26.229723386466503, Validation Accuracy: 0.718336483931947\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.70      0.64      0.67       113\n",
            "                Educational Opportunity       0.50      0.74      0.60       100\n",
            "                         Family Support       0.93      0.94      0.93       105\n",
            "                      Financial Support       0.72      0.72      0.72        97\n",
            "                 Program Implementation       0.88      0.57      0.69       114\n",
            "\n",
            "                               accuracy                           0.72       529\n",
            "                              macro avg       0.74      0.72      0.72       529\n",
            "                           weighted avg       0.75      0.72      0.72       529\n",
            "\n",
            "Epoch 4/5, Batch Loss: 0.431654691696167, Average Training Loss: 0.431654691696167, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.30709734559059143, Average Training Loss: 0.3693760186433792, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.10925458371639252, Average Training Loss: 0.282668873667717, Training Accuracy: 0.9166666666666666\n",
            "Epoch 4/5, Batch Loss: 0.42556798458099365, Average Training Loss: 0.31839365139603615, Training Accuracy: 0.890625\n",
            "Epoch 4/5, Batch Loss: 0.28212806582450867, Average Training Loss: 0.31114053428173066, Training Accuracy: 0.9\n",
            "Epoch 4/5, Batch Loss: 0.6078920364379883, Average Training Loss: 0.3605991179744403, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/5, Batch Loss: 0.198184072971344, Average Training Loss: 0.33739696868828367, Training Accuracy: 0.8928571428571429\n",
            "Epoch 4/5, Batch Loss: 0.470335990190506, Average Training Loss: 0.35401434637606144, Training Accuracy: 0.8828125\n",
            "Epoch 4/5, Batch Loss: 0.6424078345298767, Average Training Loss: 0.3860580672820409, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.24583259224891663, Average Training Loss: 0.3720355197787285, Training Accuracy: 0.88125\n",
            "Epoch 4/5, Batch Loss: 0.3196999728679657, Average Training Loss: 0.36727774278684094, Training Accuracy: 0.8806818181818182\n",
            "Epoch 4/5, Batch Loss: 0.33263126015663147, Average Training Loss: 0.3643905359009902, Training Accuracy: 0.8802083333333334\n",
            "Epoch 4/5, Batch Loss: 0.5004680156707764, Average Training Loss: 0.3748580343448199, Training Accuracy: 0.8701923076923077\n",
            "Epoch 4/5, Batch Loss: 0.22394852340221405, Average Training Loss: 0.36407878356320517, Training Accuracy: 0.8794642857142857\n",
            "Epoch 4/5, Batch Loss: 0.25142499804496765, Average Training Loss: 0.35656853119532267, Training Accuracy: 0.8791666666666667\n",
            "Epoch 4/5, Batch Loss: 0.5130197405815125, Average Training Loss: 0.36634673178195953, Training Accuracy: 0.875\n",
            "Epoch 4/5, Batch Loss: 0.27430450916290283, Average Training Loss: 0.36093248339260325, Training Accuracy: 0.8786764705882353\n",
            "Epoch 4/5, Batch Loss: 0.32958048582077026, Average Training Loss: 0.35919070574972367, Training Accuracy: 0.8784722222222222\n",
            "Epoch 4/5, Batch Loss: 0.2657298147678375, Average Training Loss: 0.3542717114875191, Training Accuracy: 0.881578947368421\n",
            "Epoch 4/5, Batch Loss: 0.2462010532617569, Average Training Loss: 0.348868178576231, Training Accuracy: 0.884375\n",
            "Epoch 4/5, Batch Loss: 0.0978505089879036, Average Training Loss: 0.3369149562148821, Training Accuracy: 0.8898809523809523\n",
            "Epoch 4/5, Batch Loss: 0.21485456824302673, Average Training Loss: 0.3313667567616159, Training Accuracy: 0.8920454545454546\n",
            "Epoch 4/5, Batch Loss: 0.14639391005039215, Average Training Loss: 0.32332445907851926, Training Accuracy: 0.8967391304347826\n",
            "Epoch 4/5, Batch Loss: 0.14351718127727509, Average Training Loss: 0.31583248917013407, Training Accuracy: 0.8984375\n",
            "Epoch 4/5, Batch Loss: 0.1540389358997345, Average Training Loss: 0.3093607470393181, Training Accuracy: 0.9025\n",
            "Epoch 4/5, Batch Loss: 0.4583510458469391, Average Training Loss: 0.3150911431473035, Training Accuracy: 0.9014423076923077\n",
            "Epoch 4/5, Batch Loss: 0.3602120280265808, Average Training Loss: 0.3167622870317212, Training Accuracy: 0.9004629629629629\n",
            "Epoch 4/5, Batch Loss: 0.19719913601875305, Average Training Loss: 0.31249217449554373, Training Accuracy: 0.9017857142857143\n",
            "Epoch 4/5, Batch Loss: 0.45946818590164185, Average Training Loss: 0.31756031281989194, Training Accuracy: 0.8987068965517241\n",
            "Epoch 4/5, Batch Loss: 0.23929576575756073, Average Training Loss: 0.3149514945844809, Training Accuracy: 0.8979166666666667\n",
            "Epoch 4/5, Batch Loss: 0.4842182397842407, Average Training Loss: 0.32041171217156994, Training Accuracy: 0.8951612903225806\n",
            "Epoch 4/5, Batch Loss: 0.30823418498039246, Average Training Loss: 0.32003116444684565, Training Accuracy: 0.896484375\n",
            "Epoch 4/5, Batch Loss: 0.5270477533340454, Average Training Loss: 0.3263043944131244, Training Accuracy: 0.8958333333333334\n",
            "Epoch 4/5, Batch Loss: 0.25141286849975586, Average Training Loss: 0.32410170247449593, Training Accuracy: 0.8988970588235294\n",
            "Epoch 4/5, Batch Loss: 0.18500041961669922, Average Training Loss: 0.3201273801071303, Training Accuracy: 0.9017857142857143\n",
            "Epoch 4/5, Batch Loss: 0.4577895402908325, Average Training Loss: 0.32395132900112206, Training Accuracy: 0.8993055555555556\n",
            "Epoch 4/5, Batch Loss: 0.3847425580024719, Average Training Loss: 0.32559433519034775, Training Accuracy: 0.8986486486486487\n",
            "Epoch 4/5, Batch Loss: 0.5177450180053711, Average Training Loss: 0.33065093210653257, Training Accuracy: 0.8947368421052632\n",
            "Epoch 4/5, Batch Loss: 0.6395012736320496, Average Training Loss: 0.3385701716328279, Training Accuracy: 0.8894230769230769\n",
            "Epoch 4/5, Batch Loss: 0.19446469843387604, Average Training Loss: 0.33496753480285407, Training Accuracy: 0.890625\n",
            "Epoch 4/5, Batch Loss: 0.26327279210090637, Average Training Loss: 0.33321888254183096, Training Accuracy: 0.8917682926829268\n",
            "Epoch 4/5, Batch Loss: 0.2990792393684387, Average Training Loss: 0.3324060338948454, Training Accuracy: 0.8913690476190477\n",
            "Epoch 4/5, Batch Loss: 0.2827504575252533, Average Training Loss: 0.33125125304904096, Training Accuracy: 0.8909883720930233\n",
            "Epoch 4/5, Batch Loss: 0.17296051979064941, Average Training Loss: 0.3276537363840775, Training Accuracy: 0.8920454545454546\n",
            "Epoch 4/5, Batch Loss: 0.40873706340789795, Average Training Loss: 0.32945558809571795, Training Accuracy: 0.8916666666666667\n",
            "Epoch 4/5, Batch Loss: 0.4380786418914795, Average Training Loss: 0.3318169588304084, Training Accuracy: 0.8913043478260869\n",
            "Epoch 4/5, Batch Loss: 0.36585327982902527, Average Training Loss: 0.3325411358729322, Training Accuracy: 0.8909574468085106\n",
            "Epoch 4/5, Batch Loss: 0.4657188653945923, Average Training Loss: 0.33531567190463346, Training Accuracy: 0.8893229166666666\n",
            "Epoch 4/5, Batch Loss: 0.5134561061859131, Average Training Loss: 0.3389511909715983, Training Accuracy: 0.889030612244898\n",
            "Epoch 4/5, Batch Loss: 0.17960494756698608, Average Training Loss: 0.33576426610350607, Training Accuracy: 0.89125\n",
            "Epoch 4/5, Batch Loss: 0.4304291903972626, Average Training Loss: 0.33762044108965816, Training Accuracy: 0.8897058823529411\n",
            "Epoch 4/5, Batch Loss: 0.18796560168266296, Average Training Loss: 0.3347424634087544, Training Accuracy: 0.890625\n",
            "Epoch 4/5, Batch Loss: 0.728844404220581, Average Training Loss: 0.3421783490844493, Training Accuracy: 0.8867924528301887\n",
            "Epoch 4/5, Batch Loss: 0.7491652965545654, Average Training Loss: 0.3497151444079699, Training Accuracy: 0.8842592592592593\n",
            "Epoch 4/5, Batch Loss: 0.5020201802253723, Average Training Loss: 0.35248432687737724, Training Accuracy: 0.8818181818181818\n",
            "Epoch 4/5, Batch Loss: 0.20611104369163513, Average Training Loss: 0.3498705182490604, Training Accuracy: 0.8839285714285714\n",
            "Epoch 4/5, Batch Loss: 0.33029621839523315, Average Training Loss: 0.349527109479695, Training Accuracy: 0.8826754385964912\n",
            "Epoch 4/5, Batch Loss: 0.21378371119499207, Average Training Loss: 0.3471867060609933, Training Accuracy: 0.8836206896551724\n",
            "Epoch 4/5, Batch Loss: 0.468173623085022, Average Training Loss: 0.34923733177326494, Training Accuracy: 0.8834745762711864\n",
            "Epoch 4/5, Batch Loss: 0.25616297125816345, Average Training Loss: 0.34768609243134657, Training Accuracy: 0.884375\n",
            "Epoch 4/5, Batch Loss: 0.29969358444213867, Average Training Loss: 0.346899330005294, Training Accuracy: 0.8842213114754098\n",
            "Epoch 4/5, Batch Loss: 0.187851682305336, Average Training Loss: 0.3443340453649721, Training Accuracy: 0.8850806451612904\n",
            "Epoch 4/5, Batch Loss: 0.733575165271759, Average Training Loss: 0.350512475839683, Training Accuracy: 0.8819444444444444\n",
            "Epoch 4/5, Batch Loss: 0.09294980019330978, Average Training Loss: 0.3464880590327084, Training Accuracy: 0.8837890625\n",
            "Epoch 4/5, Batch Loss: 0.4811501204967499, Average Training Loss: 0.3485597830552321, Training Accuracy: 0.8826923076923077\n",
            "Epoch 4/5, Batch Loss: 0.5569695234298706, Average Training Loss: 0.3517175063942418, Training Accuracy: 0.8806818181818182\n",
            "Epoch 4/5, Batch Loss: 0.14637595415115356, Average Training Loss: 0.3486527071070315, Training Accuracy: 0.8824626865671642\n",
            "Epoch 4/5, Batch Loss: 0.38769984245300293, Average Training Loss: 0.3492269296856487, Training Accuracy: 0.8814338235294118\n",
            "Epoch 4/5, Batch Loss: 0.46312573552131653, Average Training Loss: 0.35087763701660046, Training Accuracy: 0.8804347826086957\n",
            "Epoch 4/5, Batch Loss: 0.2958381474018097, Average Training Loss: 0.350091358593532, Training Accuracy: 0.88125\n",
            "Epoch 4/5, Batch Loss: 0.7040802836418152, Average Training Loss: 0.3550771181012543, Training Accuracy: 0.8776408450704225\n",
            "Epoch 4/5, Batch Loss: 0.15207132697105408, Average Training Loss: 0.352257593224446, Training Accuracy: 0.8784722222222222\n",
            "Epoch 4/5, Batch Loss: 0.14366179704666138, Average Training Loss: 0.34940011656447634, Training Accuracy: 0.8801369863013698\n",
            "Epoch 4/5, Batch Loss: 0.6050440669059753, Average Training Loss: 0.35285476454206416, Training Accuracy: 0.8783783783783784\n",
            "Epoch 4/5, Batch Loss: 0.18044491112232208, Average Training Loss: 0.3505559664964676, Training Accuracy: 0.8791666666666667\n",
            "Epoch 4/5, Batch Loss: 0.22482211887836456, Average Training Loss: 0.3489015737646504, Training Accuracy: 0.8791118421052632\n",
            "Epoch 4/5, Batch Loss: 0.12102334201335907, Average Training Loss: 0.3459421162094389, Training Accuracy: 0.8806818181818182\n",
            "Epoch 4/5, Batch Loss: 0.33804309368133545, Average Training Loss: 0.3458408466898478, Training Accuracy: 0.8806089743589743\n",
            "Epoch 4/5, Batch Loss: 0.354317307472229, Average Training Loss: 0.3459481436617767, Training Accuracy: 0.8805379746835443\n",
            "Epoch 4/5, Batch Loss: 0.24164839088916779, Average Training Loss: 0.34464439675211905, Training Accuracy: 0.88203125\n",
            "Epoch 4/5, Batch Loss: 0.1799013763666153, Average Training Loss: 0.3426105323029153, Training Accuracy: 0.8827160493827161\n",
            "Epoch 4/5, Batch Loss: 0.4090847969055176, Average Training Loss: 0.3434211940663617, Training Accuracy: 0.8833841463414634\n",
            "Epoch 4/5, Batch Loss: 0.3884900212287903, Average Training Loss: 0.3439641919839813, Training Accuracy: 0.8817771084337349\n",
            "Epoch 4/5, Batch Loss: 0.1902831643819809, Average Training Loss: 0.3421346559411004, Training Accuracy: 0.8824404761904762\n",
            "Epoch 4/5, Batch Loss: 0.21287131309509277, Average Training Loss: 0.34061391073114733, Training Accuracy: 0.8823529411764706\n",
            "Epoch 4/5, Batch Loss: 0.3577107787132263, Average Training Loss: 0.3408127115216366, Training Accuracy: 0.8822674418604651\n",
            "Epoch 4/5, Batch Loss: 0.43472734093666077, Average Training Loss: 0.34189219002065985, Training Accuracy: 0.8814655172413793\n",
            "Epoch 4/5, Batch Loss: 0.34804147481918335, Average Training Loss: 0.34196206825700676, Training Accuracy: 0.8813920454545454\n",
            "Epoch 4/5, Batch Loss: 0.07901011407375336, Average Training Loss: 0.3390075519178691, Training Accuracy: 0.8827247191011236\n",
            "Epoch 4/5, Batch Loss: 0.4589158892631531, Average Training Loss: 0.3403398667772611, Training Accuracy: 0.88125\n",
            "Epoch 4/5, Batch Loss: 0.3262268304824829, Average Training Loss: 0.3401847784663295, Training Accuracy: 0.8818681318681318\n",
            "Epoch 4/5, Batch Loss: 0.24005836248397827, Average Training Loss: 0.33909644785782567, Training Accuracy: 0.8824728260869565\n",
            "Epoch 4/5, Batch Loss: 0.32849085330963135, Average Training Loss: 0.3389824092067698, Training Accuracy: 0.8823924731182796\n",
            "Epoch 4/5, Batch Loss: 0.29544520378112793, Average Training Loss: 0.3385192474469225, Training Accuracy: 0.882313829787234\n",
            "Epoch 4/5, Batch Loss: 0.3682895004749298, Average Training Loss: 0.3388326185314279, Training Accuracy: 0.881578947368421\n",
            "Epoch 4/5, Batch Loss: 0.2762337923049927, Average Training Loss: 0.3381805474249025, Training Accuracy: 0.8815104166666666\n",
            "Epoch 4/5, Batch Loss: 0.3557486832141876, Average Training Loss: 0.33836166222685393, Training Accuracy: 0.8807989690721649\n",
            "Epoch 4/5, Batch Loss: 0.1826612502336502, Average Training Loss: 0.33677288251263754, Training Accuracy: 0.8813775510204082\n",
            "Epoch 4/5, Batch Loss: 0.21352219581604004, Average Training Loss: 0.3355279260813588, Training Accuracy: 0.8819444444444444\n",
            "Epoch 4/5, Batch Loss: 0.5911373496055603, Average Training Loss: 0.3380840203166008, Training Accuracy: 0.88\n",
            "Epoch 4/5, Batch Loss: 0.5733678936958313, Average Training Loss: 0.3404135636173853, Training Accuracy: 0.8787128712871287\n",
            "Epoch 4/5, Batch Loss: 0.4196932911872864, Average Training Loss: 0.3411908158484627, Training Accuracy: 0.8786764705882353\n",
            "Epoch 4/5, Batch Loss: 0.41307497024536133, Average Training Loss: 0.3418887202600831, Training Accuracy: 0.8780339805825242\n",
            "Epoch 4/5, Batch Loss: 0.1949412226676941, Average Training Loss: 0.34047576355246395, Training Accuracy: 0.8786057692307693\n",
            "Epoch 4/5, Batch Loss: 0.2654033601284027, Average Training Loss: 0.33976078828175865, Training Accuracy: 0.8785714285714286\n",
            "Epoch 4/5, Batch Loss: 0.5955082774162292, Average Training Loss: 0.34217350044340455, Training Accuracy: 0.8785377358490566\n",
            "Epoch 4/5, Batch Loss: 0.37669023871421814, Average Training Loss: 0.34249608678238413, Training Accuracy: 0.8779205607476636\n",
            "Epoch 4/5, Batch Loss: 0.39884528517723083, Average Training Loss: 0.34301783861937346, Training Accuracy: 0.8784722222222222\n",
            "Epoch 4/5, Batch Loss: 0.5605565309524536, Average Training Loss: 0.345013606438943, Training Accuracy: 0.8778669724770642\n",
            "Epoch 4/5, Batch Loss: 0.7598198056221008, Average Training Loss: 0.3487845718860626, Training Accuracy: 0.8767045454545455\n",
            "Epoch 4/5, Batch Loss: 0.5397858023643494, Average Training Loss: 0.3505053036921733, Training Accuracy: 0.8761261261261262\n",
            "Epoch 4/5, Batch Loss: 0.11633903533220291, Average Training Loss: 0.3484145334389593, Training Accuracy: 0.8772321428571429\n",
            "Epoch 4/5, Batch Loss: 0.28313690423965454, Average Training Loss: 0.3478368553044522, Training Accuracy: 0.8777654867256637\n",
            "Epoch 4/5, Batch Loss: 0.33353373408317566, Average Training Loss: 0.34771138932882695, Training Accuracy: 0.8771929824561403\n",
            "Epoch 4/5, Batch Loss: 0.17015641927719116, Average Training Loss: 0.34616743306750836, Training Accuracy: 0.8777173913043478\n",
            "Epoch 4/5, Batch Loss: 0.1583174169063568, Average Training Loss: 0.344548036376464, Training Accuracy: 0.8787715517241379\n",
            "Epoch 4/5, Batch Loss: 0.22819596529006958, Average Training Loss: 0.3435535742304264, Training Accuracy: 0.8792735042735043\n",
            "Epoch 4/5, Batch Loss: 0.20235762000083923, Average Training Loss: 0.3423569983471248, Training Accuracy: 0.8797669491525424\n",
            "Epoch 4/5, Batch Loss: 0.25829827785491943, Average Training Loss: 0.3416506225446693, Training Accuracy: 0.8802521008403361\n",
            "Epoch 4/5, Batch Loss: 0.37387654185295105, Average Training Loss: 0.3419191718722383, Training Accuracy: 0.8807291666666667\n",
            "Epoch 4/5, Batch Loss: 0.30050644278526306, Average Training Loss: 0.34157691791284184, Training Accuracy: 0.8806818181818182\n",
            "Epoch 4/5, Batch Loss: 0.4899853467941284, Average Training Loss: 0.3427933804446556, Training Accuracy: 0.8801229508196722\n",
            "Epoch 4/5, Batch Loss: 0.2758132815361023, Average Training Loss: 0.34224882679499263, Training Accuracy: 0.8800813008130082\n",
            "Epoch 4/5, Batch Loss: 0.23643480241298676, Average Training Loss: 0.3413954878886861, Training Accuracy: 0.8805443548387096\n",
            "Epoch 4/5, Batch Loss: 0.3845387101173401, Average Training Loss: 0.34174063366651536, Training Accuracy: 0.881\n",
            "Epoch 4/5, Batch Loss: 0.13261018693447113, Average Training Loss: 0.34008086821626105, Training Accuracy: 0.8819444444444444\n",
            "Epoch 4/5, Batch Loss: 0.37118372321128845, Average Training Loss: 0.3403257725863006, Training Accuracy: 0.8818897637795275\n",
            "Epoch 4/5, Batch Loss: 0.3709687292575836, Average Training Loss: 0.340565170685295, Training Accuracy: 0.88134765625\n",
            "Epoch 4/5, Batch Loss: 0.39596620202064514, Average Training Loss: 0.34099463604448377, Training Accuracy: 0.8812984496124031\n",
            "Epoch 4/5, Batch Loss: 0.3489522337913513, Average Training Loss: 0.3410558483348443, Training Accuracy: 0.8817307692307692\n",
            "Epoch 4/5, Batch Loss: 0.17768727242946625, Average Training Loss: 0.3398087599691544, Training Accuracy: 0.8826335877862596\n",
            "Epoch 4/5, Batch Loss: 0.3575286567211151, Average Training Loss: 0.3399430016112147, Training Accuracy: 0.8825757575757576\n",
            "Epoch 4/5, Batch Loss: 0.16492421925067902, Average Training Loss: 0.34086963430032935, Training Accuracy: 0.8826868495742668\n",
            "Epoch 4/5, Average Training Loss: 0.3386270709167746, Training Accuracy: 0.8826868495742668\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.89      0.89      0.89       427\n",
            "                Educational Opportunity       0.78      0.82      0.80       451\n",
            "                         Family Support       0.96      0.98      0.97       396\n",
            "                      Financial Support       0.91      0.92      0.91       404\n",
            "                 Program Implementation       0.90      0.81      0.85       436\n",
            "\n",
            "                               accuracy                           0.88      2114\n",
            "                              macro avg       0.89      0.89      0.89      2114\n",
            "                           weighted avg       0.88      0.88      0.88      2114\n",
            "\n",
            "Epoch 4/5, Validation Loss: 26.403196416795254, Validation Accuracy: 0.7353497164461248\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.66      0.67       113\n",
            "                Educational Opportunity       0.54      0.61      0.58       100\n",
            "                         Family Support       0.92      0.96      0.94       105\n",
            "                      Financial Support       0.76      0.75      0.76        97\n",
            "                 Program Implementation       0.80      0.69      0.74       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.74      0.74      0.74       529\n",
            "                           weighted avg       0.74      0.74      0.74       529\n",
            "\n",
            "Epoch 5/5, Batch Loss: 0.2846923768520355, Average Training Loss: 0.2846923768520355, Training Accuracy: 0.9375\n",
            "Epoch 5/5, Batch Loss: 0.2724980413913727, Average Training Loss: 0.2785952091217041, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.30038097500801086, Average Training Loss: 0.28585713108380634, Training Accuracy: 0.8958333333333334\n",
            "Epoch 5/5, Batch Loss: 0.3878611624240875, Average Training Loss: 0.31135813891887665, Training Accuracy: 0.890625\n",
            "Epoch 5/5, Batch Loss: 0.12337438762187958, Average Training Loss: 0.27376138865947724, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.2869460880756378, Average Training Loss: 0.2759588385621707, Training Accuracy: 0.8958333333333334\n",
            "Epoch 5/5, Batch Loss: 0.267580509185791, Average Training Loss: 0.274761934365545, Training Accuracy: 0.9017857142857143\n",
            "Epoch 5/5, Batch Loss: 0.4666289985179901, Average Training Loss: 0.29874531738460064, Training Accuracy: 0.890625\n",
            "Epoch 5/5, Batch Loss: 0.5153182148933411, Average Training Loss: 0.32280897266334957, Training Accuracy: 0.8888888888888888\n",
            "Epoch 5/5, Batch Loss: 0.1286356896162033, Average Training Loss: 0.30339164435863497, Training Accuracy: 0.9\n",
            "Epoch 5/5, Batch Loss: 0.24507731199264526, Average Training Loss: 0.2980903414162723, Training Accuracy: 0.9034090909090909\n",
            "Epoch 5/5, Batch Loss: 0.10436117649078369, Average Training Loss: 0.2819462443391482, Training Accuracy: 0.9114583333333334\n",
            "Epoch 5/5, Batch Loss: 0.1844315230846405, Average Training Loss: 0.2744451119349553, Training Accuracy: 0.9134615384615384\n",
            "Epoch 5/5, Batch Loss: 0.47909635305404663, Average Training Loss: 0.2890630577291761, Training Accuracy: 0.9107142857142857\n",
            "Epoch 5/5, Batch Loss: 0.23752643167972565, Average Training Loss: 0.2856272826592127, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.31746208667755127, Average Training Loss: 0.2876169579103589, Training Accuracy: 0.9140625\n",
            "Epoch 5/5, Batch Loss: 0.4166422188282013, Average Training Loss: 0.2952066791408202, Training Accuracy: 0.9080882352941176\n",
            "Epoch 5/5, Batch Loss: 0.22114087641239166, Average Training Loss: 0.2910919123225742, Training Accuracy: 0.9097222222222222\n",
            "Epoch 5/5, Batch Loss: 0.6141272187232971, Average Training Loss: 0.3080937705541912, Training Accuracy: 0.9046052631578947\n",
            "Epoch 5/5, Batch Loss: 0.3526545763015747, Average Training Loss: 0.31032181084156035, Training Accuracy: 0.903125\n",
            "Epoch 5/5, Batch Loss: 0.437056303024292, Average Training Loss: 0.31635678665978567, Training Accuracy: 0.9047619047619048\n",
            "Epoch 5/5, Batch Loss: 0.31958600878715515, Average Training Loss: 0.316503569483757, Training Accuracy: 0.9034090909090909\n",
            "Epoch 5/5, Batch Loss: 0.34208086133003235, Average Training Loss: 0.3176156256509864, Training Accuracy: 0.9021739130434783\n",
            "Epoch 5/5, Batch Loss: 0.2930602729320526, Average Training Loss: 0.3165924859543641, Training Accuracy: 0.9036458333333334\n",
            "Epoch 5/5, Batch Loss: 0.24090434610843658, Average Training Loss: 0.31356496036052706, Training Accuracy: 0.905\n",
            "Epoch 5/5, Batch Loss: 0.17856626212596893, Average Training Loss: 0.30837270273612094, Training Accuracy: 0.90625\n",
            "Epoch 5/5, Batch Loss: 0.17931148409843445, Average Training Loss: 0.3035926576013918, Training Accuracy: 0.9074074074074074\n",
            "Epoch 5/5, Batch Loss: 0.2622185945510864, Average Training Loss: 0.3021150124924524, Training Accuracy: 0.9084821428571429\n",
            "Epoch 5/5, Batch Loss: 0.10292398184537888, Average Training Loss: 0.2952463562632429, Training Accuracy: 0.9116379310344828\n",
            "Epoch 5/5, Batch Loss: 0.11669380217790604, Average Training Loss: 0.28929460446039834, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.21257449686527252, Average Training Loss: 0.2868197622799104, Training Accuracy: 0.9133064516129032\n",
            "Epoch 5/5, Batch Loss: 0.3811055123806, Average Training Loss: 0.289766191970557, Training Accuracy: 0.91015625\n",
            "Epoch 5/5, Batch Loss: 0.19102777540683746, Average Training Loss: 0.28677411874135333, Training Accuracy: 0.9109848484848485\n",
            "Epoch 5/5, Batch Loss: 0.5911530256271362, Average Training Loss: 0.2957264395321117, Training Accuracy: 0.9080882352941176\n",
            "Epoch 5/5, Batch Loss: 0.2572784721851349, Average Training Loss: 0.2946279261793409, Training Accuracy: 0.9089285714285714\n",
            "Epoch 5/5, Batch Loss: 0.18443672358989716, Average Training Loss: 0.29156705944074524, Training Accuracy: 0.9097222222222222\n",
            "Epoch 5/5, Batch Loss: 0.29367661476135254, Average Training Loss: 0.2916240744494103, Training Accuracy: 0.9087837837837838\n",
            "Epoch 5/5, Batch Loss: 0.07679174095392227, Average Training Loss: 0.2859705919890027, Training Accuracy: 0.9111842105263158\n",
            "Epoch 5/5, Batch Loss: 0.5969951748847961, Average Training Loss: 0.2939455812940231, Training Accuracy: 0.9086538461538461\n",
            "Epoch 5/5, Batch Loss: 0.20939098298549652, Average Training Loss: 0.2918317163363099, Training Accuracy: 0.9078125\n",
            "Epoch 5/5, Batch Loss: 0.13163286447525024, Average Training Loss: 0.28792442726652795, Training Accuracy: 0.9085365853658537\n",
            "Epoch 5/5, Batch Loss: 0.25426605343818665, Average Training Loss: 0.2871230374134722, Training Accuracy: 0.9077380952380952\n",
            "Epoch 5/5, Batch Loss: 0.16903600096702576, Average Training Loss: 0.28437682726355484, Training Accuracy: 0.9084302325581395\n",
            "Epoch 5/5, Batch Loss: 0.26802611351013184, Average Training Loss: 0.2840052201327952, Training Accuracy: 0.9076704545454546\n",
            "Epoch 5/5, Batch Loss: 0.15824759006500244, Average Training Loss: 0.28121060613128873, Training Accuracy: 0.9097222222222222\n",
            "Epoch 5/5, Batch Loss: 0.515490710735321, Average Training Loss: 0.28630365188355034, Training Accuracy: 0.9089673913043478\n",
            "Epoch 5/5, Batch Loss: 0.1790483146905899, Average Training Loss: 0.28402162343263626, Training Accuracy: 0.9095744680851063\n",
            "Epoch 5/5, Batch Loss: 0.10329329967498779, Average Training Loss: 0.28025645002101857, Training Accuracy: 0.9114583333333334\n",
            "Epoch 5/5, Batch Loss: 0.3156130611896515, Average Training Loss: 0.280978013514256, Training Accuracy: 0.9107142857142857\n",
            "Epoch 5/5, Batch Loss: 0.34853434562683105, Average Training Loss: 0.2823291401565075, Training Accuracy: 0.91\n",
            "Epoch 5/5, Batch Loss: 0.17450624704360962, Average Training Loss: 0.28021496578174476, Training Accuracy: 0.9105392156862745\n",
            "Epoch 5/5, Batch Loss: 0.15348029136657715, Average Training Loss: 0.27777776050453, Training Accuracy: 0.9110576923076923\n",
            "Epoch 5/5, Batch Loss: 0.20327648520469666, Average Training Loss: 0.27637207606491054, Training Accuracy: 0.9115566037735849\n",
            "Epoch 5/5, Batch Loss: 0.42694926261901855, Average Training Loss: 0.2791605424825792, Training Accuracy: 0.9108796296296297\n",
            "Epoch 5/5, Batch Loss: 0.21953096985816956, Average Training Loss: 0.27807636843486266, Training Accuracy: 0.9113636363636364\n",
            "Epoch 5/5, Batch Loss: 0.1978215128183365, Average Training Loss: 0.276643246013139, Training Accuracy: 0.9118303571428571\n",
            "Epoch 5/5, Batch Loss: 0.1536531299352646, Average Training Loss: 0.27448552467843945, Training Accuracy: 0.9122807017543859\n",
            "Epoch 5/5, Batch Loss: 0.19096767902374268, Average Training Loss: 0.273045561822324, Training Accuracy: 0.9137931034482759\n",
            "Epoch 5/5, Batch Loss: 0.27362391352653503, Average Training Loss: 0.2730553643935818, Training Accuracy: 0.913135593220339\n",
            "Epoch 5/5, Batch Loss: 0.17828048765659332, Average Training Loss: 0.271475783114632, Training Accuracy: 0.9135416666666667\n",
            "Epoch 5/5, Batch Loss: 0.5879188179969788, Average Training Loss: 0.2766633738504081, Training Accuracy: 0.9118852459016393\n",
            "Epoch 5/5, Batch Loss: 0.26518943905830383, Average Training Loss: 0.2764783103860194, Training Accuracy: 0.9112903225806451\n",
            "Epoch 5/5, Batch Loss: 0.0902935266494751, Average Training Loss: 0.2735229963584552, Training Accuracy: 0.9126984126984127\n",
            "Epoch 5/5, Batch Loss: 0.29974061250686646, Average Training Loss: 0.2739326466107741, Training Accuracy: 0.912109375\n",
            "Epoch 5/5, Batch Loss: 0.1901116520166397, Average Training Loss: 0.2726430928477874, Training Accuracy: 0.9125\n",
            "Epoch 5/5, Batch Loss: 0.23383034765720367, Average Training Loss: 0.2720550209509604, Training Accuracy: 0.9119318181818182\n",
            "Epoch 5/5, Batch Loss: 0.14176756143569946, Average Training Loss: 0.2701104320029714, Training Accuracy: 0.9132462686567164\n",
            "Epoch 5/5, Batch Loss: 0.11135885864496231, Average Training Loss: 0.26777585004182425, Training Accuracy: 0.9145220588235294\n",
            "Epoch 5/5, Batch Loss: 0.15766362845897675, Average Training Loss: 0.2661800207435221, Training Accuracy: 0.9148550724637681\n",
            "Epoch 5/5, Batch Loss: 0.2900431752204895, Average Training Loss: 0.2665209229503359, Training Accuracy: 0.9142857142857143\n",
            "Epoch 5/5, Batch Loss: 0.22796684503555298, Average Training Loss: 0.26597790776843755, Training Accuracy: 0.914612676056338\n",
            "Epoch 5/5, Batch Loss: 0.11137315630912781, Average Training Loss: 0.26383061955372494, Training Accuracy: 0.9157986111111112\n",
            "Epoch 5/5, Batch Loss: 0.31409183144569397, Average Training Loss: 0.26451912930566973, Training Accuracy: 0.9152397260273972\n",
            "Epoch 5/5, Batch Loss: 0.2317487746477127, Average Training Loss: 0.26407628667515676, Training Accuracy: 0.9155405405405406\n",
            "Epoch 5/5, Batch Loss: 0.24112096428871155, Average Training Loss: 0.2637702157100042, Training Accuracy: 0.9158333333333334\n",
            "Epoch 5/5, Batch Loss: 0.22286877036094666, Average Training Loss: 0.26323203879751655, Training Accuracy: 0.9161184210526315\n",
            "Epoch 5/5, Batch Loss: 0.19386950135231018, Average Training Loss: 0.2623312266229035, Training Accuracy: 0.9163961038961039\n",
            "Epoch 5/5, Batch Loss: 0.15864297747612, Average Training Loss: 0.26100189009538066, Training Accuracy: 0.9174679487179487\n",
            "Epoch 5/5, Batch Loss: 0.1605065017938614, Average Training Loss: 0.2597297965725766, Training Accuracy: 0.9185126582278481\n",
            "Epoch 5/5, Batch Loss: 0.3817080557346344, Average Training Loss: 0.2612545248121023, Training Accuracy: 0.9171875\n",
            "Epoch 5/5, Batch Loss: 0.22376801073551178, Average Training Loss: 0.26079172834202097, Training Accuracy: 0.9174382716049383\n",
            "Epoch 5/5, Batch Loss: 0.3936658501625061, Average Training Loss: 0.26241214446178296, Training Accuracy: 0.9161585365853658\n",
            "Epoch 5/5, Batch Loss: 0.44600236415863037, Average Training Loss: 0.2646240748195763, Training Accuracy: 0.9149096385542169\n",
            "Epoch 5/5, Batch Loss: 0.5914894938468933, Average Training Loss: 0.26851532980799675, Training Accuracy: 0.9136904761904762\n",
            "Epoch 5/5, Batch Loss: 0.1001679077744484, Average Training Loss: 0.2665347719017197, Training Accuracy: 0.9147058823529411\n",
            "Epoch 5/5, Batch Loss: 0.16700580716133118, Average Training Loss: 0.26537745835822685, Training Accuracy: 0.9149709302325582\n",
            "Epoch 5/5, Batch Loss: 0.42875754833221436, Average Training Loss: 0.26725539042689334, Training Accuracy: 0.9145114942528736\n",
            "Epoch 5/5, Batch Loss: 0.17517177760601044, Average Training Loss: 0.266208985735747, Training Accuracy: 0.9147727272727273\n",
            "Epoch 5/5, Batch Loss: 0.4529576301574707, Average Training Loss: 0.26830728511127194, Training Accuracy: 0.913623595505618\n",
            "Epoch 5/5, Batch Loss: 0.2780805826187134, Average Training Loss: 0.2684158773057991, Training Accuracy: 0.9131944444444444\n",
            "Epoch 5/5, Batch Loss: 0.13926208019256592, Average Training Loss: 0.2669966048100492, Training Accuracy: 0.9134615384615384\n",
            "Epoch 5/5, Batch Loss: 0.27779990434646606, Average Training Loss: 0.26711403197892336, Training Accuracy: 0.9130434782608695\n",
            "Epoch 5/5, Batch Loss: 0.33636194467544556, Average Training Loss: 0.2678586331907139, Training Accuracy: 0.9133064516129032\n",
            "Epoch 5/5, Batch Loss: 0.11858595907688141, Average Training Loss: 0.26627062601929014, Training Accuracy: 0.9142287234042553\n",
            "Epoch 5/5, Batch Loss: 0.16781239211559296, Average Training Loss: 0.265234223557146, Training Accuracy: 0.9144736842105263\n",
            "Epoch 5/5, Batch Loss: 0.1384563446044922, Average Training Loss: 0.2639136206513892, Training Accuracy: 0.9153645833333334\n",
            "Epoch 5/5, Batch Loss: 0.2763495147228241, Average Training Loss: 0.2640418257449091, Training Accuracy: 0.9155927835051546\n",
            "Epoch 5/5, Batch Loss: 0.2600860595703125, Average Training Loss: 0.2640014607839438, Training Accuracy: 0.9151785714285714\n",
            "Epoch 5/5, Batch Loss: 0.21561264991760254, Average Training Loss: 0.26351268491660707, Training Accuracy: 0.9154040404040404\n",
            "Epoch 5/5, Batch Loss: 0.11663051694631577, Average Training Loss: 0.26204386323690415, Training Accuracy: 0.91625\n",
            "Epoch 5/5, Batch Loss: 0.1419522613286972, Average Training Loss: 0.26085483747543675, Training Accuracy: 0.9164603960396039\n",
            "Epoch 5/5, Batch Loss: 0.1438780575990677, Average Training Loss: 0.2597080063001782, Training Accuracy: 0.9172794117647058\n",
            "Epoch 5/5, Batch Loss: 0.32103803753852844, Average Training Loss: 0.26030344349666706, Training Accuracy: 0.9168689320388349\n",
            "Epoch 5/5, Batch Loss: 0.07003004848957062, Average Training Loss: 0.25847389162159884, Training Accuracy: 0.9176682692307693\n",
            "Epoch 5/5, Batch Loss: 0.09270051121711731, Average Training Loss: 0.25689509752250855, Training Accuracy: 0.9184523809523809\n",
            "Epoch 5/5, Batch Loss: 0.09066284447908401, Average Training Loss: 0.2553268687202121, Training Accuracy: 0.9192216981132075\n",
            "Epoch 5/5, Batch Loss: 0.43545445799827576, Average Training Loss: 0.25701030413402576, Training Accuracy: 0.919392523364486\n",
            "Epoch 5/5, Batch Loss: 0.1910649985074997, Average Training Loss: 0.2563996994522987, Training Accuracy: 0.9195601851851852\n",
            "Epoch 5/5, Batch Loss: 0.2179306000471115, Average Training Loss: 0.2560467719348199, Training Accuracy: 0.9197247706422018\n",
            "Epoch 5/5, Batch Loss: 0.1589314043521881, Average Training Loss: 0.255163904956796, Training Accuracy: 0.9198863636363637\n",
            "Epoch 5/5, Batch Loss: 0.2525307834148407, Average Training Loss: 0.25514018314110265, Training Accuracy: 0.920045045045045\n",
            "Epoch 5/5, Batch Loss: 0.15775437653064728, Average Training Loss: 0.25427066701065215, Training Accuracy: 0.9207589285714286\n",
            "Epoch 5/5, Batch Loss: 0.4956905245780945, Average Training Loss: 0.2564071259271782, Training Accuracy: 0.9198008849557522\n",
            "Epoch 5/5, Batch Loss: 0.08927595615386963, Average Training Loss: 0.25494106303442987, Training Accuracy: 0.9205043859649122\n",
            "Epoch 5/5, Batch Loss: 0.27049025893211365, Average Training Loss: 0.25507627343354017, Training Accuracy: 0.9206521739130434\n",
            "Epoch 5/5, Batch Loss: 0.22080188989639282, Average Training Loss: 0.25478080460994407, Training Accuracy: 0.9207974137931034\n",
            "Epoch 5/5, Batch Loss: 0.1764380782842636, Average Training Loss: 0.25411120865844256, Training Accuracy: 0.9209401709401709\n",
            "Epoch 5/5, Batch Loss: 0.1563197821378708, Average Training Loss: 0.2532824677557258, Training Accuracy: 0.9216101694915254\n",
            "Epoch 5/5, Batch Loss: 0.20288023352622986, Average Training Loss: 0.25285891956892337, Training Accuracy: 0.9222689075630253\n",
            "Epoch 5/5, Batch Loss: 0.16321444511413574, Average Training Loss: 0.2521118822818001, Training Accuracy: 0.9229166666666667\n",
            "Epoch 5/5, Batch Loss: 0.16631518304347992, Average Training Loss: 0.25140281865173136, Training Accuracy: 0.9235537190082644\n",
            "Epoch 5/5, Batch Loss: 0.10457611083984375, Average Training Loss: 0.2501993210467159, Training Accuracy: 0.9241803278688525\n",
            "Epoch 5/5, Batch Loss: 0.19226108491420746, Average Training Loss: 0.2497282784765329, Training Accuracy: 0.9242886178861789\n",
            "Epoch 5/5, Batch Loss: 0.12080472707748413, Average Training Loss: 0.24868857241686312, Training Accuracy: 0.9248991935483871\n",
            "Epoch 5/5, Batch Loss: 0.08185926824808121, Average Training Loss: 0.24735393798351288, Training Accuracy: 0.9255\n",
            "Epoch 5/5, Batch Loss: 0.13600416481494904, Average Training Loss: 0.24647020962503222, Training Accuracy: 0.9255952380952381\n",
            "Epoch 5/5, Batch Loss: 0.15152838826179504, Average Training Loss: 0.2457226362284713, Training Accuracy: 0.9261811023622047\n",
            "Epoch 5/5, Batch Loss: 0.22766247391700745, Average Training Loss: 0.24558154121041298, Training Accuracy: 0.92626953125\n",
            "Epoch 5/5, Batch Loss: 0.2716521918773651, Average Training Loss: 0.24578363927759866, Training Accuracy: 0.9263565891472868\n",
            "Epoch 5/5, Batch Loss: 0.0999809056520462, Average Training Loss: 0.24466207978817134, Training Accuracy: 0.926923076923077\n",
            "Epoch 5/5, Batch Loss: 0.48194652795791626, Average Training Loss: 0.24647341145358923, Training Accuracy: 0.9270038167938931\n",
            "Epoch 5/5, Batch Loss: 0.14327649772167206, Average Training Loss: 0.24569161665258984, Training Accuracy: 0.9275568181818182\n",
            "Epoch 5/5, Batch Loss: 0.04649724066257477, Average Training Loss: 0.24581109281971192, Training Accuracy: 0.9276253547776726\n",
            "Epoch 5/5, Average Training Loss: 0.24419391457747697, Training Accuracy: 0.9276253547776726\n",
            "Training Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.94      0.94      0.94       427\n",
            "                Educational Opportunity       0.85      0.89      0.87       451\n",
            "                         Family Support       0.98      0.99      0.98       396\n",
            "                      Financial Support       0.95      0.97      0.96       404\n",
            "                 Program Implementation       0.92      0.86      0.89       436\n",
            "\n",
            "                               accuracy                           0.93      2114\n",
            "                              macro avg       0.93      0.93      0.93      2114\n",
            "                           weighted avg       0.93      0.93      0.93      2114\n",
            "\n",
            "Epoch 5/5, Validation Loss: 27.241883624345064, Validation Accuracy: 0.7391304347826086\n",
            "Validation Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "Academic Focus and Personal Development       0.67      0.67      0.67       113\n",
            "                Educational Opportunity       0.56      0.62      0.59       100\n",
            "                         Family Support       0.91      0.97      0.94       105\n",
            "                      Financial Support       0.74      0.77      0.76        97\n",
            "                 Program Implementation       0.83      0.67      0.74       114\n",
            "\n",
            "                               accuracy                           0.74       529\n",
            "                              macro avg       0.74      0.74      0.74       529\n",
            "                           weighted avg       0.74      0.74      0.74       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - BatchSize-16, Epoch-1, Learning Rate-1e-5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from bs4 import BeautifulSoup  # For removing HTML tags\n",
        "from contractions import contractions_dict  # You may need to install the contractions library\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')  # Add this line to download the 'punkt' resource\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/drive/MyDrive/Dissertation_UC/UAQTE_Experience_Multi_Class_TC_Datasets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    text = ' '.join([contractions_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "    # Remove irrelevant characters, symbols, and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization and lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove short words\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "df['Processed_Response'] = df['Responses'].apply(preprocess_text)\n",
        "\n",
        "# Print 10 preprocessed responses\n",
        "print(df['Processed_Response'].head(10))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded_Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_text(df, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in df['Processed_Response']:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt',\n",
        "                            truncation=True\n",
        "                       )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_inputs, train_masks = tokenize_text(train_df)\n",
        "val_inputs, val_masks = tokenize_text(val_df)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['Encoded_Label'].values)\n",
        "val_labels = torch.tensor(val_df['Encoded_Label'].values)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Fine-tune BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Add optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_preds_train = []\n",
        "    all_labels_train = []\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "\n",
        "        correct_predictions += np.sum(preds == labels.numpy())\n",
        "        total_samples += len(labels)\n",
        "\n",
        "        all_preds_train.extend(preds.tolist())\n",
        "        all_labels_train.extend(labels.numpy().tolist())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print average training loss and accuracy for the batch\n",
        "        avg_train_loss = total_loss / (total_samples / batch_size)\n",
        "        train_accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Batch Loss: {loss.item()}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Calculate average training loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
        "\n",
        "    # Training classification report\n",
        "    train_classification_report = classification_report(all_labels_train, all_preds_train, target_names=label_encoder.classes_)\n",
        "    print('Training Classification Report:')\n",
        "    print(train_classification_report)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        inputs, masks, labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = np.argmax(logits.detach().numpy(), axis=1)\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate validation accuracy and other metrics\n",
        "    val_accuracy = accuracy_score(true_labels, predictions)\n",
        "    val_classification_report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "    print('Validation Classification Report:')\n",
        "    print(val_classification_report)\n"
      ],
      "metadata": {
        "id": "p6cr3MpjCiNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}